{"path":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","commits":[{"id":"7b13106276bb5ea342253dbf6aae7b675adb38d3","date":1428054414,"type":1,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(SolrCore,boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    \n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = Paths.get(solrCore.getDataDir(), tmpIdxDirName).toString();\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param core the SolrCore\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n   boolean fetchLatestIndex(final SolrCore core, boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex = null;\n    Directory indexDir = null;\n    String indexDirPath = null;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!core.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response = null;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = core.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = core.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = core.getUpdateHandler().getSolrCoreState().getIndexWriter(core);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(core,\n              new ModifiableSolrParams());\n          core.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if(filesToDownload.isEmpty()) return false;\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = createTempindexDir(core, tmpIdxDirName);\n\n      tmpIndexDir = core.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = core.getIndexDir();\n      indexDir = core.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(core, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  core.getDirectoryFactory().doneWithDirectory(indexDir);\n                  core.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(core);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", core.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              core.getDirectoryFactory().doneWithDirectory(indexDir);\n              core.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(core, true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c","date":1428091986,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(SolrCore,boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    \n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = Paths.get(solrCore.getDataDir(), tmpIdxDirName).toString();\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param core the SolrCore\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n   boolean fetchLatestIndex(final SolrCore core, boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex = null;\n    Directory indexDir = null;\n    String indexDirPath = null;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!core.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response = null;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = core.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = core.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = core.getUpdateHandler().getSolrCoreState().getIndexWriter(core);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(core,\n              new ModifiableSolrParams());\n          core.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if(filesToDownload.isEmpty()) return false;\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = createTempindexDir(core, tmpIdxDirName);\n\n      tmpIndexDir = core.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = core.getIndexDir();\n      indexDir = core.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, core.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(core, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  core.getDirectoryFactory().doneWithDirectory(indexDir);\n                  core.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(core);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", core.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              core.getDirectoryFactory().doneWithDirectory(indexDir);\n              core.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(core, true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(core, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c42316df77794f7252857e7d5e9ce45ff1d65c61","date":1428666763,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    \n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    \n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = Paths.get(solrCore.getDataDir(), tmpIdxDirName).toString();\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cb5af3afeddbb803fb785098176e6e177c34261b","date":1428905393,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    \n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    \n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = Executors.newSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"86290366cefc1b9d4eced13b430858c4a4c0421d","date":1432321109,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n\n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            downloadTlogFiles(timestamp, latestGeneration);\n          }\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases \n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n    \n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    \n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n    \n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n        \n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n      \n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String tmpIdxDirName = \"index.\" + new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n      \n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n        \n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n        \n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n          \n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n              \n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n        \n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n          \n          openNewSearcherAndUpdateCommitPoint();\n        }\n        \n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n        \n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bcf9886c8ff537aafde14de48ebf744f5673f08b","date":1439041198,"type":3,"author":"Ramkumar Aiyengar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n\n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            downloadTlogFiles(timestamp, latestGeneration);\n          }\n          LOG.info(\"Total time taken for download: {} secs\", getReplicationTimeElapsed());\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    replicationStartTime = System.currentTimeMillis();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n\n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            downloadTlogFiles(timestamp, latestGeneration);\n          }\n          LOG.info(\"Total time taken for download : \"\n              + ((System.currentTimeMillis() - replicationStartTime) / 1000)\n              + \" secs\");\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        replicationStartTime = 0;\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6ad16d9bdc03ec6adfd5d4b7b6ea14b256ce3998","date":1445881418,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(timestamp, latestGeneration);\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download to \" + tmpIndexDir + \" fullCopy=\"\n              + isFullCopyNeeded);\n          successfulInstall = false;\n\n          downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            downloadTlogFiles(timestamp, latestGeneration);\n          }\n          LOG.info(\"Total time taken for download: {} secs\", getReplicationTimeElapsed());\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e586ff50ac71d5ef3a27ced78f69deb41ab35ad5","date":1446841099,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(timestamp, latestGeneration);\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n          LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"91e2345fb81b6c1c7faefa550ee5eaafadc54486","date":1469730189,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n\n                  SolrSnapshotMetaDataManager snapshotsMgr = solrCore.getSnapshotMetaDataManager();\n                  Collection<SnapshotMetaData> snapshots = snapshotsMgr.listSnapshotsInIndexDir(indexDirPath);\n\n                  // Delete the old index directory only if no snapshot exists in that directory.\n                  if(snapshots.isEmpty()) {\n                    LOG.info(\"removing old index directory \" + indexDir);\n                    solrCore.getDirectoryFactory().remove(indexDir);\n                  } else {\n                    SolrSnapshotManager.deleteNonSnapshotIndexFiles(indexDir, snapshots);\n                  }\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3b013574eedcdbac35dc7e35b0ee616ffc38895d","date":1470897818,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n\n                  SolrSnapshotMetaDataManager snapshotsMgr = solrCore.getSnapshotMetaDataManager();\n                  Collection<SnapshotMetaData> snapshots = snapshotsMgr.listSnapshotsInIndexDir(indexDirPath);\n\n                  // Delete the old index directory only if no snapshot exists in that directory.\n                  if(snapshots.isEmpty()) {\n                    LOG.info(\"removing old index directory \" + indexDir);\n                    solrCore.getDirectoryFactory().remove(indexDir);\n                  } else {\n                    SolrSnapshotManager.deleteNonSnapshotIndexFiles(indexDir, snapshots);\n                  }\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"138bba875d696cd48f61b681050026222022e937","date":1473262610,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n\n                  SolrSnapshotMetaDataManager snapshotsMgr = solrCore.getSnapshotMetaDataManager();\n                  Collection<SnapshotMetaData> snapshots = snapshotsMgr.listSnapshotsInIndexDir(indexDirPath);\n\n                  // Delete the old index directory only if no snapshot exists in that directory.\n                  if(snapshots.isEmpty()) {\n                    LOG.info(\"removing old index directory \" + indexDir);\n                    solrCore.getDirectoryFactory().remove(indexDir);\n                  } else {\n                    SolrSnapshotManager.deleteNonSnapshotIndexFiles(indexDir, snapshots);\n                  }\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n\n                  SolrSnapshotMetaDataManager snapshotsMgr = solrCore.getSnapshotMetaDataManager();\n                  Collection<SnapshotMetaData> snapshots = snapshotsMgr.listSnapshotsInIndexDir(indexDirPath);\n\n                  // Delete the old index directory only if no snapshot exists in that directory.\n                  if(snapshots.isEmpty()) {\n                    LOG.info(\"removing old index directory \" + indexDir);\n                    solrCore.getDirectoryFactory().remove(indexDir);\n                  } else {\n                    SolrSnapshotManager.deleteNonSnapshotIndexFiles(indexDir, snapshots);\n                  }\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"89424def13674ea17829b41c5883c54ecc31a132","date":1473767373,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n\n                  SolrSnapshotMetaDataManager snapshotsMgr = solrCore.getSnapshotMetaDataManager();\n                  Collection<SnapshotMetaData> snapshots = snapshotsMgr.listSnapshotsInIndexDir(indexDirPath);\n\n                  // Delete the old index directory only if no snapshot exists in that directory.\n                  if(snapshots.isEmpty()) {\n                    LOG.info(\"removing old index directory \" + indexDir);\n                    solrCore.getDirectoryFactory().remove(indexDir);\n                  } else {\n                    SolrSnapshotManager.deleteNonSnapshotIndexFiles(indexDir, snapshots);\n                  }\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n\n                  SolrSnapshotMetaDataManager snapshotsMgr = solrCore.getSnapshotMetaDataManager();\n                  Collection<SnapshotMetaData> snapshots = snapshotsMgr.listSnapshotsInIndexDir(indexDirPath);\n\n                  // Delete the old index directory only if no snapshot exists in that directory.\n                  if(snapshots.isEmpty()) {\n                    LOG.info(\"removing old index directory \" + indexDir);\n                    solrCore.getDirectoryFactory().remove(indexDir);\n                  } else {\n                    SolrSnapshotManager.deleteNonSnapshotIndexFiles(indexDir, snapshots);\n                  }\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n\n                  SolrSnapshotMetaDataManager snapshotsMgr = solrCore.getSnapshotMetaDataManager();\n                  Collection<SnapshotMetaData> snapshots = snapshotsMgr.listSnapshotsInIndexDir(indexDirPath);\n\n                  // Delete the old index directory only if no snapshot exists in that directory.\n                  if(snapshots.isEmpty()) {\n                    LOG.info(\"removing old index directory \" + indexDir);\n                    solrCore.getDirectoryFactory().remove(indexDir);\n                  } else {\n                    SolrSnapshotManager.deleteNonSnapshotIndexFiles(indexDir, snapshots);\n                  }\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n\n                  SolrSnapshotMetaDataManager snapshotsMgr = solrCore.getSnapshotMetaDataManager();\n                  Collection<SnapshotMetaData> snapshots = snapshotsMgr.listSnapshotsInIndexDir(indexDirPath);\n\n                  // Delete the old index directory only if no snapshot exists in that directory.\n                  if(snapshots.isEmpty()) {\n                    LOG.info(\"removing old index directory \" + indexDir);\n                    solrCore.getDirectoryFactory().remove(indexDir);\n                  } else {\n                    SolrSnapshotManager.deleteNonSnapshotIndexFiles(indexDir, snapshots);\n                  }\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c973f931d0c400a36bbdeacce57000dd3cf0e0d0","date":1475767890,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n\n                  SolrSnapshotMetaDataManager snapshotsMgr = solrCore.getSnapshotMetaDataManager();\n                  Collection<SnapshotMetaData> snapshots = snapshotsMgr.listSnapshotsInIndexDir(indexDirPath);\n\n                  // Delete the old index directory only if no snapshot exists in that directory.\n                  if(snapshots.isEmpty()) {\n                    LOG.info(\"removing old index directory \" + indexDir);\n                    solrCore.getDirectoryFactory().remove(indexDir);\n                  } else {\n                    SolrSnapshotManager.deleteNonSnapshotIndexFiles(indexDir, snapshots);\n                  }\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n\n                  SolrSnapshotMetaDataManager snapshotsMgr = solrCore.getSnapshotMetaDataManager();\n                  Collection<SnapshotMetaData> snapshots = snapshotsMgr.listSnapshotsInIndexDir(indexDirPath);\n\n                  // Delete the old index directory only if no snapshot exists in that directory.\n                  if(snapshots.isEmpty()) {\n                    LOG.info(\"removing old index directory \" + indexDir);\n                    solrCore.getDirectoryFactory().remove(indexDir);\n                  } else {\n                    SolrSnapshotManager.deleteNonSnapshotIndexFiles(indexDir, snapshots);\n                  }\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3e13696c44d3e2405098726359ab81dab178e7bc","date":1476726926,"type":3,"author":"Hrishikesh Gadre","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n\n                  SolrSnapshotMetaDataManager snapshotsMgr = solrCore.getSnapshotMetaDataManager();\n                  Collection<SnapshotMetaData> snapshots = snapshotsMgr.listSnapshotsInIndexDir(indexDirPath);\n\n                  // Delete the old index directory only if no snapshot exists in that directory.\n                  if(snapshots.isEmpty()) {\n                    LOG.info(\"removing old index directory \" + indexDir);\n                    solrCore.getDirectoryFactory().remove(indexDir);\n                  } else {\n                    SolrSnapshotManager.deleteNonSnapshotIndexFiles(indexDir, snapshots);\n                  }\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n          solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n        }\n        boolean reloadCore = false;\n\n        try {\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  LOG.info(\"removing old index directory \" + indexDir);\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  solrCore.getDirectoryFactory().remove(indexDir);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b39b1b02e442aaf736cc87417e93552cbd8ef1da","date":1484786722,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":["7b13106276bb5ea342253dbf6aae7b675adb38d3"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"90a682dc1bfd188ef61cc28373c7f5d700b4ac75","date":1485186128,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = IndexFetcher.modifyIndexProps(solrCore, tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad28156288ac00b91352582904d97e6653205757","date":1486850922,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":["6c94d2661bc1c14426980ec7882e951fdcff08d0"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"be320990bdc77e643388fa801e75017f19289c42","date":1489477067,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      if (fetchFromLeader) {\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return false;\n        }\n        masterUrl = replica.getCoreUrl();\n        LOG.info(\"Updated masterUrl to \" + masterUrl);\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f996f8177b9204bdc92f7164460c6cefad9ac99a","date":1489482690,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      if (fetchFromLeader) {\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return false;\n        }\n        masterUrl = replica.getCoreUrl();\n        LOG.info(\"Updated masterUrl to \" + masterUrl);\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ab68488225b6a6c357dda72ed11dedca9914a192","date":1490013111,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      if (fetchFromLeader) {\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return false;\n        }\n        masterUrl = replica.getCoreUrl();\n        LOG.info(\"Updated masterUrl to \" + masterUrl);\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7c641347aa34a81b8c172fd46691e3cba6357a6f","date":1490409984,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      if (fetchFromLeader) {\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        masterUrl = replica.getCoreUrl();\n        LOG.info(\"Updated masterUrl to \" + masterUrl);\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      if (fetchFromLeader) {\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return false;\n        }\n        masterUrl = replica.getCoreUrl();\n        LOG.info(\"Updated masterUrl to \" + masterUrl);\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d5f6959c652bdf332fe98fc9180b54095a4053ae","date":1490594650,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      if (fetchFromLeader) {\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        masterUrl = replica.getCoreUrl();\n        LOG.info(\"Updated masterUrl to \" + masterUrl);\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  boolean fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      if (fetchFromLeader) {\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return false;\n        }\n        masterUrl = replica.getCoreUrl();\n        LOG.info(\"Updated masterUrl to \" + masterUrl);\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        LOG.error(\"Master at: \" + masterUrl + \" is not available. Index fetch failed. Exception: \" + e.getMessage());\n        return false;\n      }\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return false;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return true;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return true;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return false;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore);\n        }\n\n        markReplicationStop();\n        return successfulInstall;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return false;\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"729cb470f975115d4c60517b2cb7c42e37a7a2e1","date":1492041760,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      if (fetchFromLeader) {\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        masterUrl = replica.getCoreUrl();\n        LOG.info(\"Updated masterUrl to \" + masterUrl);\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      if (fetchFromLeader) {\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        masterUrl = replica.getCoreUrl();\n        LOG.info(\"Updated masterUrl to \" + masterUrl);\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"54ca69905c5d9d1529286f06ab1d12c68f6c13cb","date":1492683554,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      if (fetchFromLeader) {\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        masterUrl = replica.getCoreUrl();\n        LOG.info(\"Updated masterUrl to \" + masterUrl);\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      if (fetchFromLeader) {\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        masterUrl = replica.getCoreUrl();\n        LOG.info(\"Updated masterUrl to \" + masterUrl);\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreDescriptor().getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"61c45e99cf6676da48f19d7511c73712ad39402b","date":1495508331,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      LOG.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          LOG.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          LOG.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          LOG.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          LOG.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          LOG.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        LOG.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      if (fetchFromLeader) {\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        masterUrl = replica.getCoreUrl();\n        LOG.info(\"Updated masterUrl to \" + masterUrl);\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      LOG.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          LOG.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          LOG.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          LOG.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          LOG.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          LOG.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        LOG.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n    }\n\n    try {\n      if (fetchFromLeader) {\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        masterUrl = replica.getCoreUrl();\n        LOG.info(\"Updated masterUrl to \" + masterUrl);\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04ecf884544ff74add5faa452748f160c4af904b","date":1506527215,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      LOG.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          LOG.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          LOG.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          LOG.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          LOG.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          LOG.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        LOG.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      LOG.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          LOG.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          LOG.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          LOG.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          LOG.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          LOG.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        LOG.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":["6c94d2661bc1c14426980ec7882e951fdcff08d0","7b13106276bb5ea342253dbf6aae7b675adb38d3"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6240b74b884c5587f2a4062dd27d6c32bf228889","date":1507037235,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      LOG.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          LOG.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          LOG.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          LOG.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          LOG.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          LOG.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        LOG.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      LOG.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          LOG.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          LOG.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          LOG.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          LOG.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (forceReplication && commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          LOG.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n          solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        LOG.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"98fea9928eee12529633d73f52989154dd3dea1f","date":1521122475,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      LOG.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          LOG.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          LOG.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          LOG.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          LOG.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          LOG.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        LOG.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndex;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      LOG.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          LOG.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          LOG.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          LOG.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          LOG.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          LOG.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        LOG.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndex = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndex, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        //We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        //in the metadata. If there is a mismatch for the same index file then we download the entire index again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir, tmpIndexDir, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"436eff77c0517cdabffce79a0738ab69d524d9fb","date":1522590443,"type":3,"author":"Mikhail Khludnev","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      LOG.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          LOG.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          LOG.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          LOG.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          LOG.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          LOG.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeSlaveCommitRefresh();\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        LOG.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      LOG.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          LOG.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          LOG.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          LOG.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          LOG.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          LOG.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        LOG.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6a269c1ddba3f8c9fa9a40572ecc538eddda41a","date":1528054850,"type":3,"author":"Michael Braun","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      LOG.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          LOG.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          LOG.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          LOG.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          LOG.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          LOG.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeSlaveCommitRefresh();\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        LOG.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      LOG.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          LOG.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          LOG.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          LOG.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          LOG.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          LOG.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeSlaveCommitRefresh();\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        LOG.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"628903f37b6c442da0d390db1c6af9a0e74d41a7","date":1531736685,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      LOG.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          LOG.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          LOG.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          LOG.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          LOG.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          LOG.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeSlaveCommitRefresh();\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        LOG.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      LOG.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          LOG.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          LOG.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          LOG.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          LOG.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          LOG.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeSlaveCommitRefresh();\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        LOG.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      LOG.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          LOG.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          LOG.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          LOG.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          LOG.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          LOG.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeSlaveCommitRefresh();\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        LOG.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      LOG.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          LOG.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          LOG.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          LOG.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          LOG.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          LOG.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeSlaveCommitRefresh();\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        LOG.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? new Long(bytesDownloaded/timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9c81f7e703d7ccca5bc78beb61253f0a8a22afd","date":1534976797,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      log.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          log.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          log.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          log.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          log.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            log.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            log.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      log.info(\"Master's generation: \" + latestGeneration);\n      log.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            log.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      log.info(\"Slave's generation: \" + commit.getGeneration());\n      log.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          log.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeSlaveCommitRefresh();\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        log.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        log.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      log.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      log.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        log.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              log.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                log.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              log.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          log.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          log.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              log.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         log.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              log.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          log.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        log.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      LOG.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          LOG.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          LOG.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          LOG.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          LOG.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            LOG.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      LOG.info(\"Master's generation: \" + latestGeneration);\n      LOG.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            LOG.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      LOG.info(\"Slave's generation: \" + commit.getGeneration());\n      LOG.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          LOG.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeSlaveCommitRefresh();\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        LOG.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        LOG.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      LOG.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      LOG.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        LOG.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              LOG.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                LOG.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              LOG.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          LOG.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          LOG.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              LOG.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         LOG.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              LOG.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          LOG.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        LOG.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"81d505b8f51b856e1b7e9dd377f5050c337b797a","date":1549455307,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    this.clearLocalIndexFirst = false;\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      log.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          log.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          log.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          log.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          log.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            log.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            log.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      log.info(\"Master's generation: \" + latestGeneration);\n      log.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            log.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      log.info(\"Slave's generation: \" + commit.getGeneration());\n      log.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          log.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeSlaveCommitRefresh();\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        log.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        log.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      log.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      log.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        log.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              log.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                log.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              log.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          log.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          log.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  if (!this.clearLocalIndexFirst) {//it was closed earlier\n                    solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  }\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              log.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          solrCore.searchEnabled = true;\n          solrCore.indexEnabled = true;\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         log.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              log.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          log.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        log.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      log.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          log.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          log.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          log.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          log.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            log.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            log.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      log.info(\"Master's generation: \" + latestGeneration);\n      log.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            log.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      log.info(\"Slave's generation: \" + commit.getGeneration());\n      log.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          log.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeSlaveCommitRefresh();\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        log.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        log.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      log.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      log.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        log.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              log.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                log.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              log.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          log.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          log.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              log.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         log.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              log.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          log.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        log.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb03700c9690d16b15fb4f56f6ec36b128fd894e","date":1586745995,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    this.clearLocalIndexFirst = false;\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      log.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          log.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          log.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          log.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          log.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            log.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            log.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      log.info(\"Master's generation: \" + latestGeneration);\n      log.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            log.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      log.info(\"Slave's generation: \" + commit.getGeneration());\n      log.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          log.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeSlaveCommitRefresh();\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        log.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        log.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      log.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      log.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        log.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new SolrNamedThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              log.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                log.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              log.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          log.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          log.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  if (!this.clearLocalIndexFirst) {//it was closed earlier\n                    solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  }\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              log.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          solrCore.searchEnabled = true;\n          solrCore.indexEnabled = true;\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         log.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              log.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          log.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        log.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    this.clearLocalIndexFirst = false;\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      log.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          log.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          log.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          log.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          log.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            log.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            log.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      log.info(\"Master's generation: \" + latestGeneration);\n      log.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            log.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      log.info(\"Slave's generation: \" + commit.getGeneration());\n      log.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          log.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeSlaveCommitRefresh();\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        log.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        log.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      log.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      log.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        log.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new DefaultSolrThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              log.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                log.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              log.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          log.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          log.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  if (!this.clearLocalIndexFirst) {//it was closed earlier\n                    solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  }\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              log.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          solrCore.searchEnabled = true;\n          solrCore.indexEnabled = true;\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         log.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              log.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          log.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        log.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4","date":1588172214,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    this.clearLocalIndexFirst = false;\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      log.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          if (log.isInfoEnabled()) {\n            log.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          }\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          if (log.isInfoEnabled()) {\n            log.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          }\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          log.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          log.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            log.warn(\"Master at: {} is not available. Index fetch failed by interrupt. Exception: {}\", masterUrl, errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            log.warn(\"Master at: {} is not available. Index fetch failed by exception: {}\", masterUrl, errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      log.info(\"Master's generation: {}\", latestGeneration);\n      log.info(\"Master's version: {}\", latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            log.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      if (log.isInfoEnabled()) {\n        log.info(\"Slave's generation: {}\", commit.getGeneration());\n        log.info(\"Slave's version: {}\", IndexDeletionPolicyWrapper.getCommitTimestamp(commit)); // logOK\n      }\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          log.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeSlaveCommitRefresh();\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        log.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        log.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      log.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      if (log.isInfoEnabled()) {\n        log.info(\"Number of files in latest index in master: {}\", filesToDownload.size());\n      }\n      if (tlogFilesToDownload != null) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Number of tlog files in master: {}\", tlogFilesToDownload.size());\n        }\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new SolrNamedThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              log.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                log.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              log.info(\"IndexFetcher slept for {}ms for unused lucene index files to be delete-able\", c * 1000);\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          log.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          log.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  if (!this.clearLocalIndexFirst) {//it was closed earlier\n                    solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  }\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              log.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          solrCore.searchEnabled = true;\n          solrCore.indexEnabled = true;\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         if (log.isInfoEnabled()) {\n           log.info(\"Reloading SolrCore {}\", solrCore.getName());\n         }\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              log.info(\"removing old index directory {}\", indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          log.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        log.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    this.clearLocalIndexFirst = false;\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      log.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          log.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          log.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          log.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          log.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            log.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by interrupt. Exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            log.warn(\"Master at: \" + masterUrl + \" is not available. Index fetch failed by exception: \" + errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      log.info(\"Master's generation: \" + latestGeneration);\n      log.info(\"Master's version: \" + latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            log.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      log.info(\"Slave's generation: \" + commit.getGeneration());\n      log.info(\"Slave's version: \" + IndexDeletionPolicyWrapper.getCommitTimestamp(commit));\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          log.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeSlaveCommitRefresh();\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        log.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        log.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      log.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      log.info(\"Number of files in latest index in master: \" + filesToDownload.size());\n      if (tlogFilesToDownload != null) {\n        log.info(\"Number of tlog files in master: \" + tlogFilesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new SolrNamedThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              log.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                log.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              log.info(\"IndexFetcher slept for \" + (c * 1000) + \"ms for unused lucene index files to be delete-able\");\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          log.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          log.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  if (!this.clearLocalIndexFirst) {//it was closed earlier\n                    solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  }\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              log.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          solrCore.searchEnabled = true;\n          solrCore.indexEnabled = true;\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         log.info(\"Reloading SolrCore {}\", solrCore.getName());\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              log.info(\"removing old index directory \" + indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          log.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        log.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2caf6d6e842e1a4e4ae68ec6dfa5139c31a84ec5","date":1591384964,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    this.clearLocalIndexFirst = false;\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      log.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          if (log.isInfoEnabled()) {\n            log.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          }\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          if (log.isInfoEnabled()) {\n            log.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          }\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          log.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          log.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      @SuppressWarnings({\"rawtypes\"})\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            log.warn(\"Master at: {} is not available. Index fetch failed by interrupt. Exception: {}\", masterUrl, errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            log.warn(\"Master at: {} is not available. Index fetch failed by exception: {}\", masterUrl, errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      log.info(\"Master's generation: {}\", latestGeneration);\n      log.info(\"Master's version: {}\", latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            log.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      if (log.isInfoEnabled()) {\n        log.info(\"Slave's generation: {}\", commit.getGeneration());\n        log.info(\"Slave's version: {}\", IndexDeletionPolicyWrapper.getCommitTimestamp(commit)); // logOK\n      }\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          log.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeSlaveCommitRefresh();\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        log.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        log.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      log.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      if (log.isInfoEnabled()) {\n        log.info(\"Number of files in latest index in master: {}\", filesToDownload.size());\n      }\n      if (tlogFilesToDownload != null) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Number of tlog files in master: {}\", tlogFilesToDownload.size());\n        }\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new SolrNamedThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              log.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                log.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              log.info(\"IndexFetcher slept for {}ms for unused lucene index files to be delete-able\", c * 1000);\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          log.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          log.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  if (!this.clearLocalIndexFirst) {//it was closed earlier\n                    solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  }\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              log.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          solrCore.searchEnabled = true;\n          solrCore.indexEnabled = true;\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         if (log.isInfoEnabled()) {\n           log.info(\"Reloading SolrCore {}\", solrCore.getName());\n         }\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              log.info(\"removing old index directory {}\", indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          log.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        log.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    this.clearLocalIndexFirst = false;\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      log.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          if (log.isInfoEnabled()) {\n            log.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          }\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          if (log.isInfoEnabled()) {\n            log.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          }\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          log.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          log.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            log.warn(\"Master at: {} is not available. Index fetch failed by interrupt. Exception: {}\", masterUrl, errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            log.warn(\"Master at: {} is not available. Index fetch failed by exception: {}\", masterUrl, errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      log.info(\"Master's generation: {}\", latestGeneration);\n      log.info(\"Master's version: {}\", latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            log.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      if (log.isInfoEnabled()) {\n        log.info(\"Slave's generation: {}\", commit.getGeneration());\n        log.info(\"Slave's version: {}\", IndexDeletionPolicyWrapper.getCommitTimestamp(commit)); // logOK\n      }\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          log.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeSlaveCommitRefresh();\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        log.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        log.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      log.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      if (log.isInfoEnabled()) {\n        log.info(\"Number of files in latest index in master: {}\", filesToDownload.size());\n      }\n      if (tlogFilesToDownload != null) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Number of tlog files in master: {}\", tlogFilesToDownload.size());\n        }\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new SolrNamedThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              log.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                log.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              log.info(\"IndexFetcher slept for {}ms for unused lucene index files to be delete-able\", c * 1000);\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          log.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          log.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  if (!this.clearLocalIndexFirst) {//it was closed earlier\n                    solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  }\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              log.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          solrCore.searchEnabled = true;\n          solrCore.indexEnabled = true;\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         if (log.isInfoEnabled()) {\n           log.info(\"Reloading SolrCore {}\", solrCore.getName());\n         }\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              log.info(\"removing old index directory {}\", indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          log.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        log.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"65a5d87a40f9143cd55be76eb1dde1b32a8dae5e","date":1596664368,"type":3,"author":"Marcus","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from leader to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if follower is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    this.clearLocalIndexFirst = false;\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      log.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          if (log.isInfoEnabled()) {\n            log.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          }\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          if (log.isInfoEnabled()) {\n            log.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          }\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(leaderUrl)) {\n          leaderUrl = replica.getCoreUrl();\n          log.info(\"Updated leaderUrl to {}\", leaderUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          log.debug(\"leaderUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the leader\n      @SuppressWarnings({\"rawtypes\"})\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            log.warn(\"Leader at: {} is not available. Index fetch failed by interrupt. Exception: {}\", leaderUrl, errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            log.warn(\"Leader at: {} is not available. Index fetch failed by exception: {}\", leaderUrl, errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      log.info(\"Leader's generation: {}\", latestGeneration);\n      log.info(\"Leader's version: {}\", latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            log.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      if (log.isInfoEnabled()) {\n        log.info(\"Follower's generation: {}\", commit.getGeneration());\n        log.info(\"Follower's version: {}\", IndexDeletionPolicyWrapper.getCommitTimestamp(commit)); // logOK\n      }\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          log.info(\"New index in Leader. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeFollowerCommitRefresh();\n          if (skipCommitOnLeaderVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        log.debug(\"Nothing to replicate, leader's version is 0\");\n        return IndexFetchResult.LEADER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //leader and follower are already in sync just return\n        log.info(\"Follower in sync with leader.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      log.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      if (log.isInfoEnabled()) {\n        log.info(\"Number of files in latest index in leader: {}\", filesToDownload.size());\n      }\n      if (tlogFilesToDownload != null) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Number of tlog files in leader: {}\", tlogFilesToDownload.size());\n        }\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new SolrNamedThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of leader is older than that of the follower , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the leader vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              log.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                log.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              log.info(\"IndexFetcher slept for {}ms for unused lucene index files to be delete-able\", c * 1000);\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          log.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          log.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  if (!this.clearLocalIndexFirst) {//it was closed earlier\n                    solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  }\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              log.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          solrCore.searchEnabled = true;\n          solrCore.indexEnabled = true;\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         if (log.isInfoEnabled()) {\n           log.info(\"Reloading SolrCore {}\", solrCore.getName());\n         }\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              log.info(\"removing old index directory {}\", indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          log.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        log.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from master to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if slave is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    this.clearLocalIndexFirst = false;\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      log.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          if (log.isInfoEnabled()) {\n            log.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          }\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          if (log.isInfoEnabled()) {\n            log.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          }\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(masterUrl)) {\n          masterUrl = replica.getCoreUrl();\n          log.info(\"Updated masterUrl to {}\", masterUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          log.debug(\"masterUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the master\n      @SuppressWarnings({\"rawtypes\"})\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            log.warn(\"Master at: {} is not available. Index fetch failed by interrupt. Exception: {}\", masterUrl, errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            log.warn(\"Master at: {} is not available. Index fetch failed by exception: {}\", masterUrl, errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      log.info(\"Master's generation: {}\", latestGeneration);\n      log.info(\"Master's version: {}\", latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            log.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      if (log.isInfoEnabled()) {\n        log.info(\"Slave's generation: {}\", commit.getGeneration());\n        log.info(\"Slave's version: {}\", IndexDeletionPolicyWrapper.getCommitTimestamp(commit)); // logOK\n      }\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          log.info(\"New index in Master. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeSlaveCommitRefresh();\n          if (skipCommitOnMasterVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        log.debug(\"Nothing to replicate, master's version is 0\");\n        return IndexFetchResult.MASTER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //master and slave are already in sync just return\n        log.info(\"Slave in sync with master.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      log.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      if (log.isInfoEnabled()) {\n        log.info(\"Number of files in latest index in master: {}\", filesToDownload.size());\n      }\n      if (tlogFilesToDownload != null) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Number of tlog files in master: {}\", tlogFilesToDownload.size());\n        }\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new SolrNamedThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of master is older than that of the slave , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the master vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              log.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                log.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              log.info(\"IndexFetcher slept for {}ms for unused lucene index files to be delete-able\", c * 1000);\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          log.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          log.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  if (!this.clearLocalIndexFirst) {//it was closed earlier\n                    solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  }\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              log.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          solrCore.searchEnabled = true;\n          solrCore.indexEnabled = true;\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         if (log.isInfoEnabled()) {\n           log.info(\"Reloading SolrCore {}\", solrCore.getName());\n         }\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              log.info(\"removing old index directory {}\", indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          log.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        log.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1","date":1598647393,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from leader to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if follower is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    this.clearLocalIndexFirst = false;\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      log.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          if (log.isInfoEnabled()) {\n            log.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          }\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          if (log.isInfoEnabled()) {\n            log.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          }\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(leaderUrl)) {\n          leaderUrl = replica.getCoreUrl();\n          log.info(\"Updated leaderUrl to {}\", leaderUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          log.debug(\"leaderUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the leader\n      @SuppressWarnings({\"rawtypes\"})\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            log.warn(\"Leader at: {} is not available. Index fetch failed by interrupt. Exception: {}\", leaderUrl, errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            log.warn(\"Leader at: {} is not available. Index fetch failed by exception: {}\", leaderUrl, errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      log.info(\"Leader's generation: {}\", latestGeneration);\n      log.info(\"Leader's version: {}\", latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            log.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      if (log.isInfoEnabled()) {\n        log.info(\"Follower's generation: {}\", commit.getGeneration());\n        log.info(\"Follower's version: {}\", IndexDeletionPolicyWrapper.getCommitTimestamp(commit)); // logOK\n      }\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          log.info(\"New index in Leader. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeFollowerCommitRefresh();\n          if (skipCommitOnLeaderVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        log.debug(\"Nothing to replicate, leader's version is 0\");\n        return IndexFetchResult.LEADER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //leader and follower are already in sync just return\n        log.info(\"Follower in sync with leader.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      log.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      if (log.isInfoEnabled()) {\n        log.info(\"Number of files in latest index in leader: {}\", filesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new SolrNamedThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of leader is older than that of the follower , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the leader vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              log.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                log.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              log.info(\"IndexFetcher slept for {}ms for unused lucene index files to be delete-able\", c * 1000);\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          log.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          log.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  if (!this.clearLocalIndexFirst) {//it was closed earlier\n                    solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  }\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              log.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          solrCore.searchEnabled = true;\n          solrCore.indexEnabled = true;\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         if (log.isInfoEnabled()) {\n           log.info(\"Reloading SolrCore {}\", solrCore.getName());\n         }\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              log.info(\"removing old index directory {}\", indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          log.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        log.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from leader to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if follower is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    this.clearLocalIndexFirst = false;\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      log.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          if (log.isInfoEnabled()) {\n            log.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          }\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          if (log.isInfoEnabled()) {\n            log.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          }\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(leaderUrl)) {\n          leaderUrl = replica.getCoreUrl();\n          log.info(\"Updated leaderUrl to {}\", leaderUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          log.debug(\"leaderUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the leader\n      @SuppressWarnings({\"rawtypes\"})\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            log.warn(\"Leader at: {} is not available. Index fetch failed by interrupt. Exception: {}\", leaderUrl, errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            log.warn(\"Leader at: {} is not available. Index fetch failed by exception: {}\", leaderUrl, errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      log.info(\"Leader's generation: {}\", latestGeneration);\n      log.info(\"Leader's version: {}\", latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            log.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      if (log.isInfoEnabled()) {\n        log.info(\"Follower's generation: {}\", commit.getGeneration());\n        log.info(\"Follower's version: {}\", IndexDeletionPolicyWrapper.getCommitTimestamp(commit)); // logOK\n      }\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          log.info(\"New index in Leader. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeFollowerCommitRefresh();\n          if (skipCommitOnLeaderVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        log.debug(\"Nothing to replicate, leader's version is 0\");\n        return IndexFetchResult.LEADER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //leader and follower are already in sync just return\n        log.info(\"Follower in sync with leader.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      log.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      if (log.isInfoEnabled()) {\n        log.info(\"Number of files in latest index in leader: {}\", filesToDownload.size());\n      }\n      if (tlogFilesToDownload != null) {\n        if (log.isInfoEnabled()) {\n          log.info(\"Number of tlog files in leader: {}\", tlogFilesToDownload.size());\n        }\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new SolrNamedThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of leader is older than that of the follower , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // tmp dir for tlog files\n      if (tlogFilesToDownload != null) {\n        tmpTlogDir = new File(solrCore.getUpdateHandler().getUpdateLog().getLogDir(), \"tlog.\" + timestamp);\n      }\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the leader vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              log.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                log.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              log.info(\"IndexFetcher slept for {}ms for unused lucene index files to be delete-able\", c * 1000);\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          log.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          if (tlogFilesToDownload != null) {\n            bytesDownloaded += downloadTlogFiles(tmpTlogDir, latestGeneration);\n            reloadCore = true; // reload update log\n          }\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          log.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  if (!this.clearLocalIndexFirst) {//it was closed earlier\n                    solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  }\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              log.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (tlogFilesToDownload != null) {\n              // move tlog files and refresh ulog only if we successfully installed a new index\n              successfulInstall &= moveTlogFiles(tmpTlogDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          solrCore.searchEnabled = true;\n          solrCore.indexEnabled = true;\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         if (log.isInfoEnabled()) {\n           log.info(\"Reloading SolrCore {}\", solrCore.getName());\n         }\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              log.info(\"removing old index directory {}\", indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          log.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        log.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b2d19164145b2a65acf62a657c75f4a249b649c0","date":1601732857,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/handler/IndexFetcher#fetchLatestIndex(boolean,boolean).mjava","sourceNew":"  /**\n   * This command downloads all the necessary files from leader to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if follower is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    this.clearLocalIndexFirst = false;\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      log.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          if (log.isInfoEnabled()) {\n            log.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          }\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          if (log.isInfoEnabled()) {\n            log.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          }\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(leaderUrl)) {\n          leaderUrl = replica.getCoreUrl();\n          log.info(\"Updated leaderUrl to {}\", leaderUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          log.debug(\"leaderUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the leader\n      @SuppressWarnings({\"rawtypes\"})\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            log.warn(\"Leader at: {} is not available. Index fetch failed by interrupt. Exception: {}\", leaderUrl, errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            log.warn(\"Leader at: {} is not available. Index fetch failed by exception: {}\", leaderUrl, errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      log.info(\"Leader's generation: {}\", latestGeneration);\n      log.info(\"Leader's version: {}\", latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            log.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      if (log.isInfoEnabled()) {\n        log.info(\"Follower's generation: {}\", commit.getGeneration());\n        log.info(\"Follower's version: {}\", IndexDeletionPolicyWrapper.getCommitTimestamp(commit)); // nowarn\n      }\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          log.info(\"New index in Leader. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeFollowerCommitRefresh();\n          if (skipCommitOnLeaderVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        log.debug(\"Nothing to replicate, leader's version is 0\");\n        return IndexFetchResult.LEADER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //leader and follower are already in sync just return\n        log.info(\"Follower in sync with leader.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      log.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      if (log.isInfoEnabled()) {\n        log.info(\"Number of files in latest index in leader: {}\", filesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new SolrNamedThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of leader is older than that of the follower , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the leader vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              log.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                log.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              log.info(\"IndexFetcher slept for {}ms for unused lucene index files to be delete-able\", c * 1000);\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          log.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          log.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  if (!this.clearLocalIndexFirst) {//it was closed earlier\n                    solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  }\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              log.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          solrCore.searchEnabled = true;\n          solrCore.indexEnabled = true;\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         if (log.isInfoEnabled()) {\n           log.info(\"Reloading SolrCore {}\", solrCore.getName());\n         }\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              log.info(\"removing old index directory {}\", indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          log.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        log.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * This command downloads all the necessary files from leader to install a index commit point. Only changed files are\n   * downloaded. It also downloads the conf files (if they are modified).\n   *\n   * @param forceReplication force a replication in all cases\n   * @param forceCoreReload force a core reload in all cases\n   * @return true on success, false if follower is already in sync\n   * @throws IOException if an exception occurs\n   */\n  IndexFetchResult fetchLatestIndex(boolean forceReplication, boolean forceCoreReload) throws IOException, InterruptedException {\n\n    this.clearLocalIndexFirst = false;\n    boolean cleanupDone = false;\n    boolean successfulInstall = false;\n    markReplicationStart();\n    Directory tmpIndexDir = null;\n    String tmpIndexDirPath;\n    Directory indexDir = null;\n    String indexDirPath;\n    boolean deleteTmpIdxDir = true;\n    File tmpTlogDir = null;\n\n    if (!solrCore.getSolrCoreState().getLastReplicateIndexSuccess()) {\n      // if the last replication was not a success, we force a full replication\n      // when we are a bit more confident we may want to try a partial replication\n      // if the error is connection related or something, but we have to be careful\n      forceReplication = true;\n      log.info(\"Last replication failed, so I'll force replication\");\n    }\n\n    try {\n      if (fetchFromLeader) {\n        assert !solrCore.isClosed(): \"Replication should be stopped before closing the core\";\n        Replica replica = getLeaderReplica();\n        CloudDescriptor cd = solrCore.getCoreDescriptor().getCloudDescriptor();\n        if (cd.getCoreNodeName().equals(replica.getName())) {\n          return IndexFetchResult.EXPECTING_NON_LEADER;\n        }\n        if (replica.getState() != Replica.State.ACTIVE) {\n          if (log.isInfoEnabled()) {\n            log.info(\"Replica {} is leader but it's state is {}, skipping replication\", replica.getName(), replica.getState());\n          }\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!solrCore.getCoreContainer().getZkController().getClusterState().liveNodesContain(replica.getNodeName())) {\n          if (log.isInfoEnabled()) {\n            log.info(\"Replica {} is leader but it's not hosted on a live node, skipping replication\", replica.getName());\n          }\n          return IndexFetchResult.LEADER_IS_NOT_ACTIVE;\n        }\n        if (!replica.getCoreUrl().equals(leaderUrl)) {\n          leaderUrl = replica.getCoreUrl();\n          log.info(\"Updated leaderUrl to {}\", leaderUrl);\n          // TODO: Do we need to set forceReplication = true?\n        } else {\n          log.debug(\"leaderUrl didn't change\");\n        }\n      }\n      //get the current 'replicateable' index version in the leader\n      @SuppressWarnings({\"rawtypes\"})\n      NamedList response;\n      try {\n        response = getLatestVersion();\n      } catch (Exception e) {\n        final String errorMsg = e.toString();\n        if (!Strings.isNullOrEmpty(errorMsg) && errorMsg.contains(INTERRUPT_RESPONSE_MESSAGE)) {\n            log.warn(\"Leader at: {} is not available. Index fetch failed by interrupt. Exception: {}\", leaderUrl, errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_INTERRUPT_MESSAGE, false, e);\n        } else {\n            log.warn(\"Leader at: {} is not available. Index fetch failed by exception: {}\", leaderUrl, errorMsg);\n            return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n        }\n    }\n\n      long latestVersion = (Long) response.get(CMD_INDEX_VERSION);\n      long latestGeneration = (Long) response.get(GENERATION);\n\n      log.info(\"Leader's generation: {}\", latestGeneration);\n      log.info(\"Leader's version: {}\", latestVersion);\n\n      // TODO: make sure that getLatestCommit only returns commit points for the main index (i.e. no side-car indexes)\n      IndexCommit commit = solrCore.getDeletionPolicy().getLatestCommit();\n      if (commit == null) {\n        // Presumably the IndexWriter hasn't been opened yet, and hence the deletion policy hasn't been updated with commit points\n        RefCounted<SolrIndexSearcher> searcherRefCounted = null;\n        try {\n          searcherRefCounted = solrCore.getNewestSearcher(false);\n          if (searcherRefCounted == null) {\n            log.warn(\"No open searcher found - fetch aborted\");\n            return IndexFetchResult.NO_INDEX_COMMIT_EXIST;\n          }\n          commit = searcherRefCounted.get().getIndexReader().getIndexCommit();\n        } finally {\n          if (searcherRefCounted != null)\n            searcherRefCounted.decref();\n        }\n      }\n\n      if (log.isInfoEnabled()) {\n        log.info(\"Follower's generation: {}\", commit.getGeneration());\n        log.info(\"Follower's version: {}\", IndexDeletionPolicyWrapper.getCommitTimestamp(commit)); // logOK\n      }\n\n      if (latestVersion == 0L) {\n        if (commit.getGeneration() != 0) {\n          // since we won't get the files for an empty index,\n          // we just clear ours and commit\n          log.info(\"New index in Leader. Deleting mine...\");\n          RefCounted<IndexWriter> iw = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(solrCore);\n          try {\n            iw.get().deleteAll();\n          } finally {\n            iw.decref();\n          }\n          assert TestInjection.injectDelayBeforeFollowerCommitRefresh();\n          if (skipCommitOnLeaderVersionZero) {\n            openNewSearcherAndUpdateCommitPoint();\n          } else {\n            SolrQueryRequest req = new LocalSolrQueryRequest(solrCore, new ModifiableSolrParams());\n            solrCore.getUpdateHandler().commit(new CommitUpdateCommand(req, false));\n          }\n        }\n\n        //there is nothing to be replicated\n        successfulInstall = true;\n        log.debug(\"Nothing to replicate, leader's version is 0\");\n        return IndexFetchResult.LEADER_VERSION_ZERO;\n      }\n\n      // TODO: Should we be comparing timestamps (across machines) here?\n      if (!forceReplication && IndexDeletionPolicyWrapper.getCommitTimestamp(commit) == latestVersion) {\n        //leader and follower are already in sync just return\n        log.info(\"Follower in sync with leader.\");\n        successfulInstall = true;\n        return IndexFetchResult.ALREADY_IN_SYNC;\n      }\n      log.info(\"Starting replication process\");\n      // get the list of files first\n      fetchFileList(latestGeneration);\n      // this can happen if the commit point is deleted before we fetch the file list.\n      if (filesToDownload.isEmpty()) {\n        return IndexFetchResult.PEER_INDEX_COMMIT_DELETED;\n      }\n      if (log.isInfoEnabled()) {\n        log.info(\"Number of files in latest index in leader: {}\", filesToDownload.size());\n      }\n\n      // Create the sync service\n      fsyncService = ExecutorUtil.newMDCAwareSingleThreadExecutor(new SolrNamedThreadFactory(\"fsyncService\"));\n      // use a synchronized list because the list is read by other threads (to show details)\n      filesDownloaded = Collections.synchronizedList(new ArrayList<Map<String, Object>>());\n      // if the generation of leader is older than that of the follower , it means they are not compatible to be copied\n      // then a new index directory to be created and all the files need to be copied\n      boolean isFullCopyNeeded = IndexDeletionPolicyWrapper\n          .getCommitTimestamp(commit) >= latestVersion\n          || commit.getGeneration() >= latestGeneration || forceReplication;\n\n      String timestamp = new SimpleDateFormat(SnapShooter.DATE_FMT, Locale.ROOT).format(new Date());\n      String tmpIdxDirName = \"index.\" + timestamp;\n      tmpIndexDirPath = solrCore.getDataDir() + tmpIdxDirName;\n\n      tmpIndexDir = solrCore.getDirectoryFactory().get(tmpIndexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      // cindex dir...\n      indexDirPath = solrCore.getIndexDir();\n      indexDir = solrCore.getDirectoryFactory().get(indexDirPath, DirContext.DEFAULT, solrCore.getSolrConfig().indexConfig.lockType);\n\n      try {\n\n        // We will compare all the index files from the leader vs the index files on disk to see if there is a mismatch\n        // in the metadata. If there is a mismatch for the same index file then we download the entire index\n        // (except when differential copy is applicable) again.\n        if (!isFullCopyNeeded && isIndexStale(indexDir)) {\n          isFullCopyNeeded = true;\n        }\n\n        if (!isFullCopyNeeded && !fetchFromLeader) {\n          // a searcher might be using some flushed but not committed segments\n          // because of soft commits (which open a searcher on IW's data)\n          // so we need to close the existing searcher on the last commit\n          // and wait until we are able to clean up all unused lucene files\n          if (solrCore.getCoreContainer().isZooKeeperAware()) {\n            solrCore.closeSearcher();\n          }\n\n          // rollback and reopen index writer and wait until all unused files\n          // are successfully deleted\n          solrCore.getUpdateHandler().newIndexWriter(true);\n          RefCounted<IndexWriter> writer = solrCore.getUpdateHandler().getSolrCoreState().getIndexWriter(null);\n          try {\n            IndexWriter indexWriter = writer.get();\n            int c = 0;\n            indexWriter.deleteUnusedFiles();\n            while (hasUnusedFiles(indexDir, commit)) {\n              indexWriter.deleteUnusedFiles();\n              log.info(\"Sleeping for 1000ms to wait for unused lucene index files to be delete-able\");\n              Thread.sleep(1000);\n              c++;\n              if (c >= 30)  {\n                log.warn(\"IndexFetcher unable to cleanup unused lucene index files so we must do a full copy instead\");\n                isFullCopyNeeded = true;\n                break;\n              }\n            }\n            if (c > 0)  {\n              log.info(\"IndexFetcher slept for {}ms for unused lucene index files to be delete-able\", c * 1000);\n            }\n          } finally {\n            writer.decref();\n          }\n        }\n        boolean reloadCore = false;\n\n        try {\n          // we have to be careful and do this after we know isFullCopyNeeded won't be flipped\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().closeIndexWriter(solrCore, true);\n          }\n\n          log.info(\"Starting download (fullCopy={}) to {}\", isFullCopyNeeded, tmpIndexDir);\n          successfulInstall = false;\n\n          long bytesDownloaded = downloadIndexFiles(isFullCopyNeeded, indexDir,\n              tmpIndexDir, indexDirPath, tmpIndexDirPath, latestGeneration);\n          final long timeTakenSeconds = getReplicationTimeElapsed();\n          final Long bytesDownloadedPerSecond = (timeTakenSeconds != 0 ? Long.valueOf(bytesDownloaded / timeTakenSeconds) : null);\n          log.info(\"Total time taken for download (fullCopy={},bytesDownloaded={}) : {} secs ({} bytes/sec) to {}\",\n              isFullCopyNeeded, bytesDownloaded, timeTakenSeconds, bytesDownloadedPerSecond, tmpIndexDir);\n\n          Collection<Map<String,Object>> modifiedConfFiles = getModifiedConfFiles(confFilesToDownload);\n          if (!modifiedConfFiles.isEmpty()) {\n            reloadCore = true;\n            downloadConfFiles(confFilesToDownload, latestGeneration);\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              if (isFullCopyNeeded) {\n                // let the system know we are changing dir's and the old one\n                // may be closed\n                if (indexDir != null) {\n                  if (!this.clearLocalIndexFirst) {//it was closed earlier\n                    solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n                  }\n                  // Cleanup all index files not associated with any *named* snapshot.\n                  solrCore.deleteNonSnapshotIndexFiles(indexDirPath);\n                }\n              }\n\n              log.info(\"Configuration files are modified, core will be reloaded\");\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);// write to a file time of replication and\n                                     // conf files.\n            }\n          } else {\n            terminateAndWaitFsyncService();\n            if (isFullCopyNeeded) {\n              successfulInstall = solrCore.modifyIndexProps(tmpIdxDirName);\n              if (successfulInstall) deleteTmpIdxDir = false;\n            } else {\n              successfulInstall = moveIndexFiles(tmpIndexDir, indexDir);\n            }\n            if (successfulInstall) {\n              logReplicationTimeAndConfFiles(modifiedConfFiles,\n                  successfulInstall);\n            }\n          }\n        } finally {\n          solrCore.searchEnabled = true;\n          solrCore.indexEnabled = true;\n          if (!isFullCopyNeeded) {\n            solrCore.getUpdateHandler().getSolrCoreState().openIndexWriter(solrCore);\n          }\n        }\n\n        // we must reload the core after we open the IW back up\n       if (successfulInstall && (reloadCore || forceCoreReload)) {\n         if (log.isInfoEnabled()) {\n           log.info(\"Reloading SolrCore {}\", solrCore.getName());\n         }\n          reloadCore();\n        }\n\n        if (successfulInstall) {\n          if (isFullCopyNeeded) {\n            // let the system know we are changing dir's and the old one\n            // may be closed\n            if (indexDir != null) {\n              log.info(\"removing old index directory {}\", indexDir);\n              solrCore.getDirectoryFactory().doneWithDirectory(indexDir);\n              solrCore.getDirectoryFactory().remove(indexDir);\n            }\n          }\n          if (isFullCopyNeeded) {\n            solrCore.getUpdateHandler().newIndexWriter(isFullCopyNeeded);\n          }\n\n          openNewSearcherAndUpdateCommitPoint();\n        }\n\n        if (!isFullCopyNeeded && !forceReplication && !successfulInstall) {\n          cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n          cleanupDone = true;\n          // we try with a full copy of the index\n          log.warn(\n              \"Replication attempt was not successful - trying a full index replication reloadCore={}\",\n              reloadCore);\n          successfulInstall = fetchLatestIndex(true, reloadCore).getSuccessful();\n        }\n\n        markReplicationStop();\n        return successfulInstall ? IndexFetchResult.INDEX_FETCH_SUCCESS : IndexFetchResult.INDEX_FETCH_FAILURE;\n      } catch (ReplicationHandlerException e) {\n        log.error(\"User aborted Replication\");\n        return new IndexFetchResult(IndexFetchResult.FAILED_BY_EXCEPTION_MESSAGE, false, e);\n      } catch (SolrException e) {\n        throw e;\n      } catch (InterruptedException e) {\n        throw new InterruptedException(\"Index fetch interrupted\");\n      } catch (Exception e) {\n        throw new SolrException(ErrorCode.SERVER_ERROR, \"Index fetch failed : \", e);\n      }\n    } finally {\n      if (!cleanupDone) {\n        cleanup(solrCore, tmpIndexDir, indexDir, deleteTmpIdxDir, tmpTlogDir, successfulInstall);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"04ecf884544ff74add5faa452748f160c4af904b":["61c45e99cf6676da48f19d7511c73712ad39402b"],"ad28156288ac00b91352582904d97e6653205757":["b39b1b02e442aaf736cc87417e93552cbd8ef1da"],"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["d5f6959c652bdf332fe98fc9180b54095a4053ae"],"b6a269c1ddba3f8c9fa9a40572ecc538eddda41a":["436eff77c0517cdabffce79a0738ab69d524d9fb"],"98fea9928eee12529633d73f52989154dd3dea1f":["04ecf884544ff74add5faa452748f160c4af904b"],"89424def13674ea17829b41c5883c54ecc31a132":["91e2345fb81b6c1c7faefa550ee5eaafadc54486","138bba875d696cd48f61b681050026222022e937"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","61c45e99cf6676da48f19d7511c73712ad39402b"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["436eff77c0517cdabffce79a0738ab69d524d9fb","628903f37b6c442da0d390db1c6af9a0e74d41a7"],"6ad16d9bdc03ec6adfd5d4b7b6ea14b256ce3998":["bcf9886c8ff537aafde14de48ebf744f5673f08b"],"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4":["fb03700c9690d16b15fb4f56f6ec36b128fd894e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["91e2345fb81b6c1c7faefa550ee5eaafadc54486","89424def13674ea17829b41c5883c54ecc31a132"],"6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","7b13106276bb5ea342253dbf6aae7b675adb38d3"],"b2d19164145b2a65acf62a657c75f4a249b649c0":["23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1"],"b39b1b02e442aaf736cc87417e93552cbd8ef1da":["3e13696c44d3e2405098726359ab81dab178e7bc"],"be320990bdc77e643388fa801e75017f19289c42":["ad28156288ac00b91352582904d97e6653205757"],"ab68488225b6a6c357dda72ed11dedca9914a192":["ad28156288ac00b91352582904d97e6653205757","f996f8177b9204bdc92f7164460c6cefad9ac99a"],"e9c81f7e703d7ccca5bc78beb61253f0a8a22afd":["628903f37b6c442da0d390db1c6af9a0e74d41a7"],"91e2345fb81b6c1c7faefa550ee5eaafadc54486":["e586ff50ac71d5ef3a27ced78f69deb41ab35ad5"],"3e13696c44d3e2405098726359ab81dab178e7bc":["c973f931d0c400a36bbdeacce57000dd3cf0e0d0"],"65a5d87a40f9143cd55be76eb1dde1b32a8dae5e":["2caf6d6e842e1a4e4ae68ec6dfa5139c31a84ec5"],"61c45e99cf6676da48f19d7511c73712ad39402b":["729cb470f975115d4c60517b2cb7c42e37a7a2e1"],"138bba875d696cd48f61b681050026222022e937":["91e2345fb81b6c1c7faefa550ee5eaafadc54486"],"81d505b8f51b856e1b7e9dd377f5050c337b797a":["e9c81f7e703d7ccca5bc78beb61253f0a8a22afd"],"729cb470f975115d4c60517b2cb7c42e37a7a2e1":["7c641347aa34a81b8c172fd46691e3cba6357a6f"],"628903f37b6c442da0d390db1c6af9a0e74d41a7":["436eff77c0517cdabffce79a0738ab69d524d9fb","b6a269c1ddba3f8c9fa9a40572ecc538eddda41a"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["e586ff50ac71d5ef3a27ced78f69deb41ab35ad5","3e13696c44d3e2405098726359ab81dab178e7bc"],"90a682dc1bfd188ef61cc28373c7f5d700b4ac75":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","b39b1b02e442aaf736cc87417e93552cbd8ef1da"],"7c641347aa34a81b8c172fd46691e3cba6357a6f":["be320990bdc77e643388fa801e75017f19289c42"],"86290366cefc1b9d4eced13b430858c4a4c0421d":["cb5af3afeddbb803fb785098176e6e177c34261b"],"e586ff50ac71d5ef3a27ced78f69deb41ab35ad5":["6ad16d9bdc03ec6adfd5d4b7b6ea14b256ce3998"],"f996f8177b9204bdc92f7164460c6cefad9ac99a":["ad28156288ac00b91352582904d97e6653205757"],"6240b74b884c5587f2a4062dd27d6c32bf228889":["e9017cf144952056066919f1ebc7897ff9bd71b1","04ecf884544ff74add5faa452748f160c4af904b"],"d5f6959c652bdf332fe98fc9180b54095a4053ae":["ab68488225b6a6c357dda72ed11dedca9914a192"],"2caf6d6e842e1a4e4ae68ec6dfa5139c31a84ec5":["fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4"],"c973f931d0c400a36bbdeacce57000dd3cf0e0d0":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"fb03700c9690d16b15fb4f56f6ec36b128fd894e":["81d505b8f51b856e1b7e9dd377f5050c337b797a"],"bcf9886c8ff537aafde14de48ebf744f5673f08b":["86290366cefc1b9d4eced13b430858c4a4c0421d"],"23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1":["65a5d87a40f9143cd55be76eb1dde1b32a8dae5e"],"c42316df77794f7252857e7d5e9ce45ff1d65c61":["7b13106276bb5ea342253dbf6aae7b675adb38d3"],"436eff77c0517cdabffce79a0738ab69d524d9fb":["98fea9928eee12529633d73f52989154dd3dea1f"],"cb5af3afeddbb803fb785098176e6e177c34261b":["c42316df77794f7252857e7d5e9ce45ff1d65c61"],"7b13106276bb5ea342253dbf6aae7b675adb38d3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":["e586ff50ac71d5ef3a27ced78f69deb41ab35ad5","91e2345fb81b6c1c7faefa550ee5eaafadc54486"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b2d19164145b2a65acf62a657c75f4a249b649c0"]},"commit2Childs":{"04ecf884544ff74add5faa452748f160c4af904b":["98fea9928eee12529633d73f52989154dd3dea1f","6240b74b884c5587f2a4062dd27d6c32bf228889"],"ad28156288ac00b91352582904d97e6653205757":["be320990bdc77e643388fa801e75017f19289c42","ab68488225b6a6c357dda72ed11dedca9914a192","f996f8177b9204bdc92f7164460c6cefad9ac99a"],"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["e9017cf144952056066919f1ebc7897ff9bd71b1"],"b6a269c1ddba3f8c9fa9a40572ecc538eddda41a":["628903f37b6c442da0d390db1c6af9a0e74d41a7"],"98fea9928eee12529633d73f52989154dd3dea1f":["436eff77c0517cdabffce79a0738ab69d524d9fb"],"89424def13674ea17829b41c5883c54ecc31a132":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["6240b74b884c5587f2a4062dd27d6c32bf228889"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"6ad16d9bdc03ec6adfd5d4b7b6ea14b256ce3998":["e586ff50ac71d5ef3a27ced78f69deb41ab35ad5"],"fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4":["2caf6d6e842e1a4e4ae68ec6dfa5139c31a84ec5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c","7b13106276bb5ea342253dbf6aae7b675adb38d3"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["c973f931d0c400a36bbdeacce57000dd3cf0e0d0"],"6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c":[],"b2d19164145b2a65acf62a657c75f4a249b649c0":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b39b1b02e442aaf736cc87417e93552cbd8ef1da":["ad28156288ac00b91352582904d97e6653205757","90a682dc1bfd188ef61cc28373c7f5d700b4ac75"],"be320990bdc77e643388fa801e75017f19289c42":["7c641347aa34a81b8c172fd46691e3cba6357a6f"],"ab68488225b6a6c357dda72ed11dedca9914a192":["d5f6959c652bdf332fe98fc9180b54095a4053ae"],"91e2345fb81b6c1c7faefa550ee5eaafadc54486":["89424def13674ea17829b41c5883c54ecc31a132","17e5da53e4e5bd659e22add9bba1cfa222e7e30d","138bba875d696cd48f61b681050026222022e937","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"e9c81f7e703d7ccca5bc78beb61253f0a8a22afd":["81d505b8f51b856e1b7e9dd377f5050c337b797a"],"3e13696c44d3e2405098726359ab81dab178e7bc":["b39b1b02e442aaf736cc87417e93552cbd8ef1da","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"65a5d87a40f9143cd55be76eb1dde1b32a8dae5e":["23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1"],"61c45e99cf6676da48f19d7511c73712ad39402b":["04ecf884544ff74add5faa452748f160c4af904b","e9017cf144952056066919f1ebc7897ff9bd71b1"],"138bba875d696cd48f61b681050026222022e937":["89424def13674ea17829b41c5883c54ecc31a132"],"81d505b8f51b856e1b7e9dd377f5050c337b797a":["fb03700c9690d16b15fb4f56f6ec36b128fd894e"],"628903f37b6c442da0d390db1c6af9a0e74d41a7":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","e9c81f7e703d7ccca5bc78beb61253f0a8a22afd"],"729cb470f975115d4c60517b2cb7c42e37a7a2e1":["61c45e99cf6676da48f19d7511c73712ad39402b"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["90a682dc1bfd188ef61cc28373c7f5d700b4ac75"],"90a682dc1bfd188ef61cc28373c7f5d700b4ac75":[],"7c641347aa34a81b8c172fd46691e3cba6357a6f":["729cb470f975115d4c60517b2cb7c42e37a7a2e1"],"86290366cefc1b9d4eced13b430858c4a4c0421d":["bcf9886c8ff537aafde14de48ebf744f5673f08b"],"f996f8177b9204bdc92f7164460c6cefad9ac99a":["ab68488225b6a6c357dda72ed11dedca9914a192"],"e586ff50ac71d5ef3a27ced78f69deb41ab35ad5":["91e2345fb81b6c1c7faefa550ee5eaafadc54486","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"6240b74b884c5587f2a4062dd27d6c32bf228889":[],"d5f6959c652bdf332fe98fc9180b54095a4053ae":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb"],"c973f931d0c400a36bbdeacce57000dd3cf0e0d0":["3e13696c44d3e2405098726359ab81dab178e7bc"],"2caf6d6e842e1a4e4ae68ec6dfa5139c31a84ec5":["65a5d87a40f9143cd55be76eb1dde1b32a8dae5e"],"fb03700c9690d16b15fb4f56f6ec36b128fd894e":["fe9f2c4a0d7ac164e4bdd4eee7f87131aec83fd4"],"bcf9886c8ff537aafde14de48ebf744f5673f08b":["6ad16d9bdc03ec6adfd5d4b7b6ea14b256ce3998"],"23ec6d2969d61cadbfd0a5452e9be1f9999e8aa1":["b2d19164145b2a65acf62a657c75f4a249b649c0"],"c42316df77794f7252857e7d5e9ce45ff1d65c61":["cb5af3afeddbb803fb785098176e6e177c34261b"],"436eff77c0517cdabffce79a0738ab69d524d9fb":["b6a269c1ddba3f8c9fa9a40572ecc538eddda41a","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","628903f37b6c442da0d390db1c6af9a0e74d41a7"],"7b13106276bb5ea342253dbf6aae7b675adb38d3":["6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c","c42316df77794f7252857e7d5e9ce45ff1d65c61"],"cb5af3afeddbb803fb785098176e6e177c34261b":["86290366cefc1b9d4eced13b430858c4a4c0421d"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","6c757ac42dd1f3f893db5c4d89c61cbe1a9fab6c","90a682dc1bfd188ef61cc28373c7f5d700b4ac75","6240b74b884c5587f2a4062dd27d6c32bf228889","3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}