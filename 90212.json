{"path":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","commits":[{"id":"d264f386d864b5751209060e8886ca9845f70469","date":1372172126,"type":1,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load(String,InputStream,String).mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer {}\", System.identityHashCode(this));\n\n    ThreadPoolExecutor coreLoadExecutor = null;\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    libDir = cfg.get(ConfigSolr.CfgProp.SOLR_SHAREDLIB , null);\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = initShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg, loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg, loader);\n\n    if (cfg instanceof ConfigSolrXmlOld) { //TODO: Remove for 5.0\n      String dcoreName = cfg.get(ConfigSolr.CfgProp.SOLR_CORES_DEFAULT_CORE_NAME, null);\n      if (dcoreName != null && !dcoreName.isEmpty()) {\n        defaultCoreName = dcoreName;\n      }\n      persistent = cfg.getBool(ConfigSolr.CfgProp.SOLR_PERSISTENT, false);\n      adminPath = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINPATH, \"/admin/cores\");\n    } else {\n      adminPath = \"/admin/cores\";\n      defaultCoreName = DEFAULT_DEFAULT_CORE_NAME;\n    }\n    zkHost = cfg.get(ConfigSolr.CfgProp.SOLR_ZKHOST, null);\n    coreLoadThreads = cfg.getInt(ConfigSolr.CfgProp.SOLR_CORELOADTHREADS, CORE_LOAD_THREADS);\n    \n\n    shareSchema = cfg.getBool(ConfigSolr.CfgProp.SOLR_SHARESCHEMA, DEFAULT_SHARE_SCHEMA);\n    zkClientTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_ZKCLIENTTIMEOUT, DEFAULT_ZK_CLIENT_TIMEOUT);\n    \n    distribUpdateConnTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATECONNTIMEOUT, 0);\n    distribUpdateSoTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATESOTIMEOUT, 0);\n\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostPort = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTPORT, null);\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostContext = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTCONTEXT, null);\n\n    String host = cfg.get(ConfigSolr.CfgProp.SOLR_HOST, null);\n    \n    String leaderVoteWait = cfg.get(ConfigSolr.CfgProp.SOLR_LEADERVOTEWAIT, LEADER_VOTE_WAIT);\n\n    adminHandler = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINHANDLER, null);\n    managementPath = cfg.get(ConfigSolr.CfgProp.SOLR_MANAGEMENTPATH, null);\n\n    transientCacheSize = cfg.getInt(ConfigSolr.CfgProp.SOLR_TRANSIENTCACHESIZE, Integer.MAX_VALUE);\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkClientTimeout = Integer.parseInt(System.getProperty(\"zkClientTimeout\",\n        Integer.toString(zkClientTimeout)));\n    zkSys.initZooKeeper(this, solrHome, zkHost, zkClientTimeout, hostPort, hostContext, host, leaderVoteWait, distribUpdateConnTimeout, distribUpdateSoTimeout);\n    \n    if (isZooKeeperAware() && coreLoadThreads <= 1) {\n      throw new SolrException(ErrorCode.SERVER_ERROR,\n          \"SolrCloud requires a value of at least 2 in solr.xml for coreLoadThreads\");\n    }\n    \n    if (adminPath != null) {\n      if (adminHandler == null) {\n        coreAdminHandler = new CoreAdminHandler(this);\n      } else {\n        coreAdminHandler = this.createMultiCoreHandler(adminHandler);\n      }\n    }\n    \n    collectionsHandler = new CollectionsHandler(this);\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    coreLoadExecutor = new ThreadPoolExecutor(coreLoadThreads, coreLoadThreads, 1,\n        TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<String> allCores = cfg.getAllCoreNames();\n\n      for (String oneCoreName : allCores) {\n\n        try {\n          String rawName = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NAME, null);\n\n          if (null == rawName) {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Each core in solr.xml must have a 'name'\");\n          }\n          final String name = rawName;\n          final CoreDescriptor p = new CoreDescriptor(this, name,\n              cfg.getProperty(oneCoreName, CoreDescriptor.CORE_INSTDIR, null));\n          \n          // deal with optional settings\n          String opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_CONFIG, null);\n          \n          if (opt != null) {\n            p.setConfigName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SCHEMA, null);\n          if (opt != null) {\n            p.setSchemaName(opt);\n          }\n          \n          if (zkSys.getZkController() != null) {\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SHARD, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setShardId(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_COLLECTION, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setCollectionName(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_ROLES, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setRoles(opt);\n            }\n\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NODE_NAME, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setCoreNodeName(opt);\n            }\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_PROPERTIES, null);\n          if (opt != null) {\n            p.setPropertiesName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_DATADIR, null);\n          if (opt != null) {\n            p.setDataDir(opt);\n          }\n          \n          p.setCoreProperties(cfg.readCoreProperties(oneCoreName));\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_LOADONSTARTUP, null);\n          if (opt != null) {\n            p.setLoadOnStartup((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_TRANSIENT, null);\n          if (opt != null) {\n            p.setTransient((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n\n          if (p.isTransient() || ! p.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(rawName, p);\n          }\n\n          if (p.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(p);\n                  }\n                  c = create(p);\n                  registerCore(p.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, p);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n          \n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load a config file listing the available solr cores.\n   * \n   * @param dir the home directory of all resources.\n   * @param is the configuration file InputStream. May be a properties file or an xml file\n   */\n\n  // Let's keep this ugly boolean out of public circulation.\n  protected void load(String dir, InputStream is, String fileName)  {\n    ThreadPoolExecutor coreLoadExecutor = null;\n    if (null == dir) {\n      // don't rely on SolrResourceLoader(), determine explicitly first\n      dir = SolrResourceLoader.locateSolrHome();\n    }\n    log.info(\"Loading CoreContainer using Solr Home: '{}'\", dir);\n    \n    this.loader = new SolrResourceLoader(dir);\n    solrHome = loader.getInstanceDir();\n\n    try {\n      Config config = new Config(loader, null, new InputSource(is), null, false);\n\n      // old style defines cores in solr.xml, new style disovers them by \n      // directory structure\n      boolean oldStyle = (config.getNode(\"solr/cores\", false) != null);\n      \n      if (oldStyle) {\n        // ConfigSolr handles keep orig values around for non solrcore level items,\n        // but this is still how original core lvl attributes are kept around\n        this.origCfg = new Config(loader, null, copyDoc(config.getDocument()));\n        \n        this.cfg = new ConfigSolrXmlOld(config, this);\n      } else {\n        this.cfg = new ConfigSolrXml(config, this);\n\n      }\n    } catch (Exception e) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    // Since the cores var is now initialized to null, let's set it up right\n    // now.\n    cfg.substituteProperties();\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    libDir = cfg.get(ConfigSolr.CfgProp.SOLR_SHAREDLIB , null);\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(dir), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = initShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg, loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg, loader);\n\n    if (cfg instanceof ConfigSolrXmlOld) { //TODO: Remove for 5.0\n      String dcoreName = cfg.get(ConfigSolr.CfgProp.SOLR_CORES_DEFAULT_CORE_NAME, null);\n      if (dcoreName != null && !dcoreName.isEmpty()) {\n        defaultCoreName = dcoreName;\n      }\n      persistent = cfg.getBool(ConfigSolr.CfgProp.SOLR_PERSISTENT, false);\n      adminPath = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINPATH, \"/admin/cores\");\n    } else {\n      adminPath = \"/admin/cores\";\n      defaultCoreName = DEFAULT_DEFAULT_CORE_NAME;\n    }\n    zkHost = cfg.get(ConfigSolr.CfgProp.SOLR_ZKHOST, null);\n    coreLoadThreads = cfg.getInt(ConfigSolr.CfgProp.SOLR_CORELOADTHREADS, CORE_LOAD_THREADS);\n    \n\n    shareSchema = cfg.getBool(ConfigSolr.CfgProp.SOLR_SHARESCHEMA, DEFAULT_SHARE_SCHEMA);\n    zkClientTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_ZKCLIENTTIMEOUT, DEFAULT_ZK_CLIENT_TIMEOUT);\n    \n    distribUpdateConnTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATECONNTIMEOUT, 0);\n    distribUpdateSoTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATESOTIMEOUT, 0);\n\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostPort = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTPORT, null);\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostContext = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTCONTEXT, null);\n\n    String host = cfg.get(ConfigSolr.CfgProp.SOLR_HOST, null);\n    \n    String leaderVoteWait = cfg.get(ConfigSolr.CfgProp.SOLR_LEADERVOTEWAIT, LEADER_VOTE_WAIT);\n\n    adminHandler = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINHANDLER, null);\n    managementPath = cfg.get(ConfigSolr.CfgProp.SOLR_MANAGEMENTPATH, null);\n\n    transientCacheSize = cfg.getInt(ConfigSolr.CfgProp.SOLR_TRANSIENTCACHESIZE, Integer.MAX_VALUE);\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkClientTimeout = Integer.parseInt(System.getProperty(\"zkClientTimeout\",\n        Integer.toString(zkClientTimeout)));\n    zkSys.initZooKeeper(this, solrHome, zkHost, zkClientTimeout, hostPort, hostContext, host, leaderVoteWait, distribUpdateConnTimeout, distribUpdateSoTimeout);\n    \n    if (isZooKeeperAware() && coreLoadThreads <= 1) {\n      throw new SolrException(ErrorCode.SERVER_ERROR,\n          \"SolrCloud requires a value of at least 2 in solr.xml for coreLoadThreads\");\n    }\n    \n    if (adminPath != null) {\n      if (adminHandler == null) {\n        coreAdminHandler = new CoreAdminHandler(this);\n      } else {\n        coreAdminHandler = this.createMultiCoreHandler(adminHandler);\n      }\n    }\n    \n    collectionsHandler = new CollectionsHandler(this);\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    coreLoadExecutor = new ThreadPoolExecutor(coreLoadThreads, coreLoadThreads, 1,\n        TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<String> allCores = cfg.getAllCoreNames();\n\n      for (String oneCoreName : allCores) {\n\n        try {\n          String rawName = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NAME, null);\n\n          if (null == rawName) {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Each core in solr.xml must have a 'name'\");\n          }\n          final String name = rawName;\n          final CoreDescriptor p = new CoreDescriptor(this, name,\n              cfg.getProperty(oneCoreName, CoreDescriptor.CORE_INSTDIR, null));\n          \n          // deal with optional settings\n          String opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_CONFIG, null);\n          \n          if (opt != null) {\n            p.setConfigName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SCHEMA, null);\n          if (opt != null) {\n            p.setSchemaName(opt);\n          }\n          \n          if (zkSys.getZkController() != null) {\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SHARD, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setShardId(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_COLLECTION, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setCollectionName(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_ROLES, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setRoles(opt);\n            }\n\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NODE_NAME, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setCoreNodeName(opt);\n            }\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_PROPERTIES, null);\n          if (opt != null) {\n            p.setPropertiesName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_DATADIR, null);\n          if (opt != null) {\n            p.setDataDir(opt);\n          }\n          \n          p.setCoreProperties(cfg.readCoreProperties(oneCoreName));\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_LOADONSTARTUP, null);\n          if (opt != null) {\n            p.setLoadOnStartup((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_TRANSIENT, null);\n          if (opt != null) {\n            p.setTransient((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n\n          if (p.isTransient() || ! p.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(rawName, p);\n          }\n\n          if (p.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(p);\n                  }\n                  c = create(p);\n                  registerCore(p.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, p);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n          \n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"354983dcdf70c800bf2573d10b54a7391b1dc167","date":1372183171,"type":5,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load(String,InputStream,String).mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load a config file listing the available solr cores.\n   * \n   * @param dir the home directory of all resources.\n   * @param is the configuration file InputStream. May be a properties file or an xml file\n   */\n\n  // Let's keep this ugly boolean out of public circulation.\n  protected void load(String dir, InputStream is, String fileName)  {\n    ThreadPoolExecutor coreLoadExecutor = null;\n    if (null == dir) {\n      // don't rely on SolrResourceLoader(), determine explicitly first\n      dir = SolrResourceLoader.locateSolrHome();\n    }\n    log.info(\"Loading CoreContainer using Solr Home: '{}'\", dir);\n    \n    this.loader = new SolrResourceLoader(dir);\n    solrHome = loader.getInstanceDir();\n\n    try {\n      Config config = new Config(loader, null, new InputSource(is), null, false);\n\n      // old style defines cores in solr.xml, new style disovers them by \n      // directory structure\n      boolean oldStyle = (config.getNode(\"solr/cores\", false) != null);\n      \n      if (oldStyle) {\n        // ConfigSolr handles keep orig values around for non solrcore level items,\n        // but this is still how original core lvl attributes are kept around\n        this.origCfg = new Config(loader, null, copyDoc(config.getDocument()));\n        \n        this.cfg = new ConfigSolrXmlOld(config, this);\n      } else {\n        this.cfg = new ConfigSolrXml(config, this);\n\n      }\n    } catch (Exception e) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    // Since the cores var is now initialized to null, let's set it up right\n    // now.\n    cfg.substituteProperties();\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    libDir = cfg.get(ConfigSolr.CfgProp.SOLR_SHAREDLIB , null);\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(dir), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = initShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg, loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg, loader);\n\n    if (cfg instanceof ConfigSolrXmlOld) { //TODO: Remove for 5.0\n      String dcoreName = cfg.get(ConfigSolr.CfgProp.SOLR_CORES_DEFAULT_CORE_NAME, null);\n      if (dcoreName != null && !dcoreName.isEmpty()) {\n        defaultCoreName = dcoreName;\n      }\n      persistent = cfg.getBool(ConfigSolr.CfgProp.SOLR_PERSISTENT, false);\n      adminPath = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINPATH, \"/admin/cores\");\n    } else {\n      adminPath = \"/admin/cores\";\n      defaultCoreName = DEFAULT_DEFAULT_CORE_NAME;\n    }\n    zkHost = cfg.get(ConfigSolr.CfgProp.SOLR_ZKHOST, null);\n    coreLoadThreads = cfg.getInt(ConfigSolr.CfgProp.SOLR_CORELOADTHREADS, CORE_LOAD_THREADS);\n    \n\n    shareSchema = cfg.getBool(ConfigSolr.CfgProp.SOLR_SHARESCHEMA, DEFAULT_SHARE_SCHEMA);\n    zkClientTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_ZKCLIENTTIMEOUT, DEFAULT_ZK_CLIENT_TIMEOUT);\n    \n    distribUpdateConnTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATECONNTIMEOUT, 0);\n    distribUpdateSoTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATESOTIMEOUT, 0);\n\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostPort = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTPORT, null);\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostContext = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTCONTEXT, null);\n\n    String host = cfg.get(ConfigSolr.CfgProp.SOLR_HOST, null);\n    \n    String leaderVoteWait = cfg.get(ConfigSolr.CfgProp.SOLR_LEADERVOTEWAIT, LEADER_VOTE_WAIT);\n\n    adminHandler = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINHANDLER, null);\n    managementPath = cfg.get(ConfigSolr.CfgProp.SOLR_MANAGEMENTPATH, null);\n\n    transientCacheSize = cfg.getInt(ConfigSolr.CfgProp.SOLR_TRANSIENTCACHESIZE, Integer.MAX_VALUE);\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkClientTimeout = Integer.parseInt(System.getProperty(\"zkClientTimeout\",\n        Integer.toString(zkClientTimeout)));\n    zkSys.initZooKeeper(this, solrHome, zkHost, zkClientTimeout, hostPort, hostContext, host, leaderVoteWait, distribUpdateConnTimeout, distribUpdateSoTimeout);\n    \n    if (isZooKeeperAware() && coreLoadThreads <= 1) {\n      throw new SolrException(ErrorCode.SERVER_ERROR,\n          \"SolrCloud requires a value of at least 2 in solr.xml for coreLoadThreads\");\n    }\n    \n    if (adminPath != null) {\n      if (adminHandler == null) {\n        coreAdminHandler = new CoreAdminHandler(this);\n      } else {\n        coreAdminHandler = this.createMultiCoreHandler(adminHandler);\n      }\n    }\n    \n    collectionsHandler = new CollectionsHandler(this);\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    coreLoadExecutor = new ThreadPoolExecutor(coreLoadThreads, coreLoadThreads, 1,\n        TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<String> allCores = cfg.getAllCoreNames();\n\n      for (String oneCoreName : allCores) {\n\n        try {\n          String rawName = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NAME, null);\n\n          if (null == rawName) {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Each core in solr.xml must have a 'name'\");\n          }\n          final String name = rawName;\n          final CoreDescriptor p = new CoreDescriptor(this, name,\n              cfg.getProperty(oneCoreName, CoreDescriptor.CORE_INSTDIR, null));\n          \n          // deal with optional settings\n          String opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_CONFIG, null);\n          \n          if (opt != null) {\n            p.setConfigName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SCHEMA, null);\n          if (opt != null) {\n            p.setSchemaName(opt);\n          }\n          \n          if (zkSys.getZkController() != null) {\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SHARD, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setShardId(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_COLLECTION, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setCollectionName(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_ROLES, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setRoles(opt);\n            }\n\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NODE_NAME, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setCoreNodeName(opt);\n            }\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_PROPERTIES, null);\n          if (opt != null) {\n            p.setPropertiesName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_DATADIR, null);\n          if (opt != null) {\n            p.setDataDir(opt);\n          }\n          \n          p.setCoreProperties(cfg.readCoreProperties(oneCoreName));\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_LOADONSTARTUP, null);\n          if (opt != null) {\n            p.setLoadOnStartup((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_TRANSIENT, null);\n          if (opt != null) {\n            p.setTransient((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n\n          if (p.isTransient() || ! p.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(rawName, p);\n          }\n\n          if (p.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(p);\n                  }\n                  c = create(p);\n                  registerCore(p.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, p);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n          \n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer {}\", System.identityHashCode(this));\n\n    ThreadPoolExecutor coreLoadExecutor = null;\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    libDir = cfg.get(ConfigSolr.CfgProp.SOLR_SHAREDLIB , null);\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = initShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg, loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg, loader);\n\n    if (cfg instanceof ConfigSolrXmlOld) { //TODO: Remove for 5.0\n      String dcoreName = cfg.get(ConfigSolr.CfgProp.SOLR_CORES_DEFAULT_CORE_NAME, null);\n      if (dcoreName != null && !dcoreName.isEmpty()) {\n        defaultCoreName = dcoreName;\n      }\n      persistent = cfg.getBool(ConfigSolr.CfgProp.SOLR_PERSISTENT, false);\n      adminPath = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINPATH, \"/admin/cores\");\n    } else {\n      adminPath = \"/admin/cores\";\n      defaultCoreName = DEFAULT_DEFAULT_CORE_NAME;\n    }\n    zkHost = cfg.get(ConfigSolr.CfgProp.SOLR_ZKHOST, null);\n    coreLoadThreads = cfg.getInt(ConfigSolr.CfgProp.SOLR_CORELOADTHREADS, CORE_LOAD_THREADS);\n    \n\n    shareSchema = cfg.getBool(ConfigSolr.CfgProp.SOLR_SHARESCHEMA, DEFAULT_SHARE_SCHEMA);\n    zkClientTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_ZKCLIENTTIMEOUT, DEFAULT_ZK_CLIENT_TIMEOUT);\n    \n    distribUpdateConnTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATECONNTIMEOUT, 0);\n    distribUpdateSoTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATESOTIMEOUT, 0);\n\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostPort = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTPORT, null);\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostContext = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTCONTEXT, null);\n\n    String host = cfg.get(ConfigSolr.CfgProp.SOLR_HOST, null);\n    \n    String leaderVoteWait = cfg.get(ConfigSolr.CfgProp.SOLR_LEADERVOTEWAIT, LEADER_VOTE_WAIT);\n\n    adminHandler = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINHANDLER, null);\n    managementPath = cfg.get(ConfigSolr.CfgProp.SOLR_MANAGEMENTPATH, null);\n\n    transientCacheSize = cfg.getInt(ConfigSolr.CfgProp.SOLR_TRANSIENTCACHESIZE, Integer.MAX_VALUE);\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkClientTimeout = Integer.parseInt(System.getProperty(\"zkClientTimeout\",\n        Integer.toString(zkClientTimeout)));\n    zkSys.initZooKeeper(this, solrHome, zkHost, zkClientTimeout, hostPort, hostContext, host, leaderVoteWait, distribUpdateConnTimeout, distribUpdateSoTimeout);\n    \n    if (isZooKeeperAware() && coreLoadThreads <= 1) {\n      throw new SolrException(ErrorCode.SERVER_ERROR,\n          \"SolrCloud requires a value of at least 2 in solr.xml for coreLoadThreads\");\n    }\n    \n    if (adminPath != null) {\n      if (adminHandler == null) {\n        coreAdminHandler = new CoreAdminHandler(this);\n      } else {\n        coreAdminHandler = this.createMultiCoreHandler(adminHandler);\n      }\n    }\n    \n    collectionsHandler = new CollectionsHandler(this);\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    coreLoadExecutor = new ThreadPoolExecutor(coreLoadThreads, coreLoadThreads, 1,\n        TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<String> allCores = cfg.getAllCoreNames();\n\n      for (String oneCoreName : allCores) {\n\n        try {\n          String rawName = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NAME, null);\n\n          if (null == rawName) {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Each core in solr.xml must have a 'name'\");\n          }\n          final String name = rawName;\n          final CoreDescriptor p = new CoreDescriptor(this, name,\n              cfg.getProperty(oneCoreName, CoreDescriptor.CORE_INSTDIR, null));\n          \n          // deal with optional settings\n          String opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_CONFIG, null);\n          \n          if (opt != null) {\n            p.setConfigName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SCHEMA, null);\n          if (opt != null) {\n            p.setSchemaName(opt);\n          }\n          \n          if (zkSys.getZkController() != null) {\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SHARD, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setShardId(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_COLLECTION, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setCollectionName(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_ROLES, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setRoles(opt);\n            }\n\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NODE_NAME, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setCoreNodeName(opt);\n            }\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_PROPERTIES, null);\n          if (opt != null) {\n            p.setPropertiesName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_DATADIR, null);\n          if (opt != null) {\n            p.setDataDir(opt);\n          }\n          \n          p.setCoreProperties(cfg.readCoreProperties(oneCoreName));\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_LOADONSTARTUP, null);\n          if (opt != null) {\n            p.setLoadOnStartup((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_TRANSIENT, null);\n          if (opt != null) {\n            p.setTransient((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n\n          if (p.isTransient() || ! p.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(rawName, p);\n          }\n\n          if (p.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(p);\n                  }\n                  c = create(p);\n                  registerCore(p.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, p);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n          \n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7116474e2e390259937401cf928323e0cbc75e60","date":1372780249,"type":1,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load(String,InputStream,String).mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    ThreadPoolExecutor coreLoadExecutor = null;\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    libDir = cfg.get(ConfigSolr.CfgProp.SOLR_SHAREDLIB , null);\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = initShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg, loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg, loader);\n\n    if (cfg instanceof ConfigSolrXmlOld) { //TODO: Remove for 5.0\n      String dcoreName = cfg.get(ConfigSolr.CfgProp.SOLR_CORES_DEFAULT_CORE_NAME, null);\n      if (dcoreName != null && !dcoreName.isEmpty()) {\n        defaultCoreName = dcoreName;\n      }\n      persistent = cfg.getBool(ConfigSolr.CfgProp.SOLR_PERSISTENT, false);\n      adminPath = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINPATH, \"/admin/cores\");\n    } else {\n      adminPath = \"/admin/cores\";\n      defaultCoreName = DEFAULT_DEFAULT_CORE_NAME;\n    }\n    zkHost = cfg.get(ConfigSolr.CfgProp.SOLR_ZKHOST, null);\n    coreLoadThreads = cfg.getInt(ConfigSolr.CfgProp.SOLR_CORELOADTHREADS, CORE_LOAD_THREADS);\n    \n\n    shareSchema = cfg.getBool(ConfigSolr.CfgProp.SOLR_SHARESCHEMA, DEFAULT_SHARE_SCHEMA);\n    zkClientTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_ZKCLIENTTIMEOUT, DEFAULT_ZK_CLIENT_TIMEOUT);\n    \n    distribUpdateConnTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATECONNTIMEOUT, 0);\n    distribUpdateSoTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATESOTIMEOUT, 0);\n\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostPort = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTPORT, null);\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostContext = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTCONTEXT, null);\n\n    String host = cfg.get(ConfigSolr.CfgProp.SOLR_HOST, null);\n    \n    String leaderVoteWait = cfg.get(ConfigSolr.CfgProp.SOLR_LEADERVOTEWAIT, LEADER_VOTE_WAIT);\n\n    adminHandler = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINHANDLER, null);\n    managementPath = cfg.get(ConfigSolr.CfgProp.SOLR_MANAGEMENTPATH, null);\n\n    transientCacheSize = cfg.getInt(ConfigSolr.CfgProp.SOLR_TRANSIENTCACHESIZE, Integer.MAX_VALUE);\n\n    boolean genericCoreNodeNames = cfg.getBool(ConfigSolr.CfgProp.SOLR_GENERICCORENODENAMES, false);\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkClientTimeout = Integer.parseInt(System.getProperty(\"zkClientTimeout\",\n        Integer.toString(zkClientTimeout)));\n    zkSys.initZooKeeper(this, solrHome, zkHost, zkClientTimeout, hostPort, hostContext, host, leaderVoteWait, genericCoreNodeNames, distribUpdateConnTimeout, distribUpdateSoTimeout);\n    \n    if (isZooKeeperAware() && coreLoadThreads <= 1) {\n      throw new SolrException(ErrorCode.SERVER_ERROR,\n          \"SolrCloud requires a value of at least 2 in solr.xml for coreLoadThreads\");\n    }\n    \n    if (adminPath != null) {\n      if (adminHandler == null) {\n        coreAdminHandler = new CoreAdminHandler(this);\n      } else {\n        coreAdminHandler = this.createMultiCoreHandler(adminHandler);\n      }\n    }\n    \n    collectionsHandler = new CollectionsHandler(this);\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    coreLoadExecutor = new ThreadPoolExecutor(coreLoadThreads, coreLoadThreads, 1,\n        TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<String> allCores = cfg.getAllCoreNames();\n\n      for (String oneCoreName : allCores) {\n\n        try {\n          String rawName = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NAME, null);\n\n          if (null == rawName) {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Each core in solr.xml must have a 'name'\");\n          }\n          final String name = rawName;\n          final CoreDescriptor p = new CoreDescriptor(this, name,\n              cfg.getProperty(oneCoreName, CoreDescriptor.CORE_INSTDIR, null));\n          \n          // deal with optional settings\n          String opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_CONFIG, null);\n          \n          if (opt != null) {\n            p.setConfigName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SCHEMA, null);\n          if (opt != null) {\n            p.setSchemaName(opt);\n          }\n          \n          if (zkSys.getZkController() != null) {\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SHARD, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setShardId(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_COLLECTION, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setCollectionName(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_ROLES, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setRoles(opt);\n            }\n\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NODE_NAME, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setCoreNodeName(opt);\n            }\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_PROPERTIES, null);\n          if (opt != null) {\n            p.setPropertiesName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_DATADIR, null);\n          if (opt != null) {\n            p.setDataDir(opt);\n          }\n          \n          p.setCoreProperties(cfg.readCoreProperties(oneCoreName));\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_LOADONSTARTUP, null);\n          if (opt != null) {\n            p.setLoadOnStartup((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_TRANSIENT, null);\n          if (opt != null) {\n            p.setTransient((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n\n          if (p.isTransient() || ! p.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(rawName, p);\n          }\n\n          if (p.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(p);\n                  }\n                  c = create(p);\n                  registerCore(p.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, p);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n          \n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load a config file listing the available solr cores.\n   * \n   * @param dir the home directory of all resources.\n   * @param is the configuration file InputStream. May be a properties file or an xml file\n   */\n\n  // Let's keep this ugly boolean out of public circulation.\n  protected void load(String dir, InputStream is, String fileName)  {\n    ThreadPoolExecutor coreLoadExecutor = null;\n    if (null == dir) {\n      // don't rely on SolrResourceLoader(), determine explicitly first\n      dir = SolrResourceLoader.locateSolrHome();\n    }\n    log.info(\"Loading CoreContainer using Solr Home: '{}'\", dir);\n    \n    this.loader = new SolrResourceLoader(dir);\n    solrHome = loader.getInstanceDir();\n\n    try {\n      Config config = new Config(loader, null, new InputSource(is), null, false);\n\n      // old style defines cores in solr.xml, new style disovers them by \n      // directory structure\n      boolean oldStyle = (config.getNode(\"solr/cores\", false) != null);\n      \n      if (oldStyle) {\n        // ConfigSolr handles keep orig values around for non solrcore level items,\n        // but this is still how original core lvl attributes are kept around\n        this.origCfg = new Config(loader, null, copyDoc(config.getDocument()));\n        \n        this.cfg = new ConfigSolrXmlOld(config, this);\n      } else {\n        this.cfg = new ConfigSolrXml(config, this);\n\n      }\n    } catch (Exception e) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, \"\", e);\n    }\n    // Since the cores var is now initialized to null, let's set it up right\n    // now.\n    cfg.substituteProperties();\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    libDir = cfg.get(ConfigSolr.CfgProp.SOLR_SHAREDLIB , null);\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(dir), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = initShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg, loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg, loader);\n\n    if (cfg instanceof ConfigSolrXmlOld) { //TODO: Remove for 5.0\n      String dcoreName = cfg.get(ConfigSolr.CfgProp.SOLR_CORES_DEFAULT_CORE_NAME, null);\n      if (dcoreName != null && !dcoreName.isEmpty()) {\n        defaultCoreName = dcoreName;\n      }\n      persistent = cfg.getBool(ConfigSolr.CfgProp.SOLR_PERSISTENT, false);\n      adminPath = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINPATH, \"/admin/cores\");\n    } else {\n      adminPath = \"/admin/cores\";\n      defaultCoreName = DEFAULT_DEFAULT_CORE_NAME;\n    }\n    zkHost = cfg.get(ConfigSolr.CfgProp.SOLR_ZKHOST, null);\n    coreLoadThreads = cfg.getInt(ConfigSolr.CfgProp.SOLR_CORELOADTHREADS, CORE_LOAD_THREADS);\n    \n\n    shareSchema = cfg.getBool(ConfigSolr.CfgProp.SOLR_SHARESCHEMA, DEFAULT_SHARE_SCHEMA);\n    zkClientTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_ZKCLIENTTIMEOUT, DEFAULT_ZK_CLIENT_TIMEOUT);\n    \n    distribUpdateConnTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATECONNTIMEOUT, 0);\n    distribUpdateSoTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATESOTIMEOUT, 0);\n\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostPort = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTPORT, null);\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostContext = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTCONTEXT, null);\n\n    String host = cfg.get(ConfigSolr.CfgProp.SOLR_HOST, null);\n    \n    String leaderVoteWait = cfg.get(ConfigSolr.CfgProp.SOLR_LEADERVOTEWAIT, LEADER_VOTE_WAIT);\n\n    adminHandler = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINHANDLER, null);\n    managementPath = cfg.get(ConfigSolr.CfgProp.SOLR_MANAGEMENTPATH, null);\n\n    transientCacheSize = cfg.getInt(ConfigSolr.CfgProp.SOLR_TRANSIENTCACHESIZE, Integer.MAX_VALUE);\n\n    boolean genericCoreNodeNames = cfg.getBool(ConfigSolr.CfgProp.SOLR_GENERICCORENODENAMES, false);\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkClientTimeout = Integer.parseInt(System.getProperty(\"zkClientTimeout\",\n        Integer.toString(zkClientTimeout)));\n    zkSys.initZooKeeper(this, solrHome, zkHost, zkClientTimeout, hostPort, hostContext, host, leaderVoteWait, genericCoreNodeNames, distribUpdateConnTimeout, distribUpdateSoTimeout);\n    \n    if (isZooKeeperAware() && coreLoadThreads <= 1) {\n      throw new SolrException(ErrorCode.SERVER_ERROR,\n          \"SolrCloud requires a value of at least 2 in solr.xml for coreLoadThreads\");\n    }\n    \n    if (adminPath != null) {\n      if (adminHandler == null) {\n        coreAdminHandler = new CoreAdminHandler(this);\n      } else {\n        coreAdminHandler = this.createMultiCoreHandler(adminHandler);\n      }\n    }\n    \n    collectionsHandler = new CollectionsHandler(this);\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    coreLoadExecutor = new ThreadPoolExecutor(coreLoadThreads, coreLoadThreads, 1,\n        TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<String> allCores = cfg.getAllCoreNames();\n\n      for (String oneCoreName : allCores) {\n\n        try {\n          String rawName = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NAME, null);\n\n          if (null == rawName) {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Each core in solr.xml must have a 'name'\");\n          }\n          final String name = rawName;\n          final CoreDescriptor p = new CoreDescriptor(this, name,\n              cfg.getProperty(oneCoreName, CoreDescriptor.CORE_INSTDIR, null));\n          \n          // deal with optional settings\n          String opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_CONFIG, null);\n          \n          if (opt != null) {\n            p.setConfigName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SCHEMA, null);\n          if (opt != null) {\n            p.setSchemaName(opt);\n          }\n          \n          if (zkSys.getZkController() != null) {\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SHARD, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setShardId(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_COLLECTION, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setCollectionName(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_ROLES, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setRoles(opt);\n            }\n\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NODE_NAME, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setCoreNodeName(opt);\n            }\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_PROPERTIES, null);\n          if (opt != null) {\n            p.setPropertiesName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_DATADIR, null);\n          if (opt != null) {\n            p.setDataDir(opt);\n          }\n          \n          p.setCoreProperties(cfg.readCoreProperties(oneCoreName));\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_LOADONSTARTUP, null);\n          if (opt != null) {\n            p.setLoadOnStartup((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_TRANSIENT, null);\n          if (opt != null) {\n            p.setTransient((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n\n          if (p.isTransient() || ! p.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(rawName, p);\n          }\n\n          if (p.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(p);\n                  }\n                  c = create(p);\n                  registerCore(p.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, p);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n          \n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b64a893a6d2efaa60e289534b1f8713e4aa2c776","date":1373480880,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    ThreadPoolExecutor coreLoadExecutor = null;\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    libDir = cfg.get(ConfigSolr.CfgProp.SOLR_SHAREDLIB , null);\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = initShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg, loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg, loader);\n\n    if (cfg instanceof ConfigSolrXmlOld) { //TODO: Remove for 5.0\n      String dcoreName = cfg.get(ConfigSolr.CfgProp.SOLR_CORES_DEFAULT_CORE_NAME, null);\n      if (dcoreName != null && !dcoreName.isEmpty()) {\n        defaultCoreName = dcoreName;\n      }\n      persistent = cfg.getBool(ConfigSolr.CfgProp.SOLR_PERSISTENT, false);\n      adminPath = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINPATH, \"/admin/cores\");\n    } else {\n      adminPath = \"/admin/cores\";\n      defaultCoreName = DEFAULT_DEFAULT_CORE_NAME;\n    }\n    zkHost = cfg.get(ConfigSolr.CfgProp.SOLR_ZKHOST, null);\n    coreLoadThreads = cfg.getInt(ConfigSolr.CfgProp.SOLR_CORELOADTHREADS, CORE_LOAD_THREADS);\n    \n\n    shareSchema = cfg.getBool(ConfigSolr.CfgProp.SOLR_SHARESCHEMA, DEFAULT_SHARE_SCHEMA);\n    zkClientTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_ZKCLIENTTIMEOUT, DEFAULT_ZK_CLIENT_TIMEOUT);\n    \n    distribUpdateConnTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATECONNTIMEOUT, 0);\n    distribUpdateSoTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATESOTIMEOUT, 0);\n\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostPort = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTPORT, null);\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostContext = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTCONTEXT, null);\n\n    String host = cfg.get(ConfigSolr.CfgProp.SOLR_HOST, null);\n    \n    String leaderVoteWait = cfg.get(ConfigSolr.CfgProp.SOLR_LEADERVOTEWAIT, LEADER_VOTE_WAIT);\n\n    adminHandler = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINHANDLER, null);\n    managementPath = cfg.get(ConfigSolr.CfgProp.SOLR_MANAGEMENTPATH, null);\n\n    transientCacheSize = cfg.getInt(ConfigSolr.CfgProp.SOLR_TRANSIENTCACHESIZE, Integer.MAX_VALUE);\n\n    boolean genericCoreNodeNames = cfg.getBool(ConfigSolr.CfgProp.SOLR_GENERICCORENODENAMES, false);\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkClientTimeout = Integer.parseInt(System.getProperty(\"zkClientTimeout\",\n        Integer.toString(zkClientTimeout)));\n    zkSys.initZooKeeper(this, solrHome, zkHost, zkClientTimeout, hostPort, hostContext, host, leaderVoteWait, genericCoreNodeNames, distribUpdateConnTimeout, distribUpdateSoTimeout);\n    \n    if (isZooKeeperAware() && coreLoadThreads <= 1) {\n      throw new SolrException(ErrorCode.SERVER_ERROR,\n          \"SolrCloud requires a value of at least 2 in solr.xml for coreLoadThreads\");\n    }\n    \n    if (adminPath != null) {\n      if (adminHandler == null) {\n        coreAdminHandler = new CoreAdminHandler(this);\n      } else {\n        coreAdminHandler = this.createMultiCoreHandler(adminHandler);\n      }\n    }\n    \n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    coreLoadExecutor = new ThreadPoolExecutor(coreLoadThreads, coreLoadThreads, 1,\n        TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<String> allCores = cfg.getAllCoreNames();\n\n      for (String oneCoreName : allCores) {\n\n        try {\n          String rawName = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NAME, null);\n\n          if (null == rawName) {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Each core in solr.xml must have a 'name'\");\n          }\n          final String name = rawName;\n          final CoreDescriptor p = new CoreDescriptor(this, name,\n              cfg.getProperty(oneCoreName, CoreDescriptor.CORE_INSTDIR, null));\n          \n          // deal with optional settings\n          String opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_CONFIG, null);\n          \n          if (opt != null) {\n            p.setConfigName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SCHEMA, null);\n          if (opt != null) {\n            p.setSchemaName(opt);\n          }\n          \n          if (zkSys.getZkController() != null) {\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SHARD, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setShardId(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_COLLECTION, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setCollectionName(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_ROLES, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setRoles(opt);\n            }\n\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NODE_NAME, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setCoreNodeName(opt);\n            }\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_PROPERTIES, null);\n          if (opt != null) {\n            p.setPropertiesName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_DATADIR, null);\n          if (opt != null) {\n            p.setDataDir(opt);\n          }\n          \n          p.setCoreProperties(cfg.readCoreProperties(oneCoreName));\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_LOADONSTARTUP, null);\n          if (opt != null) {\n            p.setLoadOnStartup((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_TRANSIENT, null);\n          if (opt != null) {\n            p.setTransient((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n\n          if (p.isTransient() || ! p.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(rawName, p);\n          }\n\n          if (p.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(p);\n                  }\n                  c = create(p);\n                  registerCore(p.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, p);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n          \n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    ThreadPoolExecutor coreLoadExecutor = null;\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    libDir = cfg.get(ConfigSolr.CfgProp.SOLR_SHAREDLIB , null);\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = initShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg, loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg, loader);\n\n    if (cfg instanceof ConfigSolrXmlOld) { //TODO: Remove for 5.0\n      String dcoreName = cfg.get(ConfigSolr.CfgProp.SOLR_CORES_DEFAULT_CORE_NAME, null);\n      if (dcoreName != null && !dcoreName.isEmpty()) {\n        defaultCoreName = dcoreName;\n      }\n      persistent = cfg.getBool(ConfigSolr.CfgProp.SOLR_PERSISTENT, false);\n      adminPath = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINPATH, \"/admin/cores\");\n    } else {\n      adminPath = \"/admin/cores\";\n      defaultCoreName = DEFAULT_DEFAULT_CORE_NAME;\n    }\n    zkHost = cfg.get(ConfigSolr.CfgProp.SOLR_ZKHOST, null);\n    coreLoadThreads = cfg.getInt(ConfigSolr.CfgProp.SOLR_CORELOADTHREADS, CORE_LOAD_THREADS);\n    \n\n    shareSchema = cfg.getBool(ConfigSolr.CfgProp.SOLR_SHARESCHEMA, DEFAULT_SHARE_SCHEMA);\n    zkClientTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_ZKCLIENTTIMEOUT, DEFAULT_ZK_CLIENT_TIMEOUT);\n    \n    distribUpdateConnTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATECONNTIMEOUT, 0);\n    distribUpdateSoTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATESOTIMEOUT, 0);\n\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostPort = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTPORT, null);\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostContext = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTCONTEXT, null);\n\n    String host = cfg.get(ConfigSolr.CfgProp.SOLR_HOST, null);\n    \n    String leaderVoteWait = cfg.get(ConfigSolr.CfgProp.SOLR_LEADERVOTEWAIT, LEADER_VOTE_WAIT);\n\n    adminHandler = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINHANDLER, null);\n    managementPath = cfg.get(ConfigSolr.CfgProp.SOLR_MANAGEMENTPATH, null);\n\n    transientCacheSize = cfg.getInt(ConfigSolr.CfgProp.SOLR_TRANSIENTCACHESIZE, Integer.MAX_VALUE);\n\n    boolean genericCoreNodeNames = cfg.getBool(ConfigSolr.CfgProp.SOLR_GENERICCORENODENAMES, false);\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkClientTimeout = Integer.parseInt(System.getProperty(\"zkClientTimeout\",\n        Integer.toString(zkClientTimeout)));\n    zkSys.initZooKeeper(this, solrHome, zkHost, zkClientTimeout, hostPort, hostContext, host, leaderVoteWait, genericCoreNodeNames, distribUpdateConnTimeout, distribUpdateSoTimeout);\n    \n    if (isZooKeeperAware() && coreLoadThreads <= 1) {\n      throw new SolrException(ErrorCode.SERVER_ERROR,\n          \"SolrCloud requires a value of at least 2 in solr.xml for coreLoadThreads\");\n    }\n    \n    if (adminPath != null) {\n      if (adminHandler == null) {\n        coreAdminHandler = new CoreAdminHandler(this);\n      } else {\n        coreAdminHandler = this.createMultiCoreHandler(adminHandler);\n      }\n    }\n    \n    collectionsHandler = new CollectionsHandler(this);\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    coreLoadExecutor = new ThreadPoolExecutor(coreLoadThreads, coreLoadThreads, 1,\n        TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<String> allCores = cfg.getAllCoreNames();\n\n      for (String oneCoreName : allCores) {\n\n        try {\n          String rawName = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NAME, null);\n\n          if (null == rawName) {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Each core in solr.xml must have a 'name'\");\n          }\n          final String name = rawName;\n          final CoreDescriptor p = new CoreDescriptor(this, name,\n              cfg.getProperty(oneCoreName, CoreDescriptor.CORE_INSTDIR, null));\n          \n          // deal with optional settings\n          String opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_CONFIG, null);\n          \n          if (opt != null) {\n            p.setConfigName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SCHEMA, null);\n          if (opt != null) {\n            p.setSchemaName(opt);\n          }\n          \n          if (zkSys.getZkController() != null) {\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SHARD, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setShardId(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_COLLECTION, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setCollectionName(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_ROLES, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setRoles(opt);\n            }\n\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NODE_NAME, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setCoreNodeName(opt);\n            }\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_PROPERTIES, null);\n          if (opt != null) {\n            p.setPropertiesName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_DATADIR, null);\n          if (opt != null) {\n            p.setDataDir(opt);\n          }\n          \n          p.setCoreProperties(cfg.readCoreProperties(oneCoreName));\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_LOADONSTARTUP, null);\n          if (opt != null) {\n            p.setLoadOnStartup((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_TRANSIENT, null);\n          if (opt != null) {\n            p.setTransient((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n\n          if (p.isTransient() || ! p.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(rawName, p);\n          }\n\n          if (p.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(p);\n                  }\n                  c = create(p);\n                  registerCore(p.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, p);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n          \n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f225b9b576dc345ee8c27f91147b4afc0350511c","date":1373552135,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    ThreadPoolExecutor coreLoadExecutor = null;\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    libDir = cfg.get(ConfigSolr.CfgProp.SOLR_SHAREDLIB , null);\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg, loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg, loader);\n\n    if (cfg instanceof ConfigSolrXmlOld) { //TODO: Remove for 5.0\n      String dcoreName = cfg.get(ConfigSolr.CfgProp.SOLR_CORES_DEFAULT_CORE_NAME, null);\n      if (dcoreName != null && !dcoreName.isEmpty()) {\n        defaultCoreName = dcoreName;\n      }\n      persistent = cfg.getBool(ConfigSolr.CfgProp.SOLR_PERSISTENT, false);\n      adminPath = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINPATH, \"/admin/cores\");\n    } else {\n      adminPath = \"/admin/cores\";\n      defaultCoreName = DEFAULT_DEFAULT_CORE_NAME;\n    }\n    zkHost = cfg.get(ConfigSolr.CfgProp.SOLR_ZKHOST, null);\n    coreLoadThreads = cfg.getInt(ConfigSolr.CfgProp.SOLR_CORELOADTHREADS, CORE_LOAD_THREADS);\n    \n\n    shareSchema = cfg.getBool(ConfigSolr.CfgProp.SOLR_SHARESCHEMA, DEFAULT_SHARE_SCHEMA);\n    zkClientTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_ZKCLIENTTIMEOUT, DEFAULT_ZK_CLIENT_TIMEOUT);\n    \n    distribUpdateConnTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATECONNTIMEOUT, 0);\n    distribUpdateSoTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATESOTIMEOUT, 0);\n\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostPort = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTPORT, null);\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostContext = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTCONTEXT, null);\n\n    String host = cfg.get(ConfigSolr.CfgProp.SOLR_HOST, null);\n    \n    String leaderVoteWait = cfg.get(ConfigSolr.CfgProp.SOLR_LEADERVOTEWAIT, LEADER_VOTE_WAIT);\n\n    adminHandler = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINHANDLER, null);\n    managementPath = cfg.get(ConfigSolr.CfgProp.SOLR_MANAGEMENTPATH, null);\n\n    transientCacheSize = cfg.getInt(ConfigSolr.CfgProp.SOLR_TRANSIENTCACHESIZE, Integer.MAX_VALUE);\n\n    boolean genericCoreNodeNames = cfg.getBool(ConfigSolr.CfgProp.SOLR_GENERICCORENODENAMES, false);\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkClientTimeout = Integer.parseInt(System.getProperty(\"zkClientTimeout\",\n        Integer.toString(zkClientTimeout)));\n    zkSys.initZooKeeper(this, solrHome, zkHost, zkClientTimeout, hostPort, hostContext, host, leaderVoteWait, genericCoreNodeNames, distribUpdateConnTimeout, distribUpdateSoTimeout);\n    \n    if (isZooKeeperAware() && coreLoadThreads <= 1) {\n      throw new SolrException(ErrorCode.SERVER_ERROR,\n          \"SolrCloud requires a value of at least 2 in solr.xml for coreLoadThreads\");\n    }\n    \n    if (adminPath != null) {\n      if (adminHandler == null) {\n        coreAdminHandler = new CoreAdminHandler(this);\n      } else {\n        coreAdminHandler = this.createMultiCoreHandler(adminHandler);\n      }\n    }\n    \n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    coreLoadExecutor = new ThreadPoolExecutor(coreLoadThreads, coreLoadThreads, 1,\n        TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<String> allCores = cfg.getAllCoreNames();\n\n      for (String oneCoreName : allCores) {\n\n        try {\n          String rawName = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NAME, null);\n\n          if (null == rawName) {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Each core in solr.xml must have a 'name'\");\n          }\n          final String name = rawName;\n          final CoreDescriptor p = new CoreDescriptor(this, name,\n              cfg.getProperty(oneCoreName, CoreDescriptor.CORE_INSTDIR, null));\n          \n          // deal with optional settings\n          String opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_CONFIG, null);\n          \n          if (opt != null) {\n            p.setConfigName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SCHEMA, null);\n          if (opt != null) {\n            p.setSchemaName(opt);\n          }\n          \n          if (zkSys.getZkController() != null) {\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SHARD, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setShardId(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_COLLECTION, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setCollectionName(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_ROLES, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setRoles(opt);\n            }\n\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NODE_NAME, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setCoreNodeName(opt);\n            }\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_PROPERTIES, null);\n          if (opt != null) {\n            p.setPropertiesName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_DATADIR, null);\n          if (opt != null) {\n            p.setDataDir(opt);\n          }\n          \n          p.setCoreProperties(cfg.readCoreProperties(oneCoreName));\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_LOADONSTARTUP, null);\n          if (opt != null) {\n            p.setLoadOnStartup((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_TRANSIENT, null);\n          if (opt != null) {\n            p.setTransient((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n\n          if (p.isTransient() || ! p.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(rawName, p);\n          }\n\n          if (p.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(p);\n                  }\n                  c = create(p);\n                  registerCore(p.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, p);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n          \n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    ThreadPoolExecutor coreLoadExecutor = null;\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    libDir = cfg.get(ConfigSolr.CfgProp.SOLR_SHAREDLIB , null);\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = initShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg, loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg, loader);\n\n    if (cfg instanceof ConfigSolrXmlOld) { //TODO: Remove for 5.0\n      String dcoreName = cfg.get(ConfigSolr.CfgProp.SOLR_CORES_DEFAULT_CORE_NAME, null);\n      if (dcoreName != null && !dcoreName.isEmpty()) {\n        defaultCoreName = dcoreName;\n      }\n      persistent = cfg.getBool(ConfigSolr.CfgProp.SOLR_PERSISTENT, false);\n      adminPath = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINPATH, \"/admin/cores\");\n    } else {\n      adminPath = \"/admin/cores\";\n      defaultCoreName = DEFAULT_DEFAULT_CORE_NAME;\n    }\n    zkHost = cfg.get(ConfigSolr.CfgProp.SOLR_ZKHOST, null);\n    coreLoadThreads = cfg.getInt(ConfigSolr.CfgProp.SOLR_CORELOADTHREADS, CORE_LOAD_THREADS);\n    \n\n    shareSchema = cfg.getBool(ConfigSolr.CfgProp.SOLR_SHARESCHEMA, DEFAULT_SHARE_SCHEMA);\n    zkClientTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_ZKCLIENTTIMEOUT, DEFAULT_ZK_CLIENT_TIMEOUT);\n    \n    distribUpdateConnTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATECONNTIMEOUT, 0);\n    distribUpdateSoTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATESOTIMEOUT, 0);\n\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostPort = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTPORT, null);\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostContext = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTCONTEXT, null);\n\n    String host = cfg.get(ConfigSolr.CfgProp.SOLR_HOST, null);\n    \n    String leaderVoteWait = cfg.get(ConfigSolr.CfgProp.SOLR_LEADERVOTEWAIT, LEADER_VOTE_WAIT);\n\n    adminHandler = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINHANDLER, null);\n    managementPath = cfg.get(ConfigSolr.CfgProp.SOLR_MANAGEMENTPATH, null);\n\n    transientCacheSize = cfg.getInt(ConfigSolr.CfgProp.SOLR_TRANSIENTCACHESIZE, Integer.MAX_VALUE);\n\n    boolean genericCoreNodeNames = cfg.getBool(ConfigSolr.CfgProp.SOLR_GENERICCORENODENAMES, false);\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkClientTimeout = Integer.parseInt(System.getProperty(\"zkClientTimeout\",\n        Integer.toString(zkClientTimeout)));\n    zkSys.initZooKeeper(this, solrHome, zkHost, zkClientTimeout, hostPort, hostContext, host, leaderVoteWait, genericCoreNodeNames, distribUpdateConnTimeout, distribUpdateSoTimeout);\n    \n    if (isZooKeeperAware() && coreLoadThreads <= 1) {\n      throw new SolrException(ErrorCode.SERVER_ERROR,\n          \"SolrCloud requires a value of at least 2 in solr.xml for coreLoadThreads\");\n    }\n    \n    if (adminPath != null) {\n      if (adminHandler == null) {\n        coreAdminHandler = new CoreAdminHandler(this);\n      } else {\n        coreAdminHandler = this.createMultiCoreHandler(adminHandler);\n      }\n    }\n    \n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    coreLoadExecutor = new ThreadPoolExecutor(coreLoadThreads, coreLoadThreads, 1,\n        TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<String> allCores = cfg.getAllCoreNames();\n\n      for (String oneCoreName : allCores) {\n\n        try {\n          String rawName = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NAME, null);\n\n          if (null == rawName) {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Each core in solr.xml must have a 'name'\");\n          }\n          final String name = rawName;\n          final CoreDescriptor p = new CoreDescriptor(this, name,\n              cfg.getProperty(oneCoreName, CoreDescriptor.CORE_INSTDIR, null));\n          \n          // deal with optional settings\n          String opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_CONFIG, null);\n          \n          if (opt != null) {\n            p.setConfigName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SCHEMA, null);\n          if (opt != null) {\n            p.setSchemaName(opt);\n          }\n          \n          if (zkSys.getZkController() != null) {\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SHARD, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setShardId(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_COLLECTION, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setCollectionName(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_ROLES, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setRoles(opt);\n            }\n\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NODE_NAME, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setCoreNodeName(opt);\n            }\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_PROPERTIES, null);\n          if (opt != null) {\n            p.setPropertiesName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_DATADIR, null);\n          if (opt != null) {\n            p.setDataDir(opt);\n          }\n          \n          p.setCoreProperties(cfg.readCoreProperties(oneCoreName));\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_LOADONSTARTUP, null);\n          if (opt != null) {\n            p.setLoadOnStartup((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_TRANSIENT, null);\n          if (opt != null) {\n            p.setTransient((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n\n          if (p.isTransient() || ! p.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(rawName, p);\n          }\n\n          if (p.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(p);\n                  }\n                  c = create(p);\n                  registerCore(p.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, p);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n          \n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","bugFix":["c7c73b6560033b6dcc828fbcc94ba9315c20f3c0"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6e764e9a107f93be9fa3c922bc6a197b3eec387e","date":1373560501,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    ThreadPoolExecutor coreLoadExecutor = null;\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    libDir = cfg.get(ConfigSolr.CfgProp.SOLR_SHAREDLIB , null);\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg, loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg, loader);\n\n    if (cfg instanceof ConfigSolrXmlOld) { //TODO: Remove for 5.0\n      String dcoreName = cfg.get(ConfigSolr.CfgProp.SOLR_CORES_DEFAULT_CORE_NAME, null);\n      if (dcoreName != null && !dcoreName.isEmpty()) {\n        defaultCoreName = dcoreName;\n      }\n      persistent = cfg.getBool(ConfigSolr.CfgProp.SOLR_PERSISTENT, false);\n      adminPath = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINPATH, \"/admin/cores\");\n    } else {\n      adminPath = \"/admin/cores\";\n      defaultCoreName = DEFAULT_DEFAULT_CORE_NAME;\n    }\n    zkHost = cfg.get(ConfigSolr.CfgProp.SOLR_ZKHOST, null);\n    coreLoadThreads = cfg.getInt(ConfigSolr.CfgProp.SOLR_CORELOADTHREADS, CORE_LOAD_THREADS);\n    \n\n    shareSchema = cfg.getBool(ConfigSolr.CfgProp.SOLR_SHARESCHEMA, DEFAULT_SHARE_SCHEMA);\n    zkClientTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_ZKCLIENTTIMEOUT, DEFAULT_ZK_CLIENT_TIMEOUT);\n    \n    distribUpdateConnTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATECONNTIMEOUT, 0);\n    distribUpdateSoTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATESOTIMEOUT, 0);\n\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostPort = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTPORT, null);\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostContext = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTCONTEXT, null);\n\n    String host = cfg.get(ConfigSolr.CfgProp.SOLR_HOST, null);\n    \n    String leaderVoteWait = cfg.get(ConfigSolr.CfgProp.SOLR_LEADERVOTEWAIT, LEADER_VOTE_WAIT);\n\n    adminHandler = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINHANDLER, null);\n    managementPath = cfg.get(ConfigSolr.CfgProp.SOLR_MANAGEMENTPATH, null);\n\n    transientCacheSize = cfg.getInt(ConfigSolr.CfgProp.SOLR_TRANSIENTCACHESIZE, Integer.MAX_VALUE);\n\n    boolean genericCoreNodeNames = cfg.getBool(ConfigSolr.CfgProp.SOLR_GENERICCORENODENAMES, false);\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkClientTimeout = Integer.parseInt(System.getProperty(\"zkClientTimeout\",\n        Integer.toString(zkClientTimeout)));\n    zkSys.initZooKeeper(this, solrHome, zkHost, zkClientTimeout, hostPort, hostContext, host, leaderVoteWait, genericCoreNodeNames, distribUpdateConnTimeout, distribUpdateSoTimeout);\n    \n    if (isZooKeeperAware() && coreLoadThreads <= 1) {\n      throw new SolrException(ErrorCode.SERVER_ERROR,\n          \"SolrCloud requires a value of at least 2 in solr.xml for coreLoadThreads\");\n    }\n    \n    if (adminPath != null) {\n      if (adminHandler == null) {\n        coreAdminHandler = new CoreAdminHandler(this);\n      } else {\n        coreAdminHandler = this.createMultiCoreHandler(adminHandler);\n      }\n    }\n    \n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    coreLoadExecutor = new ThreadPoolExecutor(coreLoadThreads, coreLoadThreads, 1,\n        TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n          \n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    ThreadPoolExecutor coreLoadExecutor = null;\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    libDir = cfg.get(ConfigSolr.CfgProp.SOLR_SHAREDLIB , null);\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg, loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg, loader);\n\n    if (cfg instanceof ConfigSolrXmlOld) { //TODO: Remove for 5.0\n      String dcoreName = cfg.get(ConfigSolr.CfgProp.SOLR_CORES_DEFAULT_CORE_NAME, null);\n      if (dcoreName != null && !dcoreName.isEmpty()) {\n        defaultCoreName = dcoreName;\n      }\n      persistent = cfg.getBool(ConfigSolr.CfgProp.SOLR_PERSISTENT, false);\n      adminPath = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINPATH, \"/admin/cores\");\n    } else {\n      adminPath = \"/admin/cores\";\n      defaultCoreName = DEFAULT_DEFAULT_CORE_NAME;\n    }\n    zkHost = cfg.get(ConfigSolr.CfgProp.SOLR_ZKHOST, null);\n    coreLoadThreads = cfg.getInt(ConfigSolr.CfgProp.SOLR_CORELOADTHREADS, CORE_LOAD_THREADS);\n    \n\n    shareSchema = cfg.getBool(ConfigSolr.CfgProp.SOLR_SHARESCHEMA, DEFAULT_SHARE_SCHEMA);\n    zkClientTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_ZKCLIENTTIMEOUT, DEFAULT_ZK_CLIENT_TIMEOUT);\n    \n    distribUpdateConnTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATECONNTIMEOUT, 0);\n    distribUpdateSoTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATESOTIMEOUT, 0);\n\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostPort = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTPORT, null);\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostContext = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTCONTEXT, null);\n\n    String host = cfg.get(ConfigSolr.CfgProp.SOLR_HOST, null);\n    \n    String leaderVoteWait = cfg.get(ConfigSolr.CfgProp.SOLR_LEADERVOTEWAIT, LEADER_VOTE_WAIT);\n\n    adminHandler = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINHANDLER, null);\n    managementPath = cfg.get(ConfigSolr.CfgProp.SOLR_MANAGEMENTPATH, null);\n\n    transientCacheSize = cfg.getInt(ConfigSolr.CfgProp.SOLR_TRANSIENTCACHESIZE, Integer.MAX_VALUE);\n\n    boolean genericCoreNodeNames = cfg.getBool(ConfigSolr.CfgProp.SOLR_GENERICCORENODENAMES, false);\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkClientTimeout = Integer.parseInt(System.getProperty(\"zkClientTimeout\",\n        Integer.toString(zkClientTimeout)));\n    zkSys.initZooKeeper(this, solrHome, zkHost, zkClientTimeout, hostPort, hostContext, host, leaderVoteWait, genericCoreNodeNames, distribUpdateConnTimeout, distribUpdateSoTimeout);\n    \n    if (isZooKeeperAware() && coreLoadThreads <= 1) {\n      throw new SolrException(ErrorCode.SERVER_ERROR,\n          \"SolrCloud requires a value of at least 2 in solr.xml for coreLoadThreads\");\n    }\n    \n    if (adminPath != null) {\n      if (adminHandler == null) {\n        coreAdminHandler = new CoreAdminHandler(this);\n      } else {\n        coreAdminHandler = this.createMultiCoreHandler(adminHandler);\n      }\n    }\n    \n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    coreLoadExecutor = new ThreadPoolExecutor(coreLoadThreads, coreLoadThreads, 1,\n        TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<String> allCores = cfg.getAllCoreNames();\n\n      for (String oneCoreName : allCores) {\n\n        try {\n          String rawName = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NAME, null);\n\n          if (null == rawName) {\n            throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n                \"Each core in solr.xml must have a 'name'\");\n          }\n          final String name = rawName;\n          final CoreDescriptor p = new CoreDescriptor(this, name,\n              cfg.getProperty(oneCoreName, CoreDescriptor.CORE_INSTDIR, null));\n          \n          // deal with optional settings\n          String opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_CONFIG, null);\n          \n          if (opt != null) {\n            p.setConfigName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SCHEMA, null);\n          if (opt != null) {\n            p.setSchemaName(opt);\n          }\n          \n          if (zkSys.getZkController() != null) {\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_SHARD, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setShardId(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_COLLECTION, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setCollectionName(opt);\n            }\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_ROLES, null);\n            if (opt != null) {\n              p.getCloudDescriptor().setRoles(opt);\n            }\n\n            opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_NODE_NAME, null);\n            if (opt != null && opt.length() > 0) {\n              p.getCloudDescriptor().setCoreNodeName(opt);\n            }\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_PROPERTIES, null);\n          if (opt != null) {\n            p.setPropertiesName(opt);\n          }\n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_DATADIR, null);\n          if (opt != null) {\n            p.setDataDir(opt);\n          }\n          \n          p.setCoreProperties(cfg.readCoreProperties(oneCoreName));\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_LOADONSTARTUP, null);\n          if (opt != null) {\n            p.setLoadOnStartup((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n          \n          opt = cfg.getProperty(oneCoreName, CoreDescriptor.CORE_TRANSIENT, null);\n          if (opt != null) {\n            p.setTransient((\"true\".equalsIgnoreCase(opt) || \"on\"\n                .equalsIgnoreCase(opt)) ? true : false);\n          }\n\n          if (p.isTransient() || ! p.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(rawName, p);\n          }\n\n          if (p.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(p);\n                  }\n                  c = create(p);\n                  registerCore(p.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, p);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n          \n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":0,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    ThreadPoolExecutor coreLoadExecutor = null;\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    libDir = cfg.get(ConfigSolr.CfgProp.SOLR_SHAREDLIB , null);\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg, loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg, loader);\n\n    if (cfg instanceof ConfigSolrXmlOld) { //TODO: Remove for 5.0\n      String dcoreName = cfg.get(ConfigSolr.CfgProp.SOLR_CORES_DEFAULT_CORE_NAME, null);\n      if (dcoreName != null && !dcoreName.isEmpty()) {\n        defaultCoreName = dcoreName;\n      }\n      persistent = cfg.getBool(ConfigSolr.CfgProp.SOLR_PERSISTENT, false);\n      adminPath = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINPATH, \"/admin/cores\");\n    } else {\n      adminPath = \"/admin/cores\";\n      defaultCoreName = DEFAULT_DEFAULT_CORE_NAME;\n    }\n    zkHost = cfg.get(ConfigSolr.CfgProp.SOLR_ZKHOST, null);\n    coreLoadThreads = cfg.getInt(ConfigSolr.CfgProp.SOLR_CORELOADTHREADS, CORE_LOAD_THREADS);\n    \n\n    shareSchema = cfg.getBool(ConfigSolr.CfgProp.SOLR_SHARESCHEMA, DEFAULT_SHARE_SCHEMA);\n    zkClientTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_ZKCLIENTTIMEOUT, DEFAULT_ZK_CLIENT_TIMEOUT);\n    \n    distribUpdateConnTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATECONNTIMEOUT, 0);\n    distribUpdateSoTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATESOTIMEOUT, 0);\n\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostPort = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTPORT, null);\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostContext = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTCONTEXT, null);\n\n    String host = cfg.get(ConfigSolr.CfgProp.SOLR_HOST, null);\n    \n    String leaderVoteWait = cfg.get(ConfigSolr.CfgProp.SOLR_LEADERVOTEWAIT, LEADER_VOTE_WAIT);\n\n    adminHandler = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINHANDLER, null);\n    managementPath = cfg.get(ConfigSolr.CfgProp.SOLR_MANAGEMENTPATH, null);\n\n    transientCacheSize = cfg.getInt(ConfigSolr.CfgProp.SOLR_TRANSIENTCACHESIZE, Integer.MAX_VALUE);\n\n    boolean genericCoreNodeNames = cfg.getBool(ConfigSolr.CfgProp.SOLR_GENERICCORENODENAMES, false);\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkClientTimeout = Integer.parseInt(System.getProperty(\"zkClientTimeout\",\n        Integer.toString(zkClientTimeout)));\n    zkSys.initZooKeeper(this, solrHome, zkHost, zkClientTimeout, hostPort, hostContext, host, leaderVoteWait, genericCoreNodeNames, distribUpdateConnTimeout, distribUpdateSoTimeout);\n    \n    if (isZooKeeperAware() && coreLoadThreads <= 1) {\n      throw new SolrException(ErrorCode.SERVER_ERROR,\n          \"SolrCloud requires a value of at least 2 in solr.xml for coreLoadThreads\");\n    }\n    \n    if (adminPath != null) {\n      if (adminHandler == null) {\n        coreAdminHandler = new CoreAdminHandler(this);\n      } else {\n        coreAdminHandler = this.createMultiCoreHandler(adminHandler);\n      }\n    }\n    \n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    coreLoadExecutor = new ThreadPoolExecutor(coreLoadThreads, coreLoadThreads, 1,\n        TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n          \n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92a4da96826f502cf1a56a096929b37ce73e523a","date":1374584011,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    coreAdminHandler = createMultiCoreHandler(cfg.getCoreAdminHandlerClass());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(cfg.getCoreLoadThreadCount(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    ThreadPoolExecutor coreLoadExecutor = null;\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    libDir = cfg.get(ConfigSolr.CfgProp.SOLR_SHAREDLIB , null);\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg, loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg, loader);\n\n    if (cfg instanceof ConfigSolrXmlOld) { //TODO: Remove for 5.0\n      String dcoreName = cfg.get(ConfigSolr.CfgProp.SOLR_CORES_DEFAULT_CORE_NAME, null);\n      if (dcoreName != null && !dcoreName.isEmpty()) {\n        defaultCoreName = dcoreName;\n      }\n      persistent = cfg.getBool(ConfigSolr.CfgProp.SOLR_PERSISTENT, false);\n      adminPath = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINPATH, \"/admin/cores\");\n    } else {\n      adminPath = \"/admin/cores\";\n      defaultCoreName = DEFAULT_DEFAULT_CORE_NAME;\n    }\n    zkHost = cfg.get(ConfigSolr.CfgProp.SOLR_ZKHOST, null);\n    coreLoadThreads = cfg.getInt(ConfigSolr.CfgProp.SOLR_CORELOADTHREADS, CORE_LOAD_THREADS);\n    \n\n    shareSchema = cfg.getBool(ConfigSolr.CfgProp.SOLR_SHARESCHEMA, DEFAULT_SHARE_SCHEMA);\n    zkClientTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_ZKCLIENTTIMEOUT, DEFAULT_ZK_CLIENT_TIMEOUT);\n    \n    distribUpdateConnTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATECONNTIMEOUT, 0);\n    distribUpdateSoTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATESOTIMEOUT, 0);\n\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostPort = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTPORT, null);\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostContext = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTCONTEXT, null);\n\n    String host = cfg.get(ConfigSolr.CfgProp.SOLR_HOST, null);\n    \n    String leaderVoteWait = cfg.get(ConfigSolr.CfgProp.SOLR_LEADERVOTEWAIT, LEADER_VOTE_WAIT);\n\n    adminHandler = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINHANDLER, null);\n    managementPath = cfg.get(ConfigSolr.CfgProp.SOLR_MANAGEMENTPATH, null);\n\n    transientCacheSize = cfg.getInt(ConfigSolr.CfgProp.SOLR_TRANSIENTCACHESIZE, Integer.MAX_VALUE);\n\n    boolean genericCoreNodeNames = cfg.getBool(ConfigSolr.CfgProp.SOLR_GENERICCORENODENAMES, false);\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkClientTimeout = Integer.parseInt(System.getProperty(\"zkClientTimeout\",\n        Integer.toString(zkClientTimeout)));\n    zkSys.initZooKeeper(this, solrHome, zkHost, zkClientTimeout, hostPort, hostContext, host, leaderVoteWait, genericCoreNodeNames, distribUpdateConnTimeout, distribUpdateSoTimeout);\n    \n    if (isZooKeeperAware() && coreLoadThreads <= 1) {\n      throw new SolrException(ErrorCode.SERVER_ERROR,\n          \"SolrCloud requires a value of at least 2 in solr.xml for coreLoadThreads\");\n    }\n    \n    if (adminPath != null) {\n      if (adminHandler == null) {\n        coreAdminHandler = new CoreAdminHandler(this);\n      } else {\n        coreAdminHandler = this.createMultiCoreHandler(adminHandler);\n      }\n    }\n    \n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    coreLoadExecutor = new ThreadPoolExecutor(coreLoadThreads, coreLoadThreads, 1,\n        TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n          \n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["c8c09c323959c458fb515b3f9a2ce29958ce1478","275019a81d0883a1db4560391b072d1fbe272ec4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec","date":1376375609,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    coreAdminHandler = createMultiCoreHandler(cfg.getCoreAdminHandlerClass());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(cfg.getCoreLoadThreadCount(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    ThreadPoolExecutor coreLoadExecutor = null;\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    libDir = cfg.get(ConfigSolr.CfgProp.SOLR_SHAREDLIB , null);\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg, loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg, loader);\n\n    if (cfg instanceof ConfigSolrXmlOld) { //TODO: Remove for 5.0\n      String dcoreName = cfg.get(ConfigSolr.CfgProp.SOLR_CORES_DEFAULT_CORE_NAME, null);\n      if (dcoreName != null && !dcoreName.isEmpty()) {\n        defaultCoreName = dcoreName;\n      }\n      persistent = cfg.getBool(ConfigSolr.CfgProp.SOLR_PERSISTENT, false);\n      adminPath = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINPATH, \"/admin/cores\");\n    } else {\n      adminPath = \"/admin/cores\";\n      defaultCoreName = DEFAULT_DEFAULT_CORE_NAME;\n    }\n    zkHost = cfg.get(ConfigSolr.CfgProp.SOLR_ZKHOST, null);\n    coreLoadThreads = cfg.getInt(ConfigSolr.CfgProp.SOLR_CORELOADTHREADS, CORE_LOAD_THREADS);\n    \n\n    shareSchema = cfg.getBool(ConfigSolr.CfgProp.SOLR_SHARESCHEMA, DEFAULT_SHARE_SCHEMA);\n    zkClientTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_ZKCLIENTTIMEOUT, DEFAULT_ZK_CLIENT_TIMEOUT);\n    \n    distribUpdateConnTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATECONNTIMEOUT, 0);\n    distribUpdateSoTimeout = cfg.getInt(ConfigSolr.CfgProp.SOLR_DISTRIBUPDATESOTIMEOUT, 0);\n\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostPort = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTPORT, null);\n    // Note: initZooKeeper will apply hardcoded default if cloud mode\n    String hostContext = cfg.get(ConfigSolr.CfgProp.SOLR_HOSTCONTEXT, null);\n\n    String host = cfg.get(ConfigSolr.CfgProp.SOLR_HOST, null);\n    \n    String leaderVoteWait = cfg.get(ConfigSolr.CfgProp.SOLR_LEADERVOTEWAIT, LEADER_VOTE_WAIT);\n\n    adminHandler = cfg.get(ConfigSolr.CfgProp.SOLR_ADMINHANDLER, null);\n    managementPath = cfg.get(ConfigSolr.CfgProp.SOLR_MANAGEMENTPATH, null);\n\n    transientCacheSize = cfg.getInt(ConfigSolr.CfgProp.SOLR_TRANSIENTCACHESIZE, Integer.MAX_VALUE);\n\n    boolean genericCoreNodeNames = cfg.getBool(ConfigSolr.CfgProp.SOLR_GENERICCORENODENAMES, false);\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkClientTimeout = Integer.parseInt(System.getProperty(\"zkClientTimeout\",\n        Integer.toString(zkClientTimeout)));\n    zkSys.initZooKeeper(this, solrHome, zkHost, zkClientTimeout, hostPort, hostContext, host, leaderVoteWait, genericCoreNodeNames, distribUpdateConnTimeout, distribUpdateSoTimeout);\n    \n    if (isZooKeeperAware() && coreLoadThreads <= 1) {\n      throw new SolrException(ErrorCode.SERVER_ERROR,\n          \"SolrCloud requires a value of at least 2 in solr.xml for coreLoadThreads\");\n    }\n    \n    if (adminPath != null) {\n      if (adminHandler == null) {\n        coreAdminHandler = new CoreAdminHandler(this);\n      } else {\n        coreAdminHandler = this.createMultiCoreHandler(adminHandler);\n      }\n    }\n    \n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    coreLoadExecutor = new ThreadPoolExecutor(coreLoadThreads, coreLoadThreads, 1,\n        TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n      \n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n          \n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5e732472e86aa53222c571de21dcb7d6a75c1c87","date":1377608255,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    coreAdminHandler = createMultiCoreHandler(cfg.getCoreAdminHandlerClass());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(cfg.getCoreLoadThreadCount(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    coreAdminHandler = createMultiCoreHandler(cfg.getCoreAdminHandlerClass());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(cfg.getCoreLoadThreadCount(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3dffec77fb8f7d0e9ca4869dddd6af94528b4576","date":1377875202,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    coreAdminHandler = createMultiCoreHandler(cfg.getCoreAdminHandlerClass());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(cfg.getCoreLoadThreadCount(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = JulWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    coreAdminHandler = createMultiCoreHandler(cfg.getCoreAdminHandlerClass());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(cfg.getCoreLoadThreadCount(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c8c09c323959c458fb515b3f9a2ce29958ce1478","date":1379384090,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    coreAdminHandler = createMultiCoreHandler(cfg.getCoreAdminHandlerClass());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    coreAdminHandler = createMultiCoreHandler(cfg.getCoreAdminHandlerClass());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(cfg.getCoreLoadThreadCount(),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\"));\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","bugFix":["92a4da96826f502cf1a56a096929b37ce73e523a","5ce60a6712f1e8ef7077bc4051aefc65f457f283"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d275f25d46bec8d215cc9d810169af5bf57ff35a","date":1383462494,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    coreAdminHandler = createMultiCoreHandler(cfg.getCoreAdminHandlerClass());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }*/\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    coreAdminHandler = createMultiCoreHandler(cfg.getCoreAdminHandlerClass());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n                  if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d9d424bd039937b4125152b454b3a32754b06f6c","date":1384391321,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n    \n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    coreAdminHandler = createMultiCoreHandler(cfg.getCoreAdminHandlerClass());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }*/\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    coreAdminHandler = createMultiCoreHandler(cfg.getCoreAdminHandlerClass());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }*/\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a7035935aa89f6951286e9005cbeb16e89a082a2","date":1385258396,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    \n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n    \n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    coreAdminHandler = createMultiCoreHandler(cfg.getCoreAdminHandlerClass());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }*/\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n    \n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    coreAdminHandler = createMultiCoreHandler(cfg.getCoreAdminHandlerClass());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }*/\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f763a1acdb27217b4799d1ca51c816739835a3e0","date":1387388124,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    \n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n    \n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }*/\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    \n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n    \n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    coreAdminHandler = createMultiCoreHandler(cfg.getCoreAdminHandlerClass());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }*/\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    \n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n    \n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }*/\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n    \n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = new CollectionsHandler(this);\n    infoHandler = new InfoHandler(this);\n    coreAdminHandler = createMultiCoreHandler(cfg.getCoreAdminHandlerClass());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }*/\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"97bd2b0da4beced82821b752b29576be986cf1ff","date":1387747012,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    \n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n    \n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false, false);\n                } catch (Throwable t) {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }*/\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    \n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n    \n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false);\n                } catch (Throwable t) {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }*/\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":["275019a81d0883a1db4560391b072d1fbe272ec4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f56da6f4f15d95f318d2d6ac2a39a9183dfecff2","date":1389633998,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    \n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n    \n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false, false);\n                } catch (Exception e) {\n                  SolrException.log(log, null, e);\n                  try {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e2) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e2);\n                    } catch (KeeperException e3) {\n                      SolrException.log(log, null, e3);\n                    }\n                  }*/\n                  } finally {\n                    if (c != null) {\n                      c.close();\n                    }\n                  }            \n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Exception e) {\n          SolrException.log(log, null, e);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    \n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n    \n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false, false);\n                } catch (Throwable t) {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e);\n                    } catch (KeeperException e) {\n                      SolrException.log(log, null, e);\n                    }\n                  }*/\n                  SolrException.log(log, null, t);\n                  if (c != null) {\n                    c.close();\n                  }\n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Throwable ex) {\n          SolrException.log(log, null, ex);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":["36f2b01395ef2bc334ebf2f94f2fe44e0f2921b1","5ce60a6712f1e8ef7077bc4051aefc65f457f283"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    \n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<>();\n    }\n    \n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false, false);\n                } catch (Exception e) {\n                  SolrException.log(log, null, e);\n                  try {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e2) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e2);\n                    } catch (KeeperException e3) {\n                      SolrException.log(log, null, e3);\n                    }\n                  }*/\n                  } finally {\n                    if (c != null) {\n                      c.close();\n                    }\n                  }            \n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Exception e) {\n          SolrException.log(log, null, e);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    \n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<String,IndexSchema>();\n    }\n    \n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<SolrCore>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<Future<SolrCore>>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false, false);\n                } catch (Exception e) {\n                  SolrException.log(log, null, e);\n                  try {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e2) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e2);\n                    } catch (KeeperException e3) {\n                      SolrException.log(log, null, e3);\n                    }\n                  }*/\n                  } finally {\n                    if (c != null) {\n                      c.close();\n                    }\n                  }            \n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Exception e) {\n          SolrException.log(log, null, e);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7e66d99e5beccb546edd910c91f646fb7d831a94","date":1395391298,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    \n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<>();\n    }\n    \n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false, false);\n                } catch (Exception e) {\n                  SolrException.log(log, null, e);\n                  try {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e2) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e2);\n                    } catch (KeeperException e3) {\n                      SolrException.log(log, null, e3);\n                    }\n                  }*/\n                  } finally {\n                    if (c != null) {\n                      c.close();\n                    }\n                  }            \n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Exception e) {\n          SolrException.log(log, null, e);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    \n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<>();\n    }\n    \n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false, false);\n                } catch (Exception e) {\n                  SolrException.log(log, null, e);\n                  try {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e2) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e2);\n                    } catch (KeeperException e3) {\n                      SolrException.log(log, null, e3);\n                    }\n                  }*/\n                  } finally {\n                    if (c != null) {\n                      c.close();\n                    }\n                  }            \n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Exception e) {\n          SolrException.log(log, null, e);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2d4e985daefcb892b529223b478c47985fc3c483","date":1395658491,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    coreConfigService = cfg.createCoreConfigService(loader, zkSys.getZkController());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false, false);\n                } catch (Exception e) {\n                  SolrException.log(log, null, e);\n                  try {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e2) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e2);\n                    } catch (KeeperException e3) {\n                      SolrException.log(log, null, e3);\n                    }\n                  }*/\n                  } finally {\n                    if (c != null) {\n                      c.close();\n                    }\n                  }            \n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Exception e) {\n          SolrException.log(log, null, e);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    \n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    shareSchema = cfg.hasSchemaCache();\n\n    if (shareSchema) {\n      indexSchemaCache = new ConcurrentHashMap<>();\n    }\n    \n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false, false);\n                } catch (Exception e) {\n                  SolrException.log(log, null, e);\n                  try {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e2) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e2);\n                    } catch (KeeperException e3) {\n                      SolrException.log(log, null, e3);\n                    }\n                  }*/\n                  } finally {\n                    if (c != null) {\n                      c.close();\n                    }\n                  }            \n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Exception e) {\n          SolrException.log(log, null, e);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"85032ab568b3f50eabd577aaa994ba197db93758","date":1404157267,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    coreConfigService = cfg.createCoreConfigService(loader, zkSys.getZkController());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                try {\n                  return create(cd, false);\n                } catch (Exception e) {\n                  SolrException.log(log, null, e);\n                  return null;\n                }\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Exception e) {\n          SolrException.log(log, null, e);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    coreConfigService = cfg.createCoreConfigService(loader, zkSys.getZkController());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                SolrCore c = null;\n                try {\n                  if (zkSys.getZkController() != null) {\n                    preRegisterInZk(cd);\n                  }\n                  c = create(cd);\n                  registerCore(cd.isTransient(), name, c, false, false);\n                } catch (Exception e) {\n                  SolrException.log(log, null, e);\n                  try {\n              /*    if (isZooKeeperAware()) {\n                    try {\n                      zkSys.zkController.unregister(name, cd);\n                    } catch (InterruptedException e2) {\n                      Thread.currentThread().interrupt();\n                      SolrException.log(log, null, e2);\n                    } catch (KeeperException e3) {\n                      SolrException.log(log, null, e3);\n                    }\n                  }*/\n                  } finally {\n                    if (c != null) {\n                      c.close();\n                    }\n                  }            \n                }\n                return c;\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Exception e) {\n          SolrException.log(log, null, e);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a4d419cdab641a032f3e0d0fa8167a5252be0ae3","date":1404159924,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    coreConfigService = cfg.createCoreConfigService(loader, zkSys.getZkController());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    coreConfigService = cfg.createCoreConfigService(loader, zkSys.getZkController());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n      CompletionService<SolrCore> completionService = new ExecutorCompletionService<>(\n          coreLoadExecutor);\n\n      Set<Future<SolrCore>> pending = new HashSet<>();\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n\n        final String name = cd.getName();\n        try {\n\n          if (cd.isTransient() || ! cd.isLoadOnStartup()) {\n            // Store it away for later use. includes non-transient but not\n            // loaded at startup cores.\n            solrCores.putDynamicDescriptor(name, cd);\n          }\n          if (cd.isLoadOnStartup()) { // The normal case\n\n            Callable<SolrCore> task = new Callable<SolrCore>() {\n              @Override\n              public SolrCore call() {\n                try {\n                  return create(cd, false);\n                } catch (Exception e) {\n                  SolrException.log(log, null, e);\n                  return null;\n                }\n              }\n            };\n            pending.add(completionService.submit(task));\n\n          }\n        } catch (Exception e) {\n          SolrException.log(log, null, e);\n        }\n      }\n\n      while (pending != null && pending.size() > 0) {\n        try {\n\n          Future<SolrCore> future = completionService.take();\n          if (future == null) return;\n          pending.remove(future);\n\n          try {\n            SolrCore c = future.get();\n            // track original names\n            if (c != null) {\n              solrCores.putCoreToOrigName(c, c.getName());\n            }\n          } catch (ExecutionException e) {\n            SolrException.log(SolrCore.log, \"Error loading core\", e);\n          }\n\n        } catch (InterruptedException e) {\n          throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE,\n              \"interrupted while loading core\", e);\n        }\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (coreLoadExecutor != null) {\n        ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":["275019a81d0883a1db4560391b072d1fbe272ec4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0ad7bdba3e91cf3373cda2e52239cb761fc0b452","date":1408019547,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    coreConfigService = cfg.createCoreConfigService(loader, zkSys.getZkController());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    coreConfigService = cfg.createCoreConfigService(loader, zkSys.getZkController());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":["275019a81d0883a1db4560391b072d1fbe272ec4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7947ef57ebadfb891b1c694f0772d616987e57c8","date":1412445663,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(\"/admin/collections\" , collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(\"/admin/info\" , infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(cfg.getAdminPath() , coreAdminHandler);\n\n    coreConfigService = cfg.createCoreConfigService(loader, zkSys.getZkController());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    coreConfigService = cfg.createCoreConfigService(loader, zkSys.getZkController());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5ba0abe4039f82ecf2e5f879913f512e941dde81","date":1412520276,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(\"/admin/collections\" , collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(\"/admin/info\" , infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(cfg.getAdminPath() , coreAdminHandler);\n\n    coreConfigService = cfg.createCoreConfigService(loader, zkSys.getZkController());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    coreConfigService = cfg.createCoreConfigService(loader, zkSys.getZkController());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd44bec977a26a118d9e809e2de6f7edb5ca0f39","date":1421673929,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = cfg.createCoreConfigService(loader, zkSys.getZkController());\n\n    containerProperties = cfg.getSolrProperties();\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(\"/admin/collections\" , collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(\"/admin/info\" , infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(cfg.getAdminPath() , coreAdminHandler);\n\n    coreConfigService = cfg.createCoreConfigService(loader, zkSys.getZkController());\n\n    containerProperties = cfg.getSolrProperties(\"solr\");\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e15199583d3635cb940942caed05132dd6c4c7c6","date":1424875551,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n    log.info(\"Node Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties = cfg.getSolrProperties();\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = cfg.createCoreConfigService(loader, zkSys.getZkController());\n\n    containerProperties = cfg.getSolrProperties();\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9bc766d645fa848f86c381c7f6acf2c881c99399","date":1425549246,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n    log.info(\"Node Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n    log.info(\"Node Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties = cfg.getSolrProperties();\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n    log.info(\"Node Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg);\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getHost();\n    log.info(\"Host Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg);\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = cfg.createCoreConfigService(loader, zkSys.getZkController());\n\n    containerProperties = cfg.getSolrProperties();\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cb5af3afeddbb803fb785098176e6e177c34261b","date":1428905393,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n    log.info(\"Node Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      MDC.put(NODE_NAME_PROP, getZkController().getNodeName());\n    }\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n    log.info(\"Node Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = Executors.newFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c3c3931df936f937d0001d9fda9ead62f8599479","date":1429011920,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n    log.info(\"Node Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n    log.info(\"Node Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      MDC.put(NODE_NAME_PROP, getZkController().getNodeName());\n    }\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"00e1c8e1340d9e31d2c6bee5f72d9040ce569049","date":1431584404,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n    log.info(\"Node Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      intializeAuthorizationPlugin();\n    }\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n    log.info(\"Node Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"58b7eb80017f1c5b32035176b965fa0cc0287d04","date":1432069816,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n    log.info(\"Node Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n\n    initializeAuthenticationPlugin();\n\n    if (isZooKeeperAware()) {\n      intializeAuthorizationPlugin();\n    }\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n    log.info(\"Node Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      intializeAuthorizationPlugin();\n    }\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"439c63ae5d22132fca810a0029a854e97d2c1a3e","date":1432733612,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n\n    initializeAuthenticationPlugin();\n\n    if (isZooKeeperAware()) {\n      intializeAuthorizationPlugin();\n    }\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n    log.info(\"Node Name: \" + hostName);\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n\n    initializeAuthenticationPlugin();\n\n    if (isZooKeeperAware()) {\n      intializeAuthorizationPlugin();\n    }\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"275019a81d0883a1db4560391b072d1fbe272ec4","date":1432741049,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n\n    initializeAuthenticationPlugin();\n\n    if (isZooKeeperAware()) {\n      intializeAuthorizationPlugin();\n    }\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (Throwable t) {\n                SolrException.log(log, \"Error registering SolrCore\", t);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n\n    initializeAuthenticationPlugin();\n\n    if (isZooKeeperAware()) {\n      intializeAuthorizationPlugin();\n    }\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n      List<Callable<SolrCore>> creators = new ArrayList<>();\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          creators.add(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              return create(cd, false);   \n            }\n          });\n        }\n      }\n\n      try {\n        coreLoadExecutor.invokeAll(creators);\n      }\n      catch (InterruptedException e) {\n        throw new SolrException(SolrException.ErrorCode.SERVICE_UNAVAILABLE, \"Interrupted while loading cores\");\n      }\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n    }\n    \n    if (isZooKeeperAware()) {\n      // register in zk in background threads\n      Collection<SolrCore> cores = getCores();\n      if (cores != null) {\n        for (SolrCore core : cores) {\n          try {\n            zkSys.registerInZk(core, true);\n          } catch (Throwable t) {\n            SolrException.log(log, \"Error registering SolrCore\", t);\n          }\n        }\n      }\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":["0ad7bdba3e91cf3373cda2e52239cb761fc0b452","92a4da96826f502cf1a56a096929b37ce73e523a","97bd2b0da4beced82821b752b29576be986cf1ff","a4d419cdab641a032f3e0d0fa8167a5252be0ae3","b24326411db492f92ea49f6fb947c90bc73cf19e"],"bugIntro":["10399eb409ace56e6d66f136f184643f7432371d"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b3a34dae868734612eb6329aa0ef754f30bd2036","date":1438783154,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    initializeAuthenticationPlugin();\n\n    if (isZooKeeperAware()) {\n      intializeAuthorizationPlugin();\n    }\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (Throwable t) {\n                SolrException.log(log, \"Error registering SolrCore\", t);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n\n    initializeAuthenticationPlugin();\n\n    if (isZooKeeperAware()) {\n      intializeAuthorizationPlugin();\n    }\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (Throwable t) {\n                SolrException.log(log, \"Error registering SolrCore\", t);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":["946009ad0fba506337041a368b0a74d2edd59e2c"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6bdcb86c29922edae9a14852e636303bc52df094","date":1438887454,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    containerHandlers.put(\"/admin/authorization\", securityConfHandler);\n    containerHandlers.put(\"/admin/authentication\", securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (Throwable t) {\n                SolrException.log(log, \"Error registering SolrCore\", t);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    initializeAuthenticationPlugin();\n\n    if (isZooKeeperAware()) {\n      intializeAuthorizationPlugin();\n    }\n\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (Throwable t) {\n                SolrException.log(log, \"Error registering SolrCore\", t);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":["e78c35bca3e32dfc7a695136fa2b5de1ae135c22"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2209af2c265d2258ec4b29c8cc78622d36994a15","date":1440641916,"type":3,"author":"Gregory Chanan","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(\"/admin/authorization\", securityConfHandler);\n    containerHandlers.put(\"/admin/authentication\", securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (Throwable t) {\n                SolrException.log(log, \"Error registering SolrCore\", t);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    containerHandlers.put(\"/admin/authorization\", securityConfHandler);\n    containerHandlers.put(\"/admin/authentication\", securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (Throwable t) {\n                SolrException.log(log, \"Error registering SolrCore\", t);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b9248e8833b6ab03d4e0ebbeaa8b26d8798e7659","date":1440978271,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(\"/admin/authorization\", securityConfHandler);\n    containerHandlers.put(\"/admin/authentication\", securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (Throwable t) {\n                SolrException.log(log, \"Error registering SolrCore\", t);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(\"/admin/authorization\", securityConfHandler);\n    containerHandlers.put(\"/admin/authentication\", securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (Throwable t) {\n                SolrException.log(log, \"Error registering SolrCore\", t);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownNowAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e78c35bca3e32dfc7a695136fa2b5de1ae135c22","date":1441118240,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (Throwable t) {\n                SolrException.log(log, \"Error registering SolrCore\", t);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(\"/admin/authorization\", securityConfHandler);\n    containerHandlers.put(\"/admin/authentication\", securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (Throwable t) {\n                SolrException.log(log, \"Error registering SolrCore\", t);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":["6bdcb86c29922edae9a14852e636303bc52df094"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"80ebe5b1d946f7c2ed9c46206b0c7254dc21206a","date":1443442239,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (Throwable t) {\n                SolrException.log(log, \"Error registering SolrCore\", t);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (Throwable t) {\n                SolrException.log(log, \"Error registering SolrCore\", t);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"10399eb409ace56e6d66f136f184643f7432371d","date":1446743029,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (RuntimeException e) {\n                SolrException.log(log, \"Error registering SolrCore\", e);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (Throwable t) {\n                SolrException.log(log, \"Error registering SolrCore\", t);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":["275019a81d0883a1db4560391b072d1fbe272ec4"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a626ec4d1c92e59fe390724d6220081047b03ce7","date":1448021525,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (RuntimeException e) {\n                SolrException.log(log, \"Error registering SolrCore\", e);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstanceDir());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      File f = FileUtils.resolvePath(new File(solrHome), libDir);\n      log.info(\"loading shared library: \" + f.getAbsolutePath());\n      loader.addToClassLoader(libDir, null, false);\n      loader.reloadLuceneSPI();\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (RuntimeException e) {\n                SolrException.log(log, \"Error registering SolrCore\", e);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fb65cc25534f4e0d77ed573d35995eb0b836b818","date":1454441028,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n\n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (RuntimeException e) {\n                SolrException.log(log, \"Error registering SolrCore\", e);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (RuntimeException e) {\n                SolrException.log(log, \"Error registering SolrCore\", e);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":["004ec9e26487ae9b6205e790f8f77ef5e98d8daf"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"acd1f5a977dc3b97799ed300423294e2c457774f","date":1454537003,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n\n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (RuntimeException e) {\n                SolrException.log(log, \"Error registering SolrCore\", e);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (RuntimeException e) {\n                SolrException.log(log, \"Error registering SolrCore\", e);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1e6acbaae7af722f17204ceccf0f7db5753eccf3","date":1454775255,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n\n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (RuntimeException e) {\n                SolrException.log(log, \"Error registering SolrCore\", e);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n                \n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (RuntimeException e) {\n                SolrException.log(log, \"Error registering SolrCore\", e);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n    \n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"043df2e9a841864922c32756a44c939ed768cb89","date":1459876536,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n\n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (RuntimeException e) {\n                SolrException.log(log, \"Error registering SolrCore\", e);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b6284684320a9808c41a5e43de958b2da22f89bd","date":1459977490,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(new Callable<SolrCore>() {\n            @Override\n            public SolrCore call() throws Exception {\n              SolrCore core;\n              try {\n                if (zkSys.getZkController() != null) {\n                  zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n                }\n\n                core = create(cd, false);\n              } finally {\n                if (asyncSolrCoreLoad) {\n                  solrCores.markCoreAsNotLoading(cd);\n                }\n              }\n              try {\n                zkSys.registerInZk(core, true);\n              } catch (RuntimeException e) {\n                SolrException.log(log, \"Error registering SolrCore\", e);\n              }\n              return core;\n            }\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b","date":1466705968,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cc69baf14413994ccde897681e5ce1d393cf7156","date":1468245555,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e22a92d60a5a6320f9653856966fcd77c60953b3","date":1468676579,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware() ? DEFAULT_CORE_LOAD_THREADS_IN_CLOUD : DEFAULT_CORE_LOAD_THREADS),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":["f3783d6f4d080f4f0116769e0e1b0f0f440565c4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f3783d6f4d080f4f0116769e0e1b0f0f440565c4","date":1468932683,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware() ? DEFAULT_CORE_LOAD_THREADS_IN_CLOUD : DEFAULT_CORE_LOAD_THREADS),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":["e22a92d60a5a6320f9653856966fcd77c60953b3"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"337a3230c591e6094030c97d6ed767b261bcd851","date":1474029187,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4aeabc53a9c50bd4c04c5261562b3e78cc2ea744","date":1474499907,"type":3,"author":"Jan Høydahl","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7f0c8426396c925de8db3ed3f8ff40fd73670a5c","date":1474556641,"type":3,"author":"Jan Høydahl","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"126d6ad24eed13163ba0959435d5a80e5672837c","date":1474567302,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d528fd7ae22865015b756e0a03832e2051de2a9c","date":1476721105,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.info(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    // do not limit the size of the executor in zk mode since cores may try and wait for each other.\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        ( zkSys.getZkController() == null ? cfg.getCoreLoadThreadCount() : Integer.MAX_VALUE ),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<Future<SolrCore>>();\n    try {\n\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      checkForDuplicateCoreNames(cds);\n\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n        Thread shutdownThread = new Thread() {\n          public void run() {\n            try {\n              for (Future<SolrCore> future : futures) {\n                try {\n                  future.get();\n                } catch (InterruptedException e) {\n                  Thread.currentThread().interrupt();\n                } catch (ExecutionException e) {\n                  log.error(\"Error waiting for SolrCore to be created\", e);\n                }\n              }\n            } finally {\n              ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n            }\n          }\n        };\n        coreContainerWorkExecutor.submit(shutdownThread);\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"170ef9c82c0d27d4151feff316ba63fbedd91bbf","date":1477436680,"type":3,"author":"Jan Høydahl","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b363b110592b02d7f488aff0dbe40a53d3ce81df","date":1477469211,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"80d0e6d59ae23f4a6f30eaf40bfb40742300287f","date":1477598926,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    ZkStateReader.ConfigData securityConfig = isZooKeeperAware() ? getZkController().getZkStateReader().getSecurityProps(false) : new ZkStateReader.ConfigData(EMPTY_MAP, -1);\n    initializeAuthorizationPlugin((Map<String, Object>) securityConfig.data.get(\"authorization\"));\n    initializeAuthenticationPlugin((Map<String, Object>) securityConfig.data.get(\"authentication\"));\n\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    securityConfHandler = new SecurityConfHandler(this);\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0265144286422ad99682a00904cc2536b79c8535","date":1482222684,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    metricManager = new SolrMetricManager();\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.http);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\", \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","date":1482251961,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    metricManager = new SolrMetricManager();\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.http);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\", \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(ZK_PATH, new ZookeeperInfoHandler(this));\n    collectionsHandler = createHandler(cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.put(COLLECTIONS_HANDLER_PATH, collectionsHandler);\n    infoHandler        = createHandler(cfg.getInfoHandlerClass(), InfoHandler.class);\n    containerHandlers.put(INFO_HANDLER_PATH, infoHandler);\n    coreAdminHandler   = createHandler(cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    containerHandlers.put(CORES_HANDLER_PATH, coreAdminHandler);\n    configSetsHandler = createHandler(cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    containerHandlers.put(CONFIGSETS_HANDLER_PATH, configSetsHandler);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"16fa358573e3c2508728b3c7c438a8c19a3f0ae4","date":1482846144,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.http.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.http.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.http);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\", \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    metricManager = new SolrMetricManager();\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.http);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\", \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bf28d12ff32dc50412338f84022406e2be7d44f2","date":1483438921,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.http.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.http.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.http);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\", \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.http.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.http.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.http);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\", \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f03e4bed5023ec3ef93a771b8888cae991cf448d","date":1483469262,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.http.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.http.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.http);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\", \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    metricManager = new SolrMetricManager();\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.http);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\", \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = ExecutorUtil.newMDCAwareFixedThreadPool(\n        cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n        new DefaultSolrThreadFactory(\"coreLoadExecutor\") );\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b16266db764c72c65ab2977b36da1436b4efbb9f","date":1483628123,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\", \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.http.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.http.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.http);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\", \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"491c9672ec42582fe43960452dbd37f1c80fe0f0","date":1483739222,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\", \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.http.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.http.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.http);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\", \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9b10b88c8af8835e23b0d566418ef8397a7bb8ed","date":1484223252,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\", \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","date":1484239864,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\", \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\", \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1214bb624eb41181e5c8e260e0050c7e973ba0f4","date":1487943042,"type":3,"author":"Jan Høydahl","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    pkiAuthenticationPlugin = isZooKeeperAware() ?\n        new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName()) :\n        new PKIAuthenticationPlugin(this, getNodeNameLocal());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b61ef53ee9899b83a89bf97542c28a4cfd0a64bf","date":1487979822,"type":3,"author":"Jan Høydahl","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    pkiAuthenticationPlugin = isZooKeeperAware() ?\n        new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName()) :\n        new PKIAuthenticationPlugin(this, getNodeNameLocal());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":["946009ad0fba506337041a368b0a74d2edd59e2c"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"073f1aa70444ec64f3e216816af2a3b43fa38fe7","date":1488920481,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f34d83c894e07c24f5f957820777b5da2cc29e5a","date":1489491395,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node);\n    metricManager.registerGauge(registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size(),\n        true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d402ed03d3abe439fa7859facfae3c2fe0aba77e","date":1489517911,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node);\n    metricManager.registerGauge(registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size(),\n        true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node);\n    metricManager.registerGauge(registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size(),\n        true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0d5e442cae8cd58c4f22df43dacbd0018fc0ac1b","date":1489651910,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node);\n    metricManager.registerGauge(registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size(),\n        true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6db2a2569883aff84117ae03caf199738df62519","date":1489651910,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node);\n    metricManager.registerGauge(registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size(),\n        true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node);\n    metricManager.registerGauge(registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size(),\n        true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ab68488225b6a6c357dda72ed11dedca9914a192","date":1490013111,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node);\n    metricManager.registerGauge(registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size(),\n        true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores\n    Gauge<Integer> loadedCores = () -> solrCores.getCores().size();\n    Gauge<Integer> lazyCores = () -> solrCores.getCoreNames().size() - solrCores.getCores().size();\n    Gauge<Integer> unloadedCores = () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size();\n\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        loadedCores, true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        lazyCores, true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.register(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node),\n        unloadedCores, true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9227359ab3bd86e5b85fab89a99332da7d5bacb1","date":1490341270,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node);\n    metricManager.registerGauge(registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size(),\n        true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node);\n    metricManager.registerGauge(registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size(),\n        true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9435d55e3ea95c5d94406d3affc36f9505b6a736","date":1491251232,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node);\n    metricManager.registerGauge(registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node);\n    metricManager.registerGauge(registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size(),\n        true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8b6a4b585aed7660a589375f6a09b90efd29c961","date":1491296430,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node);\n    metricManager.registerGauge(registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.allocateLazyCores(cfg.getTransientCacheSize(), loader);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node);\n    metricManager.registerGauge(registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getCoreNames().size(),\n        true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"816521ebaad5add9cb96bb88c577394e2938c40b","date":1491931343,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node);\n    metricManager.registerGauge(registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":["bfc52860e6d13d034226a760813c59d984c6817a"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"729cb470f975115d4c60517b2cb7c42e37a7a2e1","date":1492041760,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"54ca69905c5d9d1529286f06ab1d12c68f6c13cb","date":1492683554,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoMBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoMBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node);\n    metricManager.registerGauge(registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\",SolrInfoMBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoMBean.Category.CONTAINER.toString(), \"fs\");\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")),\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoMBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\",SolrInfoMBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.putDynamicDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"195fcfcffd8f9047ac27ac642ee9da64f4e6c4fa","date":1494330459,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2b2cafc02486bd97e4f7849f5360581a8084c8c1","date":1495567258,"type":3,"author":"Erick","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n      \n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a513b6a92751e54c76fb5447948c9e7d437163a7","date":1496136565,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n      \n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"74aea047dff7f7c38a2d766827bd20d356f98c6a","date":1496721416,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n      \n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager();\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(cfg.getMetricReporterPlugins(), loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(cfg.getMetricReporterPlugins(), this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7871f9c286dce2a9370bcf517a3e7d12e3bd9602","date":1498708934,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n      \n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"30c8e5574b55d57947e989443dfde611646530ee","date":1499131153,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    transientCoreCache = TransientSolrCoreCacheFactory.newInstance(loader, this);\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bd7a2b4785d366164d3cd69f9948de6ff34d23a1","date":1500527874,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d301cb76d81de80d07b44735622a04d49ed938eb","date":1500536382,"type":3,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"936cdd5882761db3b844afd6f84ab81cbb011a75","date":1500973524,"type":3,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = create(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"056ef30406180176075c44183ec40de4d2b8c68a","date":1501495731,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":["bfc52860e6d13d034226a760813c59d984c6817a"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2f472c757c161e228505e389efda705e2cf3c09e","date":1501700089,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b2fdcd0303309a07ecdda1d98f6806404d741129","date":1502140581,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","date":1502192746,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit((Runnable) () -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6a9fde5df1c4cdd5292c6a5292c39c630896af8c","date":1502287655,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":["bfc52860e6d13d034226a760813c59d984c6817a"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"58884af1f68e9d61c217c753fbd6266d86a63b14","date":1502363401,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.getTransientCacheHandler().addTransientDescriptor(cd.getName(), cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"93d40a0287bd8a5b69a8df49a797dcd4a8b1a7be","date":1502692251,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3301c97f51316f9c9937654c07d7a6a21e7aecb8","date":1503489616,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"004ec9e26487ae9b6205e790f8f77ef5e98d8daf","date":1506366751,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":["fb65cc25534f4e0d77ed573d35995eb0b836b818"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9efa9c0fcd87863d1a86eed29d4304c11bc7d50a","date":1506410441,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6240b74b884c5587f2a4062dd27d6c32bf228889","date":1507037235,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c304e97e7c1d472bc70e801b35ee78583916c6cd","date":1507105431,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"560c18d71dad43d675158783c3840f8c80d6d39c","date":1507105532,"type":3,"author":"Cao Manh Dat","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f90f26c648df8320685eb76fec8bb9972e1994c4","date":1508340424,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","date":1513252583,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    autoScalingHandler = createHandler(AutoScalingHandler.HANDLER_PATH, AutoScalingHandler.class.getName(), AutoScalingHandler.class);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":["bfc52860e6d13d034226a760813c59d984c6817a"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bfc52860e6d13d034226a760813c59d984c6817a","date":1522229027,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":["6a9fde5df1c4cdd5292c6a5292c39c630896af8c","816521ebaad5add9cb96bb88c577394e2938c40b","056ef30406180176075c44183ec40de4d2b8c68a","1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"43564cbb30b064675027cfb569564e8531096e97","date":1522334265,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4aea71c8b6a44bbbd3b8fcc42e5838a92b35634f","date":1522415499,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"aa5e39259dfd4a68287c824d3b7e1bc9097dc895","date":1522505041,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be created\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a","date":1527582939,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(metricManager);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    if (isZooKeeperAware()) {\n      PluginInfo plugin = cfg.getMetricsConfig().getHistoryHandler();\n      Map<String, Object> initArgs;\n      if (plugin != null && plugin.initArgs != null) {\n        initArgs = plugin.initArgs.asMap(5);\n        initArgs.put(MetricsHistoryHandler.ENABLE_PROP, plugin.isEnabled());\n      } else {\n        initArgs = Collections.emptyMap();\n      }\n      metricsHistoryHandler = new MetricsHistoryHandler(getZkController().getNodeName(), metricsHandler,\n          new CloudSolrClient.Builder(Collections.singletonList(getZkController().getZkServerAddress()), Optional.empty())\n      .withHttpClient(updateShardHandler.getDefaultHttpClient()).build(), getZkController().getSolrCloudManager(), initArgs);\n      containerHandlers.put(METRICS_HISTORY_PATH, metricsHistoryHandler);\n      metricsHistoryHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_HISTORY_PATH);\n    }\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    metricsHandler = createHandler(METRICS_PATH, MetricsHandler.class.getName(), MetricsHandler.class);\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":["f8f0f2472d437d44ec2144932e1d13fb494e82a3"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"946009ad0fba506337041a368b0a74d2edd59e2c","date":1528114477,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n        (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(metricManager);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    if (isZooKeeperAware()) {\n      PluginInfo plugin = cfg.getMetricsConfig().getHistoryHandler();\n      Map<String, Object> initArgs;\n      if (plugin != null && plugin.initArgs != null) {\n        initArgs = plugin.initArgs.asMap(5);\n        initArgs.put(MetricsHistoryHandler.ENABLE_PROP, plugin.isEnabled());\n      } else {\n        initArgs = Collections.emptyMap();\n      }\n      metricsHistoryHandler = new MetricsHistoryHandler(getZkController().getNodeName(), metricsHandler,\n          new CloudSolrClient.Builder(Collections.singletonList(getZkController().getZkServerAddress()), Optional.empty())\n      .withHttpClient(updateShardHandler.getDefaultHttpClient()).build(), getZkController().getSolrCloudManager(), initArgs);\n      containerHandlers.put(METRICS_HISTORY_PATH, metricsHistoryHandler);\n      metricsHistoryHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_HISTORY_PATH);\n    }\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(metricManager);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    if (isZooKeeperAware()) {\n      PluginInfo plugin = cfg.getMetricsConfig().getHistoryHandler();\n      Map<String, Object> initArgs;\n      if (plugin != null && plugin.initArgs != null) {\n        initArgs = plugin.initArgs.asMap(5);\n        initArgs.put(MetricsHistoryHandler.ENABLE_PROP, plugin.isEnabled());\n      } else {\n        initArgs = Collections.emptyMap();\n      }\n      metricsHistoryHandler = new MetricsHistoryHandler(getZkController().getNodeName(), metricsHandler,\n          new CloudSolrClient.Builder(Collections.singletonList(getZkController().getZkServerAddress()), Optional.empty())\n      .withHttpClient(updateShardHandler.getDefaultHttpClient()).build(), getZkController().getSolrCloudManager(), initArgs);\n      containerHandlers.put(METRICS_HISTORY_PATH, metricsHistoryHandler);\n      metricsHistoryHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_HISTORY_PATH);\n    }\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":["b3a34dae868734612eb6329aa0ef754f30bd2036","b61ef53ee9899b83a89bf97542c28a4cfd0a64bf"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f592209545c71895260367152601e9200399776d","date":1528238935,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n        (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(metricManager);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    if (isZooKeeperAware()) {\n      PluginInfo plugin = cfg.getMetricsConfig().getHistoryHandler();\n      Map<String, Object> initArgs;\n      if (plugin != null && plugin.initArgs != null) {\n        initArgs = plugin.initArgs.asMap(5);\n        initArgs.put(MetricsHistoryHandler.ENABLE_PROP, plugin.isEnabled());\n      } else {\n        initArgs = Collections.emptyMap();\n      }\n      metricsHistoryHandler = new MetricsHistoryHandler(getZkController().getNodeName(), metricsHandler,\n          new CloudSolrClient.Builder(Collections.singletonList(getZkController().getZkServerAddress()), Optional.empty())\n      .withHttpClient(updateShardHandler.getDefaultHttpClient()).build(), getZkController().getSolrCloudManager(), initArgs);\n      containerHandlers.put(METRICS_HISTORY_PATH, metricsHistoryHandler);\n      metricsHistoryHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_HISTORY_PATH);\n    }\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(metricManager);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    if (isZooKeeperAware()) {\n      PluginInfo plugin = cfg.getMetricsConfig().getHistoryHandler();\n      Map<String, Object> initArgs;\n      if (plugin != null && plugin.initArgs != null) {\n        initArgs = plugin.initArgs.asMap(5);\n        initArgs.put(MetricsHistoryHandler.ENABLE_PROP, plugin.isEnabled());\n      } else {\n        initArgs = Collections.emptyMap();\n      }\n      metricsHistoryHandler = new MetricsHistoryHandler(getZkController().getNodeName(), metricsHandler,\n          new CloudSolrClient.Builder(Collections.singletonList(getZkController().getZkServerAddress()), Optional.empty())\n      .withHttpClient(updateShardHandler.getDefaultHttpClient()).build(), getZkController().getSolrCloudManager(), initArgs);\n      containerHandlers.put(METRICS_HISTORY_PATH, metricsHistoryHandler);\n      metricsHistoryHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_HISTORY_PATH);\n    }\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b70042a8a492f7054d480ccdd2be9796510d4327","date":1528386658,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n        (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(metricManager);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    if (isZooKeeperAware()) {\n      PluginInfo plugin = cfg.getMetricsConfig().getHistoryHandler();\n      Map<String, Object> initArgs;\n      if (plugin != null && plugin.initArgs != null) {\n        initArgs = plugin.initArgs.asMap(5);\n        initArgs.put(MetricsHistoryHandler.ENABLE_PROP, plugin.isEnabled());\n      } else {\n        initArgs = Collections.emptyMap();\n      }\n      metricsHistoryHandler = new MetricsHistoryHandler(getZkController().getNodeName(), metricsHandler,\n          new CloudSolrClient.Builder(Collections.singletonList(getZkController().getZkServerAddress()), Optional.empty())\n      .withHttpClient(updateShardHandler.getDefaultHttpClient()).build(), getZkController().getSolrCloudManager(), initArgs);\n      containerHandlers.put(METRICS_HISTORY_PATH, metricsHistoryHandler);\n      metricsHistoryHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_HISTORY_PATH);\n    }\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName());\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(metricManager);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    if (isZooKeeperAware()) {\n      PluginInfo plugin = cfg.getMetricsConfig().getHistoryHandler();\n      Map<String, Object> initArgs;\n      if (plugin != null && plugin.initArgs != null) {\n        initArgs = plugin.initArgs.asMap(5);\n        initArgs.put(MetricsHistoryHandler.ENABLE_PROP, plugin.isEnabled());\n      } else {\n        initArgs = Collections.emptyMap();\n      }\n      metricsHistoryHandler = new MetricsHistoryHandler(getZkController().getNodeName(), metricsHandler,\n          new CloudSolrClient.Builder(Collections.singletonList(getZkController().getZkServerAddress()), Optional.empty())\n      .withHttpClient(updateShardHandler.getDefaultHttpClient()).build(), getZkController().getSolrCloudManager(), initArgs);\n      containerHandlers.put(METRICS_HISTORY_PATH, metricsHistoryHandler);\n      metricsHistoryHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_HISTORY_PATH);\n    }\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n    if(pkiAuthenticationPlugin != null)\n      containerHandlers.put(PKIAuthenticationPlugin.PATH, pkiAuthenticationPlugin.getRequestHandler());\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f8f0f2472d437d44ec2144932e1d13fb494e82a3","date":1528403207,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n        (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(metricManager);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n        (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(metricManager);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    if (isZooKeeperAware()) {\n      PluginInfo plugin = cfg.getMetricsConfig().getHistoryHandler();\n      Map<String, Object> initArgs;\n      if (plugin != null && plugin.initArgs != null) {\n        initArgs = plugin.initArgs.asMap(5);\n        initArgs.put(MetricsHistoryHandler.ENABLE_PROP, plugin.isEnabled());\n      } else {\n        initArgs = Collections.emptyMap();\n      }\n      metricsHistoryHandler = new MetricsHistoryHandler(getZkController().getNodeName(), metricsHandler,\n          new CloudSolrClient.Builder(Collections.singletonList(getZkController().getZkServerAddress()), Optional.empty())\n      .withHttpClient(updateShardHandler.getDefaultHttpClient()).build(), getZkController().getSolrCloudManager(), initArgs);\n      containerHandlers.put(METRICS_HISTORY_PATH, metricsHistoryHandler);\n      metricsHistoryHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_HISTORY_PATH);\n    }\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":["4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n        (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(metricManager);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n        (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(metricManager);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    if (isZooKeeperAware()) {\n      PluginInfo plugin = cfg.getMetricsConfig().getHistoryHandler();\n      Map<String, Object> initArgs;\n      if (plugin != null && plugin.initArgs != null) {\n        initArgs = plugin.initArgs.asMap(5);\n        initArgs.put(MetricsHistoryHandler.ENABLE_PROP, plugin.isEnabled());\n      } else {\n        initArgs = Collections.emptyMap();\n      }\n      metricsHistoryHandler = new MetricsHistoryHandler(getZkController().getNodeName(), metricsHandler,\n          new CloudSolrClient.Builder(Collections.singletonList(getZkController().getZkServerAddress()), Optional.empty())\n      .withHttpClient(updateShardHandler.getDefaultHttpClient()).build(), getZkController().getSolrCloudManager(), initArgs);\n      containerHandlers.put(METRICS_HISTORY_PATH, metricsHistoryHandler);\n      metricsHistoryHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_HISTORY_PATH);\n    }\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n        (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(metricManager);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n        (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(metricManager);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    if (isZooKeeperAware()) {\n      PluginInfo plugin = cfg.getMetricsConfig().getHistoryHandler();\n      Map<String, Object> initArgs;\n      if (plugin != null && plugin.initArgs != null) {\n        initArgs = plugin.initArgs.asMap(5);\n        initArgs.put(MetricsHistoryHandler.ENABLE_PROP, plugin.isEnabled());\n      } else {\n        initArgs = Collections.emptyMap();\n      }\n      metricsHistoryHandler = new MetricsHistoryHandler(getZkController().getNodeName(), metricsHandler,\n          new CloudSolrClient.Builder(Collections.singletonList(getZkController().getZkServerAddress()), Optional.empty())\n      .withHttpClient(updateShardHandler.getDefaultHttpClient()).build(), getZkController().getSolrCloudManager(), initArgs);\n      containerHandlers.put(METRICS_HISTORY_PATH, metricsHistoryHandler);\n      metricsHistoryHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_HISTORY_PATH);\n    }\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"750239682d222924398443d581163940f48d68fc","date":1533297311,"type":3,"author":"Jan Høydahl","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n        (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n        (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(metricManager);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"01f63edf15d2e3dbb3355d974f733b263098cb46","date":1533724999,"type":3,"author":"Jan Høydahl","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n        (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n        (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4bb866c04f137107dcf5b8f0e5bcee02fc832050","date":1546758709,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n        (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n        (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    healthCheckHandler = createHandler(HEALTH_CHECK_HANDLER_PATH, cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cbaf96cfda5422c42955ce34344f0e01839894ea","date":1559675051,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n        (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2668c99990e4c94a78bac005aa682b7c5986d23a","date":1561446137,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag, true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag, true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag, true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag, true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag, true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load()  {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if(isZooKeeperAware())  {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler        = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler   = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag,true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag,true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag,true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag,true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag,true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag,true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag,true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag,true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag,true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb50877dc038c021eba3a70999fd1f6ed85001c1","date":1563596432,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      getZkController().getZkStateReader().registerClusterPropertiesListener(clusterPropertiesListener);\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(\"/ext\", clusterPropertiesListener.extHandler);\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag, true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag, true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag, true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag, true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag, true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag, true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag, true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag, true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag, true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag, true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f912f3dd0ef8a72704a10ac2fddbae91f4db66de","date":1566155934,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      getZkController().getZkStateReader().registerClusterPropertiesListener(clusterPropertiesListener);\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      pkiAuthenticationPlugin.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(\"/ext\", clusterPropertiesListener.extHandler);\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag, true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag, true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag, true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag, true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag, true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      getZkController().getZkStateReader().registerClusterPropertiesListener(clusterPropertiesListener);\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(\"/ext\", clusterPropertiesListener.extHandler);\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag, true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag, true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag, true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag, true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag, true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"99d6782cf9de8c5ffeb8d0b0f103b578205af068","date":1566878682,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      getZkController().getZkStateReader().registerClusterPropertiesListener(clusterPropertiesListener);\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      pkiAuthenticationPlugin.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(\"/ext\", clusterPropertiesListener.extHandler);\n    containerHandlers.put(\"/blob-get\", blobRepository.blobRead);\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag, true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag, true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag, true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag, true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag, true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      getZkController().getZkStateReader().registerClusterPropertiesListener(clusterPropertiesListener);\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      pkiAuthenticationPlugin.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(\"/ext\", clusterPropertiesListener.extHandler);\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag, true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag, true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag, true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag, true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag, true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c44cc06c26e456fe9c215072b79fce30babe3975","date":1570365040,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      pkiAuthenticationPlugin.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag, true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag, true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag, true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag, true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag, true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      getZkController().getZkStateReader().registerClusterPropertiesListener(clusterPropertiesListener);\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      pkiAuthenticationPlugin.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(\"/ext\", clusterPropertiesListener.extHandler);\n    containerHandlers.put(\"/blob-get\", blobRepository.blobRead);\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag, true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag, true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag, true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag, true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag, true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8476949555f799dff381770c01cfad051a264487","date":1570505073,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      pkiAuthenticationPlugin.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag, true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag, true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag, true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag, true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag, true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      pkiAuthenticationPlugin.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag, true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag, true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag, true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag, true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag, true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0b597c65628ca9e73913a07e81691f8229bae35","date":1571224353,"type":3,"author":"jimczi","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      pkiAuthenticationPlugin.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag, true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag, true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag, true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag, true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag, true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      getZkController().getZkStateReader().registerClusterPropertiesListener(clusterPropertiesListener);\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      pkiAuthenticationPlugin.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    containerHandlers.put(\"/ext\", clusterPropertiesListener.extHandler);\n    containerHandlers.put(\"/blob-get\", blobRepository.blobRead);\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag, true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag, true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag, true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag, true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag, true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c959a64c5b52cc12eb8daa17f4f0ed9cf2dfcaaa","date":1571411704,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(\n          solrMetricsContext.metricManager, solrMetricsContext.registry, solrMetricsContext.tag, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(null, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(null, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(null, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(null, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(null, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(null, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(null, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(null, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(null, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      pkiAuthenticationPlugin.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    String metricTag = Integer.toHexString(hashCode());\n    metricManager.registerGauge(null, registryName, () -> solrCores.getCores().size(),\n        metricTag, true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        metricTag, true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    metricManager.registerGauge(null, registryName, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        metricTag, true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> dataHome.toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        metricTag, true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        metricTag, true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        metricTag, true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    metricManager.registerGauge(null, registryName, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        metricTag, true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getSpecificationVersion(),\n        metricTag, true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    metricManager.registerGauge(null, registryName, () -> this.getClass().getPackage().getImplementationVersion(),\n        metricTag, true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(metricManager, registryName, metricTag, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e9e5eaf280a6aa21423126b8232aa157a9b7366","date":1571772228,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(null, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(null, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(null, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(null, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(null, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(null, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(null, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(null, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(null, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(\n          solrMetricsContext.metricManager, solrMetricsContext.registry, solrMetricsContext.tag, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(metricManager, SolrInfoBean.Group.node.toString(), metricTag, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(null, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(null, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(null, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(null, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(null, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(null, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(null, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(null, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(null, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"954ae83b7dfacaa33d48ea056448ae11f7745a93","date":1571867711,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(null, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(null, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(null, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(null, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(null, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(null, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(null, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(null, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(null, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(null, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(null, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(null, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(null, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(null, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(null, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(null, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(null, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(null, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":["d218decf811b7a0a4d86218c54c79c74a962374b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7c2af5a711bd6e2d33e0221ced0f47ac596ed275","date":1572877903,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(null, () -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(null, () -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(null, () -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(null, () -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(null, () -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(null, () -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(null, () -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(null, () -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(null, () -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(null, () -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"42f6b881386654cc8e0dab45bc451dc41b627f68","date":1574147118,"type":3,"author":"noble","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      containerHandlers.getApiBag().register(new AnnotatedApi(new ZkRead(this)), Collections.EMPTY_MAP);\n      metricManager.loadClusterReporters(metricReporters, this);\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fbedb82f40fd431141e6baeedc018c99a07ab6a0","date":1574190486,"type":3,"author":"noble","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      containerHandlers.getApiBag().register(new AnnotatedApi(new ZkRead(this)), Collections.EMPTY_MAP);\n      metricManager.loadClusterReporters(metricReporters, this);\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6bbcc5460302e3534b1328862b0be6276184560f","date":1576066569,"type":3,"author":"Jason Gerlowski","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6c6b7e01cb749c3b01e226e06085dfb1d9ed8eab","date":1576073026,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d218decf811b7a0a4d86218c54c79c74a962374b","date":1578632144,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":["954ae83b7dfacaa33d48ea056448ae11f7745a93"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b8f0a7504661c8e51be5c63e87f9d79a36d9116c","date":1578657638,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0dda625d0f49ef568959e45adabe6d6faa39412","date":1582809393,"type":3,"author":"Jan Høydahl","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        modified = true;\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    String libDir = cfg.getSharedLibDirectory();\n    if (libDir != null) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        loader.reloadLuceneSPI();\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bd680b8f0b159dc1c7a01439c3c7f065bf3e69c7","date":1583235377,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        modified = true;\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(new ZkRead(this)), Collections.EMPTY_MAP);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        modified = true;\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"38fb691372ae1411a8a486192885334fd3ae7244","date":1583496514,"type":3,"author":"noble","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        modified = true;\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        modified = true;\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(new ZkRead(this)), Collections.EMPTY_MAP);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ec5a4e4c455009870c1cb8d21cf6671b8b78d3e3","date":1583932828,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", loader.getInstancePath());\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = loader.getInstancePath().resolve(libDir);\n      try {\n        loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n        modified = true;\n      } catch (IOException e) {\n        if (!libDir.equals(\"lib\")) { // Don't complain if default \"lib\" dir does not exist\n          log.warn(\"Couldn't add files from {} to classpath: {}\", libPath, e.getMessage());\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, solrHome, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"919b9b89b8d44ea491f18a92e6d52efcf5f7a065","date":1585280660,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      if (isZooKeeperAware()) {\n        //sort the cores if it is in SolrCloud. In standalone node the order does not matter\n        CoreSorter coreComparator = new CoreSorter().init(this);\n        cds = new ArrayList<>(cds);//make a copy\n        Collections.sort(cds, coreComparator::compare);\n      }\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb03700c9690d16b15fb4f56f6ec36b128fd894e","date":1586745995,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new DefaultSolrThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"140be51d03394488536f4aacedace29f9b318347","date":1587170432,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0cdbfc1e5714aafb41cabb055936a38ba4db5362","date":1587983533,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.readAPI), Collections.EMPTY_MAP);\n    containerHandlers.getApiBag().register(new AnnotatedApi(packageStoreAPI.writeAPI), Collections.EMPTY_MAP);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().editAPI), Collections.EMPTY_MAP);\n      containerHandlers.getApiBag().register(new AnnotatedApi(packageLoader.getPackageAPI().readAPI), Collections.EMPTY_MAP);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2022c62013ac31ba0bed28b0f0e6faf9af8dd2aa","date":1589312640,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dfc068060fd93e9c7417d1271ca797dc90496f67","date":1592771305,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome);\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome.toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toAbsolutePath().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory().toAbsolutePath());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"650b520f2a4daa4b0712e2393dc29ae7f21f10ac","date":1593054531,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome);\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      customContainerPlugins.refresh();\n      getZkController().zkStateReader.registerClusterPropertiesListener(customContainerPlugins);\n      ContainerPluginsApi containerPluginsApi = new ContainerPluginsApi(this);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.readAPI);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.editAPI);\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome);\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57c238f5fb83803b49b37b3a1a12224a64d47542","date":1593655679,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome);\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      customContainerPlugins.refresh();\n      getZkController().zkStateReader.registerClusterPropertiesListener(customContainerPlugins);\n      ContainerPluginsApi containerPluginsApi = new ContainerPluginsApi(this);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.readAPI);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.editAPI);\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome);\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e.getCause());\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      customContainerPlugins.refresh();\n      getZkController().zkStateReader.registerClusterPropertiesListener(customContainerPlugins);\n      ContainerPluginsApi containerPluginsApi = new ContainerPluginsApi(this);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.readAPI);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.editAPI);\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f504512a03d978990cbff30db0522b354e846db","date":1595247421,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome);\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      customContainerPlugins.refresh();\n      getZkController().zkStateReader.registerClusterPropertiesListener(customContainerPlugins);\n      ContainerPluginsApi containerPluginsApi = new ContainerPluginsApi(this);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.readAPI);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.editAPI);\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    autoscalingHistoryHandler = createHandler(AUTOSCALING_HISTORY_PATH, AutoscalingHistoryHandler.class.getName(), AutoscalingHistoryHandler.class);\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome);\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      customContainerPlugins.refresh();\n      getZkController().zkStateReader.registerClusterPropertiesListener(customContainerPlugins);\n      ContainerPluginsApi containerPluginsApi = new ContainerPluginsApi(this);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.readAPI);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.editAPI);\n      zkSys.getZkController().checkOverseerDesignate();\n      // initialize this handler here when SolrCloudManager is ready\n      autoScalingHandler = new AutoScalingHandler(getZkController().getSolrCloudManager(), loader);\n      containerHandlers.put(AutoScalingHandler.HANDLER_PATH, autoScalingHandler);\n      autoScalingHandler.initializeMetrics(solrMetricsContext, AutoScalingHandler.HANDLER_PATH);\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"434ea3e1b8afaaa792776459544b57703cd6872b","date":1598655596,"type":3,"author":"Tomas Fernandez Lobbe","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    /*\n     * HealthCheckHandler needs to be initialized before InfoHandler, since the later one will call CoreContainer.getHealthCheckHandler().\n     * We don't register the handler here because it'll be registered inside InfoHandler\n     */\n    healthCheckHandler = loader.newInstance(cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class, null, new Class<?>[]{CoreContainer.class}, new Object[]{this});\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome);\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      customContainerPlugins.refresh();\n      getZkController().zkStateReader.registerClusterPropertiesListener(customContainerPlugins);\n      ContainerPluginsApi containerPluginsApi = new ContainerPluginsApi(this);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.readAPI);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.editAPI);\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome);\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      customContainerPlugins.refresh();\n      getZkController().zkStateReader.registerClusterPropertiesListener(customContainerPlugins);\n      ContainerPluginsApi containerPluginsApi = new ContainerPluginsApi(this);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.readAPI);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.editAPI);\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0b6680904fafe5905f847812d32dc7ad79c96a0","date":1600243603,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    ClusterAPI clusterAPI = new ClusterAPI(collectionsHandler);\n    containerHandlers.getApiBag().registerObject(clusterAPI);\n    containerHandlers.getApiBag().registerObject(clusterAPI.commands);\n    /*\n     * HealthCheckHandler needs to be initialized before InfoHandler, since the later one will call CoreContainer.getHealthCheckHandler().\n     * We don't register the handler here because it'll be registered inside InfoHandler\n     */\n    healthCheckHandler = loader.newInstance(cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class, null, new Class<?>[]{CoreContainer.class}, new Object[]{this});\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome);\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      customContainerPlugins.refresh();\n      getZkController().zkStateReader.registerClusterPropertiesListener(customContainerPlugins);\n      ContainerPluginsApi containerPluginsApi = new ContainerPluginsApi(this);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.readAPI);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.editAPI);\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    /*\n     * HealthCheckHandler needs to be initialized before InfoHandler, since the later one will call CoreContainer.getHealthCheckHandler().\n     * We don't register the handler here because it'll be registered inside InfoHandler\n     */\n    healthCheckHandler = loader.newInstance(cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class, null, new Class<?>[]{CoreContainer.class}, new Object[]{this});\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome);\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      customContainerPlugins.refresh();\n      getZkController().zkStateReader.registerClusterPropertiesListener(customContainerPlugins);\n      ContainerPluginsApi containerPluginsApi = new ContainerPluginsApi(this);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.readAPI);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.editAPI);\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"680b6449f09827f58fe987aff279e014c311d966","date":1600247985,"type":3,"author":"noblepaul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    ClusterAPI clusterAPI = new ClusterAPI(collectionsHandler);\n    containerHandlers.getApiBag().registerObject(clusterAPI);\n    containerHandlers.getApiBag().registerObject(clusterAPI.commands);\n    /*\n     * HealthCheckHandler needs to be initialized before InfoHandler, since the later one will call CoreContainer.getHealthCheckHandler().\n     * We don't register the handler here because it'll be registered inside InfoHandler\n     */\n    healthCheckHandler = loader.newInstance(cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class, null, new Class<?>[]{CoreContainer.class}, new Object[]{this});\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome);\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      customContainerPlugins.refresh();\n      getZkController().zkStateReader.registerClusterPropertiesListener(customContainerPlugins);\n      ContainerPluginsApi containerPluginsApi = new ContainerPluginsApi(this);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.readAPI);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.editAPI);\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    /*\n     * HealthCheckHandler needs to be initialized before InfoHandler, since the later one will call CoreContainer.getHealthCheckHandler().\n     * We don't register the handler here because it'll be registered inside InfoHandler\n     */\n    healthCheckHandler = loader.newInstance(cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class, null, new Class<?>[]{CoreContainer.class}, new Object[]{this});\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome);\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      customContainerPlugins.refresh();\n      getZkController().zkStateReader.registerClusterPropertiesListener(customContainerPlugins);\n      ContainerPluginsApi containerPluginsApi = new ContainerPluginsApi(this);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.readAPI);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.editAPI);\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1852cb03cf4922477072449dd9de2fab588d1adb","date":1600862151,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    ClusterAPI clusterAPI = new ClusterAPI(collectionsHandler, configSetsHandler);\n    containerHandlers.getApiBag().registerObject(clusterAPI);\n    containerHandlers.getApiBag().registerObject(clusterAPI.commands);\n    containerHandlers.getApiBag().registerObject(clusterAPI.configSetCommands);\n    /*\n     * HealthCheckHandler needs to be initialized before InfoHandler, since the later one will call CoreContainer.getHealthCheckHandler().\n     * We don't register the handler here because it'll be registered inside InfoHandler\n     */\n    healthCheckHandler = loader.newInstance(cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class, null, new Class<?>[]{CoreContainer.class}, new Object[]{this});\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome);\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      customContainerPlugins.refresh();\n      getZkController().zkStateReader.registerClusterPropertiesListener(customContainerPlugins);\n      ContainerPluginsApi containerPluginsApi = new ContainerPluginsApi(this);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.readAPI);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.editAPI);\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    ClusterAPI clusterAPI = new ClusterAPI(collectionsHandler);\n    containerHandlers.getApiBag().registerObject(clusterAPI);\n    containerHandlers.getApiBag().registerObject(clusterAPI.commands);\n    /*\n     * HealthCheckHandler needs to be initialized before InfoHandler, since the later one will call CoreContainer.getHealthCheckHandler().\n     * We don't register the handler here because it'll be registered inside InfoHandler\n     */\n    healthCheckHandler = loader.newInstance(cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class, null, new Class<?>[]{CoreContainer.class}, new Object[]{this});\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome);\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      customContainerPlugins.refresh();\n      getZkController().zkStateReader.registerClusterPropertiesListener(customContainerPlugins);\n      ContainerPluginsApi containerPluginsApi = new ContainerPluginsApi(this);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.readAPI);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.editAPI);\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92d579a5d677457eb3cbac9551000f590be33b55","date":1600915032,"type":3,"author":"noblepaul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","pathOld":"solr/core/src/java/org/apache/solr/core/CoreContainer#load().mjava","sourceNew":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    containerHandlers.getApiBag().registerObject(new CollectionsAPI(collectionsHandler));\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    ClusterAPI clusterAPI = new ClusterAPI(collectionsHandler, configSetsHandler);\n    containerHandlers.getApiBag().registerObject(clusterAPI);\n    containerHandlers.getApiBag().registerObject(clusterAPI.commands);\n    containerHandlers.getApiBag().registerObject(clusterAPI.configSetCommands);\n    /*\n     * HealthCheckHandler needs to be initialized before InfoHandler, since the later one will call CoreContainer.getHealthCheckHandler().\n     * We don't register the handler here because it'll be registered inside InfoHandler\n     */\n    healthCheckHandler = loader.newInstance(cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class, null, new Class<?>[]{CoreContainer.class}, new Object[]{this});\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome);\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      customContainerPlugins.refresh();\n      getZkController().zkStateReader.registerClusterPropertiesListener(customContainerPlugins);\n      ContainerPluginsApi containerPluginsApi = new ContainerPluginsApi(this);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.readAPI);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.editAPI);\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","sourceOld":"  /**\n   * Load the cores defined for this CoreContainer\n   */\n  public void load() {\n    if (log.isDebugEnabled()) {\n      log.debug(\"Loading cores into CoreContainer [instanceDir={}]\", getSolrHome());\n    }\n\n    // Always add $SOLR_HOME/lib to the shared resource loader\n    Set<String> libDirs = new LinkedHashSet<>();\n    libDirs.add(\"lib\");\n\n    if (!StringUtils.isBlank(cfg.getSharedLibDirectory())) {\n      List<String> sharedLibs = Arrays.asList(cfg.getSharedLibDirectory().split(\"\\\\s*,\\\\s*\"));\n      libDirs.addAll(sharedLibs);\n    }\n\n    boolean modified = false;\n    // add the sharedLib to the shared resource loader before initializing cfg based plugins\n    for (String libDir : libDirs) {\n      Path libPath = Paths.get(getSolrHome()).resolve(libDir);\n      if (Files.exists(libPath)) {\n        try {\n          loader.addToClassLoader(SolrResourceLoader.getURLs(libPath));\n          modified = true;\n        } catch (IOException e) {\n          throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't load libs: \" + e, e);\n        }\n      }\n    }\n    if (modified) {\n      loader.reloadLuceneSPI();\n    }\n\n    packageStoreAPI = new PackageStoreAPI(this);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.readAPI);\n    containerHandlers.getApiBag().registerObject(packageStoreAPI.writeAPI);\n\n    metricManager = new SolrMetricManager(loader, cfg.getMetricsConfig());\n    String registryName = SolrMetricManager.getRegistryName(SolrInfoBean.Group.node);\n    solrMetricsContext = new SolrMetricsContext(metricManager, registryName, metricTag);\n\n    coreContainerWorkExecutor = MetricUtils.instrumentedExecutorService(\n        coreContainerWorkExecutor, null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreContainerWorkExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n\n    shardHandlerFactory = ShardHandlerFactory.newInstance(cfg.getShardHandlerFactoryPluginInfo(), loader);\n    if (shardHandlerFactory instanceof SolrMetricProducer) {\n      SolrMetricProducer metricProducer = (SolrMetricProducer) shardHandlerFactory;\n      metricProducer.initializeMetrics(solrMetricsContext, \"httpShardHandler\");\n    }\n\n    updateShardHandler = new UpdateShardHandler(cfg.getUpdateShardHandlerConfig());\n    updateShardHandler.initializeMetrics(solrMetricsContext, \"updateShardHandler\");\n\n    solrClientCache = new SolrClientCache(updateShardHandler.getDefaultHttpClient());\n\n    // initialize CalciteSolrDriver instance to use this solrClientCache\n    CalciteSolrDriver.INSTANCE.setSolrClientCache(solrClientCache);\n\n    solrCores.load(loader);\n\n\n    logging = LogWatcher.newRegisteredLogWatcher(cfg.getLogWatcherConfig(), loader);\n\n    hostName = cfg.getNodeName();\n\n    zkSys.initZooKeeper(this, cfg.getCloudConfig());\n    if (isZooKeeperAware()) {\n      pkiAuthenticationPlugin = new PKIAuthenticationPlugin(this, zkSys.getZkController().getNodeName(),\n          (PublicKeyHandler) containerHandlers.get(PublicKeyHandler.PATH));\n      // use deprecated API for back-compat, remove in 9.0\n      pkiAuthenticationPlugin.initializeMetrics(solrMetricsContext, \"/authentication/pki\");\n      TracerConfigurator.loadTracer(loader, cfg.getTracerConfiguratorPluginInfo(), getZkController().getZkStateReader());\n      packageLoader = new PackageLoader(this);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().editAPI);\n      containerHandlers.getApiBag().registerObject(packageLoader.getPackageAPI().readAPI);\n      ZookeeperReadAPI zookeeperReadAPI = new ZookeeperReadAPI(this);\n      containerHandlers.getApiBag().registerObject(zookeeperReadAPI);\n    }\n\n    MDCLoggingContext.setNode(this);\n\n    securityConfHandler = isZooKeeperAware() ? new SecurityConfHandlerZk(this) : new SecurityConfHandlerLocal(this);\n    reloadSecurityProperties();\n    warnUsersOfInsecureSettings();\n    this.backupRepoFactory = new BackupRepositoryFactory(cfg.getBackupRepositoryPlugins());\n\n    createHandler(ZK_PATH, ZookeeperInfoHandler.class.getName(), ZookeeperInfoHandler.class);\n    createHandler(ZK_STATUS_PATH, ZookeeperStatusHandler.class.getName(), ZookeeperStatusHandler.class);\n    collectionsHandler = createHandler(COLLECTIONS_HANDLER_PATH, cfg.getCollectionsHandlerClass(), CollectionsHandler.class);\n    configSetsHandler = createHandler(CONFIGSETS_HANDLER_PATH, cfg.getConfigSetsHandlerClass(), ConfigSetsHandler.class);\n    ClusterAPI clusterAPI = new ClusterAPI(collectionsHandler, configSetsHandler);\n    containerHandlers.getApiBag().registerObject(clusterAPI);\n    containerHandlers.getApiBag().registerObject(clusterAPI.commands);\n    containerHandlers.getApiBag().registerObject(clusterAPI.configSetCommands);\n    /*\n     * HealthCheckHandler needs to be initialized before InfoHandler, since the later one will call CoreContainer.getHealthCheckHandler().\n     * We don't register the handler here because it'll be registered inside InfoHandler\n     */\n    healthCheckHandler = loader.newInstance(cfg.getHealthCheckHandlerClass(), HealthCheckHandler.class, null, new Class<?>[]{CoreContainer.class}, new Object[]{this});\n    infoHandler = createHandler(INFO_HANDLER_PATH, cfg.getInfoHandlerClass(), InfoHandler.class);\n    coreAdminHandler = createHandler(CORES_HANDLER_PATH, cfg.getCoreAdminHandlerClass(), CoreAdminHandler.class);\n\n    // metricsHistoryHandler uses metricsHandler, so create it first\n    metricsHandler = new MetricsHandler(this);\n    containerHandlers.put(METRICS_PATH, metricsHandler);\n    metricsHandler.initializeMetrics(solrMetricsContext, METRICS_PATH);\n\n    createMetricsHistoryHandler();\n\n    metricsCollectorHandler = createHandler(MetricsCollectorHandler.HANDLER_PATH, MetricsCollectorHandler.class.getName(), MetricsCollectorHandler.class);\n    // may want to add some configuration here in the future\n    metricsCollectorHandler.init(null);\n\n    containerHandlers.put(AUTHZ_PATH, securityConfHandler);\n    securityConfHandler.initializeMetrics(solrMetricsContext, AUTHZ_PATH);\n    containerHandlers.put(AUTHC_PATH, securityConfHandler);\n\n\n    PluginInfo[] metricReporters = cfg.getMetricsConfig().getMetricReporters();\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.node);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jvm);\n    metricManager.loadReporters(metricReporters, loader, this, null, null, SolrInfoBean.Group.jetty);\n\n    coreConfigService = ConfigSetService.createConfigSetService(cfg, loader, zkSys.zkController);\n\n    containerProperties.putAll(cfg.getSolrProperties());\n\n    // initialize gauges for reporting the number of cores and disk total/free\n\n    solrMetricsContext.gauge(() -> solrCores.getCores().size(),\n        true, \"loaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getLoadedCoreNames().size() - solrCores.getCores().size(),\n        true, \"lazy\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    solrMetricsContext.gauge(() -> solrCores.getAllCoreNames().size() - solrCores.getLoadedCoreNames().size(),\n        true, \"unloaded\", SolrInfoBean.Category.CONTAINER.toString(), \"cores\");\n    Path dataHome = cfg.getSolrDataHome() != null ? cfg.getSolrDataHome() : cfg.getCoreRootDirectory();\n    solrMetricsContext.gauge(() -> dataHome.toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> dataHome.toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(dataHome);\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getTotalSpace(),\n        true, \"totalSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toFile().getUsableSpace(),\n        true, \"usableSpace\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> cfg.getCoreRootDirectory().toString(),\n        true, \"path\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    solrMetricsContext.gauge(() -> {\n          try {\n            return org.apache.lucene.util.IOUtils.spins(cfg.getCoreRootDirectory());\n          } catch (IOException e) {\n            // default to spinning\n            return true;\n          }\n        },\n        true, \"spins\", SolrInfoBean.Category.CONTAINER.toString(), \"fs\", \"coreRoot\");\n    // add version information\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getSpecificationVersion(),\n        true, \"specification\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n    solrMetricsContext.gauge(() -> this.getClass().getPackage().getImplementationVersion(),\n        true, \"implementation\", SolrInfoBean.Category.CONTAINER.toString(), \"version\");\n\n    SolrFieldCacheBean fieldCacheBean = new SolrFieldCacheBean();\n    fieldCacheBean.initializeMetrics(solrMetricsContext, null);\n\n    if (isZooKeeperAware()) {\n      metricManager.loadClusterReporters(metricReporters, this);\n    }\n\n\n    // setup executor to load cores in parallel\n    ExecutorService coreLoadExecutor = MetricUtils.instrumentedExecutorService(\n        ExecutorUtil.newMDCAwareFixedThreadPool(\n            cfg.getCoreLoadThreadCount(isZooKeeperAware()),\n            new SolrNamedThreadFactory(\"coreLoadExecutor\")), null,\n        metricManager.registry(SolrMetricManager.getRegistryName(SolrInfoBean.Group.node)),\n        SolrMetricManager.mkName(\"coreLoadExecutor\", SolrInfoBean.Category.CONTAINER.toString(), \"threadPool\"));\n    final List<Future<SolrCore>> futures = new ArrayList<>();\n    try {\n      List<CoreDescriptor> cds = coresLocator.discover(this);\n      cds = CoreSorter.sortCores(this, cds);\n      checkForDuplicateCoreNames(cds);\n      status |= CORE_DISCOVERY_COMPLETE;\n\n      for (final CoreDescriptor cd : cds) {\n        if (cd.isTransient() || !cd.isLoadOnStartup()) {\n          solrCores.addCoreDescriptor(cd);\n        } else if (asyncSolrCoreLoad) {\n          solrCores.markCoreAsLoading(cd);\n        }\n        if (cd.isLoadOnStartup()) {\n          futures.add(coreLoadExecutor.submit(() -> {\n            SolrCore core;\n            try {\n              if (zkSys.getZkController() != null) {\n                zkSys.getZkController().throwErrorIfReplicaReplaced(cd);\n              }\n              solrCores.waitAddPendingCoreOps(cd.getName());\n              core = createFromDescriptor(cd, false, false);\n            } finally {\n              solrCores.removeFromPendingOps(cd.getName());\n              if (asyncSolrCoreLoad) {\n                solrCores.markCoreAsNotLoading(cd);\n              }\n            }\n            try {\n              zkSys.registerInZk(core, true, false);\n            } catch (RuntimeException e) {\n              SolrException.log(log, \"Error registering SolrCore\", e);\n            }\n            return core;\n          }));\n        }\n      }\n\n\n      // Start the background thread\n      backgroundCloser = new CloserThread(this, solrCores, cfg);\n      backgroundCloser.start();\n\n    } finally {\n      if (asyncSolrCoreLoad && futures != null) {\n\n        coreContainerWorkExecutor.submit(() -> {\n          try {\n            for (Future<SolrCore> future : futures) {\n              try {\n                future.get();\n              } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n              } catch (ExecutionException e) {\n                log.error(\"Error waiting for SolrCore to be loaded on startup\", e);\n              }\n            }\n          } finally {\n            ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n          }\n        });\n      } else {\n        ExecutorUtil.shutdownAndAwaitTermination(coreLoadExecutor);\n      }\n    }\n\n    if (isZooKeeperAware()) {\n      customContainerPlugins.refresh();\n      getZkController().zkStateReader.registerClusterPropertiesListener(customContainerPlugins);\n      ContainerPluginsApi containerPluginsApi = new ContainerPluginsApi(this);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.readAPI);\n      containerHandlers.getApiBag().registerObject(containerPluginsApi.editAPI);\n      zkSys.getZkController().checkOverseerDesignate();\n    }\n    // This is a bit redundant but these are two distinct concepts for all they're accomplished at the same time.\n    status |= LOAD_COMPLETE | INITIAL_CORE_LOAD_COMPLETE;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b8f0a7504661c8e51be5c63e87f9d79a36d9116c":["6c6b7e01cb749c3b01e226e06085dfb1d9ed8eab","d218decf811b7a0a4d86218c54c79c74a962374b"],"7116474e2e390259937401cf928323e0cbc75e60":["354983dcdf70c800bf2573d10b54a7391b1dc167"],"2209af2c265d2258ec4b29c8cc78622d36994a15":["6bdcb86c29922edae9a14852e636303bc52df094"],"97bd2b0da4beced82821b752b29576be986cf1ff":["f763a1acdb27217b4799d1ca51c816739835a3e0"],"58b7eb80017f1c5b32035176b965fa0cc0287d04":["00e1c8e1340d9e31d2c6bee5f72d9040ce569049"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","6e764e9a107f93be9fa3c922bc6a197b3eec387e"],"d218decf811b7a0a4d86218c54c79c74a962374b":["6bbcc5460302e3534b1328862b0be6276184560f"],"8b6a4b585aed7660a589375f6a09b90efd29c961":["9227359ab3bd86e5b85fab89a99332da7d5bacb1"],"f225b9b576dc345ee8c27f91147b4afc0350511c":["b64a893a6d2efaa60e289534b1f8713e4aa2c776"],"1852cb03cf4922477072449dd9de2fab588d1adb":["680b6449f09827f58fe987aff279e014c311d966"],"9227359ab3bd86e5b85fab89a99332da7d5bacb1":["ab68488225b6a6c357dda72ed11dedca9914a192"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","74aea047dff7f7c38a2d766827bd20d356f98c6a"],"58884af1f68e9d61c217c753fbd6266d86a63b14":["2f472c757c161e228505e389efda705e2cf3c09e","6a9fde5df1c4cdd5292c6a5292c39c630896af8c"],"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf":["80d0e6d59ae23f4a6f30eaf40bfb40742300287f","0265144286422ad99682a00904cc2536b79c8535"],"0cdbfc1e5714aafb41cabb055936a38ba4db5362":["140be51d03394488536f4aacedace29f9b318347"],"140be51d03394488536f4aacedace29f9b318347":["fb03700c9690d16b15fb4f56f6ec36b128fd894e"],"073f1aa70444ec64f3e216816af2a3b43fa38fe7":["b61ef53ee9899b83a89bf97542c28a4cfd0a64bf"],"38fb691372ae1411a8a486192885334fd3ae7244":["bd680b8f0b159dc1c7a01439c3c7f065bf3e69c7"],"f56da6f4f15d95f318d2d6ac2a39a9183dfecff2":["97bd2b0da4beced82821b752b29576be986cf1ff"],"ab68488225b6a6c357dda72ed11dedca9914a192":["073f1aa70444ec64f3e216816af2a3b43fa38fe7","6db2a2569883aff84117ae03caf199738df62519"],"4aea71c8b6a44bbbd3b8fcc42e5838a92b35634f":["43564cbb30b064675027cfb569564e8531096e97"],"004ec9e26487ae9b6205e790f8f77ef5e98d8daf":["6a9fde5df1c4cdd5292c6a5292c39c630896af8c"],"3f504512a03d978990cbff30db0522b354e846db":["57c238f5fb83803b49b37b3a1a12224a64d47542"],"e22a92d60a5a6320f9653856966fcd77c60953b3":["cc69baf14413994ccde897681e5ce1d393cf7156"],"2e9e5eaf280a6aa21423126b8232aa157a9b7366":["c959a64c5b52cc12eb8daa17f4f0ed9cf2dfcaaa"],"92a4da96826f502cf1a56a096929b37ce73e523a":["6e764e9a107f93be9fa3c922bc6a197b3eec387e"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":["a626ec4d1c92e59fe390724d6220081047b03ce7","fb65cc25534f4e0d77ed573d35995eb0b836b818"],"30c8e5574b55d57947e989443dfde611646530ee":["e9017cf144952056066919f1ebc7897ff9bd71b1","28288370235ed02234a64753cdbf0c6ec096304a"],"729cb470f975115d4c60517b2cb7c42e37a7a2e1":["816521ebaad5add9cb96bb88c577394e2938c40b"],"d301cb76d81de80d07b44735622a04d49ed938eb":["28288370235ed02234a64753cdbf0c6ec096304a","bd7a2b4785d366164d3cd69f9948de6ff34d23a1"],"f912f3dd0ef8a72704a10ac2fddbae91f4db66de":["fb50877dc038c021eba3a70999fd1f6ed85001c1"],"126d6ad24eed13163ba0959435d5a80e5672837c":["4aeabc53a9c50bd4c04c5261562b3e78cc2ea744","7f0c8426396c925de8db3ed3f8ff40fd73670a5c"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["936cdd5882761db3b844afd6f84ab81cbb011a75","b2fdcd0303309a07ecdda1d98f6806404d741129"],"4bb866c04f137107dcf5b8f0e5bcee02fc832050":["01f63edf15d2e3dbb3355d974f733b263098cb46"],"bfc52860e6d13d034226a760813c59d984c6817a":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"7c2af5a711bd6e2d33e0221ced0f47ac596ed275":["954ae83b7dfacaa33d48ea056448ae11f7745a93"],"fb50877dc038c021eba3a70999fd1f6ed85001c1":["2668c99990e4c94a78bac005aa682b7c5986d23a"],"b6284684320a9808c41a5e43de958b2da22f89bd":["fb65cc25534f4e0d77ed573d35995eb0b836b818","043df2e9a841864922c32756a44c939ed768cb89"],"3301c97f51316f9c9937654c07d7a6a21e7aecb8":["93d40a0287bd8a5b69a8df49a797dcd4a8b1a7be"],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","b363b110592b02d7f488aff0dbe40a53d3ce81df"],"275019a81d0883a1db4560391b072d1fbe272ec4":["439c63ae5d22132fca810a0029a854e97d2c1a3e"],"6a9fde5df1c4cdd5292c6a5292c39c630896af8c":["b2fdcd0303309a07ecdda1d98f6806404d741129"],"9bc766d645fa848f86c381c7f6acf2c881c99399":["e15199583d3635cb940942caed05132dd6c4c7c6"],"f90f26c648df8320685eb76fec8bb9972e1994c4":["560c18d71dad43d675158783c3840f8c80d6d39c"],"c44cc06c26e456fe9c215072b79fce30babe3975":["99d6782cf9de8c5ffeb8d0b0f103b578205af068"],"cc69baf14413994ccde897681e5ce1d393cf7156":["a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b"],"439c63ae5d22132fca810a0029a854e97d2c1a3e":["58b7eb80017f1c5b32035176b965fa0cc0287d04"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["fd44bec977a26a118d9e809e2de6f7edb5ca0f39","9bc766d645fa848f86c381c7f6acf2c881c99399"],"4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a":["aa5e39259dfd4a68287c824d3b7e1bc9097dc895"],"b16266db764c72c65ab2977b36da1436b4efbb9f":["bf28d12ff32dc50412338f84022406e2be7d44f2"],"434ea3e1b8afaaa792776459544b57703cd6872b":["3f504512a03d978990cbff30db0522b354e846db"],"170ef9c82c0d27d4151feff316ba63fbedd91bbf":["d528fd7ae22865015b756e0a03832e2051de2a9c"],"2668c99990e4c94a78bac005aa682b7c5986d23a":["cbaf96cfda5422c42955ce34344f0e01839894ea"],"74aea047dff7f7c38a2d766827bd20d356f98c6a":["2b2cafc02486bd97e4f7849f5360581a8084c8c1","a513b6a92751e54c76fb5447948c9e7d437163a7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"01f63edf15d2e3dbb3355d974f733b263098cb46":["750239682d222924398443d581163940f48d68fc"],"6e764e9a107f93be9fa3c922bc6a197b3eec387e":["f225b9b576dc345ee8c27f91147b4afc0350511c"],"6db2a2569883aff84117ae03caf199738df62519":["0d5e442cae8cd58c4f22df43dacbd0018fc0ac1b"],"a7035935aa89f6951286e9005cbeb16e89a082a2":["d9d424bd039937b4125152b454b3a32754b06f6c"],"d402ed03d3abe439fa7859facfae3c2fe0aba77e":["f34d83c894e07c24f5f957820777b5da2cc29e5a"],"9435d55e3ea95c5d94406d3affc36f9505b6a736":["d402ed03d3abe439fa7859facfae3c2fe0aba77e"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["f56da6f4f15d95f318d2d6ac2a39a9183dfecff2"],"043df2e9a841864922c32756a44c939ed768cb89":["fb65cc25534f4e0d77ed573d35995eb0b836b818"],"337a3230c591e6094030c97d6ed767b261bcd851":["f3783d6f4d080f4f0116769e0e1b0f0f440565c4"],"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec":["37a0f60745e53927c4c876cfe5b5a58170f0646c","92a4da96826f502cf1a56a096929b37ce73e523a"],"2022c62013ac31ba0bed28b0f0e6faf9af8dd2aa":["0cdbfc1e5714aafb41cabb055936a38ba4db5362"],"b61ef53ee9899b83a89bf97542c28a4cfd0a64bf":["1214bb624eb41181e5c8e260e0050c7e973ba0f4"],"99d6782cf9de8c5ffeb8d0b0f103b578205af068":["f912f3dd0ef8a72704a10ac2fddbae91f4db66de"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":["716d18f3a9b0993bc679d7fa7abdc9bfb03411ec","5e732472e86aa53222c571de21dcb7d6a75c1c87"],"57c238f5fb83803b49b37b3a1a12224a64d47542":["650b520f2a4daa4b0712e2393dc29ae7f21f10ac"],"fb65cc25534f4e0d77ed573d35995eb0b836b818":["a626ec4d1c92e59fe390724d6220081047b03ce7"],"b9248e8833b6ab03d4e0ebbeaa8b26d8798e7659":["2209af2c265d2258ec4b29c8cc78622d36994a15"],"d528fd7ae22865015b756e0a03832e2051de2a9c":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"d264f386d864b5751209060e8886ca9845f70469":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5ba0abe4039f82ecf2e5f879913f512e941dde81":["0ad7bdba3e91cf3373cda2e52239cb761fc0b452","7947ef57ebadfb891b1c694f0772d616987e57c8"],"816521ebaad5add9cb96bb88c577394e2938c40b":["9435d55e3ea95c5d94406d3affc36f9505b6a736"],"28288370235ed02234a64753cdbf0c6ec096304a":["2b2cafc02486bd97e4f7849f5360581a8084c8c1","7871f9c286dce2a9370bcf517a3e7d12e3bd9602"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["b6284684320a9808c41a5e43de958b2da22f89bd","d528fd7ae22865015b756e0a03832e2051de2a9c"],"d9d424bd039937b4125152b454b3a32754b06f6c":["d275f25d46bec8d215cc9d810169af5bf57ff35a"],"cbaf96cfda5422c42955ce34344f0e01839894ea":["4bb866c04f137107dcf5b8f0e5bcee02fc832050"],"650b520f2a4daa4b0712e2393dc29ae7f21f10ac":["dfc068060fd93e9c7417d1271ca797dc90496f67"],"a513b6a92751e54c76fb5447948c9e7d437163a7":["2b2cafc02486bd97e4f7849f5360581a8084c8c1"],"f3783d6f4d080f4f0116769e0e1b0f0f440565c4":["e22a92d60a5a6320f9653856966fcd77c60953b3"],"f34d83c894e07c24f5f957820777b5da2cc29e5a":["073f1aa70444ec64f3e216816af2a3b43fa38fe7"],"2d4e985daefcb892b529223b478c47985fc3c483":["7e66d99e5beccb546edd910c91f646fb7d831a94"],"10399eb409ace56e6d66f136f184643f7432371d":["80ebe5b1d946f7c2ed9c46206b0c7254dc21206a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["92d579a5d677457eb3cbac9551000f590be33b55"],"16fa358573e3c2508728b3c7c438a8c19a3f0ae4":["0265144286422ad99682a00904cc2536b79c8535"],"b0dda625d0f49ef568959e45adabe6d6faa39412":["d218decf811b7a0a4d86218c54c79c74a962374b"],"9efa9c0fcd87863d1a86eed29d4304c11bc7d50a":["6a9fde5df1c4cdd5292c6a5292c39c630896af8c","004ec9e26487ae9b6205e790f8f77ef5e98d8daf"],"919b9b89b8d44ea491f18a92e6d52efcf5f7a065":["ec5a4e4c455009870c1cb8d21cf6671b8b78d3e3"],"9b10b88c8af8835e23b0d566418ef8397a7bb8ed":["b16266db764c72c65ab2977b36da1436b4efbb9f"],"c8c09c323959c458fb515b3f9a2ce29958ce1478":["5e732472e86aa53222c571de21dcb7d6a75c1c87"],"d275f25d46bec8d215cc9d810169af5bf57ff35a":["c8c09c323959c458fb515b3f9a2ce29958ce1478"],"680b6449f09827f58fe987aff279e014c311d966":["434ea3e1b8afaaa792776459544b57703cd6872b","c0b6680904fafe5905f847812d32dc7ad79c96a0"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["b70042a8a492f7054d480ccdd2be9796510d4327","f8f0f2472d437d44ec2144932e1d13fb494e82a3"],"954ae83b7dfacaa33d48ea056448ae11f7745a93":["2e9e5eaf280a6aa21423126b8232aa157a9b7366"],"2b2cafc02486bd97e4f7849f5360581a8084c8c1":["195fcfcffd8f9047ac27ac642ee9da64f4e6c4fa"],"b64a893a6d2efaa60e289534b1f8713e4aa2c776":["7116474e2e390259937401cf928323e0cbc75e60"],"a626ec4d1c92e59fe390724d6220081047b03ce7":["10399eb409ace56e6d66f136f184643f7432371d"],"b70042a8a492f7054d480ccdd2be9796510d4327":["4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a","946009ad0fba506337041a368b0a74d2edd59e2c"],"b363b110592b02d7f488aff0dbe40a53d3ce81df":["d528fd7ae22865015b756e0a03832e2051de2a9c","170ef9c82c0d27d4151feff316ba63fbedd91bbf"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["f90f26c648df8320685eb76fec8bb9972e1994c4"],"7e66d99e5beccb546edd910c91f646fb7d831a94":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"560c18d71dad43d675158783c3840f8c80d6d39c":["9efa9c0fcd87863d1a86eed29d4304c11bc7d50a","c304e97e7c1d472bc70e801b35ee78583916c6cd"],"bd680b8f0b159dc1c7a01439c3c7f065bf3e69c7":["b0dda625d0f49ef568959e45adabe6d6faa39412"],"fbedb82f40fd431141e6baeedc018c99a07ab6a0":["42f6b881386654cc8e0dab45bc451dc41b627f68"],"6bbcc5460302e3534b1328862b0be6276184560f":["fbedb82f40fd431141e6baeedc018c99a07ab6a0"],"8476949555f799dff381770c01cfad051a264487":["c44cc06c26e456fe9c215072b79fce30babe3975"],"bf28d12ff32dc50412338f84022406e2be7d44f2":["16fa358573e3c2508728b3c7c438a8c19a3f0ae4"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","bf28d12ff32dc50412338f84022406e2be7d44f2"],"0265144286422ad99682a00904cc2536b79c8535":["b363b110592b02d7f488aff0dbe40a53d3ce81df"],"6240b74b884c5587f2a4062dd27d6c32bf228889":["3301c97f51316f9c9937654c07d7a6a21e7aecb8","9efa9c0fcd87863d1a86eed29d4304c11bc7d50a"],"6c6b7e01cb749c3b01e226e06085dfb1d9ed8eab":["fbedb82f40fd431141e6baeedc018c99a07ab6a0","6bbcc5460302e3534b1328862b0be6276184560f"],"fb03700c9690d16b15fb4f56f6ec36b128fd894e":["919b9b89b8d44ea491f18a92e6d52efcf5f7a065"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["d9d424bd039937b4125152b454b3a32754b06f6c","f763a1acdb27217b4799d1ca51c816739835a3e0"],"195fcfcffd8f9047ac27ac642ee9da64f4e6c4fa":["729cb470f975115d4c60517b2cb7c42e37a7a2e1"],"f592209545c71895260367152601e9200399776d":["4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a","946009ad0fba506337041a368b0a74d2edd59e2c"],"750239682d222924398443d581163940f48d68fc":["f8f0f2472d437d44ec2144932e1d13fb494e82a3"],"cb5af3afeddbb803fb785098176e6e177c34261b":["9bc766d645fa848f86c381c7f6acf2c881c99399"],"6bdcb86c29922edae9a14852e636303bc52df094":["b3a34dae868734612eb6329aa0ef754f30bd2036"],"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["8b6a4b585aed7660a589375f6a09b90efd29c961"],"c304e97e7c1d472bc70e801b35ee78583916c6cd":["9efa9c0fcd87863d1a86eed29d4304c11bc7d50a","6240b74b884c5587f2a4062dd27d6c32bf228889"],"b2fdcd0303309a07ecdda1d98f6806404d741129":["2f472c757c161e228505e389efda705e2cf3c09e"],"acd1f5a977dc3b97799ed300423294e2c457774f":["a626ec4d1c92e59fe390724d6220081047b03ce7","fb65cc25534f4e0d77ed573d35995eb0b836b818"],"fd44bec977a26a118d9e809e2de6f7edb5ca0f39":["7947ef57ebadfb891b1c694f0772d616987e57c8"],"b3a34dae868734612eb6329aa0ef754f30bd2036":["275019a81d0883a1db4560391b072d1fbe272ec4"],"5e732472e86aa53222c571de21dcb7d6a75c1c87":["92a4da96826f502cf1a56a096929b37ce73e523a"],"aa5e39259dfd4a68287c824d3b7e1bc9097dc895":["43564cbb30b064675027cfb569564e8531096e97","4aea71c8b6a44bbbd3b8fcc42e5838a92b35634f"],"4aeabc53a9c50bd4c04c5261562b3e78cc2ea744":["337a3230c591e6094030c97d6ed767b261bcd851"],"7f0c8426396c925de8db3ed3f8ff40fd73670a5c":["4aeabc53a9c50bd4c04c5261562b3e78cc2ea744"],"946009ad0fba506337041a368b0a74d2edd59e2c":["4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a"],"1214bb624eb41181e5c8e260e0050c7e973ba0f4":["9b10b88c8af8835e23b0d566418ef8397a7bb8ed"],"e15199583d3635cb940942caed05132dd6c4c7c6":["fd44bec977a26a118d9e809e2de6f7edb5ca0f39"],"ec5a4e4c455009870c1cb8d21cf6671b8b78d3e3":["38fb691372ae1411a8a486192885334fd3ae7244"],"80ebe5b1d946f7c2ed9c46206b0c7254dc21206a":["e78c35bca3e32dfc7a695136fa2b5de1ae135c22"],"dfc068060fd93e9c7417d1271ca797dc90496f67":["2022c62013ac31ba0bed28b0f0e6faf9af8dd2aa"],"e78c35bca3e32dfc7a695136fa2b5de1ae135c22":["b9248e8833b6ab03d4e0ebbeaa8b26d8798e7659"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["f3783d6f4d080f4f0116769e0e1b0f0f440565c4","126d6ad24eed13163ba0959435d5a80e5672837c"],"a4d419cdab641a032f3e0d0fa8167a5252be0ae3":["85032ab568b3f50eabd577aaa994ba197db93758"],"bd7a2b4785d366164d3cd69f9948de6ff34d23a1":["28288370235ed02234a64753cdbf0c6ec096304a"],"056ef30406180176075c44183ec40de4d2b8c68a":["d301cb76d81de80d07b44735622a04d49ed938eb"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["f592209545c71895260367152601e9200399776d","f8f0f2472d437d44ec2144932e1d13fb494e82a3"],"491c9672ec42582fe43960452dbd37f1c80fe0f0":["f03e4bed5023ec3ef93a771b8888cae991cf448d","b16266db764c72c65ab2977b36da1436b4efbb9f"],"42f6b881386654cc8e0dab45bc451dc41b627f68":["7c2af5a711bd6e2d33e0221ced0f47ac596ed275"],"c959a64c5b52cc12eb8daa17f4f0ed9cf2dfcaaa":["8476949555f799dff381770c01cfad051a264487"],"43564cbb30b064675027cfb569564e8531096e97":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","bfc52860e6d13d034226a760813c59d984c6817a"],"c3c3931df936f937d0001d9fda9ead62f8599479":["cb5af3afeddbb803fb785098176e6e177c34261b"],"354983dcdf70c800bf2573d10b54a7391b1dc167":["d264f386d864b5751209060e8886ca9845f70469"],"7871f9c286dce2a9370bcf517a3e7d12e3bd9602":["74aea047dff7f7c38a2d766827bd20d356f98c6a"],"936cdd5882761db3b844afd6f84ab81cbb011a75":["30c8e5574b55d57947e989443dfde611646530ee","d301cb76d81de80d07b44735622a04d49ed938eb"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":["491c9672ec42582fe43960452dbd37f1c80fe0f0","9b10b88c8af8835e23b0d566418ef8397a7bb8ed"],"c0b6680904fafe5905f847812d32dc7ad79c96a0":["434ea3e1b8afaaa792776459544b57703cd6872b"],"2f472c757c161e228505e389efda705e2cf3c09e":["056ef30406180176075c44183ec40de4d2b8c68a"],"f8f0f2472d437d44ec2144932e1d13fb494e82a3":["946009ad0fba506337041a368b0a74d2edd59e2c"],"f763a1acdb27217b4799d1ca51c816739835a3e0":["a7035935aa89f6951286e9005cbeb16e89a082a2"],"a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b":["b6284684320a9808c41a5e43de958b2da22f89bd"],"0ad7bdba3e91cf3373cda2e52239cb761fc0b452":["a4d419cdab641a032f3e0d0fa8167a5252be0ae3"],"92d579a5d677457eb3cbac9551000f590be33b55":["1852cb03cf4922477072449dd9de2fab588d1adb"],"93d40a0287bd8a5b69a8df49a797dcd4a8b1a7be":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","6a9fde5df1c4cdd5292c6a5292c39c630896af8c"],"85032ab568b3f50eabd577aaa994ba197db93758":["2d4e985daefcb892b529223b478c47985fc3c483"],"00e1c8e1340d9e31d2c6bee5f72d9040ce569049":["c3c3931df936f937d0001d9fda9ead62f8599479"],"7947ef57ebadfb891b1c694f0772d616987e57c8":["0ad7bdba3e91cf3373cda2e52239cb761fc0b452"],"0d5e442cae8cd58c4f22df43dacbd0018fc0ac1b":["073f1aa70444ec64f3e216816af2a3b43fa38fe7"],"b0b597c65628ca9e73913a07e81691f8229bae35":["99d6782cf9de8c5ffeb8d0b0f103b578205af068","8476949555f799dff381770c01cfad051a264487"]},"commit2Childs":{"b8f0a7504661c8e51be5c63e87f9d79a36d9116c":[],"7116474e2e390259937401cf928323e0cbc75e60":["b64a893a6d2efaa60e289534b1f8713e4aa2c776"],"2209af2c265d2258ec4b29c8cc78622d36994a15":["b9248e8833b6ab03d4e0ebbeaa8b26d8798e7659"],"97bd2b0da4beced82821b752b29576be986cf1ff":["f56da6f4f15d95f318d2d6ac2a39a9183dfecff2"],"58b7eb80017f1c5b32035176b965fa0cc0287d04":["439c63ae5d22132fca810a0029a854e97d2c1a3e"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["716d18f3a9b0993bc679d7fa7abdc9bfb03411ec"],"d218decf811b7a0a4d86218c54c79c74a962374b":["b8f0a7504661c8e51be5c63e87f9d79a36d9116c","b0dda625d0f49ef568959e45adabe6d6faa39412"],"8b6a4b585aed7660a589375f6a09b90efd29c961":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb"],"f225b9b576dc345ee8c27f91147b4afc0350511c":["6e764e9a107f93be9fa3c922bc6a197b3eec387e"],"1852cb03cf4922477072449dd9de2fab588d1adb":["92d579a5d677457eb3cbac9551000f590be33b55"],"9227359ab3bd86e5b85fab89a99332da7d5bacb1":["8b6a4b585aed7660a589375f6a09b90efd29c961"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["30c8e5574b55d57947e989443dfde611646530ee"],"58884af1f68e9d61c217c753fbd6266d86a63b14":[],"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf":["f03e4bed5023ec3ef93a771b8888cae991cf448d"],"0cdbfc1e5714aafb41cabb055936a38ba4db5362":["2022c62013ac31ba0bed28b0f0e6faf9af8dd2aa"],"140be51d03394488536f4aacedace29f9b318347":["0cdbfc1e5714aafb41cabb055936a38ba4db5362"],"073f1aa70444ec64f3e216816af2a3b43fa38fe7":["ab68488225b6a6c357dda72ed11dedca9914a192","f34d83c894e07c24f5f957820777b5da2cc29e5a","0d5e442cae8cd58c4f22df43dacbd0018fc0ac1b"],"38fb691372ae1411a8a486192885334fd3ae7244":["ec5a4e4c455009870c1cb8d21cf6671b8b78d3e3"],"ab68488225b6a6c357dda72ed11dedca9914a192":["9227359ab3bd86e5b85fab89a99332da7d5bacb1"],"f56da6f4f15d95f318d2d6ac2a39a9183dfecff2":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"4aea71c8b6a44bbbd3b8fcc42e5838a92b35634f":["aa5e39259dfd4a68287c824d3b7e1bc9097dc895"],"004ec9e26487ae9b6205e790f8f77ef5e98d8daf":["9efa9c0fcd87863d1a86eed29d4304c11bc7d50a"],"3f504512a03d978990cbff30db0522b354e846db":["434ea3e1b8afaaa792776459544b57703cd6872b"],"e22a92d60a5a6320f9653856966fcd77c60953b3":["f3783d6f4d080f4f0116769e0e1b0f0f440565c4"],"2e9e5eaf280a6aa21423126b8232aa157a9b7366":["954ae83b7dfacaa33d48ea056448ae11f7745a93"],"92a4da96826f502cf1a56a096929b37ce73e523a":["716d18f3a9b0993bc679d7fa7abdc9bfb03411ec","5e732472e86aa53222c571de21dcb7d6a75c1c87"],"1e6acbaae7af722f17204ceccf0f7db5753eccf3":[],"30c8e5574b55d57947e989443dfde611646530ee":["936cdd5882761db3b844afd6f84ab81cbb011a75"],"729cb470f975115d4c60517b2cb7c42e37a7a2e1":["195fcfcffd8f9047ac27ac642ee9da64f4e6c4fa"],"d301cb76d81de80d07b44735622a04d49ed938eb":["056ef30406180176075c44183ec40de4d2b8c68a","936cdd5882761db3b844afd6f84ab81cbb011a75"],"f912f3dd0ef8a72704a10ac2fddbae91f4db66de":["99d6782cf9de8c5ffeb8d0b0f103b578205af068"],"126d6ad24eed13163ba0959435d5a80e5672837c":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["93d40a0287bd8a5b69a8df49a797dcd4a8b1a7be"],"4bb866c04f137107dcf5b8f0e5bcee02fc832050":["cbaf96cfda5422c42955ce34344f0e01839894ea"],"bfc52860e6d13d034226a760813c59d984c6817a":["43564cbb30b064675027cfb569564e8531096e97"],"fb50877dc038c021eba3a70999fd1f6ed85001c1":["f912f3dd0ef8a72704a10ac2fddbae91f4db66de"],"7c2af5a711bd6e2d33e0221ced0f47ac596ed275":["42f6b881386654cc8e0dab45bc451dc41b627f68"],"b6284684320a9808c41a5e43de958b2da22f89bd":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b"],"3301c97f51316f9c9937654c07d7a6a21e7aecb8":["6240b74b884c5587f2a4062dd27d6c32bf228889"],"80d0e6d59ae23f4a6f30eaf40bfb40742300287f":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf"],"275019a81d0883a1db4560391b072d1fbe272ec4":["b3a34dae868734612eb6329aa0ef754f30bd2036"],"6a9fde5df1c4cdd5292c6a5292c39c630896af8c":["58884af1f68e9d61c217c753fbd6266d86a63b14","004ec9e26487ae9b6205e790f8f77ef5e98d8daf","9efa9c0fcd87863d1a86eed29d4304c11bc7d50a","93d40a0287bd8a5b69a8df49a797dcd4a8b1a7be"],"9bc766d645fa848f86c381c7f6acf2c881c99399":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cb5af3afeddbb803fb785098176e6e177c34261b"],"f90f26c648df8320685eb76fec8bb9972e1994c4":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"c44cc06c26e456fe9c215072b79fce30babe3975":["8476949555f799dff381770c01cfad051a264487"],"cc69baf14413994ccde897681e5ce1d393cf7156":["e22a92d60a5a6320f9653856966fcd77c60953b3"],"439c63ae5d22132fca810a0029a854e97d2c1a3e":["275019a81d0883a1db4560391b072d1fbe272ec4"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","946009ad0fba506337041a368b0a74d2edd59e2c"],"b16266db764c72c65ab2977b36da1436b4efbb9f":["9b10b88c8af8835e23b0d566418ef8397a7bb8ed","491c9672ec42582fe43960452dbd37f1c80fe0f0"],"434ea3e1b8afaaa792776459544b57703cd6872b":["680b6449f09827f58fe987aff279e014c311d966","c0b6680904fafe5905f847812d32dc7ad79c96a0"],"170ef9c82c0d27d4151feff316ba63fbedd91bbf":["b363b110592b02d7f488aff0dbe40a53d3ce81df"],"74aea047dff7f7c38a2d766827bd20d356f98c6a":["e9017cf144952056066919f1ebc7897ff9bd71b1","7871f9c286dce2a9370bcf517a3e7d12e3bd9602"],"2668c99990e4c94a78bac005aa682b7c5986d23a":["fb50877dc038c021eba3a70999fd1f6ed85001c1"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["37a0f60745e53927c4c876cfe5b5a58170f0646c","d264f386d864b5751209060e8886ca9845f70469"],"6e764e9a107f93be9fa3c922bc6a197b3eec387e":["37a0f60745e53927c4c876cfe5b5a58170f0646c","92a4da96826f502cf1a56a096929b37ce73e523a"],"6db2a2569883aff84117ae03caf199738df62519":["ab68488225b6a6c357dda72ed11dedca9914a192"],"01f63edf15d2e3dbb3355d974f733b263098cb46":["4bb866c04f137107dcf5b8f0e5bcee02fc832050"],"a7035935aa89f6951286e9005cbeb16e89a082a2":["f763a1acdb27217b4799d1ca51c816739835a3e0"],"d402ed03d3abe439fa7859facfae3c2fe0aba77e":["9435d55e3ea95c5d94406d3affc36f9505b6a736"],"043df2e9a841864922c32756a44c939ed768cb89":["b6284684320a9808c41a5e43de958b2da22f89bd"],"9435d55e3ea95c5d94406d3affc36f9505b6a736":["816521ebaad5add9cb96bb88c577394e2938c40b"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["7e66d99e5beccb546edd910c91f646fb7d831a94"],"337a3230c591e6094030c97d6ed767b261bcd851":["4aeabc53a9c50bd4c04c5261562b3e78cc2ea744"],"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576"],"2022c62013ac31ba0bed28b0f0e6faf9af8dd2aa":["dfc068060fd93e9c7417d1271ca797dc90496f67"],"b61ef53ee9899b83a89bf97542c28a4cfd0a64bf":["073f1aa70444ec64f3e216816af2a3b43fa38fe7"],"99d6782cf9de8c5ffeb8d0b0f103b578205af068":["c44cc06c26e456fe9c215072b79fce30babe3975","b0b597c65628ca9e73913a07e81691f8229bae35"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":[],"57c238f5fb83803b49b37b3a1a12224a64d47542":["3f504512a03d978990cbff30db0522b354e846db"],"fb65cc25534f4e0d77ed573d35995eb0b836b818":["1e6acbaae7af722f17204ceccf0f7db5753eccf3","b6284684320a9808c41a5e43de958b2da22f89bd","043df2e9a841864922c32756a44c939ed768cb89","acd1f5a977dc3b97799ed300423294e2c457774f"],"b9248e8833b6ab03d4e0ebbeaa8b26d8798e7659":["e78c35bca3e32dfc7a695136fa2b5de1ae135c22"],"d528fd7ae22865015b756e0a03832e2051de2a9c":["170ef9c82c0d27d4151feff316ba63fbedd91bbf","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","b363b110592b02d7f488aff0dbe40a53d3ce81df"],"d264f386d864b5751209060e8886ca9845f70469":["354983dcdf70c800bf2573d10b54a7391b1dc167"],"5ba0abe4039f82ecf2e5f879913f512e941dde81":[],"28288370235ed02234a64753cdbf0c6ec096304a":["30c8e5574b55d57947e989443dfde611646530ee","d301cb76d81de80d07b44735622a04d49ed938eb","bd7a2b4785d366164d3cd69f9948de6ff34d23a1"],"816521ebaad5add9cb96bb88c577394e2938c40b":["729cb470f975115d4c60517b2cb7c42e37a7a2e1"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["80d0e6d59ae23f4a6f30eaf40bfb40742300287f"],"d9d424bd039937b4125152b454b3a32754b06f6c":["a7035935aa89f6951286e9005cbeb16e89a082a2","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"cbaf96cfda5422c42955ce34344f0e01839894ea":["2668c99990e4c94a78bac005aa682b7c5986d23a"],"a513b6a92751e54c76fb5447948c9e7d437163a7":["74aea047dff7f7c38a2d766827bd20d356f98c6a"],"650b520f2a4daa4b0712e2393dc29ae7f21f10ac":["57c238f5fb83803b49b37b3a1a12224a64d47542"],"f3783d6f4d080f4f0116769e0e1b0f0f440565c4":["337a3230c591e6094030c97d6ed767b261bcd851","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"f34d83c894e07c24f5f957820777b5da2cc29e5a":["d402ed03d3abe439fa7859facfae3c2fe0aba77e"],"2d4e985daefcb892b529223b478c47985fc3c483":["85032ab568b3f50eabd577aaa994ba197db93758"],"10399eb409ace56e6d66f136f184643f7432371d":["a626ec4d1c92e59fe390724d6220081047b03ce7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"16fa358573e3c2508728b3c7c438a8c19a3f0ae4":["bf28d12ff32dc50412338f84022406e2be7d44f2"],"b0dda625d0f49ef568959e45adabe6d6faa39412":["bd680b8f0b159dc1c7a01439c3c7f065bf3e69c7"],"9efa9c0fcd87863d1a86eed29d4304c11bc7d50a":["560c18d71dad43d675158783c3840f8c80d6d39c","6240b74b884c5587f2a4062dd27d6c32bf228889","c304e97e7c1d472bc70e801b35ee78583916c6cd"],"919b9b89b8d44ea491f18a92e6d52efcf5f7a065":["fb03700c9690d16b15fb4f56f6ec36b128fd894e"],"9b10b88c8af8835e23b0d566418ef8397a7bb8ed":["1214bb624eb41181e5c8e260e0050c7e973ba0f4","09ab8ee44ca898536770d0106a7c0ee4be4f0eb7"],"c8c09c323959c458fb515b3f9a2ce29958ce1478":["d275f25d46bec8d215cc9d810169af5bf57ff35a"],"d275f25d46bec8d215cc9d810169af5bf57ff35a":["d9d424bd039937b4125152b454b3a32754b06f6c"],"680b6449f09827f58fe987aff279e014c311d966":["1852cb03cf4922477072449dd9de2fab588d1adb"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"b64a893a6d2efaa60e289534b1f8713e4aa2c776":["f225b9b576dc345ee8c27f91147b4afc0350511c"],"954ae83b7dfacaa33d48ea056448ae11f7745a93":["7c2af5a711bd6e2d33e0221ced0f47ac596ed275"],"2b2cafc02486bd97e4f7849f5360581a8084c8c1":["74aea047dff7f7c38a2d766827bd20d356f98c6a","28288370235ed02234a64753cdbf0c6ec096304a","a513b6a92751e54c76fb5447948c9e7d437163a7"],"a626ec4d1c92e59fe390724d6220081047b03ce7":["1e6acbaae7af722f17204ceccf0f7db5753eccf3","fb65cc25534f4e0d77ed573d35995eb0b836b818","acd1f5a977dc3b97799ed300423294e2c457774f"],"b70042a8a492f7054d480ccdd2be9796510d4327":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5"],"b363b110592b02d7f488aff0dbe40a53d3ce81df":["80d0e6d59ae23f4a6f30eaf40bfb40742300287f","0265144286422ad99682a00904cc2536b79c8535"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["bfc52860e6d13d034226a760813c59d984c6817a","43564cbb30b064675027cfb569564e8531096e97"],"7e66d99e5beccb546edd910c91f646fb7d831a94":["2d4e985daefcb892b529223b478c47985fc3c483"],"560c18d71dad43d675158783c3840f8c80d6d39c":["f90f26c648df8320685eb76fec8bb9972e1994c4"],"bd680b8f0b159dc1c7a01439c3c7f065bf3e69c7":["38fb691372ae1411a8a486192885334fd3ae7244"],"fbedb82f40fd431141e6baeedc018c99a07ab6a0":["6bbcc5460302e3534b1328862b0be6276184560f","6c6b7e01cb749c3b01e226e06085dfb1d9ed8eab"],"6bbcc5460302e3534b1328862b0be6276184560f":["d218decf811b7a0a4d86218c54c79c74a962374b","6c6b7e01cb749c3b01e226e06085dfb1d9ed8eab"],"8476949555f799dff381770c01cfad051a264487":["c959a64c5b52cc12eb8daa17f4f0ed9cf2dfcaaa","b0b597c65628ca9e73913a07e81691f8229bae35"],"bf28d12ff32dc50412338f84022406e2be7d44f2":["b16266db764c72c65ab2977b36da1436b4efbb9f","f03e4bed5023ec3ef93a771b8888cae991cf448d"],"f03e4bed5023ec3ef93a771b8888cae991cf448d":["491c9672ec42582fe43960452dbd37f1c80fe0f0"],"0265144286422ad99682a00904cc2536b79c8535":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","16fa358573e3c2508728b3c7c438a8c19a3f0ae4"],"6c6b7e01cb749c3b01e226e06085dfb1d9ed8eab":["b8f0a7504661c8e51be5c63e87f9d79a36d9116c"],"6240b74b884c5587f2a4062dd27d6c32bf228889":["c304e97e7c1d472bc70e801b35ee78583916c6cd"],"fb03700c9690d16b15fb4f56f6ec36b128fd894e":["140be51d03394488536f4aacedace29f9b318347"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"195fcfcffd8f9047ac27ac642ee9da64f4e6c4fa":["2b2cafc02486bd97e4f7849f5360581a8084c8c1"],"f592209545c71895260367152601e9200399776d":["7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"750239682d222924398443d581163940f48d68fc":["01f63edf15d2e3dbb3355d974f733b263098cb46"],"cb5af3afeddbb803fb785098176e6e177c34261b":["c3c3931df936f937d0001d9fda9ead62f8599479"],"6bdcb86c29922edae9a14852e636303bc52df094":["2209af2c265d2258ec4b29c8cc78622d36994a15"],"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["e9017cf144952056066919f1ebc7897ff9bd71b1"],"c304e97e7c1d472bc70e801b35ee78583916c6cd":["560c18d71dad43d675158783c3840f8c80d6d39c"],"b2fdcd0303309a07ecdda1d98f6806404d741129":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","6a9fde5df1c4cdd5292c6a5292c39c630896af8c"],"acd1f5a977dc3b97799ed300423294e2c457774f":[],"fd44bec977a26a118d9e809e2de6f7edb5ca0f39":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","e15199583d3635cb940942caed05132dd6c4c7c6"],"aa5e39259dfd4a68287c824d3b7e1bc9097dc895":["4181b4cf0450ea3c6d1aff8dc3ad4ed9cd3eeb6a"],"5e732472e86aa53222c571de21dcb7d6a75c1c87":["3dffec77fb8f7d0e9ca4869dddd6af94528b4576","c8c09c323959c458fb515b3f9a2ce29958ce1478"],"b3a34dae868734612eb6329aa0ef754f30bd2036":["6bdcb86c29922edae9a14852e636303bc52df094"],"4aeabc53a9c50bd4c04c5261562b3e78cc2ea744":["126d6ad24eed13163ba0959435d5a80e5672837c","7f0c8426396c925de8db3ed3f8ff40fd73670a5c"],"7f0c8426396c925de8db3ed3f8ff40fd73670a5c":["126d6ad24eed13163ba0959435d5a80e5672837c"],"e15199583d3635cb940942caed05132dd6c4c7c6":["9bc766d645fa848f86c381c7f6acf2c881c99399"],"1214bb624eb41181e5c8e260e0050c7e973ba0f4":["b61ef53ee9899b83a89bf97542c28a4cfd0a64bf"],"946009ad0fba506337041a368b0a74d2edd59e2c":["b70042a8a492f7054d480ccdd2be9796510d4327","f592209545c71895260367152601e9200399776d","f8f0f2472d437d44ec2144932e1d13fb494e82a3"],"ec5a4e4c455009870c1cb8d21cf6671b8b78d3e3":["919b9b89b8d44ea491f18a92e6d52efcf5f7a065"],"80ebe5b1d946f7c2ed9c46206b0c7254dc21206a":["10399eb409ace56e6d66f136f184643f7432371d"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["d528fd7ae22865015b756e0a03832e2051de2a9c"],"dfc068060fd93e9c7417d1271ca797dc90496f67":["650b520f2a4daa4b0712e2393dc29ae7f21f10ac"],"e78c35bca3e32dfc7a695136fa2b5de1ae135c22":["80ebe5b1d946f7c2ed9c46206b0c7254dc21206a"],"a4d419cdab641a032f3e0d0fa8167a5252be0ae3":["0ad7bdba3e91cf3373cda2e52239cb761fc0b452"],"bd7a2b4785d366164d3cd69f9948de6ff34d23a1":["d301cb76d81de80d07b44735622a04d49ed938eb"],"056ef30406180176075c44183ec40de4d2b8c68a":["2f472c757c161e228505e389efda705e2cf3c09e"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[],"491c9672ec42582fe43960452dbd37f1c80fe0f0":["09ab8ee44ca898536770d0106a7c0ee4be4f0eb7"],"42f6b881386654cc8e0dab45bc451dc41b627f68":["fbedb82f40fd431141e6baeedc018c99a07ab6a0"],"43564cbb30b064675027cfb569564e8531096e97":["4aea71c8b6a44bbbd3b8fcc42e5838a92b35634f","aa5e39259dfd4a68287c824d3b7e1bc9097dc895"],"c959a64c5b52cc12eb8daa17f4f0ed9cf2dfcaaa":["2e9e5eaf280a6aa21423126b8232aa157a9b7366"],"c3c3931df936f937d0001d9fda9ead62f8599479":["00e1c8e1340d9e31d2c6bee5f72d9040ce569049"],"354983dcdf70c800bf2573d10b54a7391b1dc167":["7116474e2e390259937401cf928323e0cbc75e60"],"936cdd5882761db3b844afd6f84ab81cbb011a75":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac"],"7871f9c286dce2a9370bcf517a3e7d12e3bd9602":["28288370235ed02234a64753cdbf0c6ec096304a"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":[],"c0b6680904fafe5905f847812d32dc7ad79c96a0":["680b6449f09827f58fe987aff279e014c311d966"],"2f472c757c161e228505e389efda705e2cf3c09e":["58884af1f68e9d61c217c753fbd6266d86a63b14","b2fdcd0303309a07ecdda1d98f6806404d741129"],"f8f0f2472d437d44ec2144932e1d13fb494e82a3":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","750239682d222924398443d581163940f48d68fc","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"f763a1acdb27217b4799d1ca51c816739835a3e0":["97bd2b0da4beced82821b752b29576be986cf1ff","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b":["cc69baf14413994ccde897681e5ce1d393cf7156"],"0ad7bdba3e91cf3373cda2e52239cb761fc0b452":["5ba0abe4039f82ecf2e5f879913f512e941dde81","7947ef57ebadfb891b1c694f0772d616987e57c8"],"93d40a0287bd8a5b69a8df49a797dcd4a8b1a7be":["3301c97f51316f9c9937654c07d7a6a21e7aecb8"],"92d579a5d677457eb3cbac9551000f590be33b55":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"85032ab568b3f50eabd577aaa994ba197db93758":["a4d419cdab641a032f3e0d0fa8167a5252be0ae3"],"00e1c8e1340d9e31d2c6bee5f72d9040ce569049":["58b7eb80017f1c5b32035176b965fa0cc0287d04"],"0d5e442cae8cd58c4f22df43dacbd0018fc0ac1b":["6db2a2569883aff84117ae03caf199738df62519"],"7947ef57ebadfb891b1c694f0772d616987e57c8":["5ba0abe4039f82ecf2e5f879913f512e941dde81","fd44bec977a26a118d9e809e2de6f7edb5ca0f39"],"b0b597c65628ca9e73913a07e81691f8229bae35":[]},"heads":["b8f0a7504661c8e51be5c63e87f9d79a36d9116c","58884af1f68e9d61c217c753fbd6266d86a63b14","1e6acbaae7af722f17204ceccf0f7db5753eccf3","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","5ba0abe4039f82ecf2e5f879913f512e941dde81","cd5edd1f2b162a5cfa08efd17851a07373a96817","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","74f45af4339b0daf7a95c820ab88c1aea74fbce0","acd1f5a977dc3b97799ed300423294e2c457774f","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","b0b597c65628ca9e73913a07e81691f8229bae35"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}