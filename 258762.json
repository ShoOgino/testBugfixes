{"path":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // TODO: Support out-of-order scoring!\n        // For now we return false here, as we always get the scorer in order\n        return false;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSet.EMPTY_DOCIDSET.iterator() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSet.EMPTY_DOCIDSET.iterator();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() { return FilteredQuery.this; }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n        \n        final DocIdSetIterator filterIter = filterDocIdSet.iterator();\n        if (filterIter == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        final int firstFilterDoc = filterIter.nextDoc();\n        if (firstFilterDoc == DocIdSetIterator.NO_MORE_DOCS) {\n          return null;\n        }\n        \n        final Bits filterAcceptDocs = filterDocIdSet.bits();\n        final boolean useRandomAccess = (filterAcceptDocs != null && FilteredQuery.this.useRandomAccess(filterAcceptDocs, firstFilterDoc));\n\n        if (useRandomAccess) {\n          // if we are using random access, we return the inner scorer, just with other acceptDocs\n          // TODO, replace this by when BooleanWeight is fixed to be consistent with its scorer implementations:\n          // return weight.scorer(context, scoreDocsInOrder, topScorer, filterAcceptDocs);\n          return weight.scorer(context, true, topScorer, filterAcceptDocs);\n        } else {\n          assert firstFilterDoc > -1;\n          // we are gonna advance() this scorer, so we set inorder=true/toplevel=false\n          // we pass null as acceptDocs, as our filter has already respected acceptDocs, no need to do twice\n          final Scorer scorer = weight.scorer(context, true, false, null);\n          return (scorer == null) ? null : new Scorer(this) {\n            private int scorerDoc = -1, filterDoc = firstFilterDoc;\n            \n            // optimization: we are topScorer and collect directly using short-circuited algo\n            @Override\n            public void score(Collector collector) throws IOException {\n              int filterDoc = firstFilterDoc;\n              int scorerDoc = scorer.advance(filterDoc);\n              // the normalization trick already applies the boost of this query,\n              // so we can use the wrapped scorer directly:\n              collector.setScorer(scorer);\n              for (;;) {\n                if (scorerDoc == filterDoc) {\n                  // Check if scorer has exhausted, only before collecting.\n                  if (scorerDoc == DocIdSetIterator.NO_MORE_DOCS) {\n                    break;\n                  }\n                  collector.collect(scorerDoc);\n                  filterDoc = filterIter.nextDoc();\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc > filterDoc) {\n                  filterDoc = filterIter.advance(scorerDoc);\n                } else {\n                  scorerDoc = scorer.advance(filterDoc);\n                }\n              }\n            }\n            \n            private int advanceToNextCommonDoc() throws IOException {\n              for (;;) {\n                if (scorerDoc < filterDoc) {\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc == filterDoc) {\n                  return scorerDoc;\n                } else {\n                  filterDoc = filterIter.advance(scorerDoc);\n                }\n              }\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              // don't go to next doc on first call\n              // (because filterIter is already on first doc):\n              if (scorerDoc != -1) {\n                filterDoc = filterIter.nextDoc();\n              }\n              return advanceToNextCommonDoc();\n            }\n            \n            @Override\n            public int advance(int target) throws IOException {\n              if (target > filterDoc) {\n                filterDoc = filterIter.advance(target);\n              }\n              return advanceToNextCommonDoc();\n            }\n\n            @Override\n            public int docID() {\n              return scorerDoc;\n            }\n            \n            @Override\n            public float score() throws IOException {\n              return scorer.score();\n            }\n          };\n        }\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // TODO: Support out-of-order scoring!\n        // For now we return false here, as we always get the scorer in order\n        return false;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSet.EMPTY_DOCIDSET.iterator() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSet.EMPTY_DOCIDSET.iterator();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() { return FilteredQuery.this; }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n        \n        final DocIdSetIterator filterIter = filterDocIdSet.iterator();\n        if (filterIter == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        final int firstFilterDoc = filterIter.nextDoc();\n        if (firstFilterDoc == DocIdSetIterator.NO_MORE_DOCS) {\n          return null;\n        }\n        \n        final Bits filterAcceptDocs = filterDocIdSet.bits();\n        final boolean useRandomAccess = (filterAcceptDocs != null && FilteredQuery.this.useRandomAccess(filterAcceptDocs, firstFilterDoc));\n\n        if (useRandomAccess) {\n          // if we are using random access, we return the inner scorer, just with other acceptDocs\n          // TODO, replace this by when BooleanWeight is fixed to be consistent with its scorer implementations:\n          // return weight.scorer(context, scoreDocsInOrder, topScorer, filterAcceptDocs);\n          return weight.scorer(context, true, topScorer, filterAcceptDocs);\n        } else {\n          assert firstFilterDoc > -1;\n          // we are gonna advance() this scorer, so we set inorder=true/toplevel=false\n          // we pass null as acceptDocs, as our filter has already respected acceptDocs, no need to do twice\n          final Scorer scorer = weight.scorer(context, true, false, null);\n          return (scorer == null) ? null : new Scorer(this) {\n            private int scorerDoc = -1, filterDoc = firstFilterDoc;\n            \n            // optimization: we are topScorer and collect directly using short-circuited algo\n            @Override\n            public void score(Collector collector) throws IOException {\n              int filterDoc = firstFilterDoc;\n              int scorerDoc = scorer.advance(filterDoc);\n              // the normalization trick already applies the boost of this query,\n              // so we can use the wrapped scorer directly:\n              collector.setScorer(scorer);\n              for (;;) {\n                if (scorerDoc == filterDoc) {\n                  // Check if scorer has exhausted, only before collecting.\n                  if (scorerDoc == DocIdSetIterator.NO_MORE_DOCS) {\n                    break;\n                  }\n                  collector.collect(scorerDoc);\n                  filterDoc = filterIter.nextDoc();\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc > filterDoc) {\n                  filterDoc = filterIter.advance(scorerDoc);\n                } else {\n                  scorerDoc = scorer.advance(filterDoc);\n                }\n              }\n            }\n            \n            private int advanceToNextCommonDoc() throws IOException {\n              for (;;) {\n                if (scorerDoc < filterDoc) {\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc == filterDoc) {\n                  return scorerDoc;\n                } else {\n                  filterDoc = filterIter.advance(scorerDoc);\n                }\n              }\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              // don't go to next doc on first call\n              // (because filterIter is already on first doc):\n              if (scorerDoc != -1) {\n                filterDoc = filterIter.nextDoc();\n              }\n              return advanceToNextCommonDoc();\n            }\n            \n            @Override\n            public int advance(int target) throws IOException {\n              if (target > filterDoc) {\n                filterDoc = filterIter.advance(target);\n              }\n              return advanceToNextCommonDoc();\n            }\n\n            @Override\n            public int docID() {\n              return scorerDoc;\n            }\n            \n            @Override\n            public float score() throws IOException {\n              return scorer.score();\n            }\n          };\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ea8268d5f00bb25a4ea1d0bac6e2ffe238712c45","date":1342645458,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // TODO: Support out-of-order scoring!\n        // For now we return false here, as we always get the scorer in order\n        return false;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSet.EMPTY_DOCIDSET.iterator() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSet.EMPTY_DOCIDSET.iterator();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() { return FilteredQuery.this; }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n        \n        final DocIdSetIterator filterIter = filterDocIdSet.iterator();\n        if (filterIter == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        final int firstFilterDoc = filterIter.nextDoc();\n        if (firstFilterDoc == DocIdSetIterator.NO_MORE_DOCS) {\n          return null;\n        }\n        \n        final Bits filterAcceptDocs = filterDocIdSet.bits();\n        final boolean useRandomAccess = (filterAcceptDocs != null && FilteredQuery.this.useRandomAccess(filterAcceptDocs, firstFilterDoc));\n\n        if (useRandomAccess) {\n          // if we are using random access, we return the inner scorer, just with other acceptDocs\n          // TODO, replace this by when BooleanWeight is fixed to be consistent with its scorer implementations:\n          // return weight.scorer(context, scoreDocsInOrder, topScorer, filterAcceptDocs);\n          return weight.scorer(context, true, topScorer, filterAcceptDocs);\n        } else {\n          assert firstFilterDoc > -1;\n          // we are gonna advance() this scorer, so we set inorder=true/toplevel=false\n          // we pass null as acceptDocs, as our filter has already respected acceptDocs, no need to do twice\n          final Scorer scorer = weight.scorer(context, true, false, null);\n          return (scorer == null) ? null : new Scorer(this) {\n            private int scorerDoc = -1, filterDoc = firstFilterDoc;\n            \n            // optimization: we are topScorer and collect directly using short-circuited algo\n            @Override\n            public void score(Collector collector) throws IOException {\n              int filterDoc = firstFilterDoc;\n              int scorerDoc = scorer.advance(filterDoc);\n              // the normalization trick already applies the boost of this query,\n              // so we can use the wrapped scorer directly:\n              collector.setScorer(scorer);\n              for (;;) {\n                if (scorerDoc == filterDoc) {\n                  // Check if scorer has exhausted, only before collecting.\n                  if (scorerDoc == DocIdSetIterator.NO_MORE_DOCS) {\n                    break;\n                  }\n                  collector.collect(scorerDoc);\n                  filterDoc = filterIter.nextDoc();\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc > filterDoc) {\n                  filterDoc = filterIter.advance(scorerDoc);\n                } else {\n                  scorerDoc = scorer.advance(filterDoc);\n                }\n              }\n            }\n            \n            private int advanceToNextCommonDoc() throws IOException {\n              for (;;) {\n                if (scorerDoc < filterDoc) {\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc == filterDoc) {\n                  return scorerDoc;\n                } else {\n                  filterDoc = filterIter.advance(scorerDoc);\n                }\n              }\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              // don't go to next doc on first call\n              // (because filterIter is already on first doc):\n              if (scorerDoc != -1) {\n                filterDoc = filterIter.nextDoc();\n              }\n              return advanceToNextCommonDoc();\n            }\n            \n            @Override\n            public int advance(int target) throws IOException {\n              if (target > filterDoc) {\n                filterDoc = filterIter.advance(target);\n              }\n              return advanceToNextCommonDoc();\n            }\n\n            @Override\n            public int docID() {\n              return scorerDoc;\n            }\n            \n            @Override\n            public float score() throws IOException {\n              return scorer.score();\n            }\n            \n            @Override\n            public float freq() throws IOException { return scorer.freq(); }\n            \n            @Override\n            public Collection<ChildScorer> getChildren() {\n              return Collections.singleton(new ChildScorer(scorer, \"FILTERED\"));\n            }\n          };\n        }\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // TODO: Support out-of-order scoring!\n        // For now we return false here, as we always get the scorer in order\n        return false;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSet.EMPTY_DOCIDSET.iterator() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSet.EMPTY_DOCIDSET.iterator();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() { return FilteredQuery.this; }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n        \n        final DocIdSetIterator filterIter = filterDocIdSet.iterator();\n        if (filterIter == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        final int firstFilterDoc = filterIter.nextDoc();\n        if (firstFilterDoc == DocIdSetIterator.NO_MORE_DOCS) {\n          return null;\n        }\n        \n        final Bits filterAcceptDocs = filterDocIdSet.bits();\n        final boolean useRandomAccess = (filterAcceptDocs != null && FilteredQuery.this.useRandomAccess(filterAcceptDocs, firstFilterDoc));\n\n        if (useRandomAccess) {\n          // if we are using random access, we return the inner scorer, just with other acceptDocs\n          // TODO, replace this by when BooleanWeight is fixed to be consistent with its scorer implementations:\n          // return weight.scorer(context, scoreDocsInOrder, topScorer, filterAcceptDocs);\n          return weight.scorer(context, true, topScorer, filterAcceptDocs);\n        } else {\n          assert firstFilterDoc > -1;\n          // we are gonna advance() this scorer, so we set inorder=true/toplevel=false\n          // we pass null as acceptDocs, as our filter has already respected acceptDocs, no need to do twice\n          final Scorer scorer = weight.scorer(context, true, false, null);\n          return (scorer == null) ? null : new Scorer(this) {\n            private int scorerDoc = -1, filterDoc = firstFilterDoc;\n            \n            // optimization: we are topScorer and collect directly using short-circuited algo\n            @Override\n            public void score(Collector collector) throws IOException {\n              int filterDoc = firstFilterDoc;\n              int scorerDoc = scorer.advance(filterDoc);\n              // the normalization trick already applies the boost of this query,\n              // so we can use the wrapped scorer directly:\n              collector.setScorer(scorer);\n              for (;;) {\n                if (scorerDoc == filterDoc) {\n                  // Check if scorer has exhausted, only before collecting.\n                  if (scorerDoc == DocIdSetIterator.NO_MORE_DOCS) {\n                    break;\n                  }\n                  collector.collect(scorerDoc);\n                  filterDoc = filterIter.nextDoc();\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc > filterDoc) {\n                  filterDoc = filterIter.advance(scorerDoc);\n                } else {\n                  scorerDoc = scorer.advance(filterDoc);\n                }\n              }\n            }\n            \n            private int advanceToNextCommonDoc() throws IOException {\n              for (;;) {\n                if (scorerDoc < filterDoc) {\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc == filterDoc) {\n                  return scorerDoc;\n                } else {\n                  filterDoc = filterIter.advance(scorerDoc);\n                }\n              }\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              // don't go to next doc on first call\n              // (because filterIter is already on first doc):\n              if (scorerDoc != -1) {\n                filterDoc = filterIter.nextDoc();\n              }\n              return advanceToNextCommonDoc();\n            }\n            \n            @Override\n            public int advance(int target) throws IOException {\n              if (target > filterDoc) {\n                filterDoc = filterIter.advance(target);\n              }\n              return advanceToNextCommonDoc();\n            }\n\n            @Override\n            public int docID() {\n              return scorerDoc;\n            }\n            \n            @Override\n            public float score() throws IOException {\n              return scorer.score();\n            }\n          };\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // TODO: Support out-of-order scoring!\n        // For now we return false here, as we always get the scorer in order\n        return false;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSet.EMPTY_DOCIDSET.iterator() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSet.EMPTY_DOCIDSET.iterator();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() { return FilteredQuery.this; }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n        \n        final DocIdSetIterator filterIter = filterDocIdSet.iterator();\n        if (filterIter == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        final int firstFilterDoc = filterIter.nextDoc();\n        if (firstFilterDoc == DocIdSetIterator.NO_MORE_DOCS) {\n          return null;\n        }\n        \n        final Bits filterAcceptDocs = filterDocIdSet.bits();\n        final boolean useRandomAccess = (filterAcceptDocs != null && FilteredQuery.this.useRandomAccess(filterAcceptDocs, firstFilterDoc));\n\n        if (useRandomAccess) {\n          // if we are using random access, we return the inner scorer, just with other acceptDocs\n          // TODO, replace this by when BooleanWeight is fixed to be consistent with its scorer implementations:\n          // return weight.scorer(context, scoreDocsInOrder, topScorer, filterAcceptDocs);\n          return weight.scorer(context, true, topScorer, filterAcceptDocs);\n        } else {\n          assert firstFilterDoc > -1;\n          // we are gonna advance() this scorer, so we set inorder=true/toplevel=false\n          // we pass null as acceptDocs, as our filter has already respected acceptDocs, no need to do twice\n          final Scorer scorer = weight.scorer(context, true, false, null);\n          return (scorer == null) ? null : new Scorer(this) {\n            private int scorerDoc = -1, filterDoc = firstFilterDoc;\n            \n            // optimization: we are topScorer and collect directly using short-circuited algo\n            @Override\n            public void score(Collector collector) throws IOException {\n              int filterDoc = firstFilterDoc;\n              int scorerDoc = scorer.advance(filterDoc);\n              // the normalization trick already applies the boost of this query,\n              // so we can use the wrapped scorer directly:\n              collector.setScorer(scorer);\n              for (;;) {\n                if (scorerDoc == filterDoc) {\n                  // Check if scorer has exhausted, only before collecting.\n                  if (scorerDoc == DocIdSetIterator.NO_MORE_DOCS) {\n                    break;\n                  }\n                  collector.collect(scorerDoc);\n                  filterDoc = filterIter.nextDoc();\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc > filterDoc) {\n                  filterDoc = filterIter.advance(scorerDoc);\n                } else {\n                  scorerDoc = scorer.advance(filterDoc);\n                }\n              }\n            }\n            \n            private int advanceToNextCommonDoc() throws IOException {\n              for (;;) {\n                if (scorerDoc < filterDoc) {\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc == filterDoc) {\n                  return scorerDoc;\n                } else {\n                  filterDoc = filterIter.advance(scorerDoc);\n                }\n              }\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              // don't go to next doc on first call\n              // (because filterIter is already on first doc):\n              if (scorerDoc != -1) {\n                filterDoc = filterIter.nextDoc();\n              }\n              return advanceToNextCommonDoc();\n            }\n            \n            @Override\n            public int advance(int target) throws IOException {\n              if (target > filterDoc) {\n                filterDoc = filterIter.advance(target);\n              }\n              return advanceToNextCommonDoc();\n            }\n\n            @Override\n            public int docID() {\n              return scorerDoc;\n            }\n            \n            @Override\n            public float score() throws IOException {\n              return scorer.score();\n            }\n            \n            @Override\n            public float freq() throws IOException { return scorer.freq(); }\n            \n            @Override\n            public Collection<ChildScorer> getChildren() {\n              return Collections.singleton(new ChildScorer(scorer, \"FILTERED\"));\n            }\n          };\n        }\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // TODO: Support out-of-order scoring!\n        // For now we return false here, as we always get the scorer in order\n        return false;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSet.EMPTY_DOCIDSET.iterator() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSet.EMPTY_DOCIDSET.iterator();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() { return FilteredQuery.this; }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n        \n        final DocIdSetIterator filterIter = filterDocIdSet.iterator();\n        if (filterIter == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        final int firstFilterDoc = filterIter.nextDoc();\n        if (firstFilterDoc == DocIdSetIterator.NO_MORE_DOCS) {\n          return null;\n        }\n        \n        final Bits filterAcceptDocs = filterDocIdSet.bits();\n        final boolean useRandomAccess = (filterAcceptDocs != null && FilteredQuery.this.useRandomAccess(filterAcceptDocs, firstFilterDoc));\n\n        if (useRandomAccess) {\n          // if we are using random access, we return the inner scorer, just with other acceptDocs\n          // TODO, replace this by when BooleanWeight is fixed to be consistent with its scorer implementations:\n          // return weight.scorer(context, scoreDocsInOrder, topScorer, filterAcceptDocs);\n          return weight.scorer(context, true, topScorer, filterAcceptDocs);\n        } else {\n          assert firstFilterDoc > -1;\n          // we are gonna advance() this scorer, so we set inorder=true/toplevel=false\n          // we pass null as acceptDocs, as our filter has already respected acceptDocs, no need to do twice\n          final Scorer scorer = weight.scorer(context, true, false, null);\n          return (scorer == null) ? null : new Scorer(this) {\n            private int scorerDoc = -1, filterDoc = firstFilterDoc;\n            \n            // optimization: we are topScorer and collect directly using short-circuited algo\n            @Override\n            public void score(Collector collector) throws IOException {\n              int filterDoc = firstFilterDoc;\n              int scorerDoc = scorer.advance(filterDoc);\n              // the normalization trick already applies the boost of this query,\n              // so we can use the wrapped scorer directly:\n              collector.setScorer(scorer);\n              for (;;) {\n                if (scorerDoc == filterDoc) {\n                  // Check if scorer has exhausted, only before collecting.\n                  if (scorerDoc == DocIdSetIterator.NO_MORE_DOCS) {\n                    break;\n                  }\n                  collector.collect(scorerDoc);\n                  filterDoc = filterIter.nextDoc();\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc > filterDoc) {\n                  filterDoc = filterIter.advance(scorerDoc);\n                } else {\n                  scorerDoc = scorer.advance(filterDoc);\n                }\n              }\n            }\n            \n            private int advanceToNextCommonDoc() throws IOException {\n              for (;;) {\n                if (scorerDoc < filterDoc) {\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc == filterDoc) {\n                  return scorerDoc;\n                } else {\n                  filterDoc = filterIter.advance(scorerDoc);\n                }\n              }\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              // don't go to next doc on first call\n              // (because filterIter is already on first doc):\n              if (scorerDoc != -1) {\n                filterDoc = filterIter.nextDoc();\n              }\n              return advanceToNextCommonDoc();\n            }\n            \n            @Override\n            public int advance(int target) throws IOException {\n              if (target > filterDoc) {\n                filterDoc = filterIter.advance(target);\n              }\n              return advanceToNextCommonDoc();\n            }\n\n            @Override\n            public int docID() {\n              return scorerDoc;\n            }\n            \n            @Override\n            public float score() throws IOException {\n              return scorer.score();\n            }\n          };\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aba371508186796cc6151d8223a5b4e16d02e26e","date":1343474871,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // TODO: Support out-of-order scoring!\n        // For now we return false here, as we always get the scorer in order\n        return false;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSet.EMPTY_DOCIDSET.iterator() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSet.EMPTY_DOCIDSET.iterator();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() { return FilteredQuery.this; }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n        \n        final DocIdSetIterator filterIter = filterDocIdSet.iterator();\n        if (filterIter == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        final int firstFilterDoc = filterIter.nextDoc();\n        if (firstFilterDoc == DocIdSetIterator.NO_MORE_DOCS) {\n          return null;\n        }\n        \n        final Bits filterAcceptDocs = filterDocIdSet.bits();\n        final boolean useRandomAccess = (filterAcceptDocs != null && FilteredQuery.this.useRandomAccess(filterAcceptDocs, firstFilterDoc));\n\n        if (useRandomAccess) {\n          // if we are using random access, we return the inner scorer, just with other acceptDocs\n          // TODO, replace this by when BooleanWeight is fixed to be consistent with its scorer implementations:\n          // return weight.scorer(context, scoreDocsInOrder, topScorer, filterAcceptDocs);\n          return weight.scorer(context, true, topScorer, filterAcceptDocs);\n        } else {\n          assert firstFilterDoc > -1;\n          // we are gonna advance() this scorer, so we set inorder=true/toplevel=false\n          // we pass null as acceptDocs, as our filter has already respected acceptDocs, no need to do twice\n          final Scorer scorer = weight.scorer(context, true, false, null);\n          return (scorer == null) ? null : new Scorer(this) {\n            private int scorerDoc = -1, filterDoc = firstFilterDoc;\n            \n            // optimization: we are topScorer and collect directly using short-circuited algo\n            @Override\n            public void score(Collector collector) throws IOException {\n              int filterDoc = firstFilterDoc;\n              int scorerDoc = scorer.advance(filterDoc);\n              // the normalization trick already applies the boost of this query,\n              // so we can use the wrapped scorer directly:\n              collector.setScorer(scorer);\n              for (;;) {\n                if (scorerDoc == filterDoc) {\n                  // Check if scorer has exhausted, only before collecting.\n                  if (scorerDoc == DocIdSetIterator.NO_MORE_DOCS) {\n                    break;\n                  }\n                  collector.collect(scorerDoc);\n                  filterDoc = filterIter.nextDoc();\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc > filterDoc) {\n                  filterDoc = filterIter.advance(scorerDoc);\n                } else {\n                  scorerDoc = scorer.advance(filterDoc);\n                }\n              }\n            }\n            \n            private int advanceToNextCommonDoc() throws IOException {\n              for (;;) {\n                if (scorerDoc < filterDoc) {\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc == filterDoc) {\n                  return scorerDoc;\n                } else {\n                  filterDoc = filterIter.advance(scorerDoc);\n                }\n              }\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              // don't go to next doc on first call\n              // (because filterIter is already on first doc):\n              if (scorerDoc != -1) {\n                filterDoc = filterIter.nextDoc();\n              }\n              return advanceToNextCommonDoc();\n            }\n            \n            @Override\n            public int advance(int target) throws IOException {\n              if (target > filterDoc) {\n                filterDoc = filterIter.advance(target);\n              }\n              return advanceToNextCommonDoc();\n            }\n\n            @Override\n            public int docID() {\n              return scorerDoc;\n            }\n            \n            @Override\n            public float score() throws IOException {\n              return scorer.score();\n            }\n            \n            @Override\n            public float freq() throws IOException { return scorer.freq(); }\n            \n            @Override\n            public Collection<ChildScorer> getChildren() {\n              return Collections.singleton(new ChildScorer(scorer, \"FILTERED\"));\n            }\n          };\n        }\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // TODO: Support out-of-order scoring!\n        // For now we return false here, as we always get the scorer in order\n        return false;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSet.EMPTY_DOCIDSET.iterator() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSet.EMPTY_DOCIDSET.iterator();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() { return FilteredQuery.this; }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n        \n        final DocIdSetIterator filterIter = filterDocIdSet.iterator();\n        if (filterIter == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        final int firstFilterDoc = filterIter.nextDoc();\n        if (firstFilterDoc == DocIdSetIterator.NO_MORE_DOCS) {\n          return null;\n        }\n        \n        final Bits filterAcceptDocs = filterDocIdSet.bits();\n        final boolean useRandomAccess = (filterAcceptDocs != null && FilteredQuery.this.useRandomAccess(filterAcceptDocs, firstFilterDoc));\n\n        if (useRandomAccess) {\n          // if we are using random access, we return the inner scorer, just with other acceptDocs\n          // TODO, replace this by when BooleanWeight is fixed to be consistent with its scorer implementations:\n          // return weight.scorer(context, scoreDocsInOrder, topScorer, filterAcceptDocs);\n          return weight.scorer(context, true, topScorer, filterAcceptDocs);\n        } else {\n          assert firstFilterDoc > -1;\n          // we are gonna advance() this scorer, so we set inorder=true/toplevel=false\n          // we pass null as acceptDocs, as our filter has already respected acceptDocs, no need to do twice\n          final Scorer scorer = weight.scorer(context, true, false, null);\n          return (scorer == null) ? null : new Scorer(this) {\n            private int scorerDoc = -1, filterDoc = firstFilterDoc;\n            \n            // optimization: we are topScorer and collect directly using short-circuited algo\n            @Override\n            public void score(Collector collector) throws IOException {\n              int filterDoc = firstFilterDoc;\n              int scorerDoc = scorer.advance(filterDoc);\n              // the normalization trick already applies the boost of this query,\n              // so we can use the wrapped scorer directly:\n              collector.setScorer(scorer);\n              for (;;) {\n                if (scorerDoc == filterDoc) {\n                  // Check if scorer has exhausted, only before collecting.\n                  if (scorerDoc == DocIdSetIterator.NO_MORE_DOCS) {\n                    break;\n                  }\n                  collector.collect(scorerDoc);\n                  filterDoc = filterIter.nextDoc();\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc > filterDoc) {\n                  filterDoc = filterIter.advance(scorerDoc);\n                } else {\n                  scorerDoc = scorer.advance(filterDoc);\n                }\n              }\n            }\n            \n            private int advanceToNextCommonDoc() throws IOException {\n              for (;;) {\n                if (scorerDoc < filterDoc) {\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc == filterDoc) {\n                  return scorerDoc;\n                } else {\n                  filterDoc = filterIter.advance(scorerDoc);\n                }\n              }\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              // don't go to next doc on first call\n              // (because filterIter is already on first doc):\n              if (scorerDoc != -1) {\n                filterDoc = filterIter.nextDoc();\n              }\n              return advanceToNextCommonDoc();\n            }\n            \n            @Override\n            public int advance(int target) throws IOException {\n              if (target > filterDoc) {\n                filterDoc = filterIter.advance(target);\n              }\n              return advanceToNextCommonDoc();\n            }\n\n            @Override\n            public int docID() {\n              return scorerDoc;\n            }\n            \n            @Override\n            public float score() throws IOException {\n              return scorer.score();\n            }\n          };\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d7e5e8b8d73f2aac82ca5aa45d34d8adaa6940f6","date":1345834972,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSet.EMPTY_DOCIDSET.iterator() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSet.EMPTY_DOCIDSET.iterator();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() { return FilteredQuery.this; }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n        \n        final DocIdSetIterator filterIter = filterDocIdSet.iterator();\n        if (filterIter == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        final int firstFilterDoc = filterIter.nextDoc();\n        if (firstFilterDoc == DocIdSetIterator.NO_MORE_DOCS) {\n          return null;\n        }\n        \n        final Bits filterAcceptDocs = filterDocIdSet.bits();\n        final boolean useRandomAccess = (filterAcceptDocs != null && FilteredQuery.this.useRandomAccess(filterAcceptDocs, firstFilterDoc));\n\n        if (useRandomAccess) {\n          // if we are using random access, we return the inner scorer, just with other acceptDocs\n          return weight.scorer(context, scoreDocsInOrder, topScorer, filterAcceptDocs);\n        } else {\n          assert firstFilterDoc > -1;\n          // we are gonna advance() this scorer, so we set inorder=true/toplevel=false\n          // we pass null as acceptDocs, as our filter has already respected acceptDocs, no need to do twice\n          final Scorer scorer = weight.scorer(context, true, false, null);\n          return (scorer == null) ? null : new Scorer(this) {\n            private int scorerDoc = -1, filterDoc = firstFilterDoc;\n            \n            // optimization: we are topScorer and collect directly using short-circuited algo\n            @Override\n            public void score(Collector collector) throws IOException {\n              int filterDoc = firstFilterDoc;\n              int scorerDoc = scorer.advance(filterDoc);\n              // the normalization trick already applies the boost of this query,\n              // so we can use the wrapped scorer directly:\n              collector.setScorer(scorer);\n              for (;;) {\n                if (scorerDoc == filterDoc) {\n                  // Check if scorer has exhausted, only before collecting.\n                  if (scorerDoc == DocIdSetIterator.NO_MORE_DOCS) {\n                    break;\n                  }\n                  collector.collect(scorerDoc);\n                  filterDoc = filterIter.nextDoc();\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc > filterDoc) {\n                  filterDoc = filterIter.advance(scorerDoc);\n                } else {\n                  scorerDoc = scorer.advance(filterDoc);\n                }\n              }\n            }\n            \n            private int advanceToNextCommonDoc() throws IOException {\n              for (;;) {\n                if (scorerDoc < filterDoc) {\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc == filterDoc) {\n                  return scorerDoc;\n                } else {\n                  filterDoc = filterIter.advance(scorerDoc);\n                }\n              }\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              // don't go to next doc on first call\n              // (because filterIter is already on first doc):\n              if (scorerDoc != -1) {\n                filterDoc = filterIter.nextDoc();\n              }\n              return advanceToNextCommonDoc();\n            }\n            \n            @Override\n            public int advance(int target) throws IOException {\n              if (target > filterDoc) {\n                filterDoc = filterIter.advance(target);\n              }\n              return advanceToNextCommonDoc();\n            }\n\n            @Override\n            public int docID() {\n              return scorerDoc;\n            }\n            \n            @Override\n            public float score() throws IOException {\n              return scorer.score();\n            }\n            \n            @Override\n            public float freq() throws IOException { return scorer.freq(); }\n            \n            @Override\n            public Collection<ChildScorer> getChildren() {\n              return Collections.singleton(new ChildScorer(scorer, \"FILTERED\"));\n            }\n          };\n        }\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // TODO: Support out-of-order scoring!\n        // For now we return false here, as we always get the scorer in order\n        return false;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSet.EMPTY_DOCIDSET.iterator() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSet.EMPTY_DOCIDSET.iterator();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() { return FilteredQuery.this; }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n        \n        final DocIdSetIterator filterIter = filterDocIdSet.iterator();\n        if (filterIter == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        final int firstFilterDoc = filterIter.nextDoc();\n        if (firstFilterDoc == DocIdSetIterator.NO_MORE_DOCS) {\n          return null;\n        }\n        \n        final Bits filterAcceptDocs = filterDocIdSet.bits();\n        final boolean useRandomAccess = (filterAcceptDocs != null && FilteredQuery.this.useRandomAccess(filterAcceptDocs, firstFilterDoc));\n\n        if (useRandomAccess) {\n          // if we are using random access, we return the inner scorer, just with other acceptDocs\n          // TODO, replace this by when BooleanWeight is fixed to be consistent with its scorer implementations:\n          // return weight.scorer(context, scoreDocsInOrder, topScorer, filterAcceptDocs);\n          return weight.scorer(context, true, topScorer, filterAcceptDocs);\n        } else {\n          assert firstFilterDoc > -1;\n          // we are gonna advance() this scorer, so we set inorder=true/toplevel=false\n          // we pass null as acceptDocs, as our filter has already respected acceptDocs, no need to do twice\n          final Scorer scorer = weight.scorer(context, true, false, null);\n          return (scorer == null) ? null : new Scorer(this) {\n            private int scorerDoc = -1, filterDoc = firstFilterDoc;\n            \n            // optimization: we are topScorer and collect directly using short-circuited algo\n            @Override\n            public void score(Collector collector) throws IOException {\n              int filterDoc = firstFilterDoc;\n              int scorerDoc = scorer.advance(filterDoc);\n              // the normalization trick already applies the boost of this query,\n              // so we can use the wrapped scorer directly:\n              collector.setScorer(scorer);\n              for (;;) {\n                if (scorerDoc == filterDoc) {\n                  // Check if scorer has exhausted, only before collecting.\n                  if (scorerDoc == DocIdSetIterator.NO_MORE_DOCS) {\n                    break;\n                  }\n                  collector.collect(scorerDoc);\n                  filterDoc = filterIter.nextDoc();\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc > filterDoc) {\n                  filterDoc = filterIter.advance(scorerDoc);\n                } else {\n                  scorerDoc = scorer.advance(filterDoc);\n                }\n              }\n            }\n            \n            private int advanceToNextCommonDoc() throws IOException {\n              for (;;) {\n                if (scorerDoc < filterDoc) {\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc == filterDoc) {\n                  return scorerDoc;\n                } else {\n                  filterDoc = filterIter.advance(scorerDoc);\n                }\n              }\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              // don't go to next doc on first call\n              // (because filterIter is already on first doc):\n              if (scorerDoc != -1) {\n                filterDoc = filterIter.nextDoc();\n              }\n              return advanceToNextCommonDoc();\n            }\n            \n            @Override\n            public int advance(int target) throws IOException {\n              if (target > filterDoc) {\n                filterDoc = filterIter.advance(target);\n              }\n              return advanceToNextCommonDoc();\n            }\n\n            @Override\n            public int docID() {\n              return scorerDoc;\n            }\n            \n            @Override\n            public float score() throws IOException {\n              return scorer.score();\n            }\n            \n            @Override\n            public float freq() throws IOException { return scorer.freq(); }\n            \n            @Override\n            public Collection<ChildScorer> getChildren() {\n              return Collections.singleton(new ChildScorer(scorer, \"FILTERED\"));\n            }\n          };\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"001b25b42373b22a52f399dbf072f1224632e8e6","date":1345889167,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSet.EMPTY_DOCIDSET.iterator() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSet.EMPTY_DOCIDSET.iterator();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() { return FilteredQuery.this; }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n        \n        final DocIdSetIterator filterIter = filterDocIdSet.iterator();\n        if (filterIter == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        final int firstFilterDoc = filterIter.nextDoc();\n        if (firstFilterDoc == DocIdSetIterator.NO_MORE_DOCS) {\n          return null;\n        }\n        \n        final Bits filterAcceptDocs = filterDocIdSet.bits();\n        final boolean useRandomAccess = (filterAcceptDocs != null && FilteredQuery.this.useRandomAccess(filterAcceptDocs, firstFilterDoc));\n\n        if (useRandomAccess) {\n          // if we are using random access, we return the inner scorer, just with other acceptDocs\n          return weight.scorer(context, scoreDocsInOrder, topScorer, filterAcceptDocs);\n        } else {\n          assert firstFilterDoc > -1;\n          // we are gonna advance() this scorer, so we set inorder=true/toplevel=false\n          // we pass null as acceptDocs, as our filter has already respected acceptDocs, no need to do twice\n          final Scorer scorer = weight.scorer(context, true, false, null);\n          return (scorer == null) ? null : new Scorer(this) {\n            private int scorerDoc = -1, filterDoc = firstFilterDoc;\n            \n            // optimization: we are topScorer and collect directly using short-circuited algo\n            @Override\n            public void score(Collector collector) throws IOException {\n              int filterDoc = firstFilterDoc;\n              int scorerDoc = scorer.advance(filterDoc);\n              // the normalization trick already applies the boost of this query,\n              // so we can use the wrapped scorer directly:\n              collector.setScorer(scorer);\n              for (;;) {\n                if (scorerDoc == filterDoc) {\n                  // Check if scorer has exhausted, only before collecting.\n                  if (scorerDoc == DocIdSetIterator.NO_MORE_DOCS) {\n                    break;\n                  }\n                  collector.collect(scorerDoc);\n                  filterDoc = filterIter.nextDoc();\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc > filterDoc) {\n                  filterDoc = filterIter.advance(scorerDoc);\n                } else {\n                  scorerDoc = scorer.advance(filterDoc);\n                }\n              }\n            }\n            \n            private int advanceToNextCommonDoc() throws IOException {\n              for (;;) {\n                if (scorerDoc < filterDoc) {\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc == filterDoc) {\n                  return scorerDoc;\n                } else {\n                  filterDoc = filterIter.advance(scorerDoc);\n                }\n              }\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              // don't go to next doc on first call\n              // (because filterIter is already on first doc):\n              if (scorerDoc != -1) {\n                filterDoc = filterIter.nextDoc();\n              }\n              return advanceToNextCommonDoc();\n            }\n            \n            @Override\n            public int advance(int target) throws IOException {\n              if (target > filterDoc) {\n                filterDoc = filterIter.advance(target);\n              }\n              return advanceToNextCommonDoc();\n            }\n\n            @Override\n            public int docID() {\n              return scorerDoc;\n            }\n            \n            @Override\n            public float score() throws IOException {\n              return scorer.score();\n            }\n            \n            @Override\n            public float freq() throws IOException { return scorer.freq(); }\n            \n            @Override\n            public Collection<ChildScorer> getChildren() {\n              return Collections.singleton(new ChildScorer(scorer, \"FILTERED\"));\n            }\n          };\n        }\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        // TODO: Support out-of-order scoring!\n        // For now we return false here, as we always get the scorer in order\n        return false;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSet.EMPTY_DOCIDSET.iterator() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSet.EMPTY_DOCIDSET.iterator();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() { return FilteredQuery.this; }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n        \n        final DocIdSetIterator filterIter = filterDocIdSet.iterator();\n        if (filterIter == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        final int firstFilterDoc = filterIter.nextDoc();\n        if (firstFilterDoc == DocIdSetIterator.NO_MORE_DOCS) {\n          return null;\n        }\n        \n        final Bits filterAcceptDocs = filterDocIdSet.bits();\n        final boolean useRandomAccess = (filterAcceptDocs != null && FilteredQuery.this.useRandomAccess(filterAcceptDocs, firstFilterDoc));\n\n        if (useRandomAccess) {\n          // if we are using random access, we return the inner scorer, just with other acceptDocs\n          // TODO, replace this by when BooleanWeight is fixed to be consistent with its scorer implementations:\n          // return weight.scorer(context, scoreDocsInOrder, topScorer, filterAcceptDocs);\n          return weight.scorer(context, true, topScorer, filterAcceptDocs);\n        } else {\n          assert firstFilterDoc > -1;\n          // we are gonna advance() this scorer, so we set inorder=true/toplevel=false\n          // we pass null as acceptDocs, as our filter has already respected acceptDocs, no need to do twice\n          final Scorer scorer = weight.scorer(context, true, false, null);\n          return (scorer == null) ? null : new Scorer(this) {\n            private int scorerDoc = -1, filterDoc = firstFilterDoc;\n            \n            // optimization: we are topScorer and collect directly using short-circuited algo\n            @Override\n            public void score(Collector collector) throws IOException {\n              int filterDoc = firstFilterDoc;\n              int scorerDoc = scorer.advance(filterDoc);\n              // the normalization trick already applies the boost of this query,\n              // so we can use the wrapped scorer directly:\n              collector.setScorer(scorer);\n              for (;;) {\n                if (scorerDoc == filterDoc) {\n                  // Check if scorer has exhausted, only before collecting.\n                  if (scorerDoc == DocIdSetIterator.NO_MORE_DOCS) {\n                    break;\n                  }\n                  collector.collect(scorerDoc);\n                  filterDoc = filterIter.nextDoc();\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc > filterDoc) {\n                  filterDoc = filterIter.advance(scorerDoc);\n                } else {\n                  scorerDoc = scorer.advance(filterDoc);\n                }\n              }\n            }\n            \n            private int advanceToNextCommonDoc() throws IOException {\n              for (;;) {\n                if (scorerDoc < filterDoc) {\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc == filterDoc) {\n                  return scorerDoc;\n                } else {\n                  filterDoc = filterIter.advance(scorerDoc);\n                }\n              }\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              // don't go to next doc on first call\n              // (because filterIter is already on first doc):\n              if (scorerDoc != -1) {\n                filterDoc = filterIter.nextDoc();\n              }\n              return advanceToNextCommonDoc();\n            }\n            \n            @Override\n            public int advance(int target) throws IOException {\n              if (target > filterDoc) {\n                filterDoc = filterIter.advance(target);\n              }\n              return advanceToNextCommonDoc();\n            }\n\n            @Override\n            public int docID() {\n              return scorerDoc;\n            }\n            \n            @Override\n            public float score() throws IOException {\n              return scorer.score();\n            }\n            \n            @Override\n            public float freq() throws IOException { return scorer.freq(); }\n            \n            @Override\n            public Collection<ChildScorer> getChildren() {\n              return Collections.singleton(new ChildScorer(scorer, \"FILTERED\"));\n            }\n          };\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cc7674a6feb46b954ebfb8ace9eb0383adb93de9","date":1348214796,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSet.EMPTY_DOCIDSET.iterator() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSet.EMPTY_DOCIDSET.iterator();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() { return FilteredQuery.this; }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, final Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n        return strategy.filteredScorer(context, scoreDocsInOrder, topScorer, weight, filterDocIdSet);\n        \n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSet.EMPTY_DOCIDSET.iterator() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSet.EMPTY_DOCIDSET.iterator();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() { return FilteredQuery.this; }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n        \n        final DocIdSetIterator filterIter = filterDocIdSet.iterator();\n        if (filterIter == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        final int firstFilterDoc = filterIter.nextDoc();\n        if (firstFilterDoc == DocIdSetIterator.NO_MORE_DOCS) {\n          return null;\n        }\n        \n        final Bits filterAcceptDocs = filterDocIdSet.bits();\n        final boolean useRandomAccess = (filterAcceptDocs != null && FilteredQuery.this.useRandomAccess(filterAcceptDocs, firstFilterDoc));\n\n        if (useRandomAccess) {\n          // if we are using random access, we return the inner scorer, just with other acceptDocs\n          return weight.scorer(context, scoreDocsInOrder, topScorer, filterAcceptDocs);\n        } else {\n          assert firstFilterDoc > -1;\n          // we are gonna advance() this scorer, so we set inorder=true/toplevel=false\n          // we pass null as acceptDocs, as our filter has already respected acceptDocs, no need to do twice\n          final Scorer scorer = weight.scorer(context, true, false, null);\n          return (scorer == null) ? null : new Scorer(this) {\n            private int scorerDoc = -1, filterDoc = firstFilterDoc;\n            \n            // optimization: we are topScorer and collect directly using short-circuited algo\n            @Override\n            public void score(Collector collector) throws IOException {\n              int filterDoc = firstFilterDoc;\n              int scorerDoc = scorer.advance(filterDoc);\n              // the normalization trick already applies the boost of this query,\n              // so we can use the wrapped scorer directly:\n              collector.setScorer(scorer);\n              for (;;) {\n                if (scorerDoc == filterDoc) {\n                  // Check if scorer has exhausted, only before collecting.\n                  if (scorerDoc == DocIdSetIterator.NO_MORE_DOCS) {\n                    break;\n                  }\n                  collector.collect(scorerDoc);\n                  filterDoc = filterIter.nextDoc();\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc > filterDoc) {\n                  filterDoc = filterIter.advance(scorerDoc);\n                } else {\n                  scorerDoc = scorer.advance(filterDoc);\n                }\n              }\n            }\n            \n            private int advanceToNextCommonDoc() throws IOException {\n              for (;;) {\n                if (scorerDoc < filterDoc) {\n                  scorerDoc = scorer.advance(filterDoc);\n                } else if (scorerDoc == filterDoc) {\n                  return scorerDoc;\n                } else {\n                  filterDoc = filterIter.advance(scorerDoc);\n                }\n              }\n            }\n\n            @Override\n            public int nextDoc() throws IOException {\n              // don't go to next doc on first call\n              // (because filterIter is already on first doc):\n              if (scorerDoc != -1) {\n                filterDoc = filterIter.nextDoc();\n              }\n              return advanceToNextCommonDoc();\n            }\n            \n            @Override\n            public int advance(int target) throws IOException {\n              if (target > filterDoc) {\n                filterDoc = filterIter.advance(target);\n              }\n              return advanceToNextCommonDoc();\n            }\n\n            @Override\n            public int docID() {\n              return scorerDoc;\n            }\n            \n            @Override\n            public float score() throws IOException {\n              return scorer.score();\n            }\n            \n            @Override\n            public float freq() throws IOException { return scorer.freq(); }\n            \n            @Override\n            public Collection<ChildScorer> getChildren() {\n              return Collections.singleton(new ChildScorer(scorer, \"FILTERED\"));\n            }\n          };\n        }\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dc06632ede7e48a5ddc6917badec25c8336feedc","date":1366983006,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() { return FilteredQuery.this; }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, final Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n        return strategy.filteredScorer(context, scoreDocsInOrder, topScorer, weight, filterDocIdSet);\n        \n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSet.EMPTY_DOCIDSET.iterator() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSet.EMPTY_DOCIDSET.iterator();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() { return FilteredQuery.this; }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, final Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n        return strategy.filteredScorer(context, scoreDocsInOrder, topScorer, weight, filterDocIdSet);\n        \n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"40640359164f629dd440a47df2e145d084ce9645","date":1391711808,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, final Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, scoreDocsInOrder, topScorer, weight, filterDocIdSet);\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() { return FilteredQuery.this; }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, final Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n        return strategy.filteredScorer(context, scoreDocsInOrder, topScorer, weight, filterDocIdSet);\n        \n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2e18c86f811939bfa8cd24046c96ed026f2e9b34","date":1393893071,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, final Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, scoreDocsInOrder, topScorer, weight, filterDocIdSet);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":["781239fc84d36be12b84e4d3e2618f5f07a182e3"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f5a7a379c47cb10a09ea1ff0b2460819a73c5988","date":1394142503,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public TopScorer topScorer(AtomicReaderContext context, boolean scoreDocsInOrder, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredTopScorer(context, weight, scoreDocsInOrder, filterDocIdSet);\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, final Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a5794e5c995c57444b154b01a9f3c837cd530a77","date":1394190201,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(AtomicReaderContext context, boolean scoreDocsInOrder, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, scoreDocsInOrder, filterDocIdSet);\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public TopScorer topScorer(AtomicReaderContext context, boolean scoreDocsInOrder, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredTopScorer(context, weight, scoreDocsInOrder, filterDocIdSet);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"acf00221f44c5f08ccea014f2492b53af15ecd66","date":1394568293,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(AtomicReaderContext context, boolean scoreDocsInOrder, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, scoreDocsInOrder, filterDocIdSet);\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize (float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain (AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, boolean scoreDocsInOrder, boolean topScorer, final Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        final DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, scoreDocsInOrder, topScorer, weight, filterDocIdSet);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, boolean scoreDocsInOrder, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, scoreDocsInOrder, filterDocIdSet);\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(AtomicReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(AtomicReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(AtomicReaderContext context, boolean scoreDocsInOrder, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, scoreDocsInOrder, filterDocIdSet);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":["781239fc84d36be12b84e4d3e2618f5f07a182e3"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f582f18c13d4852b01d4fe0a0196432c5c6f2b7f","date":1421314520,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet);\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n      \n      @Override\n      public boolean scoresDocsOutOfOrder() {\n        return true;\n      }\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, boolean scoreDocsInOrder, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, scoreDocsInOrder, filterDocIdSet);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":["781239fc84d36be12b84e4d3e2618f5f07a182e3"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"781239fc84d36be12b84e4d3e2618f5f07a182e3","date":1423139668,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs, boolean needsScores) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet, needsScores);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs, boolean needsScores) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet, needsScores);\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet);\n      }\n    };\n  }\n\n","bugFix":["c9fb5f46e264daf5ba3860defe623a89d202dd87","2e18c86f811939bfa8cd24046c96ed026f2e9b34","f582f18c13d4852b01d4fe0a0196432c5c6f2b7f"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs, boolean needsScores) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet, needsScores);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs, boolean needsScores) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet, needsScores);\n\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs, boolean needsScores) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet, needsScores);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs, boolean needsScores) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet, needsScores);\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb17639909a369c1e64866842e5c213440acc17e","date":1423238093,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/search/FilteredQuery#createWeight(IndexSearcher).mjava","sourceNew":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher, boolean needsScores) throws IOException {\n    final Weight weight = query.createWeight (searcher, needsScores);\n    return new Weight(FilteredQuery.this) {\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet, needsScores);\n\n      }\n    };\n  }\n\n","sourceOld":"  /**\n   * Returns a Weight that applies the filter to the enclosed query's Weight.\n   * This is accomplished by overriding the Scorer returned by the Weight.\n   */\n  @Override\n  public Weight createWeight(final IndexSearcher searcher) throws IOException {\n    final Weight weight = query.createWeight (searcher);\n    return new Weight() {\n\n      @Override\n      public float getValueForNormalization() throws IOException { \n        return weight.getValueForNormalization() * getBoost() * getBoost(); // boost sub-weight\n      }\n\n      @Override\n      public void normalize(float norm, float topLevelBoost) { \n        weight.normalize(norm, topLevelBoost * getBoost()); // incorporate boost\n      }\n\n      @Override\n      public Explanation explain(LeafReaderContext ir, int i) throws IOException {\n        Explanation inner = weight.explain (ir, i);\n        Filter f = FilteredQuery.this.filter;\n        DocIdSet docIdSet = f.getDocIdSet(ir, ir.reader().getLiveDocs());\n        DocIdSetIterator docIdSetIterator = docIdSet == null ? DocIdSetIterator.empty() : docIdSet.iterator();\n        if (docIdSetIterator == null) {\n          docIdSetIterator = DocIdSetIterator.empty();\n        }\n        if (docIdSetIterator.advance(i) == i) {\n          return inner;\n        } else {\n          Explanation result = new Explanation\n            (0.0f, \"failure to match filter: \" + f.toString());\n          result.addDetail(inner);\n          return result;\n        }\n      }\n\n      // return this query\n      @Override\n      public Query getQuery() {\n        return FilteredQuery.this;\n      }\n\n      // return a filtering scorer\n      @Override\n      public Scorer scorer(LeafReaderContext context, Bits acceptDocs, boolean needsScores) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredScorer(context, weight, filterDocIdSet, needsScores);\n      }\n\n      // return a filtering top scorer\n      @Override\n      public BulkScorer bulkScorer(LeafReaderContext context, Bits acceptDocs, boolean needsScores) throws IOException {\n        assert filter != null;\n\n        DocIdSet filterDocIdSet = filter.getDocIdSet(context, acceptDocs);\n        if (filterDocIdSet == null) {\n          // this means the filter does not accept any documents.\n          return null;\n        }\n\n        return strategy.filteredBulkScorer(context, weight, filterDocIdSet, needsScores);\n\n      }\n    };\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"dc06632ede7e48a5ddc6917badec25c8336feedc":["cc7674a6feb46b954ebfb8ace9eb0383adb93de9"],"2e18c86f811939bfa8cd24046c96ed026f2e9b34":["40640359164f629dd440a47df2e145d084ce9645"],"001b25b42373b22a52f399dbf072f1224632e8e6":["aba371508186796cc6151d8223a5b4e16d02e26e","d7e5e8b8d73f2aac82ca5aa45d34d8adaa6940f6"],"fb17639909a369c1e64866842e5c213440acc17e":["51f5280f31484820499077f41fcdfe92d527d9dc"],"f5a7a379c47cb10a09ea1ff0b2460819a73c5988":["2e18c86f811939bfa8cd24046c96ed026f2e9b34"],"781239fc84d36be12b84e4d3e2618f5f07a182e3":["f582f18c13d4852b01d4fe0a0196432c5c6f2b7f"],"ea8268d5f00bb25a4ea1d0bac6e2ffe238712c45":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"51f5280f31484820499077f41fcdfe92d527d9dc":["781239fc84d36be12b84e4d3e2618f5f07a182e3"],"40640359164f629dd440a47df2e145d084ce9645":["dc06632ede7e48a5ddc6917badec25c8336feedc"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["acf00221f44c5f08ccea014f2492b53af15ecd66"],"aba371508186796cc6151d8223a5b4e16d02e26e":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","ea8268d5f00bb25a4ea1d0bac6e2ffe238712c45"],"f582f18c13d4852b01d4fe0a0196432c5c6f2b7f":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"d7e5e8b8d73f2aac82ca5aa45d34d8adaa6940f6":["ea8268d5f00bb25a4ea1d0bac6e2ffe238712c45"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","ea8268d5f00bb25a4ea1d0bac6e2ffe238712c45"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a5794e5c995c57444b154b01a9f3c837cd530a77":["f5a7a379c47cb10a09ea1ff0b2460819a73c5988"],"cc7674a6feb46b954ebfb8ace9eb0383adb93de9":["d7e5e8b8d73f2aac82ca5aa45d34d8adaa6940f6"],"acf00221f44c5f08ccea014f2492b53af15ecd66":["40640359164f629dd440a47df2e145d084ce9645","a5794e5c995c57444b154b01a9f3c837cd530a77"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fb17639909a369c1e64866842e5c213440acc17e"]},"commit2Childs":{"dc06632ede7e48a5ddc6917badec25c8336feedc":["40640359164f629dd440a47df2e145d084ce9645"],"2e18c86f811939bfa8cd24046c96ed026f2e9b34":["f5a7a379c47cb10a09ea1ff0b2460819a73c5988"],"001b25b42373b22a52f399dbf072f1224632e8e6":[],"fb17639909a369c1e64866842e5c213440acc17e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f5a7a379c47cb10a09ea1ff0b2460819a73c5988":["a5794e5c995c57444b154b01a9f3c837cd530a77"],"781239fc84d36be12b84e4d3e2618f5f07a182e3":["51f5280f31484820499077f41fcdfe92d527d9dc"],"ea8268d5f00bb25a4ea1d0bac6e2ffe238712c45":["aba371508186796cc6151d8223a5b4e16d02e26e","d7e5e8b8d73f2aac82ca5aa45d34d8adaa6940f6","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["ea8268d5f00bb25a4ea1d0bac6e2ffe238712c45","aba371508186796cc6151d8223a5b4e16d02e26e","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"40640359164f629dd440a47df2e145d084ce9645":["2e18c86f811939bfa8cd24046c96ed026f2e9b34","acf00221f44c5f08ccea014f2492b53af15ecd66"],"51f5280f31484820499077f41fcdfe92d527d9dc":["fb17639909a369c1e64866842e5c213440acc17e"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["f582f18c13d4852b01d4fe0a0196432c5c6f2b7f"],"aba371508186796cc6151d8223a5b4e16d02e26e":["001b25b42373b22a52f399dbf072f1224632e8e6"],"d7e5e8b8d73f2aac82ca5aa45d34d8adaa6940f6":["001b25b42373b22a52f399dbf072f1224632e8e6","cc7674a6feb46b954ebfb8ace9eb0383adb93de9"],"f582f18c13d4852b01d4fe0a0196432c5c6f2b7f":["781239fc84d36be12b84e4d3e2618f5f07a182e3"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"a5794e5c995c57444b154b01a9f3c837cd530a77":["acf00221f44c5f08ccea014f2492b53af15ecd66"],"cc7674a6feb46b954ebfb8ace9eb0383adb93de9":["dc06632ede7e48a5ddc6917badec25c8336feedc"],"acf00221f44c5f08ccea014f2492b53af15ecd66":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["001b25b42373b22a52f399dbf072f1224632e8e6","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}