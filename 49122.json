{"path":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","commits":[{"id":"2c007e7c4cf8c55bc2a5884e315123afaaeec87f","date":1327520966,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","pathOld":"/dev/null","sourceNew":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n      File logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"1\"));\n      assertU(adoc(\"id\",\"2\"));\n      assertU(adoc(\"id\",\"3\"));\n\n      h.close();\n      String[] files = UpdateLog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.seek(raf.length());  // seek to end\n      raf.writeLong(0xffffffffffffffffL);\n      raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      raf.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"4\", \"_version_\",\"104\")), params(SEEN_LEADER,SEEN_LEADER_VAL));\n      updateJ(jsonAdd(sdoc(\"id\",\"5\", \"_version_\",\"105\")), params(SEEN_LEADER,SEEN_LEADER_VAL));\n      updateJ(jsonAdd(sdoc(\"id\",\"6\", \"_version_\",\"106\")), params(SEEN_LEADER,SEEN_LEADER_VAL));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","date":1327523564,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","pathOld":"/dev/null","sourceNew":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n      File logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"1\"));\n      assertU(adoc(\"id\",\"2\"));\n      assertU(adoc(\"id\",\"3\"));\n\n      h.close();\n      String[] files = UpdateLog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.seek(raf.length());  // seek to end\n      raf.writeLong(0xffffffffffffffffL);\n      raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      raf.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"4\", \"_version_\",\"104\")), params(SEEN_LEADER,SEEN_LEADER_VAL));\n      updateJ(jsonAdd(sdoc(\"id\",\"5\", \"_version_\",\"105\")), params(SEEN_LEADER,SEEN_LEADER_VAL));\n      updateJ(jsonAdd(sdoc(\"id\",\"6\", \"_version_\",\"106\")), params(SEEN_LEADER,SEEN_LEADER_VAL));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d22ac6a4146774c1bc8400160fc0b6150294e92","date":1327528604,"type":0,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","pathOld":"/dev/null","sourceNew":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n      File logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"1\"));\n      assertU(adoc(\"id\",\"2\"));\n      assertU(adoc(\"id\",\"3\"));\n\n      h.close();\n      String[] files = UpdateLog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.seek(raf.length());  // seek to end\n      raf.writeLong(0xffffffffffffffffL);\n      raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      raf.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"4\", \"_version_\",\"104\")), params(SEEN_LEADER,SEEN_LEADER_VAL));\n      updateJ(jsonAdd(sdoc(\"id\",\"5\", \"_version_\",\"105\")), params(SEEN_LEADER,SEEN_LEADER_VAL));\n      updateJ(jsonAdd(sdoc(\"id\",\"6\", \"_version_\",\"106\")), params(SEEN_LEADER,SEEN_LEADER_VAL));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"01e98f8ae83ed9c1151cd99b37a7371fd6754ac2","date":1329660825,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","sourceNew":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n      File logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      h.close();\n      String[] files = UpdateLog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.seek(raf.length());  // seek to end\n      raf.writeLong(0xffffffffffffffffL);\n      raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      raf.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(SEEN_LEADER,SEEN_LEADER_VAL));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(SEEN_LEADER,SEEN_LEADER_VAL));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(SEEN_LEADER,SEEN_LEADER_VAL));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n      File logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"1\"));\n      assertU(adoc(\"id\",\"2\"));\n      assertU(adoc(\"id\",\"3\"));\n\n      h.close();\n      String[] files = UpdateLog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.seek(raf.length());  // seek to end\n      raf.writeLong(0xffffffffffffffffL);\n      raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      raf.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"4\", \"_version_\",\"104\")), params(SEEN_LEADER,SEEN_LEADER_VAL));\n      updateJ(jsonAdd(sdoc(\"id\",\"5\", \"_version_\",\"105\")), params(SEEN_LEADER,SEEN_LEADER_VAL));\n      updateJ(jsonAdd(sdoc(\"id\",\"6\", \"_version_\",\"106\")), params(SEEN_LEADER,SEEN_LEADER_VAL));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e2fe35ac47f8f51356d6c1724455d18f31c94fae","date":1337966698,"type":3,"author":"Chris M. Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","sourceNew":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n      File logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      h.close();\n      String[] files = UpdateLog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.seek(raf.length());  // seek to end\n      raf.writeLong(0xffffffffffffffffL);\n      raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      raf.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n      File logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      h.close();\n      String[] files = UpdateLog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.seek(raf.length());  // seek to end\n      raf.writeLong(0xffffffffffffffffL);\n      raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      raf.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(SEEN_LEADER,SEEN_LEADER_VAL));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(SEEN_LEADER,SEEN_LEADER_VAL));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(SEEN_LEADER,SEEN_LEADER_VAL));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"849494cf2f3a96af5c8c84995108ddd8456fcd04","date":1372277913,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","sourceNew":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      h.close();\n      String[] files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.seek(raf.length());  // seek to end\n      raf.writeLong(0xffffffffffffffffL);\n      raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      raf.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n      File logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      h.close();\n      String[] files = UpdateLog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.seek(raf.length());  // seek to end\n      raf.writeLong(0xffffffffffffffffL);\n      raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      raf.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","sourceNew":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      h.close();\n      String[] files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.seek(raf.length());  // seek to end\n      raf.writeLong(0xffffffffffffffffL);\n      raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      raf.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n      File logDir = h.getCore().getUpdateHandler().getUpdateLog().getLogDir();\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      h.close();\n      String[] files = UpdateLog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.seek(raf.length());  // seek to end\n      raf.writeLong(0xffffffffffffffffL);\n      raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      raf.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a0c04b71951333291abc7f317109a6a5957bd28","date":1457097827,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","sourceNew":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      h.close();\n      String[] files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.seek(raf.length());  // seek to end\n      raf.writeLong(0xffffffffffffffffL);\n      raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      raf.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = new Runnable() {\n        @Override\n        public void run() {\n          try {\n            assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n          } catch (Exception e) {\n            throw new RuntimeException(e);\n          }\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = new Runnable() {\n        @Override\n        public void run() {\n          logReplayFinish.release();\n        }\n      };\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      h.close();\n      String[] files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.seek(raf.length());  // seek to end\n      raf.writeLong(0xffffffffffffffffL);\n      raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      raf.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9efcb86f82b536ffcefcc27adbfa39b603342af1","date":1492147023,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","sourceNew":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      h.close();\n      String[] files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.seek(raf.length());  // seek to end\n      raf.writeLong(0xffffffffffffffffL);\n      raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      raf.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      String v104 = getNextVersion();\n      String v105 = getNextVersion();\n      String v106 = getNextVersion();\n      \n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",v104)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",v105)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",v106)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[\"+v106+\",\"+v105+\",\"+v104+\"]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      h.close();\n      String[] files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.seek(raf.length());  // seek to end\n      raf.writeLong(0xffffffffffffffffL);\n      raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      raf.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54ca69905c5d9d1529286f06ab1d12c68f6c13cb","date":1492683554,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","sourceNew":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      h.close();\n      String[] files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.seek(raf.length());  // seek to end\n      raf.writeLong(0xffffffffffffffffL);\n      raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      raf.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      String v104 = getNextVersion();\n      String v105 = getNextVersion();\n      String v106 = getNextVersion();\n      \n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",v104)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",v105)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",v106)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[\"+v106+\",\"+v105+\",\"+v104+\"]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      h.close();\n      String[] files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.seek(raf.length());  // seek to end\n      raf.writeLong(0xffffffffffffffffL);\n      raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      raf.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",\"104\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",\"105\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",\"106\")), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[106,105,104]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d1071f88e3697a2eb3ed682c527f5c35859bad0","date":1565425271,"type":3,"author":"Munendra S N","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","sourceNew":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      h.close();\n      String[] files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      try (RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length - 1]), \"rw\")) {\n        raf.seek(raf.length());  // seek to end\n        raf.writeLong(0xffffffffffffffffL);\n        raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      }\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      String v104 = getNextVersion();\n      String v105 = getNextVersion();\n      String v106 = getNextVersion();\n      \n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",v104)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",v105)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",v106)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[\"+v106+\",\"+v105+\",\"+v104+\"]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      h.close();\n      String[] files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length-1]), \"rw\");\n      raf.seek(raf.length());  // seek to end\n      raf.writeLong(0xffffffffffffffffL);\n      raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      raf.close();\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      String v104 = getNextVersion();\n      String v105 = getNextVersion();\n      String v106 = getNextVersion();\n      \n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",v104)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",v105)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",v106)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[\"+v106+\",\"+v105+\",\"+v104+\"]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1","date":1579200426,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRecovery#testTruncatedLog().mjava","sourceNew":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      TestInjection.skipIndexWriterCommitOnClose = true;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      h.close();\n      String[] files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      try (RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length - 1]), \"rw\")) {\n        raf.seek(raf.length());  // seek to end\n        raf.writeLong(0xffffffffffffffffL);\n        raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      }\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      String v104 = getNextVersion();\n      String v105 = getNextVersion();\n      String v106 = getNextVersion();\n      \n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",v104)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",v105)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",v106)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[\"+v106+\",\"+v105+\",\"+v104+\"]\");\n\n    } finally {\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","sourceOld":"  //\n  // test that a partially written last tlog entry (that will cause problems for both reverse reading and for\n  // log replay) doesn't stop us from coming up, and from recovering the documents that were not cut off.\n  //\n  @Test\n  public void testTruncatedLog() throws Exception {\n    try {\n      DirectUpdateHandler2.commitOnClose = false;\n      final Semaphore logReplay = new Semaphore(0);\n      final Semaphore logReplayFinish = new Semaphore(0);\n\n      UpdateLog.testing_logReplayHook = () -> {\n        try {\n          assertTrue(logReplay.tryAcquire(timeout, TimeUnit.SECONDS));\n        } catch (Exception e) {\n          throw new RuntimeException(e);\n        }\n      };\n\n      UpdateLog.testing_logReplayFinishHook = () -> logReplayFinish.release();\n\n      UpdateLog ulog = h.getCore().getUpdateHandler().getUpdateLog();\n      File logDir = new File(h.getCore().getUpdateHandler().getUpdateLog().getLogDir());\n\n      clearIndex();\n      assertU(commit());\n\n      assertU(adoc(\"id\",\"F1\"));\n      assertU(adoc(\"id\",\"F2\"));\n      assertU(adoc(\"id\",\"F3\"));\n\n      h.close();\n      String[] files = ulog.getLogList(logDir);\n      Arrays.sort(files);\n      try (RandomAccessFile raf = new RandomAccessFile(new File(logDir, files[files.length - 1]), \"rw\")) {\n        raf.seek(raf.length());  // seek to end\n        raf.writeLong(0xffffffffffffffffL);\n        raf.writeChars(\"This should be appended to a good log file, representing a bad partially written record.\");\n      }\n\n      logReplay.release(1000);\n      logReplayFinish.drainPermits();\n      ignoreException(\"OutOfBoundsException\");  // this is what the corrupted log currently produces... subject to change.\n      createCore();\n      assertTrue(logReplayFinish.tryAcquire(timeout, TimeUnit.SECONDS));\n      resetExceptionIgnores();\n      assertJQ(req(\"q\",\"*:*\") ,\"/response/numFound==3\");\n\n      //\n      // Now test that the bad log file doesn't mess up retrieving latest versions\n      //\n\n      String v104 = getNextVersion();\n      String v105 = getNextVersion();\n      String v106 = getNextVersion();\n      \n      updateJ(jsonAdd(sdoc(\"id\",\"F4\", \"_version_\",v104)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F5\", \"_version_\",v105)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n      updateJ(jsonAdd(sdoc(\"id\",\"F6\", \"_version_\",v106)), params(DISTRIB_UPDATE_PARAM,FROM_LEADER));\n\n      // This currently skips the bad log file and also returns the version of the clearIndex (del *:*)\n      // assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"6\"), \"/versions==[106,105,104]\");\n      assertJQ(req(\"qt\",\"/get\", \"getVersions\",\"3\"), \"/versions==[\"+v106+\",\"+v105+\",\"+v104+\"]\");\n\n    } finally {\n      DirectUpdateHandler2.commitOnClose = true;\n      UpdateLog.testing_logReplayHook = null;\n      UpdateLog.testing_logReplayFinishHook = null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["3a0c04b71951333291abc7f317109a6a5957bd28"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["e2fe35ac47f8f51356d6c1724455d18f31c94fae","849494cf2f3a96af5c8c84995108ddd8456fcd04"],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1":["0d1071f88e3697a2eb3ed682c527f5c35859bad0"],"3a0c04b71951333291abc7f317109a6a5957bd28":["849494cf2f3a96af5c8c84995108ddd8456fcd04"],"9efcb86f82b536ffcefcc27adbfa39b603342af1":["3a0c04b71951333291abc7f317109a6a5957bd28"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["e2fe35ac47f8f51356d6c1724455d18f31c94fae"],"0d22ac6a4146774c1bc8400160fc0b6150294e92":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"01e98f8ae83ed9c1151cd99b37a7371fd6754ac2":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"0d1071f88e3697a2eb3ed682c527f5c35859bad0":["9efcb86f82b536ffcefcc27adbfa39b603342af1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1"],"e2fe35ac47f8f51356d6c1724455d18f31c94fae":["01e98f8ae83ed9c1151cd99b37a7371fd6754ac2"]},"commit2Childs":{"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":[],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":[],"b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3a0c04b71951333291abc7f317109a6a5957bd28":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","9efcb86f82b536ffcefcc27adbfa39b603342af1"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["37a0f60745e53927c4c876cfe5b5a58170f0646c","3a0c04b71951333291abc7f317109a6a5957bd28"],"9efcb86f82b536ffcefcc27adbfa39b603342af1":["0d1071f88e3697a2eb3ed682c527f5c35859bad0"],"0d22ac6a4146774c1bc8400160fc0b6150294e92":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","0d22ac6a4146774c1bc8400160fc0b6150294e92","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","0d22ac6a4146774c1bc8400160fc0b6150294e92","01e98f8ae83ed9c1151cd99b37a7371fd6754ac2"],"01e98f8ae83ed9c1151cd99b37a7371fd6754ac2":["e2fe35ac47f8f51356d6c1724455d18f31c94fae"],"0d1071f88e3697a2eb3ed682c527f5c35859bad0":["b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1"],"e2fe35ac47f8f51356d6c1724455d18f31c94fae":["37a0f60745e53927c4c876cfe5b5a58170f0646c","849494cf2f3a96af5c8c84995108ddd8456fcd04"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","37a0f60745e53927c4c876cfe5b5a58170f0646c","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","0d22ac6a4146774c1bc8400160fc0b6150294e92","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}