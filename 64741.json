{"path":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","commits":[{"id":"e2fe60a17a7a0cfd101b1169acf089221bc6c166","date":1412767493,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public final FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();;\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType, input);\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, oldNormsType.mapping, -1, Collections.unmodifiableMap(attributes));\n      }\n\n      CodecUtil.checkEOF(input);\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();;\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType, input);\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, oldNormsType.mapping, -1, Collections.unmodifiableMap(attributes));\n      }\n\n      CodecUtil.checkEOF(input);\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55980207f1977bd1463465de1659b821347e2fa8","date":1413336386,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosReader#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public final FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();;\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType, input);\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, oldNormsType.mapping, -1, Collections.unmodifiableMap(attributes));\n      }\n\n      CodecUtil.checkEOF(input);\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();;\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType, input);\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, oldNormsType.mapping, -1, Collections.unmodifiableMap(attributes));\n      }\n\n      CodecUtil.checkEOF(input);\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"05da2d758a6089e737cdfc230e57a51b472b94b6","date":1413392310,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public final FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType, input);\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        if (isIndexed && omitNorms == false && oldNormsType.mapping == null) {\n          // Undead norms!  Lucene40NormsReader will check this and bring norms back from the dead:\n          UndeadNormsProducer.setUndead(attributes);\n        }\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, -1, Collections.unmodifiableMap(attributes));\n      }\n\n      CodecUtil.checkEOF(input);\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public final FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();;\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType, input);\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, oldNormsType.mapping, -1, Collections.unmodifiableMap(attributes));\n      }\n\n      CodecUtil.checkEOF(input);\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c93b0dbaa6abe99bc8d1b476bcacc27b324b2b84","date":1413458798,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public final FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType, input);\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        if (isIndexed && omitNorms == false && oldNormsType.mapping == null) {\n          // Undead norms!  Lucene40NormsReader will check this and bring norms back from the dead:\n          UndeadNormsProducer.setUndead(attributes);\n        }\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, -1, Collections.unmodifiableMap(attributes));\n      }\n\n      CodecUtil.checkEOF(input);\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public final FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();;\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType, input);\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, oldNormsType.mapping, -1, Collections.unmodifiableMap(attributes));\n      }\n\n      CodecUtil.checkEOF(input);\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3184874f7f3aca850248483485b4995343066875","date":1413876758,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public final FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType, input);\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        if (isIndexed && omitNorms == false && oldNormsType.mapping == null) {\n          // Undead norms!  Lucene40NormsReader will check this and bring norms back from the dead:\n          UndeadNormsProducer.setUndead(attributes);\n        }\n        infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, -1, Collections.unmodifiableMap(attributes));\n      }\n\n      CodecUtil.checkEOF(input);\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public final FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType, input);\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        if (isIndexed && omitNorms == false && oldNormsType.mapping == null) {\n          // Undead norms!  Lucene40NormsReader will check this and bring norms back from the dead:\n          UndeadNormsProducer.setUndead(attributes);\n        }\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, -1, Collections.unmodifiableMap(attributes));\n      }\n\n      CodecUtil.checkEOF(input);\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a22eafe3f72a4c2945eaad9547e6c78816978f4","date":1413956657,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":"  @Override\n  public final FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType, input);\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        if (isIndexed && omitNorms == false && oldNormsType.mapping == null) {\n          // Undead norms!  Lucene40NormsReader will check this and bring norms back from the dead:\n          UndeadNormsProducer.setUndead(attributes);\n        }\n        infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, -1, Collections.unmodifiableMap(attributes));\n      }\n\n      CodecUtil.checkEOF(input);\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","sourceOld":"  @Override\n  public final FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType, input);\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        if (isIndexed && omitNorms == false && oldNormsType.mapping == null) {\n          // Undead norms!  Lucene40NormsReader will check this and bring norms back from the dead:\n          UndeadNormsProducer.setUndead(attributes);\n        }\n        infos[i] = new FieldInfo(name, isIndexed, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, -1, Collections.unmodifiableMap(attributes));\n      }\n\n      CodecUtil.checkEOF(input);\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"71387d8cb6923eb831b17a8b734608ba2e21c653","date":1414126093,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40FieldInfosFormat#read(Directory,SegmentInfo,String,IOContext).mjava","sourceNew":null,"sourceOld":"  @Override\n  public final FieldInfos read(Directory directory, SegmentInfo segmentInfo, String segmentSuffix, IOContext iocontext) throws IOException {\n    final String fileName = IndexFileNames.segmentFileName(segmentInfo.name, \"\", Lucene40FieldInfosFormat.FIELD_INFOS_EXTENSION);\n    IndexInput input = directory.openInput(fileName, iocontext);\n    \n    boolean success = false;\n    try {\n      CodecUtil.checkHeader(input, Lucene40FieldInfosFormat.CODEC_NAME, \n                                   Lucene40FieldInfosFormat.FORMAT_START, \n                                   Lucene40FieldInfosFormat.FORMAT_CURRENT);\n\n      final int size = input.readVInt(); //read in the size\n      FieldInfo infos[] = new FieldInfo[size];\n\n      for (int i = 0; i < size; i++) {\n        String name = input.readString();\n        final int fieldNumber = input.readVInt();\n        byte bits = input.readByte();\n        boolean isIndexed = (bits & Lucene40FieldInfosFormat.IS_INDEXED) != 0;\n        boolean storeTermVector = (bits & Lucene40FieldInfosFormat.STORE_TERMVECTOR) != 0;\n        boolean omitNorms = (bits & Lucene40FieldInfosFormat.OMIT_NORMS) != 0;\n        boolean storePayloads = (bits & Lucene40FieldInfosFormat.STORE_PAYLOADS) != 0;\n        final IndexOptions indexOptions;\n        if (!isIndexed) {\n          indexOptions = null;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_TERM_FREQ_AND_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_ONLY;\n        } else if ((bits & Lucene40FieldInfosFormat.OMIT_POSITIONS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS;\n        } else if ((bits & Lucene40FieldInfosFormat.STORE_OFFSETS_IN_POSTINGS) != 0) {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS;\n        } else {\n          indexOptions = IndexOptions.DOCS_AND_FREQS_AND_POSITIONS;\n        }\n\n        // LUCENE-3027: past indices were able to write\n        // storePayloads=true when omitTFAP is also true,\n        // which is invalid.  We correct that, here:\n        if (isIndexed && indexOptions.compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) < 0) {\n          storePayloads = false;\n        }\n        // DV Types are packed in one byte\n        byte val = input.readByte();\n        final LegacyDocValuesType oldValuesType = getDocValuesType((byte) (val & 0x0F));\n        final LegacyDocValuesType oldNormsType = getDocValuesType((byte) ((val >>> 4) & 0x0F));\n        final Map<String,String> attributes = input.readStringStringMap();\n        if (oldValuesType.mapping != null) {\n          attributes.put(LEGACY_DV_TYPE_KEY, oldValuesType.name());\n        }\n        if (oldNormsType.mapping != null) {\n          if (oldNormsType.mapping != DocValuesType.NUMERIC) {\n            throw new CorruptIndexException(\"invalid norm type: \" + oldNormsType, input);\n          }\n          attributes.put(LEGACY_NORM_TYPE_KEY, oldNormsType.name());\n        }\n        if (isIndexed && omitNorms == false && oldNormsType.mapping == null) {\n          // Undead norms!  Lucene40NormsReader will check this and bring norms back from the dead:\n          UndeadNormsProducer.setUndead(attributes);\n        }\n        infos[i] = new FieldInfo(name, fieldNumber, storeTermVector, \n          omitNorms, storePayloads, indexOptions, oldValuesType.mapping, -1, Collections.unmodifiableMap(attributes));\n      }\n\n      CodecUtil.checkEOF(input);\n      FieldInfos fieldInfos = new FieldInfos(infos);\n      success = true;\n      return fieldInfos;\n    } finally {\n      if (success) {\n        input.close();\n      } else {\n        IOUtils.closeWhileHandlingException(input);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"05da2d758a6089e737cdfc230e57a51b472b94b6":["e2fe60a17a7a0cfd101b1169acf089221bc6c166"],"e2fe60a17a7a0cfd101b1169acf089221bc6c166":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c93b0dbaa6abe99bc8d1b476bcacc27b324b2b84":["55980207f1977bd1463465de1659b821347e2fa8","05da2d758a6089e737cdfc230e57a51b472b94b6"],"55980207f1977bd1463465de1659b821347e2fa8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","e2fe60a17a7a0cfd101b1169acf089221bc6c166"],"0a22eafe3f72a4c2945eaad9547e6c78816978f4":["c93b0dbaa6abe99bc8d1b476bcacc27b324b2b84","3184874f7f3aca850248483485b4995343066875"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"71387d8cb6923eb831b17a8b734608ba2e21c653":["3184874f7f3aca850248483485b4995343066875"],"3184874f7f3aca850248483485b4995343066875":["05da2d758a6089e737cdfc230e57a51b472b94b6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["71387d8cb6923eb831b17a8b734608ba2e21c653"]},"commit2Childs":{"05da2d758a6089e737cdfc230e57a51b472b94b6":["c93b0dbaa6abe99bc8d1b476bcacc27b324b2b84","3184874f7f3aca850248483485b4995343066875"],"e2fe60a17a7a0cfd101b1169acf089221bc6c166":["05da2d758a6089e737cdfc230e57a51b472b94b6","55980207f1977bd1463465de1659b821347e2fa8"],"c93b0dbaa6abe99bc8d1b476bcacc27b324b2b84":["0a22eafe3f72a4c2945eaad9547e6c78816978f4"],"55980207f1977bd1463465de1659b821347e2fa8":["c93b0dbaa6abe99bc8d1b476bcacc27b324b2b84"],"0a22eafe3f72a4c2945eaad9547e6c78816978f4":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e2fe60a17a7a0cfd101b1169acf089221bc6c166","55980207f1977bd1463465de1659b821347e2fa8"],"71387d8cb6923eb831b17a8b734608ba2e21c653":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3184874f7f3aca850248483485b4995343066875":["0a22eafe3f72a4c2945eaad9547e6c78816978f4","71387d8cb6923eb831b17a8b734608ba2e21c653"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["0a22eafe3f72a4c2945eaad9547e6c78816978f4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}