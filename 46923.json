{"path":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,StoredDocument,Analyzer).mjava","commits":[{"id":"a7e4907084808af8fdb14b9809e6dceaccf6867b","date":1343473006,"type":1,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,StoredDocument,Analyzer).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,Document,Analyzer).mjava","sourceNew":"  /**\n   * A convenience method that tries to first get a TermPositionVector for the\n   * specified docId, then, falls back to using the passed in\n   * {@link org.apache.lucene.document.Document} to retrieve the TokenStream.\n   * This is useful when you already have the document, but would prefer to use\n   * the vector first.\n   * \n   * @param reader The {@link org.apache.lucene.index.IndexReader} to use to try\n   *        and get the vector from\n   * @param docId The docId to retrieve.\n   * @param field The field to retrieve on the document\n   * @param document The document to fall back on\n   * @param analyzer The analyzer to use for creating the TokenStream if the\n   *        vector doesn't exist\n   * @return The {@link org.apache.lucene.analysis.TokenStream} for the\n   *         {@link org.apache.lucene.index.IndexableField} on the\n   *         {@link org.apache.lucene.document.Document}\n   * @throws IOException if there was an error loading\n   */\n\n  public static TokenStream getAnyTokenStream(IndexReader reader, int docId,\n      String field, StoredDocument document, Analyzer analyzer) throws IOException {\n    TokenStream ts = null;\n\n    Fields vectors = reader.getTermVectors(docId);\n    if (vectors != null) {\n      Terms vector = vectors.terms(field);\n      if (vector != null) {\n        ts = getTokenStream(vector);\n      }\n    }\n\n    // No token info stored so fall back to analyzing raw content\n    if (ts == null) {\n      ts = getTokenStream(document, field, analyzer);\n    }\n    return ts;\n  }\n\n","sourceOld":"  /**\n   * A convenience method that tries to first get a TermPositionVector for the\n   * specified docId, then, falls back to using the passed in\n   * {@link org.apache.lucene.document.Document} to retrieve the TokenStream.\n   * This is useful when you already have the document, but would prefer to use\n   * the vector first.\n   * \n   * @param reader The {@link org.apache.lucene.index.IndexReader} to use to try\n   *        and get the vector from\n   * @param docId The docId to retrieve.\n   * @param field The field to retrieve on the document\n   * @param doc The document to fall back on\n   * @param analyzer The analyzer to use for creating the TokenStream if the\n   *        vector doesn't exist\n   * @return The {@link org.apache.lucene.analysis.TokenStream} for the\n   *         {@link org.apache.lucene.index.IndexableField} on the\n   *         {@link org.apache.lucene.document.Document}\n   * @throws IOException if there was an error loading\n   */\n\n  public static TokenStream getAnyTokenStream(IndexReader reader, int docId,\n      String field, Document doc, Analyzer analyzer) throws IOException {\n    TokenStream ts = null;\n\n    Fields vectors = reader.getTermVectors(docId);\n    if (vectors != null) {\n      Terms vector = vectors.terms(field);\n      if (vector != null) {\n        ts = getTokenStream(vector);\n      }\n    }\n\n    // No token info stored so fall back to analyzing raw content\n    if (ts == null) {\n      ts = getTokenStream(doc, field, analyzer);\n    }\n    return ts;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d028314cced5858683a1bb4741423d0f934257b","date":1346596535,"type":1,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,StoredDocument,Analyzer).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,Document,Analyzer).mjava","sourceNew":"  /**\n   * A convenience method that tries to first get a TermPositionVector for the\n   * specified docId, then, falls back to using the passed in\n   * {@link org.apache.lucene.document.Document} to retrieve the TokenStream.\n   * This is useful when you already have the document, but would prefer to use\n   * the vector first.\n   * \n   * @param reader The {@link org.apache.lucene.index.IndexReader} to use to try\n   *        and get the vector from\n   * @param docId The docId to retrieve.\n   * @param field The field to retrieve on the document\n   * @param document The document to fall back on\n   * @param analyzer The analyzer to use for creating the TokenStream if the\n   *        vector doesn't exist\n   * @return The {@link org.apache.lucene.analysis.TokenStream} for the\n   *         {@link org.apache.lucene.index.IndexableField} on the\n   *         {@link org.apache.lucene.document.Document}\n   * @throws IOException if there was an error loading\n   */\n\n  public static TokenStream getAnyTokenStream(IndexReader reader, int docId,\n      String field, StoredDocument document, Analyzer analyzer) throws IOException {\n    TokenStream ts = null;\n\n    Fields vectors = reader.getTermVectors(docId);\n    if (vectors != null) {\n      Terms vector = vectors.terms(field);\n      if (vector != null) {\n        ts = getTokenStream(vector);\n      }\n    }\n\n    // No token info stored so fall back to analyzing raw content\n    if (ts == null) {\n      ts = getTokenStream(document, field, analyzer);\n    }\n    return ts;\n  }\n\n","sourceOld":"  /**\n   * A convenience method that tries to first get a TermPositionVector for the\n   * specified docId, then, falls back to using the passed in\n   * {@link org.apache.lucene.document.Document} to retrieve the TokenStream.\n   * This is useful when you already have the document, but would prefer to use\n   * the vector first.\n   * \n   * @param reader The {@link org.apache.lucene.index.IndexReader} to use to try\n   *        and get the vector from\n   * @param docId The docId to retrieve.\n   * @param field The field to retrieve on the document\n   * @param doc The document to fall back on\n   * @param analyzer The analyzer to use for creating the TokenStream if the\n   *        vector doesn't exist\n   * @return The {@link org.apache.lucene.analysis.TokenStream} for the\n   *         {@link org.apache.lucene.index.IndexableField} on the\n   *         {@link org.apache.lucene.document.Document}\n   * @throws IOException if there was an error loading\n   */\n\n  public static TokenStream getAnyTokenStream(IndexReader reader, int docId,\n      String field, Document doc, Analyzer analyzer) throws IOException {\n    TokenStream ts = null;\n\n    Fields vectors = reader.getTermVectors(docId);\n    if (vectors != null) {\n      Terms vector = vectors.terms(field);\n      if (vector != null) {\n        ts = getTokenStream(vector);\n      }\n    }\n\n    // No token info stored so fall back to analyzing raw content\n    if (ts == null) {\n      ts = getTokenStream(doc, field, analyzer);\n    }\n    return ts;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aeebe27bce18b879b80f68494c52cda1021b5705","date":1417792137,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,StoredDocument,Analyzer).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,StoredDocument,Analyzer).mjava","sourceNew":"  /**\n   * A convenience method that tries to first get a {@link TokenStreamFromTermVector} for the\n   * specified docId, then, falls back to using the passed in\n   * {@link org.apache.lucene.document.Document} to retrieve the TokenStream.\n   * This is useful when you already have the document, but would prefer to use\n   * the vector first.\n   * \n   * @param reader The {@link org.apache.lucene.index.IndexReader} to use to try\n   *        and get the vector from\n   * @param docId The docId to retrieve.\n   * @param field The field to retrieve on the document\n   * @param document The document to fall back on\n   * @param analyzer The analyzer to use for creating the TokenStream if the\n   *        vector doesn't exist\n   * @return The {@link org.apache.lucene.analysis.TokenStream} for the\n   *         {@link org.apache.lucene.index.IndexableField} on the\n   *         {@link org.apache.lucene.document.Document}\n   * @throws IOException if there was an error loading\n   */\n\n  public static TokenStream getAnyTokenStream(IndexReader reader, int docId,\n      String field, StoredDocument document, Analyzer analyzer) throws IOException {\n    TokenStream ts = null;\n\n    Fields vectors = reader.getTermVectors(docId);\n    if (vectors != null) {\n      Terms vector = vectors.terms(field);\n      if (vector != null) {\n        ts = getTokenStream(vector);\n      }\n    }\n\n    // No token info stored so fall back to analyzing raw content\n    if (ts == null) {\n      ts = getTokenStream(document, field, analyzer);\n    }\n    return ts;\n  }\n\n","sourceOld":"  /**\n   * A convenience method that tries to first get a TermPositionVector for the\n   * specified docId, then, falls back to using the passed in\n   * {@link org.apache.lucene.document.Document} to retrieve the TokenStream.\n   * This is useful when you already have the document, but would prefer to use\n   * the vector first.\n   * \n   * @param reader The {@link org.apache.lucene.index.IndexReader} to use to try\n   *        and get the vector from\n   * @param docId The docId to retrieve.\n   * @param field The field to retrieve on the document\n   * @param document The document to fall back on\n   * @param analyzer The analyzer to use for creating the TokenStream if the\n   *        vector doesn't exist\n   * @return The {@link org.apache.lucene.analysis.TokenStream} for the\n   *         {@link org.apache.lucene.index.IndexableField} on the\n   *         {@link org.apache.lucene.document.Document}\n   * @throws IOException if there was an error loading\n   */\n\n  public static TokenStream getAnyTokenStream(IndexReader reader, int docId,\n      String field, StoredDocument document, Analyzer analyzer) throws IOException {\n    TokenStream ts = null;\n\n    Fields vectors = reader.getTermVectors(docId);\n    if (vectors != null) {\n      Terms vector = vectors.terms(field);\n      if (vector != null) {\n        ts = getTokenStream(vector);\n      }\n    }\n\n    // No token info stored so fall back to analyzing raw content\n    if (ts == null) {\n      ts = getTokenStream(document, field, analyzer);\n    }\n    return ts;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5d62e4938659e263e96ae8188e11aea8a940aea5","date":1430230314,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,StoredDocument,Analyzer).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,StoredDocument,Analyzer).mjava","sourceNew":"  /**\n   * A convenience method that tries to first get a {@link TokenStreamFromTermVector} for the\n   * specified docId, then, falls back to using the passed in\n   * {@link org.apache.lucene.document.Document} to retrieve the TokenStream.\n   * This is useful when you already have the document, but would prefer to use\n   * the vector first.\n   *\n   * @param reader The {@link org.apache.lucene.index.IndexReader} to use to try\n   *        and get the vector from\n   * @param docId The docId to retrieve.\n   * @param field The field to retrieve on the document\n   * @param document The document to fall back on\n   * @param analyzer The analyzer to use for creating the TokenStream if the\n   *        vector doesn't exist\n   * @return The {@link org.apache.lucene.analysis.TokenStream} for the\n   *         {@link org.apache.lucene.index.IndexableField} on the\n   *         {@link org.apache.lucene.document.Document}\n   * @throws IOException if there was an error loading\n   */\n  @Deprecated // maintenance reasons LUCENE-6445\n  public static TokenStream getAnyTokenStream(IndexReader reader, int docId,\n      String field, StoredDocument document, Analyzer analyzer) throws IOException {\n    TokenStream ts = null;\n\n    Fields vectors = reader.getTermVectors(docId);\n    if (vectors != null) {\n      Terms vector = vectors.terms(field);\n      if (vector != null) {\n        ts = getTokenStream(vector);\n      }\n    }\n\n    // No token info stored so fall back to analyzing raw content\n    if (ts == null) {\n      ts = getTokenStream(document, field, analyzer);\n    }\n    return ts;\n  }\n\n","sourceOld":"  /**\n   * A convenience method that tries to first get a {@link TokenStreamFromTermVector} for the\n   * specified docId, then, falls back to using the passed in\n   * {@link org.apache.lucene.document.Document} to retrieve the TokenStream.\n   * This is useful when you already have the document, but would prefer to use\n   * the vector first.\n   * \n   * @param reader The {@link org.apache.lucene.index.IndexReader} to use to try\n   *        and get the vector from\n   * @param docId The docId to retrieve.\n   * @param field The field to retrieve on the document\n   * @param document The document to fall back on\n   * @param analyzer The analyzer to use for creating the TokenStream if the\n   *        vector doesn't exist\n   * @return The {@link org.apache.lucene.analysis.TokenStream} for the\n   *         {@link org.apache.lucene.index.IndexableField} on the\n   *         {@link org.apache.lucene.document.Document}\n   * @throws IOException if there was an error loading\n   */\n\n  public static TokenStream getAnyTokenStream(IndexReader reader, int docId,\n      String field, StoredDocument document, Analyzer analyzer) throws IOException {\n    TokenStream ts = null;\n\n    Fields vectors = reader.getTermVectors(docId);\n    if (vectors != null) {\n      Terms vector = vectors.terms(field);\n      if (vector != null) {\n        ts = getTokenStream(vector);\n      }\n    }\n\n    // No token info stored so fall back to analyzing raw content\n    if (ts == null) {\n      ts = getTokenStream(document, field, analyzer);\n    }\n    return ts;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,Document,Analyzer).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/highlight/TokenSources#getAnyTokenStream(IndexReader,int,String,StoredDocument,Analyzer).mjava","sourceNew":"  /**\n   * A convenience method that tries to first get a {@link TokenStreamFromTermVector} for the\n   * specified docId, then, falls back to using the passed in\n   * {@link org.apache.lucene.document.Document} to retrieve the TokenStream.\n   * This is useful when you already have the document, but would prefer to use\n   * the vector first.\n   *\n   * @param reader The {@link org.apache.lucene.index.IndexReader} to use to try\n   *        and get the vector from\n   * @param docId The docId to retrieve.\n   * @param field The field to retrieve on the document\n   * @param document The document to fall back on\n   * @param analyzer The analyzer to use for creating the TokenStream if the\n   *        vector doesn't exist\n   * @return The {@link org.apache.lucene.analysis.TokenStream} for the\n   *         {@link org.apache.lucene.index.IndexableField} on the\n   *         {@link org.apache.lucene.document.Document}\n   * @throws IOException if there was an error loading\n   */\n  @Deprecated // maintenance reasons LUCENE-6445\n  public static TokenStream getAnyTokenStream(IndexReader reader, int docId,\n      String field, Document document, Analyzer analyzer) throws IOException {\n    TokenStream ts = null;\n\n    Fields vectors = reader.getTermVectors(docId);\n    if (vectors != null) {\n      Terms vector = vectors.terms(field);\n      if (vector != null) {\n        ts = getTokenStream(vector);\n      }\n    }\n\n    // No token info stored so fall back to analyzing raw content\n    if (ts == null) {\n      ts = getTokenStream(document, field, analyzer);\n    }\n    return ts;\n  }\n\n","sourceOld":"  /**\n   * A convenience method that tries to first get a {@link TokenStreamFromTermVector} for the\n   * specified docId, then, falls back to using the passed in\n   * {@link org.apache.lucene.document.Document} to retrieve the TokenStream.\n   * This is useful when you already have the document, but would prefer to use\n   * the vector first.\n   *\n   * @param reader The {@link org.apache.lucene.index.IndexReader} to use to try\n   *        and get the vector from\n   * @param docId The docId to retrieve.\n   * @param field The field to retrieve on the document\n   * @param document The document to fall back on\n   * @param analyzer The analyzer to use for creating the TokenStream if the\n   *        vector doesn't exist\n   * @return The {@link org.apache.lucene.analysis.TokenStream} for the\n   *         {@link org.apache.lucene.index.IndexableField} on the\n   *         {@link org.apache.lucene.document.Document}\n   * @throws IOException if there was an error loading\n   */\n  @Deprecated // maintenance reasons LUCENE-6445\n  public static TokenStream getAnyTokenStream(IndexReader reader, int docId,\n      String field, StoredDocument document, Analyzer analyzer) throws IOException {\n    TokenStream ts = null;\n\n    Fields vectors = reader.getTermVectors(docId);\n    if (vectors != null) {\n      Terms vector = vectors.terms(field);\n      if (vector != null) {\n        ts = getTokenStream(vector);\n      }\n    }\n\n    // No token info stored so fall back to analyzing raw content\n    if (ts == null) {\n      ts = getTokenStream(document, field, analyzer);\n    }\n    return ts;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"1d028314cced5858683a1bb4741423d0f934257b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","a7e4907084808af8fdb14b9809e6dceaccf6867b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5d62e4938659e263e96ae8188e11aea8a940aea5":["aeebe27bce18b879b80f68494c52cda1021b5705"],"a7e4907084808af8fdb14b9809e6dceaccf6867b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["5d62e4938659e263e96ae8188e11aea8a940aea5"],"aeebe27bce18b879b80f68494c52cda1021b5705":["1d028314cced5858683a1bb4741423d0f934257b"]},"commit2Childs":{"1d028314cced5858683a1bb4741423d0f934257b":["aeebe27bce18b879b80f68494c52cda1021b5705"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["1d028314cced5858683a1bb4741423d0f934257b","a7e4907084808af8fdb14b9809e6dceaccf6867b"],"5d62e4938659e263e96ae8188e11aea8a940aea5":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"a7e4907084808af8fdb14b9809e6dceaccf6867b":["1d028314cced5858683a1bb4741423d0f934257b"],"aeebe27bce18b879b80f68494c52cda1021b5705":["5d62e4938659e263e96ae8188e11aea8a940aea5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}