{"path":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8","date":1328775259,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = ReaderUtil.leaves(searcher.getTopReaderContext());\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","date":1340090669,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final AtomicReaderContext[] leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (int i=0; i<leaves.length; i++) {\n      final SegFacet segFacet = new SegFacet(leaves[i]);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.length) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0; i<leaves.length; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6e2893fd5349134af382d33ccc3d84840394c6c1","date":1353682567,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7530de27b87b961b51f01bd1299b7004d46e8823","date":1355236261,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"49bbfc33f80659ba9aa9d301edaae82dd4e01b5a","date":1358789155,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = new SortedDocValuesTermsEnum(seg.si);\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = new SortedDocValuesTermsEnum(seg.si);\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==0) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 1;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.getTermsEnum();          \n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":["e9069c2e665572658f846820b6cb8ad53de19df0","98a8a68e6714cb8742c790308b9f5180d63417d4"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7e129598ae448211d969dd7cdf2ad4558a0658a1","date":1362963550,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = new SortedDocValuesTermsEnum(seg.si);\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"64e6baad25b7155a116cb0126b4e2a06b945a5c5","date":1362976847,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = new SortedDocValuesTermsEnum(seg.si);\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5c2b6033d1fc841b41dbf56c765ce3dc053ecba6","date":1363054647,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = new SortedDocValuesTermsEnum(seg.si);\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"19275ba31e621f6da1b83bf13af75233876fd3d4","date":1374846698,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec","date":1376375609,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9328857b6413a6142e4cf01276887353c23898ed","date":1381956348,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      val.copyBytes(seg.tempBR);\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // make a shallow copy\n      val.bytes = seg.tempBR.bytes;\n      val.offset = seg.tempBR.offset;\n      val.length = seg.tempBR.length;\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":["c42658ca6fd632045bce4a5238d766c64cb51018"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      val.copyBytes(seg.tempBR);\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<SegFacet>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<Callable<SegFacet>>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      val.copyBytes(seg.tempBR);\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","date":1407854805,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      val.copyBytes(seg.tempBR);\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val.get(), count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRef val = new BytesRef();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      val.copyBytes(seg.tempBR);\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val, count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":["c42658ca6fd632045bce4a5238d766c64cb51018","98a8a68e6714cb8742c790308b9f5180d63417d4"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final LeafReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      val.copyBytes(seg.tempBR);\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val.get(), count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<AtomicReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final AtomicReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      val.copyBytes(seg.tempBR);\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val.get(), count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"52c5280f6286c7546ab75b72c663f7bb1dc10e96","date":1427372570,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final LeafReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n      \n      // if facet.contains specified, only actually collect the count if substring contained\n      boolean collect = containsBR == null || StringHelper.contains(seg.tempBR, containsBR, ignoreCase);\n      \n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      if (collect) {\n        val.copyBytes(seg.tempBR);\n      }\n      \n      int count = 0;\n\n      do {\n        if (collect) {\n          count += seg.counts[seg.pos - seg.startTermIndex];\n        }\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        } else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      if (collect) {\n        boolean stop = collector.collect(val.get(), count);\n        if (stop) break;\n      }\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final LeafReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      val.copyBytes(seg.tempBR);\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val.get(), count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final LeafReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n      \n      // if facet.contains specified, only actually collect the count if substring contained\n      boolean collect = containsBR == null || StringHelper.contains(seg.tempBR, containsBR, ignoreCase);\n      \n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      if (collect) {\n        val.copyBytes(seg.tempBR);\n      }\n      \n      int count = 0;\n\n      do {\n        if (collect) {\n          count += seg.counts[seg.pos - seg.startTermIndex];\n        }\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        } else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      if (collect) {\n        boolean stop = collector.collect(val.get(), count);\n        if (stop) break;\n      }\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final LeafReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n\n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      val.copyBytes(seg.tempBR);\n\n      int count = 0;\n\n      do {\n        count += seg.counts[seg.pos - seg.startTermIndex];\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        }  else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      boolean stop = collector.collect(val.get(), count);\n      if (stop) break;\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5963c53b53608d00d165849e6b52e71b0209c9b6","date":1428506893,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final LeafReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n      \n      // if facet.contains specified, only actually collect the count if substring contained\n      boolean collect = contains == null || SimpleFacets.contains(seg.tempBR.utf8ToString(), contains, ignoreCase);\n      \n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      if (collect) {\n        val.copyBytes(seg.tempBR);\n      }\n      \n      int count = 0;\n\n      do {\n        if (collect) {\n          count += seg.counts[seg.pos - seg.startTermIndex];\n        }\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        } else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      if (collect) {\n        boolean stop = collector.collect(val.get(), count);\n        if (stop) break;\n      }\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final LeafReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n      \n      // if facet.contains specified, only actually collect the count if substring contained\n      boolean collect = containsBR == null || StringHelper.contains(seg.tempBR, containsBR, ignoreCase);\n      \n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      if (collect) {\n        val.copyBytes(seg.tempBR);\n      }\n      \n      int count = 0;\n\n      do {\n        if (collect) {\n          count += seg.counts[seg.pos - seg.startTermIndex];\n        }\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        } else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      if (collect) {\n        boolean stop = collector.collect(val.get(), count);\n        if (stop) break;\n      }\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e469758fd4a573bda61113c4ca812fafa6beac85","date":1453243309,"type":3,"author":"Dennis Gove","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final LeafReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex && (mincount < 1 || seg.hasAnyCount)) {  \n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n      \n      // if facet.contains specified, only actually collect the count if substring contained\n      boolean collect = contains == null || SimpleFacets.contains(seg.tempBR.utf8ToString(), contains, ignoreCase);\n      \n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      if (collect) {\n        val.copyBytes(seg.tempBR);\n      }\n      \n      int count = 0;\n\n      do {\n        if (collect) {\n          count += seg.counts[seg.pos - seg.startTermIndex];\n        }\n\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        do{\n          ++seg.pos;\n        }\n        while(  \n            (seg.pos < seg.endTermIndex)  //stop incrementing before we run off the end\n         && (seg.tenum.next() != null || true) //move term enum forward with position -- dont care about value \n         && (mincount > 0) //only skip ahead if mincount > 0\n         && (seg.counts[seg.pos - seg.startTermIndex] == 0) //check zero count\n        );\n        \n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        } else {\n          seg.tempBR = seg.tenum.term();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      if (collect) {\n        boolean stop = collector.collect(val.get(), count);\n        if (stop) break;\n      }\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final LeafReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex) {\n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n      \n      // if facet.contains specified, only actually collect the count if substring contained\n      boolean collect = contains == null || SimpleFacets.contains(seg.tempBR.utf8ToString(), contains, ignoreCase);\n      \n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      if (collect) {\n        val.copyBytes(seg.tempBR);\n      }\n      \n      int count = 0;\n\n      do {\n        if (collect) {\n          count += seg.counts[seg.pos - seg.startTermIndex];\n        }\n\n        // TODO: OPTIMIZATION...\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        seg.pos++;\n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        } else {\n          seg.tempBR = seg.tenum.next();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      if (collect) {\n        boolean stop = collector.collect(val.get(), count);\n        if (stop) break;\n      }\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"043df2e9a841864922c32756a44c939ed768cb89","date":1459876536,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final LeafReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = () -> {\n        segFacet.countTerms();\n        return segFacet;\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex && (mincount < 1 || seg.hasAnyCount)) {  \n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n      \n      // if facet.contains specified, only actually collect the count if substring contained\n      boolean collect = contains == null || SimpleFacets.contains(seg.tempBR.utf8ToString(), contains, ignoreCase);\n      \n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      if (collect) {\n        val.copyBytes(seg.tempBR);\n      }\n      \n      int count = 0;\n\n      do {\n        if (collect) {\n          count += seg.counts[seg.pos - seg.startTermIndex];\n        }\n\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        do{\n          ++seg.pos;\n        }\n        while(  \n            (seg.pos < seg.endTermIndex)  //stop incrementing before we run off the end\n         && (seg.tenum.next() != null || true) //move term enum forward with position -- dont care about value \n         && (mincount > 0) //only skip ahead if mincount > 0\n         && (seg.counts[seg.pos - seg.startTermIndex] == 0) //check zero count\n        );\n        \n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        } else {\n          seg.tempBR = seg.tenum.term();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      if (collect) {\n        boolean stop = collector.collect(val.get(), count);\n        if (stop) break;\n      }\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final LeafReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex && (mincount < 1 || seg.hasAnyCount)) {  \n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n      \n      // if facet.contains specified, only actually collect the count if substring contained\n      boolean collect = contains == null || SimpleFacets.contains(seg.tempBR.utf8ToString(), contains, ignoreCase);\n      \n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      if (collect) {\n        val.copyBytes(seg.tempBR);\n      }\n      \n      int count = 0;\n\n      do {\n        if (collect) {\n          count += seg.counts[seg.pos - seg.startTermIndex];\n        }\n\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        do{\n          ++seg.pos;\n        }\n        while(  \n            (seg.pos < seg.endTermIndex)  //stop incrementing before we run off the end\n         && (seg.tenum.next() != null || true) //move term enum forward with position -- dont care about value \n         && (mincount > 0) //only skip ahead if mincount > 0\n         && (seg.counts[seg.pos - seg.startTermIndex] == 0) //check zero count\n        );\n        \n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        } else {\n          seg.tempBR = seg.tenum.term();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      if (collect) {\n        boolean stop = collector.collect(val.get(), count);\n        if (stop) break;\n      }\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b6284684320a9808c41a5e43de958b2da22f89bd","date":1459977490,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final LeafReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = () -> {\n        segFacet.countTerms();\n        return segFacet;\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex && (mincount < 1 || seg.hasAnyCount)) {  \n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n      \n      // if facet.contains specified, only actually collect the count if substring contained\n      boolean collect = contains == null || SimpleFacets.contains(seg.tempBR.utf8ToString(), contains, ignoreCase);\n      \n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      if (collect) {\n        val.copyBytes(seg.tempBR);\n      }\n      \n      int count = 0;\n\n      do {\n        if (collect) {\n          count += seg.counts[seg.pos - seg.startTermIndex];\n        }\n\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        do{\n          ++seg.pos;\n        }\n        while(  \n            (seg.pos < seg.endTermIndex)  //stop incrementing before we run off the end\n         && (seg.tenum.next() != null || true) //move term enum forward with position -- dont care about value \n         && (mincount > 0) //only skip ahead if mincount > 0\n         && (seg.counts[seg.pos - seg.startTermIndex] == 0) //check zero count\n        );\n        \n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        } else {\n          seg.tempBR = seg.tenum.term();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      if (collect) {\n        boolean stop = collector.collect(val.get(), count);\n        if (stop) break;\n      }\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final LeafReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = new Callable<SegFacet>() {\n        @Override\n        public SegFacet call() throws Exception {\n          segFacet.countTerms();\n          return segFacet;\n        }\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex && (mincount < 1 || seg.hasAnyCount)) {  \n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n      \n      // if facet.contains specified, only actually collect the count if substring contained\n      boolean collect = contains == null || SimpleFacets.contains(seg.tempBR.utf8ToString(), contains, ignoreCase);\n      \n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      if (collect) {\n        val.copyBytes(seg.tempBR);\n      }\n      \n      int count = 0;\n\n      do {\n        if (collect) {\n          count += seg.counts[seg.pos - seg.startTermIndex];\n        }\n\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        do{\n          ++seg.pos;\n        }\n        while(  \n            (seg.pos < seg.endTermIndex)  //stop incrementing before we run off the end\n         && (seg.tenum.next() != null || true) //move term enum forward with position -- dont care about value \n         && (mincount > 0) //only skip ahead if mincount > 0\n         && (seg.counts[seg.pos - seg.startTermIndex] == 0) //check zero count\n        );\n        \n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        } else {\n          seg.tempBR = seg.tenum.term();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      if (collect) {\n        boolean stop = collector.collect(val.get(), count);\n        if (stop) break;\n      }\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"862ed062e72c1c01ecd8593b17804ac02b69cf0e","date":1486641184,"type":3,"author":"Christine Poerschke","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final LeafReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = () -> {\n        segFacet.countTerms();\n        return segFacet;\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex && (mincount < 1 || seg.hasAnyCount)) {  \n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n      \n      boolean collect = termFilter == null || termFilter.test(seg.tempBR);\n      \n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      if (collect) {\n        val.copyBytes(seg.tempBR);\n      }\n      \n      int count = 0;\n\n      do {\n        if (collect) {\n          count += seg.counts[seg.pos - seg.startTermIndex];\n        }\n\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        do{\n          ++seg.pos;\n        }\n        while(  \n            (seg.pos < seg.endTermIndex)  //stop incrementing before we run off the end\n         && (seg.tenum.next() != null || true) //move term enum forward with position -- dont care about value \n         && (mincount > 0) //only skip ahead if mincount > 0\n         && (seg.counts[seg.pos - seg.startTermIndex] == 0) //check zero count\n        );\n        \n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        } else {\n          seg.tempBR = seg.tenum.term();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      if (collect) {\n        boolean stop = collector.collect(val.get(), count);\n        if (stop) break;\n      }\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final LeafReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = () -> {\n        segFacet.countTerms();\n        return segFacet;\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex && (mincount < 1 || seg.hasAnyCount)) {  \n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n      \n      // if facet.contains specified, only actually collect the count if substring contained\n      boolean collect = contains == null || SimpleFacets.contains(seg.tempBR.utf8ToString(), contains, ignoreCase);\n      \n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      if (collect) {\n        val.copyBytes(seg.tempBR);\n      }\n      \n      int count = 0;\n\n      do {\n        if (collect) {\n          count += seg.counts[seg.pos - seg.startTermIndex];\n        }\n\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        do{\n          ++seg.pos;\n        }\n        while(  \n            (seg.pos < seg.endTermIndex)  //stop incrementing before we run off the end\n         && (seg.tenum.next() != null || true) //move term enum forward with position -- dont care about value \n         && (mincount > 0) //only skip ahead if mincount > 0\n         && (seg.counts[seg.pos - seg.startTermIndex] == 0) //check zero count\n        );\n        \n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        } else {\n          seg.tempBR = seg.tenum.term();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      if (collect) {\n        boolean stop = collector.collect(val.get(), count);\n        if (stop) break;\n      }\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7679cc7d5b465ec8936979698cedf5fdbd71c95c","date":1566227764,"type":3,"author":"Munendra S N","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","pathOld":"solr/core/src/java/org/apache/solr/request/PerSegmentSingleValuedFaceting#getFacetCounts(Executor).mjava","sourceNew":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final LeafReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = () -> {\n        segFacet.countTerms();\n        return segFacet;\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex && (mincount < 1 || seg.hasAnyCount)) {  \n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    if (limit == 0) {\n      NamedList<Integer> res = new NamedList<>();\n      return finalize(res, missingCount, hasMissingCount);\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n      \n      boolean collect = termFilter == null || termFilter.test(seg.tempBR);\n      \n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      if (collect) {\n        val.copyBytes(seg.tempBR);\n      }\n      \n      int count = 0;\n\n      do {\n        if (collect) {\n          count += seg.counts[seg.pos - seg.startTermIndex];\n        }\n\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        do{\n          ++seg.pos;\n        }\n        while(  \n            (seg.pos < seg.endTermIndex)  //stop incrementing before we run off the end\n         && (seg.tenum.next() != null || true) //move term enum forward with position -- dont care about value \n         && (mincount > 0) //only skip ahead if mincount > 0\n         && (seg.counts[seg.pos - seg.startTermIndex] == 0) //check zero count\n        );\n        \n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        } else {\n          seg.tempBR = seg.tenum.term();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      if (collect) {\n        boolean stop = collector.collect(val.get(), count);\n        if (stop) break;\n      }\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    return finalize(res, missingCount, hasMissingCount);\n  }\n\n","sourceOld":"  NamedList<Integer> getFacetCounts(Executor executor) throws IOException {\n\n    CompletionService<SegFacet> completionService = new ExecutorCompletionService<>(executor);\n\n    // reuse the translation logic to go from top level set to per-segment set\n    baseSet = docs.getTopFilter();\n\n    final List<LeafReaderContext> leaves = searcher.getTopReaderContext().leaves();\n    // The list of pending tasks that aren't immediately submitted\n    // TODO: Is there a completion service, or a delegating executor that can\n    // limit the number of concurrent tasks submitted to a bigger executor?\n    LinkedList<Callable<SegFacet>> pending = new LinkedList<>();\n\n    int threads = nThreads <= 0 ? Integer.MAX_VALUE : nThreads;\n\n    for (final LeafReaderContext leave : leaves) {\n      final SegFacet segFacet = new SegFacet(leave);\n\n      Callable<SegFacet> task = () -> {\n        segFacet.countTerms();\n        return segFacet;\n      };\n\n      // TODO: if limiting threads, submit by largest segment first?\n\n      if (--threads >= 0) {\n        completionService.submit(task);\n      } else {\n        pending.add(task);\n      }\n    }\n\n\n    // now merge the per-segment results\n    PriorityQueue<SegFacet> queue = new PriorityQueue<SegFacet>(leaves.size()) {\n      @Override\n      protected boolean lessThan(SegFacet a, SegFacet b) {\n        return a.tempBR.compareTo(b.tempBR) < 0;\n      }\n    };\n\n\n    boolean hasMissingCount=false;\n    int missingCount=0;\n    for (int i=0, c=leaves.size(); i<c; i++) {\n      SegFacet seg = null;\n\n      try {\n        Future<SegFacet> future = completionService.take();        \n        seg = future.get();\n        if (!pending.isEmpty()) {\n          completionService.submit(pending.removeFirst());\n        }\n      } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, e);\n      } catch (ExecutionException e) {\n        Throwable cause = e.getCause();\n        if (cause instanceof RuntimeException) {\n          throw (RuntimeException)cause;\n        } else {\n          throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, \"Error in per-segment faceting on field: \" + fieldName, cause);\n        }\n      }\n\n\n      if (seg.startTermIndex < seg.endTermIndex) {\n        if (seg.startTermIndex==-1) {\n          hasMissingCount=true;\n          missingCount += seg.counts[0];\n          seg.pos = 0;\n        } else {\n          seg.pos = seg.startTermIndex;\n        }\n        if (seg.pos < seg.endTermIndex && (mincount < 1 || seg.hasAnyCount)) {  \n          seg.tenum = seg.si.termsEnum();\n          seg.tenum.seekExact(seg.pos);\n          seg.tempBR = seg.tenum.term();\n          queue.add(seg);\n        }\n      }\n    }\n\n    FacetCollector collector;\n    if (sort.equals(FacetParams.FACET_SORT_COUNT) || sort.equals(FacetParams.FACET_SORT_COUNT_LEGACY)) {\n      collector = new CountSortedFacetCollector(offset, limit, mincount);\n    } else {\n      collector = new IndexSortedFacetCollector(offset, limit, mincount);\n    }\n\n    BytesRefBuilder val = new BytesRefBuilder();\n\n    while (queue.size() > 0) {\n      SegFacet seg = queue.top();\n      \n      boolean collect = termFilter == null || termFilter.test(seg.tempBR);\n      \n      // we will normally end up advancing the term enum for this segment\n      // while still using \"val\", so we need to make a copy since the BytesRef\n      // may be shared across calls.\n      if (collect) {\n        val.copyBytes(seg.tempBR);\n      }\n      \n      int count = 0;\n\n      do {\n        if (collect) {\n          count += seg.counts[seg.pos - seg.startTermIndex];\n        }\n\n        // if mincount>0 then seg.pos++ can skip ahead to the next non-zero entry.\n        do{\n          ++seg.pos;\n        }\n        while(  \n            (seg.pos < seg.endTermIndex)  //stop incrementing before we run off the end\n         && (seg.tenum.next() != null || true) //move term enum forward with position -- dont care about value \n         && (mincount > 0) //only skip ahead if mincount > 0\n         && (seg.counts[seg.pos - seg.startTermIndex] == 0) //check zero count\n        );\n        \n        if (seg.pos >= seg.endTermIndex) {\n          queue.pop();\n          seg = queue.top();\n        } else {\n          seg.tempBR = seg.tenum.term();\n          seg = queue.updateTop();\n        }\n      } while (seg != null && val.get().compareTo(seg.tempBR) == 0);\n\n      if (collect) {\n        boolean stop = collector.collect(val.get(), count);\n        if (stop) break;\n      }\n    }\n\n    NamedList<Integer> res = collector.getFacetCounts();\n\n    // convert labels to readable form    \n    FieldType ft = searcher.getSchema().getFieldType(fieldName);\n    int sz = res.size();\n    for (int i=0; i<sz; i++) {\n      res.setName(i, ft.indexedToReadable(res.getName(i)));\n    }\n\n    if (missing) {\n      if (!hasMissingCount) {\n        missingCount = SimpleFacets.getFieldMissingCount(searcher,docs,fieldName);\n      }\n      res.add(null, missingCount);\n    }\n\n    return res;\n  }\n\n","bugFix":["98a8a68e6714cb8742c790308b9f5180d63417d4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["6e2893fd5349134af382d33ccc3d84840394c6c1","7530de27b87b961b51f01bd1299b7004d46e8823"],"e469758fd4a573bda61113c4ca812fafa6beac85":["5963c53b53608d00d165849e6b52e71b0209c9b6"],"5963c53b53608d00d165849e6b52e71b0209c9b6":["52c5280f6286c7546ab75b72c663f7bb1dc10e96"],"52c5280f6286c7546ab75b72c663f7bb1dc10e96":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"7679cc7d5b465ec8936979698cedf5fdbd71c95c":["862ed062e72c1c01ecd8593b17804ac02b69cf0e"],"19275ba31e621f6da1b83bf13af75233876fd3d4":["5c2b6033d1fc841b41dbf56c765ce3dc053ecba6"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["c9fb5f46e264daf5ba3860defe623a89d202dd87","52c5280f6286c7546ab75b72c663f7bb1dc10e96"],"862ed062e72c1c01ecd8593b17804ac02b69cf0e":["b6284684320a9808c41a5e43de958b2da22f89bd"],"9328857b6413a6142e4cf01276887353c23898ed":["19275ba31e621f6da1b83bf13af75233876fd3d4"],"7e129598ae448211d969dd7cdf2ad4558a0658a1":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["9328857b6413a6142e4cf01276887353c23898ed"],"043df2e9a841864922c32756a44c939ed768cb89":["e469758fd4a573bda61113c4ca812fafa6beac85"],"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec":["5c2b6033d1fc841b41dbf56c765ce3dc053ecba6","19275ba31e621f6da1b83bf13af75233876fd3d4"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8"],"6e2893fd5349134af382d33ccc3d84840394c6c1":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8":["c26f00b574427b55127e869b935845554afde1fa"],"49bbfc33f80659ba9aa9d301edaae82dd4e01b5a":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"5c2b6033d1fc841b41dbf56c765ce3dc053ecba6":["64e6baad25b7155a116cb0126b4e2a06b945a5c5"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["7530de27b87b961b51f01bd1299b7004d46e8823","49bbfc33f80659ba9aa9d301edaae82dd4e01b5a"],"b6284684320a9808c41a5e43de958b2da22f89bd":["e469758fd4a573bda61113c4ca812fafa6beac85","043df2e9a841864922c32756a44c939ed768cb89"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"64e6baad25b7155a116cb0126b4e2a06b945a5c5":["7e129598ae448211d969dd7cdf2ad4558a0658a1"],"7530de27b87b961b51f01bd1299b7004d46e8823":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7679cc7d5b465ec8936979698cedf5fdbd71c95c"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["49bbfc33f80659ba9aa9d301edaae82dd4e01b5a"],"e469758fd4a573bda61113c4ca812fafa6beac85":["043df2e9a841864922c32756a44c939ed768cb89","b6284684320a9808c41a5e43de958b2da22f89bd"],"5963c53b53608d00d165849e6b52e71b0209c9b6":["e469758fd4a573bda61113c4ca812fafa6beac85"],"52c5280f6286c7546ab75b72c663f7bb1dc10e96":["5963c53b53608d00d165849e6b52e71b0209c9b6","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"c26f00b574427b55127e869b935845554afde1fa":["0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8"],"7679cc7d5b465ec8936979698cedf5fdbd71c95c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"19275ba31e621f6da1b83bf13af75233876fd3d4":["9328857b6413a6142e4cf01276887353c23898ed","716d18f3a9b0993bc679d7fa7abdc9bfb03411ec"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["52c5280f6286c7546ab75b72c663f7bb1dc10e96","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"862ed062e72c1c01ecd8593b17804ac02b69cf0e":["7679cc7d5b465ec8936979698cedf5fdbd71c95c"],"9328857b6413a6142e4cf01276887353c23898ed":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"7e129598ae448211d969dd7cdf2ad4558a0658a1":["64e6baad25b7155a116cb0126b4e2a06b945a5c5"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c26f00b574427b55127e869b935845554afde1fa","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"043df2e9a841864922c32756a44c939ed768cb89":["b6284684320a9808c41a5e43de958b2da22f89bd"],"716d18f3a9b0993bc679d7fa7abdc9bfb03411ec":[],"6e2893fd5349134af382d33ccc3d84840394c6c1":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["6e2893fd5349134af382d33ccc3d84840394c6c1","7530de27b87b961b51f01bd1299b7004d46e8823"],"0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"49bbfc33f80659ba9aa9d301edaae82dd4e01b5a":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"5c2b6033d1fc841b41dbf56c765ce3dc053ecba6":["19275ba31e621f6da1b83bf13af75233876fd3d4","716d18f3a9b0993bc679d7fa7abdc9bfb03411ec"],"b6284684320a9808c41a5e43de958b2da22f89bd":["862ed062e72c1c01ecd8593b17804ac02b69cf0e"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["7e129598ae448211d969dd7cdf2ad4558a0658a1"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"64e6baad25b7155a116cb0126b4e2a06b945a5c5":["5c2b6033d1fc841b41dbf56c765ce3dc053ecba6"],"7530de27b87b961b51f01bd1299b7004d46e8823":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","d4d69c535930b5cce125cff868d40f6373dc27d4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","716d18f3a9b0993bc679d7fa7abdc9bfb03411ec","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}