{"path":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","commits":[{"id":"81a4a1810b619aea1d002a09c1878b498e20bf33","date":1361142322,"type":1,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09c8567c25c02eeeb3e719841606a1269f3538ca","date":1361155063,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"849494cf2f3a96af5c8c84995108ddd8456fcd04","date":1372277913,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3c3e46d3417c353d7be14509cfab11b315927fe","date":1382292560,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fcad4b87b776f7c9cc2930166a33a1d5a3227486","date":1385306612,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(30000);\n\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cdc8313ba7bdaaa48ff54059d0eabff4436ab175","date":1386102048,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(30000);\n\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(30000);\n\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(30000);\n\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab2b909e093b9d67189d9c0cf8cfc36861907551","date":1392851109,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(30000);\n\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(30000);\n    addClient.setSoTimeout(90000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(30000);\n\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4c7856260bc28f285ae7bfefa99b28db4dca6daf","date":1395253500,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n      collectionClient.shutdown();\n      collectionClient = null;\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(30000);\n\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(30000);\n    addClient.setSoTimeout(90000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server.shutdown();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server.shutdown();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    server.shutdown();\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(30000);\n\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(30000);\n    addClient.setSoTimeout(90000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb1f22cfa77230b5f05b7784feae5367f6bbb488","date":1395968145,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir();\n    \n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n      collectionClient.shutdown();\n      collectionClient = null;\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(30000);\n\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(30000);\n    addClient.setSoTimeout(90000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server.shutdown();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server.shutdown();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    server.shutdown();\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n      collectionClient.shutdown();\n      collectionClient = null;\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(30000);\n\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(30000);\n    addClient.setSoTimeout(90000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server.shutdown();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server.shutdown();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    server.shutdown();\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2a0f5bb79c600763ffe7b8141df59a3169d31e48","date":1396689440,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir();\n    \n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n      collectionClient.shutdown();\n      collectionClient = null;\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(30000);\n\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(30000);\n    addClient.setSoTimeout(90000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server.shutdown();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server.shutdown();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    server.shutdown();\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n      collectionClient.shutdown();\n      collectionClient = null;\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(30000);\n\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(30000);\n    addClient.setSoTimeout(90000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server.shutdown();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server.shutdown();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    server.shutdown();\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f4abec28b874149a7223e32cc7a01704c27790de","date":1410644789,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir().toFile();\n    \n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n      collectionClient.shutdown();\n      collectionClient = null;\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(30000);\n\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(30000);\n    addClient.setSoTimeout(90000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server.shutdown();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server.shutdown();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    server.shutdown();\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir();\n    \n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n      collectionClient.shutdown();\n      collectionClient = null;\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(30000);\n\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(30000);\n    addClient.setSoTimeout(90000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server.shutdown();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server.shutdown();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    server.shutdown();\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bafca15d8e408346a67f4282ad1143b88023893b","date":1420034748,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir().toFile();\n    \n    // create a new collection collection\n    SolrClient client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrClient adminClient = new HttpSolrClient(url1);\n    adminClient.setConnectionTimeout(15000);\n    adminClient.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    adminClient.request(createCmd);\n    adminClient.shutdown();\n    adminClient = null;\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    adminClient = new HttpSolrClient(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    adminClient.request(createCmd);\n    adminClient.shutdown();\n    adminClient = null;\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrClient collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrClient(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n      collectionClient.shutdown();\n      collectionClient = null;\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    adminClient = new HttpSolrClient(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    adminClient.request(createCmd);\n    adminClient.shutdown();\n    adminClient = null;\n    \n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrClient addClient = new HttpSolrClient(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(30000);\n\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrClient(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrClient(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(30000);\n    addClient.setSoTimeout(90000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    adminClient = new HttpSolrClient(url4);\n    adminClient.setConnectionTimeout(15000);\n    adminClient.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    adminClient.request(createCmd);\n    adminClient.shutdown();\n    adminClient = null;\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrClient(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    adminClient = new HttpSolrClient(leaderProps.getBaseUrl());\n    adminClient.setConnectionTimeout(15000);\n    adminClient.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    adminClient.request(createCmd);\n    adminClient.shutdown();\n    adminClient = null;\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    adminClient = new HttpSolrClient(url2 + \"/unloadcollection\");\n    adminClient.setConnectionTimeout(15000);\n    adminClient.setSoTimeout(30000);\n    adminClient.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = adminClient.query(q).getResults().getNumFound();\n    adminClient.shutdown();\n    adminClient = new HttpSolrClient(url3 + \"/unloadcollection\");\n    adminClient.setConnectionTimeout(15000);\n    adminClient.setSoTimeout(30000);\n    adminClient.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = adminClient.query(q).getResults().getNumFound();\n    adminClient.shutdown();\n    adminClient = new HttpSolrClient(url4 + \"/unloadcollection\");\n    adminClient.setConnectionTimeout(15000);\n    adminClient.setSoTimeout(30000);\n    adminClient.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = adminClient.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    adminClient.shutdown();\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir().toFile();\n    \n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n      collectionClient.shutdown();\n      collectionClient = null;\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(30000);\n\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(30000);\n    addClient.setSoTimeout(90000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    server.request(createCmd);\n    server.shutdown();\n    server = null;\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server.shutdown();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server.shutdown();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    server.shutdown();\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cc3b13b430571c2e169f98fe38e1e7666f88522d","date":1422446157,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir().toFile();\n\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n\n    // create a new collection collection\n    SolrClient client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url1)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(60000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection1\");\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setNumShards(1);\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url2)) {\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection2\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n      createCmd.setDataDir(getDataDir(core2dataDir));\n      adminClient.request(createCmd);\n    }\n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url3)) {\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection3\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n      createCmd.setDataDir(getDataDir(core3dataDir));\n      adminClient.request(createCmd);\n    }\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    try (HttpSolrClient addClient = new HttpSolrClient(url3 + \"/unloadcollection3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    try (HttpSolrClient addClient = new HttpSolrClient(url2 + \"/unloadcollection2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url4)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection4\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n      createCmd.setDataDir(getDataDir(core4dataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    try (HttpSolrClient adminClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(leaderProps.getCoreName());\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n    \n    try (HttpSolrClient adminClient = new HttpSolrClient(url2 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n    try (HttpSolrClient adminClient = new HttpSolrClient(url3 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = new HttpSolrClient(url4 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir().toFile();\n    \n    // create a new collection collection\n    SolrClient client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrClient adminClient = new HttpSolrClient(url1);\n    adminClient.setConnectionTimeout(15000);\n    adminClient.setSoTimeout(60000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    adminClient.request(createCmd);\n    adminClient.shutdown();\n    adminClient = null;\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    adminClient = new HttpSolrClient(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(getDataDir(core2dataDir));\n    adminClient.request(createCmd);\n    adminClient.shutdown();\n    adminClient = null;\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrClient collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrClient(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n      collectionClient.shutdown();\n      collectionClient = null;\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    adminClient = new HttpSolrClient(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(getDataDir(core3dataDir));\n    adminClient.request(createCmd);\n    adminClient.shutdown();\n    adminClient = null;\n    \n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrClient addClient = new HttpSolrClient(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(30000);\n\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrClient(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrClient(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(30000);\n    addClient.setSoTimeout(90000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    addClient.shutdown();\n    addClient = null;\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    adminClient = new HttpSolrClient(url4);\n    adminClient.setConnectionTimeout(15000);\n    adminClient.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(getDataDir(core4dataDir));\n    adminClient.request(createCmd);\n    adminClient.shutdown();\n    adminClient = null;\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrClient(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    collectionClient.shutdown();\n    collectionClient = null;\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    adminClient = new HttpSolrClient(leaderProps.getBaseUrl());\n    adminClient.setConnectionTimeout(15000);\n    adminClient.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(getDataDir(core1DataDir));\n    adminClient.request(createCmd);\n    adminClient.shutdown();\n    adminClient = null;\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    adminClient = new HttpSolrClient(url2 + \"/unloadcollection\");\n    adminClient.setConnectionTimeout(15000);\n    adminClient.setSoTimeout(30000);\n    adminClient.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = adminClient.query(q).getResults().getNumFound();\n    adminClient.shutdown();\n    adminClient = new HttpSolrClient(url3 + \"/unloadcollection\");\n    adminClient.setConnectionTimeout(15000);\n    adminClient.setSoTimeout(30000);\n    adminClient.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = adminClient.query(q).getResults().getNumFound();\n    adminClient.shutdown();\n    adminClient = new HttpSolrClient(url4 + \"/unloadcollection\");\n    adminClient.setConnectionTimeout(15000);\n    adminClient.setSoTimeout(30000);\n    adminClient.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = adminClient.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    adminClient.shutdown();\n    \n  }\n\n","bugFix":null,"bugIntro":["add53de9835b2cd1a7a80b4e0036afee171c9fdf"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"102da6baafc0f534a59f31729343dbab9d3b9e9a","date":1438410244,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir().toFile();\n\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n\n    // create a new collection collection\n    SolrClient client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url1)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(60000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection1\");\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setNumShards(1);\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.updateClusterState();\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url2)) {\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection2\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n      createCmd.setDataDir(getDataDir(core2dataDir));\n      adminClient.request(createCmd);\n    }\n    zkStateReader.updateClusterState();\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url3)) {\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection3\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n      createCmd.setDataDir(getDataDir(core3dataDir));\n      adminClient.request(createCmd);\n    }\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    try (HttpSolrClient addClient = new HttpSolrClient(url3 + \"/unloadcollection3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    try (HttpSolrClient addClient = new HttpSolrClient(url2 + \"/unloadcollection2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url4)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection4\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n      createCmd.setDataDir(getDataDir(core4dataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    try (HttpSolrClient adminClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(leaderProps.getCoreName());\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n    \n    try (HttpSolrClient adminClient = new HttpSolrClient(url2 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n    try (HttpSolrClient adminClient = new HttpSolrClient(url3 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = new HttpSolrClient(url4 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir().toFile();\n\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n\n    // create a new collection collection\n    SolrClient client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url1)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(60000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection1\");\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setNumShards(1);\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url2)) {\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection2\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n      createCmd.setDataDir(getDataDir(core2dataDir));\n      adminClient.request(createCmd);\n    }\n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url3)) {\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection3\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n      createCmd.setDataDir(getDataDir(core3dataDir));\n      adminClient.request(createCmd);\n    }\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    try (HttpSolrClient addClient = new HttpSolrClient(url3 + \"/unloadcollection3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    try (HttpSolrClient addClient = new HttpSolrClient(url2 + \"/unloadcollection2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url4)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection4\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n      createCmd.setDataDir(getDataDir(core4dataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    try (HttpSolrClient adminClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(leaderProps.getCoreName());\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n    \n    try (HttpSolrClient adminClient = new HttpSolrClient(url2 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n    try (HttpSolrClient adminClient = new HttpSolrClient(url3 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = new HttpSolrClient(url4 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bcf9886c8ff537aafde14de48ebf744f5673f08b","date":1439041198,"type":3,"author":"Ramkumar Aiyengar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir().toFile();\n\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_1n\";\n\n    // create a new collection collection\n    SolrClient client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url1)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(60000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection1\");\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setNumShards(1);\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.updateClusterState();\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url2)) {\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection2\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_2n\";\n      createCmd.setDataDir(getDataDir(core2dataDir));\n      adminClient.request(createCmd);\n    }\n    zkStateReader.updateClusterState();\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url3)) {\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection3\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_3n\";\n      createCmd.setDataDir(getDataDir(core3dataDir));\n      adminClient.request(createCmd);\n    }\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    try (HttpSolrClient addClient = new HttpSolrClient(url3 + \"/unloadcollection3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    try (HttpSolrClient addClient = new HttpSolrClient(url2 + \"/unloadcollection2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url4)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection4\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_4n\";\n      createCmd.setDataDir(getDataDir(core4dataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    try (HttpSolrClient adminClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(leaderProps.getCoreName());\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n    \n    try (HttpSolrClient adminClient = new HttpSolrClient(url2 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n    try (HttpSolrClient adminClient = new HttpSolrClient(url3 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = new HttpSolrClient(url4 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir().toFile();\n\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n\n    // create a new collection collection\n    SolrClient client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url1)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(60000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection1\");\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setNumShards(1);\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.updateClusterState();\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url2)) {\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection2\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n      createCmd.setDataDir(getDataDir(core2dataDir));\n      adminClient.request(createCmd);\n    }\n    zkStateReader.updateClusterState();\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url3)) {\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection3\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n      createCmd.setDataDir(getDataDir(core3dataDir));\n      adminClient.request(createCmd);\n    }\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    try (HttpSolrClient addClient = new HttpSolrClient(url3 + \"/unloadcollection3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    try (HttpSolrClient addClient = new HttpSolrClient(url2 + \"/unloadcollection2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url4)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection4\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n      createCmd.setDataDir(getDataDir(core4dataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    try (HttpSolrClient adminClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(leaderProps.getCoreName());\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n    \n    try (HttpSolrClient adminClient = new HttpSolrClient(url2 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n    try (HttpSolrClient adminClient = new HttpSolrClient(url3 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = new HttpSolrClient(url4 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f","date":1457343183,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir().toFile();\n\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_1n\";\n\n    // create a new collection collection\n    SolrClient client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url1)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(60000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection1\");\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setNumShards(1);\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url2)) {\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection2\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_2n\";\n      createCmd.setDataDir(getDataDir(core2dataDir));\n      adminClient.request(createCmd);\n    }\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url3)) {\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection3\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_3n\";\n      createCmd.setDataDir(getDataDir(core3dataDir));\n      adminClient.request(createCmd);\n    }\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    try (HttpSolrClient addClient = new HttpSolrClient(url3 + \"/unloadcollection3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    try (HttpSolrClient addClient = new HttpSolrClient(url2 + \"/unloadcollection2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url4)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection4\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_4n\";\n      createCmd.setDataDir(getDataDir(core4dataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    try (HttpSolrClient adminClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(leaderProps.getCoreName());\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n    \n    try (HttpSolrClient adminClient = new HttpSolrClient(url2 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n    try (HttpSolrClient adminClient = new HttpSolrClient(url3 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = new HttpSolrClient(url4 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir().toFile();\n\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_1n\";\n\n    // create a new collection collection\n    SolrClient client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url1)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(60000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection1\");\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setNumShards(1);\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.updateClusterState();\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url2)) {\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection2\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_2n\";\n      createCmd.setDataDir(getDataDir(core2dataDir));\n      adminClient.request(createCmd);\n    }\n    zkStateReader.updateClusterState();\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url3)) {\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection3\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_3n\";\n      createCmd.setDataDir(getDataDir(core3dataDir));\n      adminClient.request(createCmd);\n    }\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    try (HttpSolrClient addClient = new HttpSolrClient(url3 + \"/unloadcollection3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    try (HttpSolrClient addClient = new HttpSolrClient(url2 + \"/unloadcollection2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url4)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection4\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_4n\";\n      createCmd.setDataDir(getDataDir(core4dataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    try (HttpSolrClient adminClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(leaderProps.getCoreName());\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n    \n    try (HttpSolrClient adminClient = new HttpSolrClient(url2 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n    try (HttpSolrClient adminClient = new HttpSolrClient(url3 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = new HttpSolrClient(url4 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e3c94a8b8bf47db4f968d9ae510ec8bbe1372088","date":1460069869,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir().toFile();\n\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_1n\";\n\n    // create a new collection collection\n    SolrClient client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url1)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(60000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection1\");\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setNumShards(1);\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url2)) {\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection2\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_2n\";\n      createCmd.setDataDir(getDataDir(core2dataDir));\n      adminClient.request(createCmd);\n    }\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url3)) {\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection3\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_3n\";\n      createCmd.setDataDir(getDataDir(core3dataDir));\n      adminClient.request(createCmd);\n    }\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    try (HttpSolrClient addClient = getHttpSolrClient(url3 + \"/unloadcollection3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    try (HttpSolrClient addClient = getHttpSolrClient(url2 + \"/unloadcollection2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url4)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection4\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_4n\";\n      createCmd.setDataDir(getDataDir(core4dataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    try (HttpSolrClient adminClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(leaderProps.getCoreName());\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n    \n    try (HttpSolrClient adminClient = getHttpSolrClient(url2 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n    try (HttpSolrClient adminClient = getHttpSolrClient(url3 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(url4 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir().toFile();\n\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_1n\";\n\n    // create a new collection collection\n    SolrClient client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url1)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(60000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection1\");\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setNumShards(1);\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url2)) {\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection2\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_2n\";\n      createCmd.setDataDir(getDataDir(core2dataDir));\n      adminClient.request(createCmd);\n    }\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url3)) {\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection3\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_3n\";\n      createCmd.setDataDir(getDataDir(core3dataDir));\n      adminClient.request(createCmd);\n    }\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    try (HttpSolrClient addClient = new HttpSolrClient(url3 + \"/unloadcollection3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    try (HttpSolrClient addClient = new HttpSolrClient(url2 + \"/unloadcollection2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url4)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection4\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_4n\";\n      createCmd.setDataDir(getDataDir(core4dataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    try (HttpSolrClient adminClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(leaderProps.getCoreName());\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n    \n    try (HttpSolrClient adminClient = new HttpSolrClient(url2 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n    try (HttpSolrClient adminClient = new HttpSolrClient(url3 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = new HttpSolrClient(url4 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5bdaf2cee03ff78b0a0cbf23df0095a3590b493b","date":1460110033,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir().toFile();\n\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_1n\";\n\n    // create a new collection collection\n    SolrClient client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url1)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(60000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection1\");\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setNumShards(1);\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url2)) {\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection2\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_2n\";\n      createCmd.setDataDir(getDataDir(core2dataDir));\n      adminClient.request(createCmd);\n    }\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url3)) {\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection3\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_3n\";\n      createCmd.setDataDir(getDataDir(core3dataDir));\n      adminClient.request(createCmd);\n    }\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    try (HttpSolrClient addClient = getHttpSolrClient(url3 + \"/unloadcollection3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    try (HttpSolrClient addClient = getHttpSolrClient(url2 + \"/unloadcollection2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url4)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection4\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_4n\";\n      createCmd.setDataDir(getDataDir(core4dataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    try (HttpSolrClient adminClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(leaderProps.getCoreName());\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n    \n    try (HttpSolrClient adminClient = getHttpSolrClient(url2 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n    try (HttpSolrClient adminClient = getHttpSolrClient(url3 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(url4 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir().toFile();\n\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_1n\";\n\n    // create a new collection collection\n    SolrClient client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url1)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(60000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection1\");\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setNumShards(1);\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url2)) {\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection2\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_2n\";\n      createCmd.setDataDir(getDataDir(core2dataDir));\n      adminClient.request(createCmd);\n    }\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url3)) {\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection3\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_3n\";\n      createCmd.setDataDir(getDataDir(core3dataDir));\n      adminClient.request(createCmd);\n    }\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    try (HttpSolrClient addClient = new HttpSolrClient(url3 + \"/unloadcollection3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    try (HttpSolrClient addClient = new HttpSolrClient(url2 + \"/unloadcollection2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = new HttpSolrClient(url4)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection4\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_4n\";\n      createCmd.setDataDir(getDataDir(core4dataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    try (HttpSolrClient adminClient = new HttpSolrClient(leaderProps.getBaseUrl())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(leaderProps.getCoreName());\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n    \n    try (HttpSolrClient adminClient = new HttpSolrClient(url2 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n    try (HttpSolrClient adminClient = new HttpSolrClient(url3 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = new HttpSolrClient(url4 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a9b4296bd51ca61b482138791478afdd0f7d3a3d","date":1498058739,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = jetty1.getCoreContainer().getCore(\"unloadcollection_shard1_replica1\");\n    String core1DataDir = solrCore.getDataDir();\n    solrCore.close();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/unloadcollection_shard1_replica4\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir().toFile();\n\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_1n\";\n\n    // create a new collection collection\n    SolrClient client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url1)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(60000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection1\");\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setNumShards(1);\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url2)) {\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection2\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_2n\";\n      createCmd.setDataDir(getDataDir(core2dataDir));\n      adminClient.request(createCmd);\n    }\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url3)) {\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection3\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_3n\";\n      createCmd.setDataDir(getDataDir(core3dataDir));\n      adminClient.request(createCmd);\n    }\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    try (HttpSolrClient addClient = getHttpSolrClient(url3 + \"/unloadcollection3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    try (HttpSolrClient addClient = getHttpSolrClient(url2 + \"/unloadcollection2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url4)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection4\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_4n\";\n      createCmd.setDataDir(getDataDir(core4dataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    try (HttpSolrClient adminClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(leaderProps.getCoreName());\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n    \n    try (HttpSolrClient adminClient = getHttpSolrClient(url2 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n    try (HttpSolrClient adminClient = getHttpSolrClient(url3 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(url4 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4c61b682431fc3a1ef6cf62c8c8d835b88675a72","date":1498098208,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = getFirstCore(\"unloadcollection\", jetty1);\n    String core1DataDir = solrCore.getDataDir();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/\" + getFirstCore(\"unloadcollection\", jettys.get(2)).getName())) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/\" + getFirstCore(\"unloadcollection\", jettys.get(1)).getName())) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/\" + getFirstCore(\"unloadcollection\", jettys.get(1)).getName())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/\" + getFirstCore(\"unloadcollection\", jettys.get(2)).getName())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/\" + getFirstCore(\"unloadcollection\", jettys.get(3)).getName())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = jetty1.getCoreContainer().getCore(\"unloadcollection_shard1_replica1\");\n    String core1DataDir = solrCore.getDataDir();\n    solrCore.close();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/unloadcollection_shard1_replica4\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c3d9a2e4ec5db2bc6cc023d9a1fd387ceb5b69b5","date":1498283633,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = getFirstCore(\"unloadcollection\", jetty1);\n    String core1DataDir = solrCore.getDataDir();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica2\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica3\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica4\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(leaderProps.getCoreName())\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/unloadcollection_shard1_replica4\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = getFirstCore(\"unloadcollection\", jetty1);\n    String core1DataDir = solrCore.getDataDir();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/\" + getFirstCore(\"unloadcollection\", jettys.get(2)).getName())) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/\" + getFirstCore(\"unloadcollection\", jettys.get(1)).getName())) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/\" + getFirstCore(\"unloadcollection\", jettys.get(1)).getName())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/\" + getFirstCore(\"unloadcollection\", jettys.get(2)).getName())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/\" + getFirstCore(\"unloadcollection\", jettys.get(3)).getName())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b7dfa64bc2074fb87d0ca70095a644c1ead107e1","date":1498356339,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = getFirstCore(\"unloadcollection\", jetty1);\n    String core1DataDir = solrCore.getDataDir();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica2\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica3\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica4\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(leaderProps.getCoreName())\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/unloadcollection_shard1_replica4\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir().toFile();\n\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_1n\";\n\n    // create a new collection collection\n    SolrClient client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url1)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(60000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection1\");\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setNumShards(1);\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url2)) {\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection2\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_2n\";\n      createCmd.setDataDir(getDataDir(core2dataDir));\n      adminClient.request(createCmd);\n    }\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url3)) {\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection3\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_3n\";\n      createCmd.setDataDir(getDataDir(core3dataDir));\n      adminClient.request(createCmd);\n    }\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    try (HttpSolrClient addClient = getHttpSolrClient(url3 + \"/unloadcollection3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    try (HttpSolrClient addClient = getHttpSolrClient(url2 + \"/unloadcollection2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url4)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection4\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_4n\";\n      createCmd.setDataDir(getDataDir(core4dataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    try (HttpSolrClient adminClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(leaderProps.getCoreName());\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n    \n    try (HttpSolrClient adminClient = getHttpSolrClient(url2 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n    try (HttpSolrClient adminClient = getHttpSolrClient(url3 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(url4 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"197bbedf08450ade98a11f4a0001448059666bec","date":1498534625,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", \"conf1\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = getFirstCore(\"unloadcollection\", jetty1);\n    String core1DataDir = solrCore.getDataDir();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica2\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica3\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica4\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(leaderProps.getCoreName())\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/unloadcollection_shard1_replica4\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = getFirstCore(\"unloadcollection\", jetty1);\n    String core1DataDir = solrCore.getDataDir();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica2\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica3\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica4\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(leaderProps.getCoreName())\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/unloadcollection_shard1_replica4\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4","date":1498540685,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", \"conf1\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = getFirstCore(\"unloadcollection\", jetty1);\n    String core1DataDir = solrCore.getDataDir();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica2\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica3\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica4\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(leaderProps.getCoreName())\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/unloadcollection_shard1_replica4\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = getFirstCore(\"unloadcollection\", jetty1);\n    String core1DataDir = solrCore.getDataDir();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica2\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica3\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica4\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(leaderProps.getCoreName())\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/unloadcollection_shard1_replica4\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"28288370235ed02234a64753cdbf0c6ec096304a","date":1498726817,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", \"conf1\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = getFirstCore(\"unloadcollection\", jetty1);\n    String core1DataDir = solrCore.getDataDir();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica2\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica3\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica4\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(leaderProps.getCoreName())\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/unloadcollection_shard1_replica4\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    File tmpDir = createTempDir().toFile();\n\n    String core1DataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_1n\";\n\n    // create a new collection collection\n    SolrClient client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url1)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(60000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection1\");\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setNumShards(1);\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url2)) {\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection2\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core2dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection1\" + \"_2n\";\n      createCmd.setDataDir(getDataDir(core2dataDir));\n      adminClient.request(createCmd);\n    }\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url3)) {\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection3\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core3dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_3n\";\n      createCmd.setDataDir(getDataDir(core3dataDir));\n      adminClient.request(createCmd);\n    }\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    try (HttpSolrClient addClient = getHttpSolrClient(url3 + \"/unloadcollection3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    try (HttpSolrClient addClient = getHttpSolrClient(url2 + \"/unloadcollection2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    try (HttpSolrClient adminClient = getHttpSolrClient(url4)) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(\"unloadcollection4\");\n      createCmd.setCollection(\"unloadcollection\");\n      String core4dataDir = tmpDir.getAbsolutePath() + File.separator + System.nanoTime() + \"unloadcollection\" + \"_4n\";\n      createCmd.setDataDir(getDataDir(core4dataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    try (HttpSolrClient adminClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n\n      Create createCmd = new Create();\n      createCmd.setCoreName(leaderProps.getCoreName());\n      createCmd.setCollection(\"unloadcollection\");\n      createCmd.setDataDir(getDataDir(core1DataDir));\n      adminClient.request(createCmd);\n    }\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n    \n    try (HttpSolrClient adminClient = getHttpSolrClient(url2 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n    try (HttpSolrClient adminClient = getHttpSolrClient(url3 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(url4 + \"/unloadcollection\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"43d1e498704edd2bba13548a189eed4dfccff11b","date":1499143458,"type":3,"author":"Anshum Gupta","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", \"conf1\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = getFirstCore(\"unloadcollection\", jetty1);\n    String core1DataDir = solrCore.getDataDir();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica2\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica3\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\", 30000)) {\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl(), 15000, 30000)) {\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\", 30000, 90000)) {\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica4\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl(), 15000, 30000)) {\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(leaderProps.getCoreName())\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\", 15000, 30000)) {\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\", 15000, 30000)) {\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/unloadcollection_shard1_replica4\", 15000, 30000)) {\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", \"conf1\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = getFirstCore(\"unloadcollection\", jetty1);\n    String core1DataDir = solrCore.getDataDir();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica2\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica3\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica4\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(leaderProps.getCoreName())\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/unloadcollection_shard1_replica4\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2ea161f828a3a7a6eb9410a431aecda6d7ab1065","date":1499213384,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", \"conf1\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = getFirstCore(\"unloadcollection\", jetty1);\n    String core1DataDir = solrCore.getDataDir();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica2\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica3\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\", 30000)) {\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl(), 15000, 30000)) {\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\", 30000, 90000)) {\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica4\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl(), 15000, 30000)) {\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(leaderProps.getCoreName())\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\", 15000, 30000)) {\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\", 15000, 30000)) {\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/unloadcollection_shard1_replica4\", 15000, 30000)) {\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", \"conf1\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = getFirstCore(\"unloadcollection\", jetty1);\n    String core1DataDir = solrCore.getDataDir();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica2\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica3\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      addClient.setConnectionTimeout(30000);\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      addClient.setConnectionTimeout(30000);\n      addClient.setSoTimeout(90000);\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica4\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl())) {\n      collectionClient.setConnectionTimeout(15000);\n      collectionClient.setSoTimeout(30000);\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(leaderProps.getCoreName())\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/unloadcollection_shard1_replica4\")) {\n      adminClient.setConnectionTimeout(15000);\n      adminClient.setSoTimeout(30000);\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"add53de9835b2cd1a7a80b4e0036afee171c9fdf","date":1552937136,"type":3,"author":"Kevin Risden","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", \"conf1\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = getFirstCore(\"unloadcollection\", jetty1);\n    String core1DataDir = solrCore.getDataDir();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica2\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica3\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\", 30000)) {\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl(), 15000, 30000)) {\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\", 30000, 90000)) {\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica4\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl(), 15000, 30000)) {\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(leaderProps.getCoreName())\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\", 15000, 30000)) {\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\", 15000, 30000)) {\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/unloadcollection_shard1_replica4\", 15000, 30000)) {\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", \"conf1\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = getFirstCore(\"unloadcollection\", jetty1);\n    String core1DataDir = solrCore.getDataDir();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica2\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica3\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\", 30000)) {\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl(), 15000, 30000)) {\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\", 30000, 90000)) {\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica4\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl(), 15000, 30000)) {\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      SolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(leaderProps.getCoreName())\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\", 15000, 30000)) {\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\", 15000, 30000)) {\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/unloadcollection_shard1_replica4\", 15000, 30000)) {\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n    \n  }\n\n","bugFix":["1525b4dfbc0d413b8d7247da232009778e624836","cc3b13b430571c2e169f98fe38e1e7666f88522d"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1","date":1579200426,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", \"conf1\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = getFirstCore(\"unloadcollection\", jetty1);\n    String core1DataDir = solrCore.getDataDir();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica2\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica3\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    TestInjection.skipIndexWriterCommitOnClose = true;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\", 30000)) {\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl(), 15000, 30000)) {\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\", 30000, 90000)) {\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica4\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl(), 15000, 30000)) {\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    TestInjection.skipIndexWriterCommitOnClose = false; // set this back\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(leaderProps.getCoreName())\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\", 15000, 30000)) {\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\", 15000, 30000)) {\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/unloadcollection_shard1_replica4\", 15000, 30000)) {\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    JettySolrRunner jetty1 = jettys.get(0);\n\n    assertEquals(0, CollectionAdminRequest\n        .createCollection(\"unloadcollection\", \"conf1\", 1,1)\n        .setCreateNodeSet(jetty1.getNodeName())\n        .process(cloudClient).getStatus());\n    ZkStateReader zkStateReader = getCommonCloudSolrClient().getZkStateReader();\n    \n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n\n    int slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    SolrCore solrCore = getFirstCore(\"unloadcollection\", jetty1);\n    String core1DataDir = solrCore.getDataDir();\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica2\")\n        .setNode(jettys.get(1).getNodeName())\n        .process(cloudClient).isSuccess());\n    zkStateReader.forceUpdateCollection(\"unloadcollection\");\n    slices = zkStateReader.getClusterState().getCollection(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    if (random.nextBoolean()) {\n      try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getCoreUrl())) {\n        // lets try and use the solrj client to index and retrieve a couple\n        // documents\n        SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n            \"humpty dumpy3 sat on a walls\");\n        SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n            \"humpty dumpy2 sat on a walled\");\n        collectionClient.add(doc1);\n        collectionClient.add(doc2);\n        collectionClient.add(doc3);\n        collectionClient.commit();\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica3\")\n        .setNode(jettys.get(2).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\", 30000)) {\n\n      // add a few docs\n      for (int x = 20; x < 100; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl(), 15000, 30000)) {\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n      collectionClient.request(unloadCmd);\n    }\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    try (HttpSolrClient addClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\", 30000, 90000)) {\n\n      // add a few docs while the leader is down\n      for (int x = 101; x < 200; x++) {\n        SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n            \"humpty dumpy sat on a wall\");\n        addClient.add(doc1);\n      }\n    }\n\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(\"unloadcollection_shard1_replica4\")\n        .setNode(jettys.get(3).getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    try (HttpSolrClient collectionClient = getHttpSolrClient(leaderProps.getBaseUrl(), 15000, 30000)) {\n\n      Unload unloadCmd = new Unload(false);\n      unloadCmd.setCoreName(leaderProps.getCoreName());\n      collectionClient.request(unloadCmd);\n    }\n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n\n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    assertTrue(CollectionAdminRequest\n        .addReplicaToShard(\"unloadcollection\", \"shard1\")\n        .setCoreName(leaderProps.getCoreName())\n        .setDataDir(core1DataDir)\n        .setNode(leaderProps.getNodeName())\n        .process(cloudClient).isSuccess());\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n\n    long found1, found3;\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(1).getBaseUrl() + \"/unloadcollection_shard1_replica2\", 15000, 30000)) {\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found1 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(2).getBaseUrl() + \"/unloadcollection_shard1_replica3\", 15000, 30000)) {\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      found3 = adminClient.query(q).getResults().getNumFound();\n    }\n\n    try (HttpSolrClient adminClient = getHttpSolrClient(jettys.get(3).getBaseUrl() + \"/unloadcollection_shard1_replica4\", 15000, 30000)) {\n      adminClient.commit();\n      SolrQuery q = new SolrQuery(\"*:*\");\n      q.set(\"distrib\", false);\n      long found4 = adminClient.query(q).getResults().getNumFound();\n\n      // all 3 shards should now have the same number of docs\n      assertEquals(found1, found3);\n      assertEquals(found3, found4);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"81a4a1810b619aea1d002a09c1878b498e20bf33":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"197bbedf08450ade98a11f4a0001448059666bec":["c3d9a2e4ec5db2bc6cc023d9a1fd387ceb5b69b5"],"c3d9a2e4ec5db2bc6cc023d9a1fd387ceb5b69b5":["4c61b682431fc3a1ef6cf62c8c8d835b88675a72"],"2a0f5bb79c600763ffe7b8141df59a3169d31e48":["4c7856260bc28f285ae7bfefa99b28db4dca6daf","bb1f22cfa77230b5f05b7784feae5367f6bbb488"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["81a4a1810b619aea1d002a09c1878b498e20bf33","849494cf2f3a96af5c8c84995108ddd8456fcd04"],"e3c94a8b8bf47db4f968d9ae510ec8bbe1372088":["7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f"],"bafca15d8e408346a67f4282ad1143b88023893b":["f4abec28b874149a7223e32cc7a01704c27790de"],"b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1":["add53de9835b2cd1a7a80b4e0036afee171c9fdf"],"7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f":["bcf9886c8ff537aafde14de48ebf744f5673f08b"],"09c8567c25c02eeeb3e719841606a1269f3538ca":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","81a4a1810b619aea1d002a09c1878b498e20bf33"],"add53de9835b2cd1a7a80b4e0036afee171c9fdf":["43d1e498704edd2bba13548a189eed4dfccff11b"],"fcad4b87b776f7c9cc2930166a33a1d5a3227486":["a3c3e46d3417c353d7be14509cfab11b315927fe"],"43d1e498704edd2bba13548a189eed4dfccff11b":["28288370235ed02234a64753cdbf0c6ec096304a"],"2ea161f828a3a7a6eb9410a431aecda6d7ab1065":["fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4","43d1e498704edd2bba13548a189eed4dfccff11b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4":["b7dfa64bc2074fb87d0ca70095a644c1ead107e1","197bbedf08450ade98a11f4a0001448059666bec"],"cc3b13b430571c2e169f98fe38e1e7666f88522d":["bafca15d8e408346a67f4282ad1143b88023893b"],"bb1f22cfa77230b5f05b7784feae5367f6bbb488":["4c7856260bc28f285ae7bfefa99b28db4dca6daf"],"a9b4296bd51ca61b482138791478afdd0f7d3a3d":["5bdaf2cee03ff78b0a0cbf23df0095a3590b493b"],"102da6baafc0f534a59f31729343dbab9d3b9e9a":["cc3b13b430571c2e169f98fe38e1e7666f88522d"],"ab2b909e093b9d67189d9c0cf8cfc36861907551":["cdc8313ba7bdaaa48ff54059d0eabff4436ab175"],"4c61b682431fc3a1ef6cf62c8c8d835b88675a72":["a9b4296bd51ca61b482138791478afdd0f7d3a3d"],"f4abec28b874149a7223e32cc7a01704c27790de":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["5bdaf2cee03ff78b0a0cbf23df0095a3590b493b","c3d9a2e4ec5db2bc6cc023d9a1fd387ceb5b69b5"],"a3c3e46d3417c353d7be14509cfab11b315927fe":["849494cf2f3a96af5c8c84995108ddd8456fcd04"],"28288370235ed02234a64753cdbf0c6ec096304a":["5bdaf2cee03ff78b0a0cbf23df0095a3590b493b","197bbedf08450ade98a11f4a0001448059666bec"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["81a4a1810b619aea1d002a09c1878b498e20bf33"],"4c7856260bc28f285ae7bfefa99b28db4dca6daf":["ab2b909e093b9d67189d9c0cf8cfc36861907551"],"5bdaf2cee03ff78b0a0cbf23df0095a3590b493b":["7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f","e3c94a8b8bf47db4f968d9ae510ec8bbe1372088"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["a3c3e46d3417c353d7be14509cfab11b315927fe","cdc8313ba7bdaaa48ff54059d0eabff4436ab175"],"bcf9886c8ff537aafde14de48ebf744f5673f08b":["102da6baafc0f534a59f31729343dbab9d3b9e9a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1"],"cdc8313ba7bdaaa48ff54059d0eabff4436ab175":["fcad4b87b776f7c9cc2930166a33a1d5a3227486"]},"commit2Childs":{"81a4a1810b619aea1d002a09c1878b498e20bf33":["37a0f60745e53927c4c876cfe5b5a58170f0646c","09c8567c25c02eeeb3e719841606a1269f3538ca","849494cf2f3a96af5c8c84995108ddd8456fcd04"],"197bbedf08450ade98a11f4a0001448059666bec":["fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4","28288370235ed02234a64753cdbf0c6ec096304a"],"c3d9a2e4ec5db2bc6cc023d9a1fd387ceb5b69b5":["197bbedf08450ade98a11f4a0001448059666bec","b7dfa64bc2074fb87d0ca70095a644c1ead107e1"],"2a0f5bb79c600763ffe7b8141df59a3169d31e48":["f4abec28b874149a7223e32cc7a01704c27790de"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"e3c94a8b8bf47db4f968d9ae510ec8bbe1372088":["5bdaf2cee03ff78b0a0cbf23df0095a3590b493b"],"bafca15d8e408346a67f4282ad1143b88023893b":["cc3b13b430571c2e169f98fe38e1e7666f88522d"],"7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f":["e3c94a8b8bf47db4f968d9ae510ec8bbe1372088","5bdaf2cee03ff78b0a0cbf23df0095a3590b493b"],"b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"09c8567c25c02eeeb3e719841606a1269f3538ca":[],"add53de9835b2cd1a7a80b4e0036afee171c9fdf":["b6a0ad05ae2af8aa028b1a6099a8222fad0bc8c1"],"fcad4b87b776f7c9cc2930166a33a1d5a3227486":["cdc8313ba7bdaaa48ff54059d0eabff4436ab175"],"43d1e498704edd2bba13548a189eed4dfccff11b":["add53de9835b2cd1a7a80b4e0036afee171c9fdf","2ea161f828a3a7a6eb9410a431aecda6d7ab1065"],"2ea161f828a3a7a6eb9410a431aecda6d7ab1065":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["81a4a1810b619aea1d002a09c1878b498e20bf33","09c8567c25c02eeeb3e719841606a1269f3538ca"],"fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4":["2ea161f828a3a7a6eb9410a431aecda6d7ab1065"],"cc3b13b430571c2e169f98fe38e1e7666f88522d":["102da6baafc0f534a59f31729343dbab9d3b9e9a"],"bb1f22cfa77230b5f05b7784feae5367f6bbb488":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"a9b4296bd51ca61b482138791478afdd0f7d3a3d":["4c61b682431fc3a1ef6cf62c8c8d835b88675a72"],"102da6baafc0f534a59f31729343dbab9d3b9e9a":["bcf9886c8ff537aafde14de48ebf744f5673f08b"],"ab2b909e093b9d67189d9c0cf8cfc36861907551":["4c7856260bc28f285ae7bfefa99b28db4dca6daf"],"4c61b682431fc3a1ef6cf62c8c8d835b88675a72":["c3d9a2e4ec5db2bc6cc023d9a1fd387ceb5b69b5"],"f4abec28b874149a7223e32cc7a01704c27790de":["bafca15d8e408346a67f4282ad1143b88023893b"],"b7dfa64bc2074fb87d0ca70095a644c1ead107e1":["fbedfa79ef95dc2b5b49f7d54d80e0b47867f9b4"],"a3c3e46d3417c353d7be14509cfab11b315927fe":["fcad4b87b776f7c9cc2930166a33a1d5a3227486","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"28288370235ed02234a64753cdbf0c6ec096304a":["43d1e498704edd2bba13548a189eed4dfccff11b"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["37a0f60745e53927c4c876cfe5b5a58170f0646c","a3c3e46d3417c353d7be14509cfab11b315927fe"],"4c7856260bc28f285ae7bfefa99b28db4dca6daf":["2a0f5bb79c600763ffe7b8141df59a3169d31e48","bb1f22cfa77230b5f05b7784feae5367f6bbb488"],"5bdaf2cee03ff78b0a0cbf23df0095a3590b493b":["a9b4296bd51ca61b482138791478afdd0f7d3a3d","b7dfa64bc2074fb87d0ca70095a644c1ead107e1","28288370235ed02234a64753cdbf0c6ec096304a"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"bcf9886c8ff537aafde14de48ebf744f5673f08b":["7c3f4fed97dabfe4bcddc3566fd190a7c909bc4f"],"cdc8313ba7bdaaa48ff54059d0eabff4436ab175":["ab2b909e093b9d67189d9c0cf8cfc36861907551","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","09c8567c25c02eeeb3e719841606a1269f3538ca","2ea161f828a3a7a6eb9410a431aecda6d7ab1065","74f45af4339b0daf7a95c820ab88c1aea74fbce0","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}