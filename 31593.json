{"path":"src/java/org/apache/solr/analysis/TrimFilter#next(Token).mjava","commits":[{"id":"fe8ae1ed027200f075b0de9f264776fa32c4862f","date":1207066219,"type":0,"author":"Grant Ingersoll","isMerge":false,"pathNew":"src/java/org/apache/solr/analysis/TrimFilter#next(Token).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public final Token next(Token in) throws IOException {\n    Token t = input.next(in);\n    if (null == t || null == t.termBuffer() || t.termLength() == 0){\n      return t;\n    }\n    char[] termBuffer = t.termBuffer();\n    int len = t.termLength();\n    int start = 0;\n    int end = 0;\n    int endOff = 0;\n\n    // eat the first characters\n    //QUESTION: Should we use Character.isWhitespace() instead?\n    for (start = 0; start < len && termBuffer[start] <= ' '; start++) {\n    }\n    // eat the end characters\n    for (end = len; end >= start && termBuffer[end - 1] <= ' '; end--) {\n      endOff++;\n    }\n    if (start > 0 || end < len) {\n      if (start < end) {\n        t.setTermBuffer(t.termBuffer(), start, (end - start));\n      } else {\n        t.setTermLength(0);\n      }\n      if (updateOffsets) {\n        t.setStartOffset(t.startOffset() + start);\n        if (start < end) {\n          t.setEndOffset(t.endOffset() - endOff);\n        } //else if end is less than, start, then the term length is 0, so, no need to bother w/ the end offset\n      }\n      /*t = new Token( t.termText().substring( start, end ),\n     t.startOffset()+start,\n     t.endOffset()-endOff,\n     t.type() );*/\n\n\n    }\n\n    return t;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"be29e0e2cef1fd569147732e48caf8538790339b","date":1250443738,"type":5,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/analysis/TrimFilter#incrementToken().mjava","pathOld":"src/java/org/apache/solr/analysis/TrimFilter#next(Token).mjava","sourceNew":"  @Override\n  public boolean incrementToken() throws IOException {\n    if (!input.incrementToken()) return false;\n\n    char[] termBuffer = termAtt.termBuffer();\n    int len = termAtt.termLength();\n    int start = 0;\n    int end = 0;\n    int endOff = 0;\n\n    // eat the first characters\n    //QUESTION: Should we use Character.isWhitespace() instead?\n    for (start = 0; start < len && termBuffer[start] <= ' '; start++) {\n    }\n    // eat the end characters\n    for (end = len; end >= start && termBuffer[end - 1] <= ' '; end--) {\n      endOff++;\n    }\n    if (start > 0 || end < len) {\n      if (start < end) {\n        termAtt.setTermBuffer(termBuffer, start, (end - start));\n      } else {\n        termAtt.setTermLength(0);\n      }\n      if (updateOffsets) {\n        int newStart = offsetAtt.startOffset()+start;\n        int newEnd = offsetAtt.endOffset() - (start<end ? endOff:0);\n        offsetAtt.setOffset(newStart, newEnd);\n      }\n    }\n\n    return true;\n  }\n\n","sourceOld":"  @Override\n  public final Token next(Token in) throws IOException {\n    Token t = input.next(in);\n    if (null == t || null == t.termBuffer() || t.termLength() == 0){\n      return t;\n    }\n    char[] termBuffer = t.termBuffer();\n    int len = t.termLength();\n    int start = 0;\n    int end = 0;\n    int endOff = 0;\n\n    // eat the first characters\n    //QUESTION: Should we use Character.isWhitespace() instead?\n    for (start = 0; start < len && termBuffer[start] <= ' '; start++) {\n    }\n    // eat the end characters\n    for (end = len; end >= start && termBuffer[end - 1] <= ' '; end--) {\n      endOff++;\n    }\n    if (start > 0 || end < len) {\n      if (start < end) {\n        t.setTermBuffer(t.termBuffer(), start, (end - start));\n      } else {\n        t.setTermLength(0);\n      }\n      if (updateOffsets) {\n        t.setStartOffset(t.startOffset() + start);\n        if (start < end) {\n          t.setEndOffset(t.endOffset() - endOff);\n        } //else if end is less than, start, then the term length is 0, so, no need to bother w/ the end offset\n      }\n      /*t = new Token( t.termText().substring( start, end ),\n     t.startOffset()+start,\n     t.endOffset()-endOff,\n     t.type() );*/\n\n\n    }\n\n    return t;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fe8ae1ed027200f075b0de9f264776fa32c4862f":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"be29e0e2cef1fd569147732e48caf8538790339b":["fe8ae1ed027200f075b0de9f264776fa32c4862f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"fe8ae1ed027200f075b0de9f264776fa32c4862f":["be29e0e2cef1fd569147732e48caf8538790339b"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["fe8ae1ed027200f075b0de9f264776fa32c4862f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"be29e0e2cef1fd569147732e48caf8538790339b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["be29e0e2cef1fd569147732e48caf8538790339b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b","a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}