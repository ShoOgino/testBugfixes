{"path":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","commits":[{"id":"5613a70439d5d429f0689c2c5a21615e58deff97","date":1512102314,"type":1,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimePartitionedUpdateProcessorTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    // First create a config using REST API.  To do this, we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete it the collection, leaving a config with the same name behind.\n    // Then when we create the \"real\" collections referencing this config.\n    CollectionAdminRequest.createCollection(configName, 1, 1).process(solrClient);\n    // manipulate the config...\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set-user-property' : {'timePartitionAliasName':'\" + alias + \"'},\" + // no data driven\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\").build()));\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'inc,tolerant'}\" +\n            \"  }\" +\n            \"}\").build()));\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n\n    // start with one collection and an alias for it\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 1, 1)\n        .withProperty(TimeRoutedAliasUpdateProcessor.TIME_PARTITION_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    assertEquals(\"We only expect 2 configSets\",\n        Arrays.asList(\"_default\", configName), new ConfigSetAdminRequest.List().process(solrClient).getConfigSets());\n\n    CollectionAdminRequest.createAlias(alias, col23rd).process(solrClient);\n    //TODO use SOLR-11617 client API to set alias metadata\n    final ZkStateReader zkStateReader = cluster.getSolrClient().getZkStateReader();\n    UnaryOperator<Aliases> op = a -> a.cloneWithCollectionAliasMetadata(alias, TimeRoutedAliasUpdateProcessor.ROUTER_FIELD_METADATA, timeField);\n    zkStateReader.aliasesHolder.applyModificationAndExportToZk(op);\n\n\n    // now we index a document\n    solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants();\n\n    // a document that is too old (throws exception... if we have a TolerantUpdateProcessor then we see it there)\n    try {\n      final UpdateResponse resp = solrClient.add(alias, newDoc(Instant.parse(\"2017-10-01T00:00:00Z\")));\n      final Object errors = resp.getResponseHeader().get(\"errors\");\n      assertTrue(errors != null && errors.toString().contains(\"couldn't be routed\"));\n    } catch (SolrException e) {\n      assertTrue(e.getMessage().contains(\"couldn't be routed\"));\n    }\n    numDocsDeletedOrFailed++;\n\n    // add another collection, add to alias  (soonest comes first)\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  2, 2) // more shards and replicas now\n        .setMaxShardsPerNode(2)\n        .withProperty(\"timePartitionAliasName\", alias)\n        .process(solrClient);\n    CollectionAdminRequest.createAlias(alias, col24th + \",\" + col23rd).process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants();\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2) { // #2 didn't make it\n      idToDelete++;\n    }\n    solrClient.deleteById(alias, Integer.toString(idToDelete));\n    solrClient.commit(alias);\n    numDocsDeletedOrFailed++;\n    assertInvariants();\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    // First create a config using REST API.  To do this, we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete it the collection, leaving a config with the same name behind.\n    // Then when we create the \"real\" collections referencing this config.\n    CollectionAdminRequest.createCollection(configName, 1, 1).process(solrClient);\n    // manipulate the config...\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set-user-property' : {'timePartitionAliasName':'\" + alias + \"'},\" + // no data driven\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\").build()));\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'inc,tolerant'}\" +\n            \"  }\" +\n            \"}\").build()));\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n\n    // start with one collection and an alias for it\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 1, 1)\n        .withProperty(TimePartitionedUpdateProcessor.TIME_PARTITION_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    assertEquals(\"We only expect 2 configSets\",\n        Arrays.asList(\"_default\", configName), new ConfigSetAdminRequest.List().process(solrClient).getConfigSets());\n\n    CollectionAdminRequest.createAlias(alias, col23rd).process(solrClient);\n    //TODO use SOLR-11617 client API to set alias metadata\n    final ZkStateReader zkStateReader = cluster.getSolrClient().getZkStateReader();\n    UnaryOperator<Aliases> op = a -> a.cloneWithCollectionAliasMetadata(alias, TimePartitionedUpdateProcessor.ROUTER_FIELD_METADATA, timeField);\n    zkStateReader.aliasesHolder.applyModificationAndExportToZk(op);\n\n\n    // now we index a document\n    solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants();\n\n    // a document that is too old (throws exception... if we have a TolerantUpdateProcessor then we see it there)\n    try {\n      final UpdateResponse resp = solrClient.add(alias, newDoc(Instant.parse(\"2017-10-01T00:00:00Z\")));\n      final Object errors = resp.getResponseHeader().get(\"errors\");\n      assertTrue(errors != null && errors.toString().contains(\"couldn't be routed\"));\n    } catch (SolrException e) {\n      assertTrue(e.getMessage().contains(\"couldn't be routed\"));\n    }\n    numDocsDeletedOrFailed++;\n\n    // add another collection, add to alias  (soonest comes first)\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  2, 2) // more shards and replicas now\n        .setMaxShardsPerNode(2)\n        .withProperty(\"timePartitionAliasName\", alias)\n        .process(solrClient);\n    CollectionAdminRequest.createAlias(alias, col24th + \",\" + col23rd).process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants();\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2) { // #2 didn't make it\n      idToDelete++;\n    }\n    solrClient.deleteById(alias, Integer.toString(idToDelete));\n    solrClient.commit(alias);\n    numDocsDeletedOrFailed++;\n    assertInvariants();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"af3e10d8a1fbcc5c79b22f7477e79de467dd326c","date":1515178406,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n    // First create a config using REST API.  To do this, we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete it the collection, leaving a config with the same name behind.\n    // Then when we create the \"real\" collections referencing this config.\n    CollectionAdminRequest.createCollection(configName, 1, 1).process(solrClient);\n    // manipulate the config...\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set-user-property' : {'timePartitionAliasName':'\" + alias + \"'},\" + // no data driven\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\").build()));\n    // only sometimes test with \"tolerant\" URP\n    final String urpNames = \"inc\" + (random().nextBoolean() ? \",tolerant\" : \"\");\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'\" + urpNames + \"'}\" +\n            \"  }\" +\n            \"}\").build()));\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n\n    // start with one collection and an alias for it\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAliasUpdateProcessor.TIME_PARTITION_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    assertEquals(\"We only expect 2 configSets\",\n        Arrays.asList(\"_default\", configName), new ConfigSetAdminRequest.List().process(solrClient).getConfigSets());\n\n    CollectionAdminRequest.createAlias(alias, col23rd).process(solrClient);\n    //TODO use SOLR-11617 client API to set alias metadata\n    final ZkStateReader zkStateReader = cluster.getSolrClient().getZkStateReader();\n\n    zkStateReader.aliasesHolder.applyModificationAndExportToZk(a ->\n        a.cloneWithCollectionAliasMetadata(alias, TimeRoutedAliasUpdateProcessor.ROUTER_FIELD_METADATA, timeField)\n        .cloneWithCollectionAliasMetadata(alias, \"collection-create.collection.configName\", configName)\n        .cloneWithCollectionAliasMetadata(alias, \"collection-create.numShards\", \"1\")\n        .cloneWithCollectionAliasMetadata(alias, \"collection-create.replicationFactor\", \"1\")\n        .cloneWithCollectionAliasMetadata(alias, \"router.interval\", \"+1DAY\"));\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection, add to alias  (soonest comes first)\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(\"timePartitionAliasName\", alias)\n        .process(solrClient);\n    CollectionAdminRequest.createAlias(alias, col24th + \",\" + col23rd).process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    // First create a config using REST API.  To do this, we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete it the collection, leaving a config with the same name behind.\n    // Then when we create the \"real\" collections referencing this config.\n    CollectionAdminRequest.createCollection(configName, 1, 1).process(solrClient);\n    // manipulate the config...\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set-user-property' : {'timePartitionAliasName':'\" + alias + \"'},\" + // no data driven\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\").build()));\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'inc,tolerant'}\" +\n            \"  }\" +\n            \"}\").build()));\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n\n    // start with one collection and an alias for it\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 1, 1)\n        .withProperty(TimeRoutedAliasUpdateProcessor.TIME_PARTITION_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    assertEquals(\"We only expect 2 configSets\",\n        Arrays.asList(\"_default\", configName), new ConfigSetAdminRequest.List().process(solrClient).getConfigSets());\n\n    CollectionAdminRequest.createAlias(alias, col23rd).process(solrClient);\n    //TODO use SOLR-11617 client API to set alias metadata\n    final ZkStateReader zkStateReader = cluster.getSolrClient().getZkStateReader();\n    UnaryOperator<Aliases> op = a -> a.cloneWithCollectionAliasMetadata(alias, TimeRoutedAliasUpdateProcessor.ROUTER_FIELD_METADATA, timeField);\n    zkStateReader.aliasesHolder.applyModificationAndExportToZk(op);\n\n\n    // now we index a document\n    solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants();\n\n    // a document that is too old (throws exception... if we have a TolerantUpdateProcessor then we see it there)\n    try {\n      final UpdateResponse resp = solrClient.add(alias, newDoc(Instant.parse(\"2017-10-01T00:00:00Z\")));\n      final Object errors = resp.getResponseHeader().get(\"errors\");\n      assertTrue(errors != null && errors.toString().contains(\"couldn't be routed\"));\n    } catch (SolrException e) {\n      assertTrue(e.getMessage().contains(\"couldn't be routed\"));\n    }\n    numDocsDeletedOrFailed++;\n\n    // add another collection, add to alias  (soonest comes first)\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  2, 2) // more shards and replicas now\n        .setMaxShardsPerNode(2)\n        .withProperty(\"timePartitionAliasName\", alias)\n        .process(solrClient);\n    CollectionAdminRequest.createAlias(alias, col24th + \",\" + col23rd).process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants();\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2) { // #2 didn't make it\n      idToDelete++;\n    }\n    solrClient.deleteById(alias, Integer.toString(idToDelete));\n    solrClient.commit(alias);\n    numDocsDeletedOrFailed++;\n    assertInvariants();\n  }\n\n","bugFix":null,"bugIntro":["ca55a3e50e219d5a29f5cf027c67b3891c57d5b9"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ca55a3e50e219d5a29f5cf027c67b3891c57d5b9","date":1516630721,"type":3,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n\n    // First create a configSet\n    // Then we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete the collection, leaving a modified config-set behind.\n    // Then when we create the \"real\" collections referencing this modified config-set.\n    final ConfigSetAdminRequest.Create adminRequest = new ConfigSetAdminRequest.Create();\n        adminRequest.setConfigSetName(configName);\n        adminRequest.setBaseConfigSetName(\"_default\");\n        ConfigSetAdminResponse adminResponse = adminRequest.process(solrClient);\n        assertEquals(adminResponse.getStatus(), 0);\n\n    CollectionAdminRequest.createCollection(configName, configName,1, 1).process(solrClient);\n    // manipulate the config...\n\n        String conf = \"{\" +\n            \"  'set-user-property' : {'timePartitionAliasName':'\" + alias + \"'},\" + // no data driven\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\";\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(conf).build()));    // only sometimes test with \"tolerant\" URP\n    final String urpNames = \"inc\" + (random().nextBoolean() ? \",tolerant\" : \"\");\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'\" + urpNames + \"'}\" +\n            \"  }\" +\n            \"}\").build()));\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n\n    assertTrue(\n        new ConfigSetAdminRequest.List().process(solrClient).getConfigSets()\n            .contains(configName)\n    );\n\n    // start with one collection and an alias for it\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAliasUpdateProcessor.TIME_PARTITION_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n    assertTrue(\"We only expect 2 configSets\",\n        expectedConfigSetNames.size() == retrievedConfigSetNames.size());\n    assertTrue(\"ConfigNames should be :\" + expectedConfigSetNames, expectedConfigSetNames.containsAll(retrievedConfigSetNames) && retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createAlias(alias, col23rd).process(solrClient);\n    //TODO use SOLR-11617 client API to set alias metadata\n    final ZkStateReader zkStateReader = cluster.getSolrClient().getZkStateReader();\n\n    zkStateReader.aliasesHolder.applyModificationAndExportToZk(a ->\n        a.cloneWithCollectionAliasMetadata(alias, TimeRoutedAliasUpdateProcessor.ROUTER_FIELD_METADATA, timeField)\n        .cloneWithCollectionAliasMetadata(alias, \"collection-create.collection.configName\", configName)\n        .cloneWithCollectionAliasMetadata(alias, \"collection-create.numShards\", \"1\")\n        .cloneWithCollectionAliasMetadata(alias, \"collection-create.replicationFactor\", \"1\")\n        .cloneWithCollectionAliasMetadata(alias, \"router.interval\", \"+1DAY\"));\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection, add to alias  (soonest comes first)\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(\"timePartitionAliasName\", alias)\n        .process(solrClient);\n    CollectionAdminRequest.createAlias(alias, col24th + \",\" + col23rd).process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    // First create a config using REST API.  To do this, we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete it the collection, leaving a config with the same name behind.\n    // Then when we create the \"real\" collections referencing this config.\n    CollectionAdminRequest.createCollection(configName, 1, 1).process(solrClient);\n    // manipulate the config...\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set-user-property' : {'timePartitionAliasName':'\" + alias + \"'},\" + // no data driven\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\").build()));\n    // only sometimes test with \"tolerant\" URP\n    final String urpNames = \"inc\" + (random().nextBoolean() ? \",tolerant\" : \"\");\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'\" + urpNames + \"'}\" +\n            \"  }\" +\n            \"}\").build()));\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n\n    // start with one collection and an alias for it\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAliasUpdateProcessor.TIME_PARTITION_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    assertEquals(\"We only expect 2 configSets\",\n        Arrays.asList(\"_default\", configName), new ConfigSetAdminRequest.List().process(solrClient).getConfigSets());\n\n    CollectionAdminRequest.createAlias(alias, col23rd).process(solrClient);\n    //TODO use SOLR-11617 client API to set alias metadata\n    final ZkStateReader zkStateReader = cluster.getSolrClient().getZkStateReader();\n\n    zkStateReader.aliasesHolder.applyModificationAndExportToZk(a ->\n        a.cloneWithCollectionAliasMetadata(alias, TimeRoutedAliasUpdateProcessor.ROUTER_FIELD_METADATA, timeField)\n        .cloneWithCollectionAliasMetadata(alias, \"collection-create.collection.configName\", configName)\n        .cloneWithCollectionAliasMetadata(alias, \"collection-create.numShards\", \"1\")\n        .cloneWithCollectionAliasMetadata(alias, \"collection-create.replicationFactor\", \"1\")\n        .cloneWithCollectionAliasMetadata(alias, \"router.interval\", \"+1DAY\"));\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection, add to alias  (soonest comes first)\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(\"timePartitionAliasName\", alias)\n        .process(solrClient);\n    CollectionAdminRequest.createAlias(alias, col24th + \",\" + col23rd).process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n  }\n\n","bugFix":["af3e10d8a1fbcc5c79b22f7477e79de467dd326c","543992c52fe295c8b15aafe4b066e7e3a9a42c48"],"bugIntro":["a980795a56f2fcbc94caeb3233071312d5684d59"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n\n    // First create a configSet\n    // Then we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete the collection, leaving a modified config-set behind.\n    // Then when we create the \"real\" collections referencing this modified config-set.\n    final ConfigSetAdminRequest.Create adminRequest = new ConfigSetAdminRequest.Create();\n        adminRequest.setConfigSetName(configName);\n        adminRequest.setBaseConfigSetName(\"_default\");\n        ConfigSetAdminResponse adminResponse = adminRequest.process(solrClient);\n        assertEquals(adminResponse.getStatus(), 0);\n\n    CollectionAdminRequest.createCollection(configName, configName,1, 1).process(solrClient);\n    // manipulate the config...\n\n        String conf = \"{\" +\n            \"  'set-user-property' : {'timePartitionAliasName':'\" + alias + \"'},\" + // no data driven\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\";\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(conf).build()));    // only sometimes test with \"tolerant\" URP\n    final String urpNames = \"inc\" + (random().nextBoolean() ? \",tolerant\" : \"\");\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'\" + urpNames + \"'}\" +\n            \"  }\" +\n            \"}\").build()));\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n\n    assertTrue(\n        new ConfigSetAdminRequest.List().process(solrClient).getConfigSets()\n            .contains(configName)\n    );\n\n    // start with one collection and an alias for it\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAliasUpdateProcessor.TIME_PARTITION_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n    assertTrue(\"We only expect 2 configSets\",\n        expectedConfigSetNames.size() == retrievedConfigSetNames.size());\n    assertTrue(\"ConfigNames should be :\" + expectedConfigSetNames, expectedConfigSetNames.containsAll(retrievedConfigSetNames) && retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createAlias(alias, col23rd).process(solrClient);\n    //TODO use SOLR-11617 client API to set alias metadata\n    final ZkStateReader zkStateReader = cluster.getSolrClient().getZkStateReader();\n\n    zkStateReader.aliasesHolder.applyModificationAndExportToZk(a ->\n        a.cloneWithCollectionAliasMetadata(alias, TimeRoutedAliasUpdateProcessor.ROUTER_FIELD_METADATA, timeField)\n        .cloneWithCollectionAliasMetadata(alias, \"collection-create.collection.configName\", configName)\n        .cloneWithCollectionAliasMetadata(alias, \"collection-create.numShards\", \"1\")\n        .cloneWithCollectionAliasMetadata(alias, \"collection-create.replicationFactor\", \"1\")\n        .cloneWithCollectionAliasMetadata(alias, \"router.interval\", \"+1DAY\"));\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection, add to alias  (soonest comes first)\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(\"timePartitionAliasName\", alias)\n        .process(solrClient);\n    CollectionAdminRequest.createAlias(alias, col24th + \",\" + col23rd).process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n    // First create a config using REST API.  To do this, we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete it the collection, leaving a config with the same name behind.\n    // Then when we create the \"real\" collections referencing this config.\n    CollectionAdminRequest.createCollection(configName, 1, 1).process(solrClient);\n    // manipulate the config...\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set-user-property' : {'timePartitionAliasName':'\" + alias + \"'},\" + // no data driven\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\").build()));\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'inc,tolerant'}\" +\n            \"  }\" +\n            \"}\").build()));\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n\n    // start with one collection and an alias for it\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 1, 1)\n        .withProperty(TimeRoutedAliasUpdateProcessor.TIME_PARTITION_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    assertEquals(\"We only expect 2 configSets\",\n        Arrays.asList(\"_default\", configName), new ConfigSetAdminRequest.List().process(solrClient).getConfigSets());\n\n    CollectionAdminRequest.createAlias(alias, col23rd).process(solrClient);\n    //TODO use SOLR-11617 client API to set alias metadata\n    final ZkStateReader zkStateReader = cluster.getSolrClient().getZkStateReader();\n    UnaryOperator<Aliases> op = a -> a.cloneWithCollectionAliasMetadata(alias, TimeRoutedAliasUpdateProcessor.ROUTER_FIELD_METADATA, timeField);\n    zkStateReader.aliasesHolder.applyModificationAndExportToZk(op);\n\n\n    // now we index a document\n    solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants();\n\n    // a document that is too old (throws exception... if we have a TolerantUpdateProcessor then we see it there)\n    try {\n      final UpdateResponse resp = solrClient.add(alias, newDoc(Instant.parse(\"2017-10-01T00:00:00Z\")));\n      final Object errors = resp.getResponseHeader().get(\"errors\");\n      assertTrue(errors != null && errors.toString().contains(\"couldn't be routed\"));\n    } catch (SolrException e) {\n      assertTrue(e.getMessage().contains(\"couldn't be routed\"));\n    }\n    numDocsDeletedOrFailed++;\n\n    // add another collection, add to alias  (soonest comes first)\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  2, 2) // more shards and replicas now\n        .setMaxShardsPerNode(2)\n        .withProperty(\"timePartitionAliasName\", alias)\n        .process(solrClient);\n    CollectionAdminRequest.createAlias(alias, col24th + \",\" + col23rd).process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants();\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2) { // #2 didn't make it\n      idToDelete++;\n    }\n    solrClient.deleteById(alias, Integer.toString(idToDelete));\n    solrClient.commit(alias);\n    numDocsDeletedOrFailed++;\n    assertInvariants();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6857f8205f8c5b4ff39a54d8aebb4fdfb7cfb691","date":1516909549,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n\n    // First create a configSet\n    // Then we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete the collection, leaving a modified config-set behind.\n    // Then when we create the \"real\" collections referencing this modified config-set.\n    final ConfigSetAdminRequest.Create adminRequest = new ConfigSetAdminRequest.Create();\n        adminRequest.setConfigSetName(configName);\n        adminRequest.setBaseConfigSetName(\"_default\");\n        ConfigSetAdminResponse adminResponse = adminRequest.process(solrClient);\n        assertEquals(adminResponse.getStatus(), 0);\n\n    CollectionAdminRequest.createCollection(configName, configName,1, 1).process(solrClient);\n    // manipulate the config...\n\n        String conf = \"{\" +\n            \"  'set-user-property' : {'timePartitionAliasName':'\" + alias + \"'},\" + // no data driven\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\";\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(conf).build()));    // only sometimes test with \"tolerant\" URP\n    final String urpNames = \"inc\" + (random().nextBoolean() ? \",tolerant\" : \"\");\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'\" + urpNames + \"'}\" +\n            \"  }\" +\n            \"}\").build()));\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n\n    assertTrue(\n        new ConfigSetAdminRequest.List().process(solrClient).getConfigSets()\n            .contains(configName)\n    );\n\n    // start with one collection and an alias for it\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAliasUpdateProcessor.TIME_PARTITION_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n    assertTrue(\"We only expect 2 configSets\",\n        expectedConfigSetNames.size() == retrievedConfigSetNames.size());\n    assertTrue(\"ConfigNames should be :\" + expectedConfigSetNames, expectedConfigSetNames.containsAll(retrievedConfigSetNames) && retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createAlias(alias, col23rd).process(solrClient);\n    //TODO use SOLR-11617 client API to set alias metadata\n    final ZkStateReader zkStateReader = cluster.getSolrClient().getZkStateReader();\n\n    zkStateReader.aliasesHolder.applyModificationAndExportToZk(a ->\n        a.cloneWithCollectionAliasMetadata(alias, TimeRoutedAliasUpdateProcessor.ROUTER_FIELD_METADATA, timeField)\n        .cloneWithCollectionAliasMetadata(alias, \"create-collection.collection.configName\", configName)\n        .cloneWithCollectionAliasMetadata(alias, \"create-collection.numShards\", \"1\")\n        .cloneWithCollectionAliasMetadata(alias, \"create-collection.replicationFactor\", \"1\")\n        .cloneWithCollectionAliasMetadata(alias, \"router.interval\", \"+1DAY\"));\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection, add to alias  (soonest comes first)\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(\"timePartitionAliasName\", alias)\n        .process(solrClient);\n    CollectionAdminRequest.createAlias(alias, col24th + \",\" + col23rd).process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n\n    // First create a configSet\n    // Then we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete the collection, leaving a modified config-set behind.\n    // Then when we create the \"real\" collections referencing this modified config-set.\n    final ConfigSetAdminRequest.Create adminRequest = new ConfigSetAdminRequest.Create();\n        adminRequest.setConfigSetName(configName);\n        adminRequest.setBaseConfigSetName(\"_default\");\n        ConfigSetAdminResponse adminResponse = adminRequest.process(solrClient);\n        assertEquals(adminResponse.getStatus(), 0);\n\n    CollectionAdminRequest.createCollection(configName, configName,1, 1).process(solrClient);\n    // manipulate the config...\n\n        String conf = \"{\" +\n            \"  'set-user-property' : {'timePartitionAliasName':'\" + alias + \"'},\" + // no data driven\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\";\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(conf).build()));    // only sometimes test with \"tolerant\" URP\n    final String urpNames = \"inc\" + (random().nextBoolean() ? \",tolerant\" : \"\");\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'\" + urpNames + \"'}\" +\n            \"  }\" +\n            \"}\").build()));\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n\n    assertTrue(\n        new ConfigSetAdminRequest.List().process(solrClient).getConfigSets()\n            .contains(configName)\n    );\n\n    // start with one collection and an alias for it\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAliasUpdateProcessor.TIME_PARTITION_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n    assertTrue(\"We only expect 2 configSets\",\n        expectedConfigSetNames.size() == retrievedConfigSetNames.size());\n    assertTrue(\"ConfigNames should be :\" + expectedConfigSetNames, expectedConfigSetNames.containsAll(retrievedConfigSetNames) && retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createAlias(alias, col23rd).process(solrClient);\n    //TODO use SOLR-11617 client API to set alias metadata\n    final ZkStateReader zkStateReader = cluster.getSolrClient().getZkStateReader();\n\n    zkStateReader.aliasesHolder.applyModificationAndExportToZk(a ->\n        a.cloneWithCollectionAliasMetadata(alias, TimeRoutedAliasUpdateProcessor.ROUTER_FIELD_METADATA, timeField)\n        .cloneWithCollectionAliasMetadata(alias, \"collection-create.collection.configName\", configName)\n        .cloneWithCollectionAliasMetadata(alias, \"collection-create.numShards\", \"1\")\n        .cloneWithCollectionAliasMetadata(alias, \"collection-create.replicationFactor\", \"1\")\n        .cloneWithCollectionAliasMetadata(alias, \"router.interval\", \"+1DAY\"));\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection, add to alias  (soonest comes first)\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(\"timePartitionAliasName\", alias)\n        .process(solrClient);\n    CollectionAdminRequest.createAlias(alias, col24th + \",\" + col23rd).process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"46589ed5cc841861bf6b5e2afc55f718ebcd02a0","date":1516984620,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n\n    // First create a configSet\n    // Then we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete the collection, leaving a modified config-set behind.\n    // Then when we create the \"real\" collections referencing this modified config-set.\n    final ConfigSetAdminRequest.Create adminRequest = new ConfigSetAdminRequest.Create();\n        adminRequest.setConfigSetName(configName);\n        adminRequest.setBaseConfigSetName(\"_default\");\n        ConfigSetAdminResponse adminResponse = adminRequest.process(solrClient);\n        assertEquals(adminResponse.getStatus(), 0);\n\n    CollectionAdminRequest.createCollection(configName, configName,1, 1).process(solrClient);\n    // manipulate the config...\n\n        String conf = \"{\" +\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\";\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(conf).build()));    // only sometimes test with \"tolerant\" URP\n    final String urpNames = \"inc\" + (random().nextBoolean() ? \",tolerant\" : \"\");\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'\" + urpNames + \"'}\" +\n            \"  }\" +\n            \"}\").build()));\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n\n    assertTrue(\n        new ConfigSetAdminRequest.List().process(solrClient).getConfigSets()\n            .contains(configName)\n    );\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n    assertTrue(\"We only expect 2 configSets\",\n        expectedConfigSetNames.size() == retrievedConfigSetNames.size());\n    assertTrue(\"ConfigNames should be :\" + expectedConfigSetNames, expectedConfigSetNames.containsAll(retrievedConfigSetNames) && retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n\n    // First create a configSet\n    // Then we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete the collection, leaving a modified config-set behind.\n    // Then when we create the \"real\" collections referencing this modified config-set.\n    final ConfigSetAdminRequest.Create adminRequest = new ConfigSetAdminRequest.Create();\n        adminRequest.setConfigSetName(configName);\n        adminRequest.setBaseConfigSetName(\"_default\");\n        ConfigSetAdminResponse adminResponse = adminRequest.process(solrClient);\n        assertEquals(adminResponse.getStatus(), 0);\n\n    CollectionAdminRequest.createCollection(configName, configName,1, 1).process(solrClient);\n    // manipulate the config...\n\n        String conf = \"{\" +\n            \"  'set-user-property' : {'timePartitionAliasName':'\" + alias + \"'},\" + // no data driven\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\";\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(conf).build()));    // only sometimes test with \"tolerant\" URP\n    final String urpNames = \"inc\" + (random().nextBoolean() ? \",tolerant\" : \"\");\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'\" + urpNames + \"'}\" +\n            \"  }\" +\n            \"}\").build()));\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n\n    assertTrue(\n        new ConfigSetAdminRequest.List().process(solrClient).getConfigSets()\n            .contains(configName)\n    );\n\n    // start with one collection and an alias for it\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAliasUpdateProcessor.TIME_PARTITION_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n    assertTrue(\"We only expect 2 configSets\",\n        expectedConfigSetNames.size() == retrievedConfigSetNames.size());\n    assertTrue(\"ConfigNames should be :\" + expectedConfigSetNames, expectedConfigSetNames.containsAll(retrievedConfigSetNames) && retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createAlias(alias, col23rd).process(solrClient);\n    //TODO use SOLR-11617 client API to set alias metadata\n    final ZkStateReader zkStateReader = cluster.getSolrClient().getZkStateReader();\n\n    zkStateReader.aliasesHolder.applyModificationAndExportToZk(a ->\n        a.cloneWithCollectionAliasMetadata(alias, TimeRoutedAliasUpdateProcessor.ROUTER_FIELD_METADATA, timeField)\n        .cloneWithCollectionAliasMetadata(alias, \"create-collection.collection.configName\", configName)\n        .cloneWithCollectionAliasMetadata(alias, \"create-collection.numShards\", \"1\")\n        .cloneWithCollectionAliasMetadata(alias, \"create-collection.replicationFactor\", \"1\")\n        .cloneWithCollectionAliasMetadata(alias, \"router.interval\", \"+1DAY\"));\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection, add to alias  (soonest comes first)\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(\"timePartitionAliasName\", alias)\n        .process(solrClient);\n    CollectionAdminRequest.createAlias(alias, col24th + \",\" + col23rd).process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3cbd743a4843f513f793670e3ab0e272bf824faf","date":1518149529,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n\n    // First create a configSet\n    // Then we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete the collection, leaving a modified config-set behind.\n    // Then when we create the \"real\" collections referencing this modified config-set.\n    final ConfigSetAdminRequest.Create adminRequest = new ConfigSetAdminRequest.Create();\n        adminRequest.setConfigSetName(configName);\n        adminRequest.setBaseConfigSetName(\"_default\");\n        ConfigSetAdminResponse adminResponse = adminRequest.process(solrClient);\n        assertEquals(adminResponse.getStatus(), 0);\n\n    CollectionAdminRequest.createCollection(configName, configName,1, 1).process(solrClient);\n    // manipulate the config...\n\n        String conf = \"{\" +\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\";\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(conf).build()));    // only sometimes test with \"tolerant\" URP\n    final String urpNames = \"inc\" + (random().nextBoolean() ? \",tolerant\" : \"\");\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'\" + urpNames + \"'}\" +\n            \"  }\" +\n            \"}\").build()));\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n\n    assertTrue(\n        new ConfigSetAdminRequest.List().process(solrClient).getConfigSets()\n            .contains(configName)\n    );\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n    assertTrue(\"We only expect 2 configSets\",\n        expectedConfigSetNames.size() == retrievedConfigSetNames.size());\n    assertTrue(\"ConfigNames should be :\" + expectedConfigSetNames, expectedConfigSetNames.containsAll(retrievedConfigSetNames) && retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.modifyAlias(alias)\n        .addMetadata(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n\n    // First create a configSet\n    // Then we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete the collection, leaving a modified config-set behind.\n    // Then when we create the \"real\" collections referencing this modified config-set.\n    final ConfigSetAdminRequest.Create adminRequest = new ConfigSetAdminRequest.Create();\n        adminRequest.setConfigSetName(configName);\n        adminRequest.setBaseConfigSetName(\"_default\");\n        ConfigSetAdminResponse adminResponse = adminRequest.process(solrClient);\n        assertEquals(adminResponse.getStatus(), 0);\n\n    CollectionAdminRequest.createCollection(configName, configName,1, 1).process(solrClient);\n    // manipulate the config...\n\n        String conf = \"{\" +\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\";\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(conf).build()));    // only sometimes test with \"tolerant\" URP\n    final String urpNames = \"inc\" + (random().nextBoolean() ? \",tolerant\" : \"\");\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'\" + urpNames + \"'}\" +\n            \"  }\" +\n            \"}\").build()));\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n\n    assertTrue(\n        new ConfigSetAdminRequest.List().process(solrClient).getConfigSets()\n            .contains(configName)\n    );\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n    assertTrue(\"We only expect 2 configSets\",\n        expectedConfigSetNames.size() == retrievedConfigSetNames.size());\n    assertTrue(\"ConfigNames should be :\" + expectedConfigSetNames, expectedConfigSetNames.containsAll(retrievedConfigSetNames) && retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6f29e9eb6c1655cd0b273f3c0dcdf43bc0822767","date":1520865397,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n\n    // First create a configSet\n    // Then we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete the collection, leaving a modified config-set behind.\n    // Then when we create the \"real\" collections referencing this modified config-set.\n    final ConfigSetAdminRequest.Create adminRequest = new ConfigSetAdminRequest.Create();\n        adminRequest.setConfigSetName(configName);\n        adminRequest.setBaseConfigSetName(\"_default\");\n        ConfigSetAdminResponse adminResponse = adminRequest.process(solrClient);\n        assertEquals(adminResponse.getStatus(), 0);\n\n    CollectionAdminRequest.createCollection(configName, configName,1, 1).process(solrClient);\n    // manipulate the config...\n\n        String conf = \"{\" +\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\";\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(conf).build()));    // only sometimes test with \"tolerant\" URP\n    final String urpNames = \"inc\" + (random().nextBoolean() ? \",tolerant\" : \"\");\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'\" + urpNames + \"'}\" +\n            \"  }\" +\n            \"}\").build()));\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n\n    assertTrue(\n        new ConfigSetAdminRequest.List().process(solrClient).getConfigSets()\n            .contains(configName)\n    );\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n    assertTrue(\"We only expect 2 configSets\",\n        expectedConfigSetNames.size() == retrievedConfigSetNames.size());\n    assertTrue(\"ConfigNames should be :\" + expectedConfigSetNames, expectedConfigSetNames.containsAll(retrievedConfigSetNames) && retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n\n    // First create a configSet\n    // Then we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete the collection, leaving a modified config-set behind.\n    // Then when we create the \"real\" collections referencing this modified config-set.\n    final ConfigSetAdminRequest.Create adminRequest = new ConfigSetAdminRequest.Create();\n        adminRequest.setConfigSetName(configName);\n        adminRequest.setBaseConfigSetName(\"_default\");\n        ConfigSetAdminResponse adminResponse = adminRequest.process(solrClient);\n        assertEquals(adminResponse.getStatus(), 0);\n\n    CollectionAdminRequest.createCollection(configName, configName,1, 1).process(solrClient);\n    // manipulate the config...\n\n        String conf = \"{\" +\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\";\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(conf).build()));    // only sometimes test with \"tolerant\" URP\n    final String urpNames = \"inc\" + (random().nextBoolean() ? \",tolerant\" : \"\");\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'\" + urpNames + \"'}\" +\n            \"  }\" +\n            \"}\").build()));\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n\n    assertTrue(\n        new ConfigSetAdminRequest.List().process(solrClient).getConfigSets()\n            .contains(configName)\n    );\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n    assertTrue(\"We only expect 2 configSets\",\n        expectedConfigSetNames.size() == retrievedConfigSetNames.size());\n    assertTrue(\"ConfigNames should be :\" + expectedConfigSetNames, expectedConfigSetNames.containsAll(retrievedConfigSetNames) && retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.modifyAlias(alias)\n        .addMetadata(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a980795a56f2fcbc94caeb3233071312d5684d59","date":1524255736,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Test\n  public void test() throws Exception {\n\n    // First create a configSet\n    // Then we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete the collection, leaving a modified config-set behind.\n    // Then when we create the \"real\" collections referencing this modified config-set.\n    assertEquals(0, new ConfigSetAdminRequest.Create()\n        .setConfigSetName(configName)\n        .setBaseConfigSetName(\"_default\")\n        .process(solrClient).getStatus());\n\n    CollectionAdminRequest.createCollection(configName, configName, 1, 1).process(solrClient);\n\n    // manipulate the config...\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\").build()));\n    // only sometimes test with \"tolerant\" URP:\n    final String urpNames = \"inc\" + (random().nextBoolean() ? \",tolerant\" : \"\");\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'\" + urpNames + \"'}\" +\n            \"  }\" +\n            \"}\").build()));\n\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n    assertTrue(\n        new ConfigSetAdminRequest.List().process(solrClient).getConfigSets()\n            .contains(configName)\n    );\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n    assertTrue(\"We only expect 2 configSets\",\n        expectedConfigSetNames.size() == retrievedConfigSetNames.size());\n    assertTrue(\"ConfigNames should be :\" + expectedConfigSetNames, expectedConfigSetNames.containsAll(retrievedConfigSetNames) && retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n\n    // First create a configSet\n    // Then we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete the collection, leaving a modified config-set behind.\n    // Then when we create the \"real\" collections referencing this modified config-set.\n    final ConfigSetAdminRequest.Create adminRequest = new ConfigSetAdminRequest.Create();\n        adminRequest.setConfigSetName(configName);\n        adminRequest.setBaseConfigSetName(\"_default\");\n        ConfigSetAdminResponse adminResponse = adminRequest.process(solrClient);\n        assertEquals(adminResponse.getStatus(), 0);\n\n    CollectionAdminRequest.createCollection(configName, configName,1, 1).process(solrClient);\n    // manipulate the config...\n\n        String conf = \"{\" +\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\";\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(conf).build()));    // only sometimes test with \"tolerant\" URP\n    final String urpNames = \"inc\" + (random().nextBoolean() ? \",tolerant\" : \"\");\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'\" + urpNames + \"'}\" +\n            \"  }\" +\n            \"}\").build()));\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n\n    assertTrue(\n        new ConfigSetAdminRequest.List().process(solrClient).getConfigSets()\n            .contains(configName)\n    );\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n    assertTrue(\"We only expect 2 configSets\",\n        expectedConfigSetNames.size() == retrievedConfigSetNames.size());\n    assertTrue(\"ConfigNames should be :\" + expectedConfigSetNames, expectedConfigSetNames.containsAll(retrievedConfigSetNames) && retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","bugFix":["543992c52fe295c8b15aafe4b066e7e3a9a42c48","ca55a3e50e219d5a29f5cf027c67b3891c57d5b9"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"60b45f127b5537b5bf62181784ef28b52f4b6a08","date":1529595959,"type":3,"author":"Gus Heck","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Slow\n  @Test\n  public void test() throws Exception {\n    String configName = TimeRoutedAliasUpdateProcessorTest.configName + getTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n\n    // First create a configSet\n    // Then we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete the collection, leaving a modified config-set behind.\n    // Then when we create the \"real\" collections referencing this modified config-set.\n    assertEquals(0, new ConfigSetAdminRequest.Create()\n        .setConfigSetName(configName)\n        .setBaseConfigSetName(\"_default\")\n        .process(solrClient).getStatus());\n\n    CollectionAdminRequest.createCollection(configName, configName, 1, 1).process(solrClient);\n\n    // manipulate the config...\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\").build()));\n    // only sometimes test with \"tolerant\" URP:\n    final String urpNames = \"inc\" + (random().nextBoolean() ? \",tolerant\" : \"\");\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'\" + urpNames + \"'}\" +\n            \"  }\" +\n            \"}\").build()));\n\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n    assertTrue(\n        new ConfigSetAdminRequest.List().process(solrClient).getConfigSets()\n            .contains(configName)\n    );\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n    assertTrue(\"We only expect 2 configSets\",\n        expectedConfigSetNames.size() == retrievedConfigSetNames.size());\n    assertTrue(\"ConfigNames should be :\" + expectedConfigSetNames, expectedConfigSetNames.containsAll(retrievedConfigSetNames) && retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Slow\n  @Test\n  public void test() throws Exception {\n    String configName = TimeRoutedAliasUpdateProcessorTest.configName + getTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n\n    // First create a configSet\n    // Then we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete the collection, leaving a modified config-set behind.\n    // Then when we create the \"real\" collections referencing this modified config-set.\n    assertEquals(0, new ConfigSetAdminRequest.Create()\n        .setConfigSetName(configName)\n        .setBaseConfigSetName(\"_default\")\n        .process(solrClient).getStatus());\n\n    CollectionAdminRequest.createCollection(configName, configName, 1, 1).process(solrClient);\n\n    // manipulate the config...\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\").build()));\n    // only sometimes test with \"tolerant\" URP:\n    final String urpNames = \"inc\" + (random().nextBoolean() ? \",tolerant\" : \"\");\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'\" + urpNames + \"'}\" +\n            \"  }\" +\n            \"}\").build()));\n\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n    assertTrue(\n        new ConfigSetAdminRequest.List().process(solrClient).getConfigSets()\n            .contains(configName)\n    );\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n    assertTrue(\"We only expect 2 configSets\",\n        expectedConfigSetNames.size() == retrievedConfigSetNames.size());\n    assertTrue(\"ConfigNames should be :\" + expectedConfigSetNames, expectedConfigSetNames.containsAll(retrievedConfigSetNames) && retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Slow\n  @Test\n  public void test() throws Exception {\n    String configName = TimeRoutedAliasUpdateProcessorTest.configName + getTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","sourceOld":"  @Test\n  public void test() throws Exception {\n\n    // First create a configSet\n    // Then we create a collection with the name of the eventual config.\n    // We configure it, and ultimately delete the collection, leaving a modified config-set behind.\n    // Then when we create the \"real\" collections referencing this modified config-set.\n    assertEquals(0, new ConfigSetAdminRequest.Create()\n        .setConfigSetName(configName)\n        .setBaseConfigSetName(\"_default\")\n        .process(solrClient).getStatus());\n\n    CollectionAdminRequest.createCollection(configName, configName, 1, 1).process(solrClient);\n\n    // manipulate the config...\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set-user-property' : {'update.autoCreateFields':false},\" + // no data driven\n            \"  'add-updateprocessor' : {\" +\n            \"    'name':'tolerant', 'class':'solr.TolerantUpdateProcessorFactory'\" +\n            \"  },\" +\n            \"  'add-updateprocessor' : {\" + // for testing\n            \"    'name':'inc', 'class':'\" + IncrementURPFactory.class.getName() + \"',\" +\n            \"    'fieldName':'\" + intField + \"'\" +\n            \"  },\" +\n            \"}\").build()));\n    // only sometimes test with \"tolerant\" URP:\n    final String urpNames = \"inc\" + (random().nextBoolean() ? \",tolerant\" : \"\");\n    checkNoError(solrClient.request(new V2Request.Builder(\"/collections/\" + configName + \"/config/params\")\n        .withMethod(SolrRequest.METHOD.POST)\n        .withPayload(\"{\" +\n            \"  'set' : {\" +\n            \"    '_UPDATE' : {'processor':'\" + urpNames + \"'}\" +\n            \"  }\" +\n            \"}\").build()));\n\n    CollectionAdminRequest.deleteCollection(configName).process(solrClient);\n    assertTrue(\n        new ConfigSetAdminRequest.List().process(solrClient).getConfigSets()\n            .contains(configName)\n    );\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n    assertTrue(\"We only expect 2 configSets\",\n        expectedConfigSetNames.size() == retrievedConfigSetNames.size());\n    assertTrue(\"ConfigNames should be :\" + expectedConfigSetNames, expectedConfigSetNames.containsAll(retrievedConfigSetNames) && retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6002eff20bbcd2773a7d31d1688bd66ae71f565a","date":1532622146,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  public void test() throws Exception {\n    String configName = TimeRoutedAliasUpdateProcessorTest.configName + getTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","sourceOld":"  @Slow\n  @Test\n  public void test() throws Exception {\n    String configName = TimeRoutedAliasUpdateProcessorTest.configName + getTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"44dd40f6c2c1465aebf4677bab10f696c7ea18d8","date":1539566013,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    String configName = TimeRoutedAliasUpdateProcessorTest.configName + getTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","sourceOld":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  public void test() throws Exception {\n    String configName = TimeRoutedAliasUpdateProcessorTest.configName + getTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    String configName = getSaferTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n    \n    cluster.waitForActiveCollection(col23rd, 2, 4);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","sourceOld":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    String configName = TimeRoutedAliasUpdateProcessorTest.configName + getTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","bugFix":["60b45f127b5537b5bf62181784ef28b52f4b6a08"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"11b67e7dc6d14dd8535564a49ca9c12ec5e8b2b6","date":1547236077,"type":3,"author":"Gus Heck","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    String configName = getSaferTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    cluster.waitForActiveCollection(col23rd, 2, 4);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","sourceOld":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    String configName = getSaferTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n    \n    cluster.waitForActiveCollection(col23rd, 2, 4);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b5c929d2716fa79d443b93a82adb1da5b578ebd8","date":1550428858,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    String configName = getSaferTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    cluster.waitForActiveCollection(col23rd, 2, 4);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","sourceOld":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    String configName = getSaferTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    cluster.waitForActiveCollection(col23rd, 2, 4);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b627755385655c7cd3fb296f17593658805cf4d5","date":1552455143,"type":3,"author":"Gus Heck","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    String configName = getSaferTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(RoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    cluster.waitForActiveCollection(col23rd, 2, 4);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", getTimeField(),\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(RoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + getIntField() + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(getTimeField() +\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","sourceOld":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    String configName = getSaferTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    cluster.waitForActiveCollection(col23rd, 2, 4);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", timeField,\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(TimeRoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + intField + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(timeField+\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7446cb4193d4f3046ab7f5d0ddfc37ddaa514966","date":1560534676,"type":3,"author":"Gus Heck","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    String configName = getSaferTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    cluster.waitForActiveCollection(col23rd, 2, 4);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", getTimeField(),\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + getIntField() + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n    // verify that collection properties are set when the collections are created. Note: first 2 collections in\n    // this test have a core property instead, of a collection property but that MUST continue to work as well\n    // for back compatibility's reasons.\n    Thread.sleep(1000);\n    byte[] data = cluster.getZkClient()\n        .getData(COLLECTIONS_ZKNODE + \"/\" + alias + \"_2017-10-26\" + \"/\" + COLLECTION_PROPS_ZKNODE,null, null, true);\n    assertNotNull(data);\n    assertTrue(data.length > 0);\n    Map<String,String> props = (Map<String, String>) Utils.fromJSON(data);\n    assertTrue(props.containsKey(ROUTED_ALIAS_NAME_CORE_PROP));\n    assertEquals(alias,props.get(ROUTED_ALIAS_NAME_CORE_PROP));\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(getTimeField() +\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","sourceOld":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    String configName = getSaferTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(RoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    cluster.waitForActiveCollection(col23rd, 2, 4);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", getTimeField(),\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(RoutedAlias.ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + getIntField() + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(getTimeField() +\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"105e345cf3c0abed3cb6c109274a379cb2655adc","date":1561038472,"type":3,"author":"Gus Heck","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    String configName = getSaferTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + TRA + \"2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    cluster.waitForActiveCollection(col23rd, 2, 4);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", getTimeField(),\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + TRA + \"2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + getIntField() + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + TRA + \"2017-10-26\", alias + TRA + \"2017-10-25\", col24th);\n\n    // verify that collection properties are set when the collections are created. Note: first 2 collections in\n    // this test have a core property instead, of a collection property but that MUST continue to work as well\n    // for back compatibility's reasons.\n    Thread.sleep(1000);\n    byte[] data = cluster.getZkClient()\n        .getData(COLLECTIONS_ZKNODE + \"/\" + alias + TRA + \"2017-10-26\" + \"/\" + COLLECTION_PROPS_ZKNODE,null, null, true);\n    assertNotNull(data);\n    assertTrue(data.length > 0);\n    @SuppressWarnings(\"unchecked\")\n    Map<String,String> props = (Map<String, String>) Utils.fromJSON(data);\n    assertTrue(props.containsKey(ROUTED_ALIAS_NAME_CORE_PROP));\n    assertEquals(alias,props.get(ROUTED_ALIAS_NAME_CORE_PROP));\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(getTimeField() +\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + TRA + \"2017-10-27\", alias + TRA + \"2017-10-26\");\n  }\n\n","sourceOld":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    String configName = getSaferTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + \"_2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    cluster.waitForActiveCollection(col23rd, 2, 4);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", getTimeField(),\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + \"_2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + getIntField() + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + \"_2017-10-26\", alias + \"_2017-10-25\", col24th);\n\n    // verify that collection properties are set when the collections are created. Note: first 2 collections in\n    // this test have a core property instead, of a collection property but that MUST continue to work as well\n    // for back compatibility's reasons.\n    Thread.sleep(1000);\n    byte[] data = cluster.getZkClient()\n        .getData(COLLECTIONS_ZKNODE + \"/\" + alias + \"_2017-10-26\" + \"/\" + COLLECTION_PROPS_ZKNODE,null, null, true);\n    assertNotNull(data);\n    assertTrue(data.length > 0);\n    Map<String,String> props = (Map<String, String>) Utils.fromJSON(data);\n    assertTrue(props.containsKey(ROUTED_ALIAS_NAME_CORE_PROP));\n    assertEquals(alias,props.get(ROUTED_ALIAS_NAME_CORE_PROP));\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(getTimeField() +\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + \"_2017-10-27\", alias + \"_2017-10-26\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1eebf1b080530bdd7572c4927fb2bb52334b7a86","date":1563199033,"type":3,"author":"Gus Heck","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    String configName = getSaferTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + TRA + \"2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    cluster.waitForActiveCollection(col23rd, 2, 4);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", getTimeField(),\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + TRA + \"2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n//    System.out.println(cluster.getRandomJetty(random()).getBaseUrl());\n//    Thread.sleep(1000000);\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + getIntField() + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + TRA + \"2017-10-26\", alias + TRA + \"2017-10-25\", col24th);\n\n    // verify that collection properties are set when the collections are created. Note: first 2 collections in\n    // this test have a core property instead, of a collection property but that MUST continue to work as well\n    // for back compatibility's reasons.\n    Thread.sleep(1000);\n    byte[] data = cluster.getZkClient()\n        .getData(COLLECTIONS_ZKNODE + \"/\" + alias + TRA + \"2017-10-26\" + \"/\" + COLLECTION_PROPS_ZKNODE,null, null, true);\n    assertNotNull(data);\n    assertTrue(data.length > 0);\n    @SuppressWarnings(\"unchecked\")\n    Map<String,String> props = (Map<String, String>) Utils.fromJSON(data);\n    assertTrue(props.containsKey(ROUTED_ALIAS_NAME_CORE_PROP));\n    assertEquals(alias,props.get(ROUTED_ALIAS_NAME_CORE_PROP));\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(getTimeField() +\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + TRA + \"2017-10-27\", alias + TRA + \"2017-10-26\");\n  }\n\n","sourceOld":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    String configName = getSaferTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + TRA + \"2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    cluster.waitForActiveCollection(col23rd, 2, 4);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", getTimeField(),\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + TRA + \"2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + getIntField() + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + TRA + \"2017-10-26\", alias + TRA + \"2017-10-25\", col24th);\n\n    // verify that collection properties are set when the collections are created. Note: first 2 collections in\n    // this test have a core property instead, of a collection property but that MUST continue to work as well\n    // for back compatibility's reasons.\n    Thread.sleep(1000);\n    byte[] data = cluster.getZkClient()\n        .getData(COLLECTIONS_ZKNODE + \"/\" + alias + TRA + \"2017-10-26\" + \"/\" + COLLECTION_PROPS_ZKNODE,null, null, true);\n    assertNotNull(data);\n    assertTrue(data.length > 0);\n    @SuppressWarnings(\"unchecked\")\n    Map<String,String> props = (Map<String, String>) Utils.fromJSON(data);\n    assertTrue(props.containsKey(ROUTED_ALIAS_NAME_CORE_PROP));\n    assertEquals(alias,props.get(ROUTED_ALIAS_NAME_CORE_PROP));\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(getTimeField() +\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + TRA + \"2017-10-27\", alias + TRA + \"2017-10-26\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e","date":1594223844,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","pathOld":"solr/core/src/test/org/apache/solr/update/processor/TimeRoutedAliasUpdateProcessorTest#test().mjava","sourceNew":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    String configName = getSaferTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + TRA + \"2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .withProperty(ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    cluster.waitForActiveCollection(col23rd, 2, 4);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", getTimeField(),\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + TRA + \"2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n//    System.out.println(cluster.getRandomJetty(random()).getBaseUrl());\n//    Thread.sleep(1000000);\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + getIntField() + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + TRA + \"2017-10-26\", alias + TRA + \"2017-10-25\", col24th);\n\n    // verify that collection properties are set when the collections are created. Note: first 2 collections in\n    // this test have a core property instead, of a collection property but that MUST continue to work as well\n    // for back compatibility's reasons.\n    Thread.sleep(1000);\n    byte[] data = cluster.getZkClient()\n        .getData(COLLECTIONS_ZKNODE + \"/\" + alias + TRA + \"2017-10-26\" + \"/\" + COLLECTION_PROPS_ZKNODE,null, null, true);\n    assertNotNull(data);\n    assertTrue(data.length > 0);\n    @SuppressWarnings(\"unchecked\")\n    Map<String,String> props = (Map<String, String>) Utils.fromJSON(data);\n    assertTrue(props.containsKey(ROUTED_ALIAS_NAME_CORE_PROP));\n    assertEquals(alias,props.get(ROUTED_ALIAS_NAME_CORE_PROP));\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(getTimeField() +\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + TRA + \"2017-10-27\", alias + TRA + \"2017-10-26\");\n  }\n\n","sourceOld":"  @Slow\n  @Test\n  @LogLevel(\"org.apache.solr.update.processor.TimeRoutedAlias=DEBUG;org.apache.solr.cloud=DEBUG\")\n  // commented out on: 17-Feb-2019   @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 14-Oct-2018\n  public void test() throws Exception {\n    String configName = getSaferTestName();\n    createConfigSet(configName);\n\n    // Start with one collection manually created (and use higher numShards & replicas than we'll use for others)\n    //  This tests we may pre-create the collection and it's acceptable.\n    final String col23rd = alias + TRA + \"2017-10-23\";\n    CollectionAdminRequest.createCollection(col23rd, configName, 2, 2)\n        .setMaxShardsPerNode(2)\n        .withProperty(ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    cluster.waitForActiveCollection(col23rd, 2, 4);\n\n    List<String> retrievedConfigSetNames = new ConfigSetAdminRequest.List().process(solrClient).getConfigSets();\n    List<String> expectedConfigSetNames = Arrays.asList(\"_default\", configName);\n\n    // config sets leak between tests so we can't be any more specific than this on the next 2 asserts\n    assertTrue(\"We expect at least 2 configSets\",\n        retrievedConfigSetNames.size() >= expectedConfigSetNames.size());\n    assertTrue(\"ConfigNames should include :\" + expectedConfigSetNames, retrievedConfigSetNames.containsAll(expectedConfigSetNames));\n\n    CollectionAdminRequest.createTimeRoutedAlias(alias, \"2017-10-23T00:00:00Z\", \"+1DAY\", getTimeField(),\n        CollectionAdminRequest.createCollection(\"_unused_\", configName, 1, 1)\n            .setMaxShardsPerNode(2))\n        .process(solrClient);\n\n    // now we index a document\n    assertUpdateResponse(solrClient.add(alias, newDoc(Instant.parse(\"2017-10-23T00:00:00Z\"))));\n    solrClient.commit(alias);\n    //assertDocRoutedToCol(lastDocId, col23rd);\n    assertInvariants(col23rd);\n\n    // a document that is too old\n    testFailedDocument(Instant.parse(\"2017-10-01T00:00:00Z\"), \"couldn't be routed\");\n\n    // a document which is too far into the future\n    testFailedDocument(Instant.now().plus(30, ChronoUnit.MINUTES), \"too far in the future\");\n\n    // add another collection with the precise name we expect, but don't add to alias explicitly.  When we add a document\n    //   destined for this collection, Solr will see it already exists and add it to the alias.\n    final String col24th = alias + TRA + \"2017-10-24\";\n    CollectionAdminRequest.createCollection(col24th, configName,  1, 1) // more shards and replicas now\n        .withProperty(ROUTED_ALIAS_NAME_CORE_PROP, alias)\n        .process(solrClient);\n\n    // index 3 documents in a random fashion\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-23T00:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T01:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-24T02:00:00Z\"))\n    );\n//    System.out.println(cluster.getRandomJetty(random()).getBaseUrl());\n//    Thread.sleep(1000000);\n    assertInvariants(col24th, col23rd);\n\n    // assert that the IncrementURP has updated all '0' to '1'\n    final SolrDocumentList checkIncResults = solrClient.query(alias, params(\"q\", \"NOT \" + getIntField() + \":1\")).getResults();\n    assertEquals(checkIncResults.toString(), 0, checkIncResults.getNumFound());\n\n    //delete a random document id; ensure we don't find it\n    int idToDelete = 1 + random().nextInt(lastDocId);\n    if (idToDelete == 2 || idToDelete == 3) { // these didn't make it\n      idToDelete = 4;\n    }\n    assertUpdateResponse(solrClient.deleteById(alias, Integer.toString(idToDelete)));\n    assertUpdateResponse(solrClient.commit(alias));\n    numDocsDeletedOrFailed++;\n    assertInvariants(col24th, col23rd);\n\n    // delete the Oct23rd (save memory)...\n    //   make sure we track that we are effectively deleting docs there\n    numDocsDeletedOrFailed += solrClient.query(col23rd, params(\"q\", \"*:*\", \"rows\", \"0\")).getResults().getNumFound();\n    //   remove from the alias\n    CollectionAdminRequest.createAlias(alias, col24th).process(solrClient);\n    //   delete the collection\n    CollectionAdminRequest.deleteCollection(col23rd).process(solrClient);\n\n    // now we're going to add documents that will trigger more collections to be created\n    //   for 25th & 26th\n    addDocsAndCommit(false, // send these to alias & collections\n        newDoc(Instant.parse(\"2017-10-24T03:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-25T04:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T05:00:00Z\")),\n        newDoc(Instant.parse(\"2017-10-26T06:00:00Z\"))\n    );\n    assertInvariants(alias + TRA + \"2017-10-26\", alias + TRA + \"2017-10-25\", col24th);\n\n    // verify that collection properties are set when the collections are created. Note: first 2 collections in\n    // this test have a core property instead, of a collection property but that MUST continue to work as well\n    // for back compatibility's reasons.\n    Thread.sleep(1000);\n    byte[] data = cluster.getZkClient()\n        .getData(COLLECTIONS_ZKNODE + \"/\" + alias + TRA + \"2017-10-26\" + \"/\" + COLLECTION_PROPS_ZKNODE,null, null, true);\n    assertNotNull(data);\n    assertTrue(data.length > 0);\n    @SuppressWarnings(\"unchecked\")\n    Map<String,String> props = (Map<String, String>) Utils.fromJSON(data);\n    assertTrue(props.containsKey(ROUTED_ALIAS_NAME_CORE_PROP));\n    assertEquals(alias,props.get(ROUTED_ALIAS_NAME_CORE_PROP));\n\n    // update metadata to auto-delete oldest collections\n    CollectionAdminRequest.setAliasProperty(alias)\n        .addProperty(TimeRoutedAlias.ROUTER_AUTO_DELETE_AGE, \"-1DAY\")  // thus usually keep 2 collections of a day size\n        .process(solrClient);\n\n    // add more docs, creating one new collection, but trigger ones prior to\n    int numDocsToBeAutoDeleted = queryNumDocs(getTimeField() +\":[* TO \\\"2017-10-26T00:00:00Z\\\"}\");\n    addDocsAndCommit(true, // send these to alias only\n        newDoc(Instant.parse(\"2017-10-26T07:00:00Z\")), // existing\n        newDoc(Instant.parse(\"2017-10-27T08:00:00Z\")) // new\n    );\n    numDocsDeletedOrFailed += numDocsToBeAutoDeleted;\n    assertInvariants(alias + TRA + \"2017-10-27\", alias + TRA + \"2017-10-26\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"44dd40f6c2c1465aebf4677bab10f696c7ea18d8":["6002eff20bbcd2773a7d31d1688bd66ae71f565a"],"b94236357aaa22b76c10629851fe4e376e0cea82":["5613a70439d5d429f0689c2c5a21615e58deff97","ca55a3e50e219d5a29f5cf027c67b3891c57d5b9"],"6f29e9eb6c1655cd0b273f3c0dcdf43bc0822767":["3cbd743a4843f513f793670e3ab0e272bf824faf"],"46589ed5cc841861bf6b5e2afc55f718ebcd02a0":["6857f8205f8c5b4ff39a54d8aebb4fdfb7cfb691"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["44dd40f6c2c1465aebf4677bab10f696c7ea18d8"],"b5c929d2716fa79d443b93a82adb1da5b578ebd8":["11b67e7dc6d14dd8535564a49ca9c12ec5e8b2b6"],"7446cb4193d4f3046ab7f5d0ddfc37ddaa514966":["b627755385655c7cd3fb296f17593658805cf4d5"],"6002eff20bbcd2773a7d31d1688bd66ae71f565a":["60b45f127b5537b5bf62181784ef28b52f4b6a08"],"11b67e7dc6d14dd8535564a49ca9c12ec5e8b2b6":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["1eebf1b080530bdd7572c4927fb2bb52334b7a86"],"6857f8205f8c5b4ff39a54d8aebb4fdfb7cfb691":["b94236357aaa22b76c10629851fe4e376e0cea82"],"105e345cf3c0abed3cb6c109274a379cb2655adc":["7446cb4193d4f3046ab7f5d0ddfc37ddaa514966"],"a980795a56f2fcbc94caeb3233071312d5684d59":["6f29e9eb6c1655cd0b273f3c0dcdf43bc0822767"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["a980795a56f2fcbc94caeb3233071312d5684d59","60b45f127b5537b5bf62181784ef28b52f4b6a08"],"3cbd743a4843f513f793670e3ab0e272bf824faf":["46589ed5cc841861bf6b5e2afc55f718ebcd02a0"],"af3e10d8a1fbcc5c79b22f7477e79de467dd326c":["5613a70439d5d429f0689c2c5a21615e58deff97"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b627755385655c7cd3fb296f17593658805cf4d5":["b5c929d2716fa79d443b93a82adb1da5b578ebd8"],"5613a70439d5d429f0689c2c5a21615e58deff97":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1eebf1b080530bdd7572c4927fb2bb52334b7a86":["105e345cf3c0abed3cb6c109274a379cb2655adc"],"ca55a3e50e219d5a29f5cf027c67b3891c57d5b9":["af3e10d8a1fbcc5c79b22f7477e79de467dd326c"],"60b45f127b5537b5bf62181784ef28b52f4b6a08":["a980795a56f2fcbc94caeb3233071312d5684d59"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["a980795a56f2fcbc94caeb3233071312d5684d59","60b45f127b5537b5bf62181784ef28b52f4b6a08"]},"commit2Childs":{"44dd40f6c2c1465aebf4677bab10f696c7ea18d8":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"b94236357aaa22b76c10629851fe4e376e0cea82":["6857f8205f8c5b4ff39a54d8aebb4fdfb7cfb691"],"6f29e9eb6c1655cd0b273f3c0dcdf43bc0822767":["a980795a56f2fcbc94caeb3233071312d5684d59"],"46589ed5cc841861bf6b5e2afc55f718ebcd02a0":["3cbd743a4843f513f793670e3ab0e272bf824faf"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["11b67e7dc6d14dd8535564a49ca9c12ec5e8b2b6"],"b5c929d2716fa79d443b93a82adb1da5b578ebd8":["b627755385655c7cd3fb296f17593658805cf4d5"],"6002eff20bbcd2773a7d31d1688bd66ae71f565a":["44dd40f6c2c1465aebf4677bab10f696c7ea18d8"],"7446cb4193d4f3046ab7f5d0ddfc37ddaa514966":["105e345cf3c0abed3cb6c109274a379cb2655adc"],"11b67e7dc6d14dd8535564a49ca9c12ec5e8b2b6":["b5c929d2716fa79d443b93a82adb1da5b578ebd8"],"6857f8205f8c5b4ff39a54d8aebb4fdfb7cfb691":["46589ed5cc841861bf6b5e2afc55f718ebcd02a0"],"e46a76bb135597b8bf35930cfdb3702bdd1cbe6e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"105e345cf3c0abed3cb6c109274a379cb2655adc":["1eebf1b080530bdd7572c4927fb2bb52334b7a86"],"a980795a56f2fcbc94caeb3233071312d5684d59":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","60b45f127b5537b5bf62181784ef28b52f4b6a08","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"3cbd743a4843f513f793670e3ab0e272bf824faf":["6f29e9eb6c1655cd0b273f3c0dcdf43bc0822767"],"af3e10d8a1fbcc5c79b22f7477e79de467dd326c":["ca55a3e50e219d5a29f5cf027c67b3891c57d5b9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5613a70439d5d429f0689c2c5a21615e58deff97"],"5613a70439d5d429f0689c2c5a21615e58deff97":["b94236357aaa22b76c10629851fe4e376e0cea82","af3e10d8a1fbcc5c79b22f7477e79de467dd326c"],"b627755385655c7cd3fb296f17593658805cf4d5":["7446cb4193d4f3046ab7f5d0ddfc37ddaa514966"],"ca55a3e50e219d5a29f5cf027c67b3891c57d5b9":["b94236357aaa22b76c10629851fe4e376e0cea82"],"1eebf1b080530bdd7572c4927fb2bb52334b7a86":["e46a76bb135597b8bf35930cfdb3702bdd1cbe6e"],"60b45f127b5537b5bf62181784ef28b52f4b6a08":["6002eff20bbcd2773a7d31d1688bd66ae71f565a","0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}