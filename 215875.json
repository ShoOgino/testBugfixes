{"path":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","commits":[{"id":"6aefa60f1ef9bec0dd4a76a2a23df98e2837a418","date":1327839887,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context) throws IOException {\n    Directory separateNormsDir = info.dir; // separate norms are never inside CFS\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.normsPresent()) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","sourceOld":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.normsPresent()) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"296df632fd63421ea20756fa11ad36fbc6f4c8a9","date":1327957998,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context) throws IOException {\n    Directory separateNormsDir = info.dir; // separate norms are never inside CFS\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.normsPresent()) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","sourceOld":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.normsPresent()) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"410e066f093e407222d9681429d209084e783149","date":1327958394,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext,Directory).mjava","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context) throws IOException {\n    Directory separateNormsDir = info.dir; // separate norms are never inside CFS\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.normsPresent()) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","sourceOld":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context, Directory separateNormsDir) throws IOException {\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.normsPresent()) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xNormsProducer#Lucene3xNormsProducer(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context) throws IOException {\n    Directory separateNormsDir = info.dir; // separate norms are never inside CFS\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.normsPresent()) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","sourceOld":"  // note: just like segmentreader in 3.x, we open up all the files here (including separate norms) up front.\n  // but we just don't do any seeks or reading yet.\n  public Lucene3xNormsProducer(Directory dir, SegmentInfo info, FieldInfos fields, IOContext context) throws IOException {\n    Directory separateNormsDir = info.dir; // separate norms are never inside CFS\n    maxdoc = info.docCount;\n    String segmentName = info.name;\n    Map<Integer,Long> normGen = info.getNormGen();\n    boolean success = false;\n    try {\n      long nextNormSeek = NORMS_HEADER.length; //skip header (header unused for now)\n      for (FieldInfo fi : fields) {\n        if (fi.normsPresent()) {\n          String fileName = getNormFilename(segmentName, normGen, fi.number);\n          Directory d = hasSeparateNorms(normGen, fi.number) ? separateNormsDir : dir;\n        \n          // singleNormFile means multiple norms share this file\n          boolean singleNormFile = IndexFileNames.matchesExtension(fileName, NORMS_EXTENSION);\n          IndexInput normInput = null;\n          long normSeek;\n\n          if (singleNormFile) {\n            normSeek = nextNormSeek;\n            if (singleNormStream == null) {\n              singleNormStream = d.openInput(fileName, context);\n              openFiles.add(singleNormStream);\n            }\n            // All norms in the .nrm file can share a single IndexInput since\n            // they are only used in a synchronized context.\n            // If this were to change in the future, a clone could be done here.\n            normInput = singleNormStream;\n          } else {\n            normInput = d.openInput(fileName, context);\n            openFiles.add(normInput);\n            // if the segment was created in 3.2 or after, we wrote the header for sure,\n            // and don't need to do the sketchy file size check. otherwise, we check \n            // if the size is exactly equal to maxDoc to detect a headerless file.\n            // NOTE: remove this check in Lucene 5.0!\n            String version = info.getVersion();\n            final boolean isUnversioned = \n                (version == null || StringHelper.getVersionComparator().compare(version, \"3.2\") < 0)\n                && normInput.length() == maxdoc;\n            if (isUnversioned) {\n              normSeek = 0;\n            } else {\n              normSeek = NORMS_HEADER.length;\n            }\n          }\n          NormsDocValues norm = new NormsDocValues(normInput, normSeek);\n          norms.put(fi.name, norm);\n          nextNormSeek += maxdoc; // increment also if some norms are separate\n        }\n      }\n      // TODO: change to a real check? see LUCENE-3619\n      assert singleNormStream == null || nextNormSeek == singleNormStream.length() : singleNormStream != null ? \"len: \" + singleNormStream.length() + \" expected: \" + nextNormSeek : \"null\";\n      success = true;\n    } finally {\n      if (!success) {\n        IOUtils.closeWhileHandlingException(openFiles);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"410e066f093e407222d9681429d209084e783149":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"6aefa60f1ef9bec0dd4a76a2a23df98e2837a418":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"296df632fd63421ea20756fa11ad36fbc6f4c8a9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","6aefa60f1ef9bec0dd4a76a2a23df98e2837a418"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"410e066f093e407222d9681429d209084e783149":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"6aefa60f1ef9bec0dd4a76a2a23df98e2837a418":["296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["410e066f093e407222d9681429d209084e783149","6aefa60f1ef9bec0dd4a76a2a23df98e2837a418","296df632fd63421ea20756fa11ad36fbc6f4c8a9"],"296df632fd63421ea20756fa11ad36fbc6f4c8a9":["410e066f093e407222d9681429d209084e783149","3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["410e066f093e407222d9681429d209084e783149","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}