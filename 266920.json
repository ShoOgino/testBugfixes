{"path":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","commits":[{"id":"744486748bc5bee772100e49230e5bca39bac99a","date":1289776426,"type":0,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp);\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetetive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          t.docFreq += termsEnum.docFreq();\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          st.docFreq = termsEnum.docFreq();\n          visitedTerms.put(st.bytes, st);\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n          } else {\n            st = new ScoreTerm(termComp);\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.quickSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.docFreq;\n      addClause(q, term, st.docFreq, query.getBoost() * st.boost); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["4d3e8520fd031bab31fd0e4d480e55958bc45efe","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9ab1f5591dc05f1f2b5407d809c9699f75554a32","date":1290008586,"type":0,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp);\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetetive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          t.docFreq += termsEnum.docFreq();\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          st.docFreq = termsEnum.docFreq();\n          visitedTerms.put(st.bytes, st);\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n          } else {\n            st = new ScoreTerm(termComp);\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.quickSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.docFreq;\n      addClause(q, term, st.docFreq, query.getBoost() * st.boost); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp);\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetetive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          t.docFreq += termsEnum.docFreq();\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          st.docFreq = termsEnum.docFreq();\n          visitedTerms.put(st.bytes, st);\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n          } else {\n            st = new ScoreTerm(termComp);\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.quickSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.docFreq;\n      addClause(q, term, st.docFreq, query.getBoost() * st.boost); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fa1a999d6674423e5c4ac858b410283f6fe03f20","date":1294868331,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetetive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.quickSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp);\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetetive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          t.docFreq += termsEnum.docFreq();\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          st.docFreq = termsEnum.docFreq();\n          visitedTerms.put(st.bytes, st);\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n          } else {\n            st = new ScoreTerm(termComp);\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.quickSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.docFreq;\n      addClause(q, term, st.docFreq, query.getBoost() * st.boost); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetetive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.quickSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp);\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetetive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          t.docFreq += termsEnum.docFreq();\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          st.docFreq = termsEnum.docFreq();\n          visitedTerms.put(st.bytes, st);\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n          } else {\n            st = new ScoreTerm(termComp);\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.quickSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.docFreq;\n      addClause(q, term, st.docFreq, query.getBoost() * st.boost); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7235f072992928845d8cfd2dfc1c90362360e1e","date":1296426876,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.quickSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetetive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.quickSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"29ef99d61cda9641b6250bf9567329a6e65f901d","date":1297244127,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.quickSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp);\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetetive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          t.docFreq += termsEnum.docFreq();\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          st.docFreq = termsEnum.docFreq();\n          visitedTerms.put(st.bytes, st);\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n          } else {\n            st = new ScoreTerm(termComp);\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.quickSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.docFreq;\n      addClause(q, term, st.docFreq, query.getBoost() * st.boost); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.quickSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetetive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.quickSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a0d986f42c7320fce5b6ba6a767c160289c738a","date":1304428044,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.quickSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c700f8d0842d3e52bb2bdfbfdc046a137e836edb","date":1305285499,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.quickSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.quickSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153","date":1308670974,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","bugFix":null,"bugIntro":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Term placeholderTerm = new Term(query.field);\n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = placeholderTerm.createTerm(st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f3cee3d20b0c786e6fca20539454262e29edcab","date":1310101685,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f0b9507caf22f292ac0e5e59f62db4275adf4511","date":1310107283,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1291e4568eb7d9463d751627596ef14baf4c1603","date":1310112572,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new PerReaderTermState(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new PerReaderTermState(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"60ba444201d2570214b6fcf1d15600dc1a01f548","date":1313868045,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) throws IOException {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRef(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copy(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq();\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","bugFix":null,"bugIntro":["9f7c14f40c65357617cada58ca9b026ab9f81c24","4d3e8520fd031bab31fd0e4d480e55958bc45efe","7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2a4965b25e439626b575c2281b39ad875f89d891","date":1321132400,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) throws IOException {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRef(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copy(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) throws IOException {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRef(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copy(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    query.incTotalNumberOfTerms(scoreTerms.length);\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e6e919043fa85ee891123768dd655a98edbbf63c","date":1322225413,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) throws IOException {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) throws IOException {\n        if (lastTerm == null && t != null) {\n          lastTerm = new BytesRef(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copy(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copy(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","bugFix":null,"bugIntro":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2725b2d479964ea5aaea0ba4ae2634716f3ec26c","date":1327188170,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) throws IOException {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      //nocommit: reenable this: assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) throws IOException {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85dda37116c8d94fccd74dfe59f4d7fe4503e74c","date":1327234819,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) throws IOException {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) throws IOException {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      //nocommit: reenable this: assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","pathOld":"lucene/src/java/org/apache/lucene/search/TopTermsRewrite#rewrite(IndexReader,MultiTermQuery).mjava","sourceNew":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) throws IOException {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","sourceOld":"  @Override\n  public final Q rewrite(final IndexReader reader, final MultiTermQuery query) throws IOException {\n    final int maxSize = Math.min(size, getMaxSize());\n    final PriorityQueue<ScoreTerm> stQueue = new PriorityQueue<ScoreTerm>();\n    collectTerms(reader, query, new TermCollector() {\n      private final MaxNonCompetitiveBoostAttribute maxBoostAtt =\n        attributes.addAttribute(MaxNonCompetitiveBoostAttribute.class);\n      \n      private final Map<BytesRef,ScoreTerm> visitedTerms = new HashMap<BytesRef,ScoreTerm>();\n      \n      private TermsEnum termsEnum;\n      private Comparator<BytesRef> termComp;\n      private BoostAttribute boostAtt;        \n      private ScoreTerm st;\n      \n      @Override\n      public void setNextEnum(TermsEnum termsEnum) throws IOException {\n        this.termsEnum = termsEnum;\n        this.termComp = termsEnum.getComparator();\n        \n        assert compareToLastTerm(null);\n\n        // lazy init the initial ScoreTerm because comparator is not known on ctor:\n        if (st == null)\n          st = new ScoreTerm(this.termComp, new TermContext(topReaderContext));\n        boostAtt = termsEnum.attributes().addAttribute(BoostAttribute.class);\n      }\n    \n      // for assert:\n      private BytesRef lastTerm;\n      private boolean compareToLastTerm(BytesRef t) throws IOException {\n        if (lastTerm == null && t != null) {\n          lastTerm = BytesRef.deepCopyOf(t);\n        } else if (t == null) {\n          lastTerm = null;\n        } else {\n          assert termsEnum.getComparator().compare(lastTerm, t) < 0: \"lastTerm=\" + lastTerm + \" t=\" + t;\n          lastTerm.copyBytes(t);\n        }\n        return true;\n      }\n  \n      @Override\n      public boolean collect(BytesRef bytes) throws IOException {\n        final float boost = boostAtt.getBoost();\n\n        // make sure within a single seg we always collect\n        // terms in order\n        assert compareToLastTerm(bytes);\n\n        //System.out.println(\"TTR.collect term=\" + bytes.utf8ToString() + \" boost=\" + boost + \" ord=\" + readerContext.ord);\n        // ignore uncompetitive hits\n        if (stQueue.size() == maxSize) {\n          final ScoreTerm t = stQueue.peek();\n          if (boost < t.boost)\n            return true;\n          if (boost == t.boost && termComp.compare(bytes, t.bytes) > 0)\n            return true;\n        }\n        ScoreTerm t = visitedTerms.get(bytes);\n        final TermState state = termsEnum.termState();\n        assert state != null;\n        if (t != null) {\n          // if the term is already in the PQ, only update docFreq of term in PQ\n          assert t.boost == boost : \"boost should be equal in all segment TermsEnums\";\n          t.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n        } else {\n          // add new entry in PQ, we must clone the term, else it may get overwritten!\n          st.bytes.copyBytes(bytes);\n          st.boost = boost;\n          visitedTerms.put(st.bytes, st);\n          assert st.termState.docFreq() == 0;\n          st.termState.register(state, readerContext.ord, termsEnum.docFreq(), termsEnum.totalTermFreq());\n          stQueue.offer(st);\n          // possibly drop entries from queue\n          if (stQueue.size() > maxSize) {\n            st = stQueue.poll();\n            visitedTerms.remove(st.bytes);\n            st.termState.clear(); // reset the termstate! \n          } else {\n            st = new ScoreTerm(termComp, new TermContext(topReaderContext));\n          }\n          assert stQueue.size() <= maxSize : \"the PQ size must be limited to maxSize\";\n          // set maxBoostAtt with values to help FuzzyTermsEnum to optimize\n          if (stQueue.size() == maxSize) {\n            t = stQueue.peek();\n            maxBoostAtt.setMaxNonCompetitiveBoost(t.boost);\n            maxBoostAtt.setCompetitiveTerm(t.bytes);\n          }\n        }\n       \n        return true;\n      }\n    });\n    \n    final Q q = getTopLevelQuery();\n    final ScoreTerm[] scoreTerms = stQueue.toArray(new ScoreTerm[stQueue.size()]);\n    ArrayUtil.mergeSort(scoreTerms, scoreTermSortByTermComp);\n    \n    for (final ScoreTerm st : scoreTerms) {\n      final Term term = new Term(query.field, st.bytes);\n      assert reader.docFreq(term) == st.termState.docFreq() : \"reader DF is \" + reader.docFreq(term) + \" vs \" + st.termState.docFreq() + \" term=\" + term;\n      addClause(q, term, st.termState.docFreq(), query.getBoost() * st.boost, st.termState); // add to query\n    }\n    return q;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["e6e919043fa85ee891123768dd655a98edbbf63c"],"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153":["2a0d986f42c7320fce5b6ba6a767c160289c738a"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","744486748bc5bee772100e49230e5bca39bac99a"],"f0b9507caf22f292ac0e5e59f62db4275adf4511":["2553b00f699380c64959ccb27991289aae87be2e","0f3cee3d20b0c786e6fca20539454262e29edcab"],"29ef99d61cda9641b6250bf9567329a6e65f901d":["9ab1f5591dc05f1f2b5407d809c9699f75554a32","c7235f072992928845d8cfd2dfc1c90362360e1e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2a4965b25e439626b575c2281b39ad875f89d891":["60ba444201d2570214b6fcf1d15600dc1a01f548"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["29ef99d61cda9641b6250bf9567329a6e65f901d","2a0d986f42c7320fce5b6ba6a767c160289c738a"],"e6e919043fa85ee891123768dd655a98edbbf63c":["2a4965b25e439626b575c2281b39ad875f89d891"],"744486748bc5bee772100e49230e5bca39bac99a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["868da859b43505d9d2a023bfeae6dd0c795f5295","c7235f072992928845d8cfd2dfc1c90362360e1e"],"2725b2d479964ea5aaea0ba4ae2634716f3ec26c":["e6e919043fa85ee891123768dd655a98edbbf63c"],"0f3cee3d20b0c786e6fca20539454262e29edcab":["fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"85dda37116c8d94fccd74dfe59f4d7fe4503e74c":["2725b2d479964ea5aaea0ba4ae2634716f3ec26c"],"9ab1f5591dc05f1f2b5407d809c9699f75554a32":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","744486748bc5bee772100e49230e5bca39bac99a"],"2553b00f699380c64959ccb27991289aae87be2e":["a3776dccca01c11e7046323cfad46a3b4a471233","fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["2a0d986f42c7320fce5b6ba6a767c160289c738a","fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"60ba444201d2570214b6fcf1d15600dc1a01f548":["0f3cee3d20b0c786e6fca20539454262e29edcab"],"1291e4568eb7d9463d751627596ef14baf4c1603":["d083e83f225b11e5fdd900e83d26ddb385b6955c","0f3cee3d20b0c786e6fca20539454262e29edcab"],"a3776dccca01c11e7046323cfad46a3b4a471233":["c7235f072992928845d8cfd2dfc1c90362360e1e","2a0d986f42c7320fce5b6ba6a767c160289c738a"],"c7235f072992928845d8cfd2dfc1c90362360e1e":["fa1a999d6674423e5c4ac858b410283f6fe03f20"],"fa1a999d6674423e5c4ac858b410283f6fe03f20":["744486748bc5bee772100e49230e5bca39bac99a"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","fa1a999d6674423e5c4ac858b410283f6fe03f20"],"2a0d986f42c7320fce5b6ba6a767c160289c738a":["c7235f072992928845d8cfd2dfc1c90362360e1e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153":["0f3cee3d20b0c786e6fca20539454262e29edcab","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"f0b9507caf22f292ac0e5e59f62db4275adf4511":[],"29ef99d61cda9641b6250bf9567329a6e65f901d":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","744486748bc5bee772100e49230e5bca39bac99a","9ab1f5591dc05f1f2b5407d809c9699f75554a32"],"2a4965b25e439626b575c2281b39ad875f89d891":["e6e919043fa85ee891123768dd655a98edbbf63c"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":[],"e6e919043fa85ee891123768dd655a98edbbf63c":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","2725b2d479964ea5aaea0ba4ae2634716f3ec26c"],"744486748bc5bee772100e49230e5bca39bac99a":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","9ab1f5591dc05f1f2b5407d809c9699f75554a32","fa1a999d6674423e5c4ac858b410283f6fe03f20"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":[],"2725b2d479964ea5aaea0ba4ae2634716f3ec26c":["85dda37116c8d94fccd74dfe59f4d7fe4503e74c"],"0f3cee3d20b0c786e6fca20539454262e29edcab":["f0b9507caf22f292ac0e5e59f62db4275adf4511","60ba444201d2570214b6fcf1d15600dc1a01f548","1291e4568eb7d9463d751627596ef14baf4c1603"],"85dda37116c8d94fccd74dfe59f4d7fe4503e74c":[],"9ab1f5591dc05f1f2b5407d809c9699f75554a32":["29ef99d61cda9641b6250bf9567329a6e65f901d"],"2553b00f699380c64959ccb27991289aae87be2e":["f0b9507caf22f292ac0e5e59f62db4275adf4511"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["1291e4568eb7d9463d751627596ef14baf4c1603"],"60ba444201d2570214b6fcf1d15600dc1a01f548":["2a4965b25e439626b575c2281b39ad875f89d891"],"1291e4568eb7d9463d751627596ef14baf4c1603":[],"a3776dccca01c11e7046323cfad46a3b4a471233":["2553b00f699380c64959ccb27991289aae87be2e"],"c7235f072992928845d8cfd2dfc1c90362360e1e":["29ef99d61cda9641b6250bf9567329a6e65f901d","bde51b089eb7f86171eb3406e38a274743f9b7ac","a3776dccca01c11e7046323cfad46a3b4a471233","2a0d986f42c7320fce5b6ba6a767c160289c738a"],"fa1a999d6674423e5c4ac858b410283f6fe03f20":["c7235f072992928845d8cfd2dfc1c90362360e1e","868da859b43505d9d2a023bfeae6dd0c795f5295"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"2a0d986f42c7320fce5b6ba6a767c160289c738a":["fafef7c83fe8e0b3ca9298d5d75d6b943dc28153","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","d083e83f225b11e5fdd900e83d26ddb385b6955c","a3776dccca01c11e7046323cfad46a3b4a471233"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f0b9507caf22f292ac0e5e59f62db4275adf4511","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","bde51b089eb7f86171eb3406e38a274743f9b7ac","85dda37116c8d94fccd74dfe59f4d7fe4503e74c","1291e4568eb7d9463d751627596ef14baf4c1603","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}