{"path":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","commits":[{"id":"9fc0d60683b47b5d922124c31f57c8b34734f9e6","date":1480846684,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"/dev/null","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9856095f7afb5a607bf5e65077615ed91273508c","date":1481837697,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"/dev/null","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"41f60ea1802fda42d3c91d023406066d00ddb5f8","date":1535615991,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, minPackedValue, offset, offset + bytesPerDim) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, maxPackedValue, offset, offset + bytesPerDim) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (StringHelper.compare(bytesPerDim, scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6652c943595e92c187ee904c382863013eae28f","date":1539042663,"type":3,"author":"Nicholas Knize","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numIndexDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, minPackedValue, offset, offset + bytesPerDim) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, maxPackedValue, offset, offset + bytesPerDim) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, minPackedValue, offset, offset + bytesPerDim) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, maxPackedValue, offset, offset + bytesPerDim) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"76a51551f05a6c96a115b5a656837ecc8fd0b1ff","date":1551422476,"type":3,"author":"iverase","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    finished = true;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numIndexDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, minPackedValue, offset, offset + bytesPerDim) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, maxPackedValue, offset, offset + bytesPerDim) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (heapPointWriter == null && tempInput == null) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    heapPointWriter = null;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numIndexDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, minPackedValue, offset, offset + bytesPerDim) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, maxPackedValue, offset, offset + bytesPerDim) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b88a121b875f9ae2ac50f85cf46dcb680f126357","date":1555416009,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    finished = true;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numIndexDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (Arrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, minPackedValue, offset, offset + bytesPerDim) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (Arrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, maxPackedValue, offset, offset + bytesPerDim) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    finished = true;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numIndexDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, minPackedValue, offset, offset + bytesPerDim) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (FutureArrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, maxPackedValue, offset, offset + bytesPerDim) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb94bf667d51f9c390c99d97afb36b7caab6b6e9","date":1599548621,"type":3,"author":"Ignacio Vera","isMerge":false,"pathNew":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","pathOld":"lucene/codecs/src/java/org/apache/lucene/codecs/simpletext/SimpleTextBKDWriter#writeFieldNDims(IndexOutput,String,MutablePointValues).mjava","sourceNew":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    finished = true;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > config.maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (config.bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<config.numIndexDims;dim++) {\n        int offset = dim*config.bytesPerDim;\n        if (Arrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + config.bytesPerDim, minPackedValue, offset, offset + config.bytesPerDim) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, config.bytesPerDim);\n        }\n        if (Arrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + config.bytesPerDim, maxPackedValue, offset, offset + config.bytesPerDim) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, config.bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[config.maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","sourceOld":"  /* In the 2+D case, we recursively pick the split dimension, compute the\n   * median value and partition other values around it. */\n  private long writeFieldNDims(IndexOutput out, String fieldName, MutablePointValues values) throws IOException {\n    if (pointCount != 0) {\n      throw new IllegalStateException(\"cannot mix add and writeField\");\n    }\n\n    // Catch user silliness:\n    if (finished == true) {\n      throw new IllegalStateException(\"already finished\");\n    }\n\n    // Mark that we already finished:\n    finished = true;\n\n    long countPerLeaf = pointCount = values.size();\n    long innerNodeCount = 1;\n\n    while (countPerLeaf > maxPointsInLeafNode) {\n      countPerLeaf = (countPerLeaf+1)/2;\n      innerNodeCount *= 2;\n    }\n\n    int numLeaves = Math.toIntExact(innerNodeCount);\n\n    checkMaxLeafNodeCount(numLeaves);\n\n    final byte[] splitPackedValues = new byte[numLeaves * (bytesPerDim + 1)];\n    final long[] leafBlockFPs = new long[numLeaves];\n\n    // compute the min/max for this slice\n    Arrays.fill(minPackedValue, (byte) 0xff);\n    Arrays.fill(maxPackedValue, (byte) 0);\n    for (int i = 0; i < Math.toIntExact(pointCount); ++i) {\n      values.getValue(i, scratchBytesRef1);\n      for(int dim=0;dim<numIndexDims;dim++) {\n        int offset = dim*bytesPerDim;\n        if (Arrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, minPackedValue, offset, offset + bytesPerDim) < 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, minPackedValue, offset, bytesPerDim);\n        }\n        if (Arrays.compareUnsigned(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, scratchBytesRef1.offset + offset + bytesPerDim, maxPackedValue, offset, offset + bytesPerDim) > 0) {\n          System.arraycopy(scratchBytesRef1.bytes, scratchBytesRef1.offset + offset, maxPackedValue, offset, bytesPerDim);\n        }\n      }\n\n      docsSeen.set(values.getDocID(i));\n    }\n\n    build(1, numLeaves, values, 0, Math.toIntExact(pointCount), out,\n        minPackedValue, maxPackedValue, splitPackedValues, leafBlockFPs,\n        new int[maxPointsInLeafNode]);\n\n    long indexFP = out.getFilePointer();\n    writeIndex(out, leafBlockFPs, splitPackedValues);\n    return indexFP;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"9fc0d60683b47b5d922124c31f57c8b34734f9e6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b88a121b875f9ae2ac50f85cf46dcb680f126357":["76a51551f05a6c96a115b5a656837ecc8fd0b1ff"],"bb94bf667d51f9c390c99d97afb36b7caab6b6e9":["b88a121b875f9ae2ac50f85cf46dcb680f126357"],"f6652c943595e92c187ee904c382863013eae28f":["41f60ea1802fda42d3c91d023406066d00ddb5f8"],"41f60ea1802fda42d3c91d023406066d00ddb5f8":["9fc0d60683b47b5d922124c31f57c8b34734f9e6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"9856095f7afb5a607bf5e65077615ed91273508c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","9fc0d60683b47b5d922124c31f57c8b34734f9e6"],"76a51551f05a6c96a115b5a656837ecc8fd0b1ff":["f6652c943595e92c187ee904c382863013eae28f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bb94bf667d51f9c390c99d97afb36b7caab6b6e9"]},"commit2Childs":{"9fc0d60683b47b5d922124c31f57c8b34734f9e6":["41f60ea1802fda42d3c91d023406066d00ddb5f8","9856095f7afb5a607bf5e65077615ed91273508c"],"b88a121b875f9ae2ac50f85cf46dcb680f126357":["bb94bf667d51f9c390c99d97afb36b7caab6b6e9"],"bb94bf667d51f9c390c99d97afb36b7caab6b6e9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f6652c943595e92c187ee904c382863013eae28f":["76a51551f05a6c96a115b5a656837ecc8fd0b1ff"],"41f60ea1802fda42d3c91d023406066d00ddb5f8":["f6652c943595e92c187ee904c382863013eae28f"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9fc0d60683b47b5d922124c31f57c8b34734f9e6","9856095f7afb5a607bf5e65077615ed91273508c"],"9856095f7afb5a607bf5e65077615ed91273508c":[],"76a51551f05a6c96a115b5a656837ecc8fd0b1ff":["b88a121b875f9ae2ac50f85cf46dcb680f126357"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9856095f7afb5a607bf5e65077615ed91273508c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}