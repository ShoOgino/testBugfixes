{"path":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","sourceNew":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString());\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(19, seg.termIndexStatus.termCount);\n    assertEquals(19, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<String>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString());\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(19, seg.termIndexStatus.termCount);\n    assertEquals(19, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<String>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","sourceNew":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString());\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(19, seg.termIndexStatus.termCount);\n    assertEquals(19, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<String>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString());\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(19, seg.termIndexStatus.termCount);\n    assertEquals(19, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<String>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bd4bc8f43232c31bb2eaa60dbba8bcdc0b4f7724","date":1341665587,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","sourceNew":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, \"UTF-8\"));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(\"UTF-8\"));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(19, seg.termIndexStatus.termCount);\n    assertEquals(19, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<String>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString());\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(19, seg.termIndexStatus.termCount);\n    assertEquals(19, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<String>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2acf500f78aa12b92e371fd89c719291986b6b90","date":1341846236,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","sourceNew":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, \"UTF-8\"));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(\"UTF-8\"));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(19, seg.termIndexStatus.termCount);\n    assertEquals(19, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<String>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString());\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(19, seg.termIndexStatus.termCount);\n    assertEquals(19, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<String>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"46d8ada1fff8d18cb197c38c7983225162599948","date":1341853497,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","sourceNew":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, \"UTF-8\"));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(\"UTF-8\"));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(19, seg.termIndexStatus.termCount);\n    assertEquals(19, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<String>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString());\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(19, seg.termIndexStatus.termCount);\n    assertEquals(19, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<String>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","sourceNew":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, \"UTF-8\"));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(\"UTF-8\"));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(19, seg.termIndexStatus.termCount);\n    assertEquals(19, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<String>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString());\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(19, seg.termIndexStatus.termCount);\n    assertEquals(19, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<String>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7312a5134c2e28e06b87256e466da72eadd966d9","date":1350427311,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","sourceNew":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, \"UTF-8\"));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(\"UTF-8\"));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<String>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, \"UTF-8\"));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(\"UTF-8\"));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(19, seg.termIndexStatus.termCount);\n    assertEquals(19, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<String>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","bugFix":["75ec8c9aaa10ac00b30fd4c2465409770c838f7b","433ef5e0ff3fa18d549774f572b36aae2ae64232"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"db4fdbf3d262768eabc027cd8321edca0cd11fa8","date":1350574784,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","sourceNew":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, \"UTF-8\"));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(\"UTF-8\"));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<String>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, \"UTF-8\"));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(\"UTF-8\"));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(19, seg.termIndexStatus.termCount);\n    assertEquals(19, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<String>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","sourceNew":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, \"UTF-8\"));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(\"UTF-8\"));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, \"UTF-8\"));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(\"UTF-8\"));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<String>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7d89d7e4e5101347833eea558851bf4209218619","date":1396265641,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","sourceNew":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, IOUtils.UTF_8));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(IOUtils.UTF_8));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, \"UTF-8\"));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(\"UTF-8\"));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","sourceNew":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, IOUtils.UTF_8));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(IOUtils.UTF_8));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, \"UTF-8\"));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(\"UTF-8\"));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","sourceNew":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.shutdown();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, IOUtils.UTF_8));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(IOUtils.UTF_8));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, IOUtils.UTF_8));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(IOUtils.UTF_8));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","sourceNew":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.shutdown();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, IOUtils.UTF_8));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(IOUtils.UTF_8));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())).setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.shutdown();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, IOUtils.UTF_8));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(IOUtils.UTF_8));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","sourceNew":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, IOUtils.UTF_8));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(IOUtils.UTF_8));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.shutdown();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, IOUtils.UTF_8));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(IOUtils.UTF_8));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f7523916a1350712e1ae710affd4e88ccd7c431d","date":1412161942,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","sourceNew":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, IOUtils.UTF_8));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(IOUtils.UTF_8));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    checker.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, IOUtils.UTF_8));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(IOUtils.UTF_8));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d9a47902d6207303f5ed3e7aaca62ca33433af66","date":1412435312,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","sourceNew":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, IOUtils.UTF_8));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(IOUtils.UTF_8));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    checker.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, IOUtils.UTF_8));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(IOUtils.UTF_8));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"552952562ab3b98c499d9cbf0b7a1691af0084ed","date":1434126156,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","sourceNew":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, IOUtils.UTF_8));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(IOUtils.UTF_8));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertNotNull(seg.diagnostics.get(\"java.vm.version\"));\n    assertNotNull(seg.diagnostics.get(\"java.runtime.version\"));\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    checker.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, IOUtils.UTF_8));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(IOUtils.UTF_8));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    checker.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ca56618660563c407aafdbd4ee4175ba2c73e6dc","date":1448923608,"type":3,"author":"Gregory Chanan","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestCheckIndex#testDeletedDocs().mjava","sourceNew":"  @Test\n  public void testDeletedDocs() throws IOException {\n    testDeletedDocs(directory);\n  }\n\n","sourceOld":"  public void testDeletedDocs() throws IOException {\n    Directory dir = newDirectory();\n    IndexWriter writer  = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                 .setMaxBufferedDocs(2));\n    for(int i=0;i<19;i++) {\n      Document doc = new Document();\n      FieldType customType = new FieldType(TextField.TYPE_STORED);\n      customType.setStoreTermVectors(true);\n      customType.setStoreTermVectorPositions(true);\n      customType.setStoreTermVectorOffsets(true);\n      doc.add(newField(\"field\", \"aaa\"+i, customType));\n      writer.addDocument(doc);\n    }\n    writer.forceMerge(1);\n    writer.commit();\n    writer.deleteDocuments(new Term(\"field\",\"aaa5\"));\n    writer.close();\n\n    ByteArrayOutputStream bos = new ByteArrayOutputStream(1024);\n    CheckIndex checker = new CheckIndex(dir);\n    checker.setInfoStream(new PrintStream(bos, false, IOUtils.UTF_8));\n    if (VERBOSE) checker.setInfoStream(System.out);\n    CheckIndex.Status indexStatus = checker.checkIndex();\n    if (indexStatus.clean == false) {\n      System.out.println(\"CheckIndex failed\");\n      System.out.println(bos.toString(IOUtils.UTF_8));\n      fail();\n    }\n    \n    final CheckIndex.Status.SegmentInfoStatus seg = indexStatus.segmentInfos.get(0);\n    assertTrue(seg.openReaderPassed);\n\n    assertNotNull(seg.diagnostics);\n    \n    assertNotNull(seg.fieldNormStatus);\n    assertNull(seg.fieldNormStatus.error);\n    assertEquals(1, seg.fieldNormStatus.totFields);\n\n    assertNotNull(seg.termIndexStatus);\n    assertNull(seg.termIndexStatus.error);\n    assertEquals(18, seg.termIndexStatus.termCount);\n    assertEquals(18, seg.termIndexStatus.totFreq);\n    assertEquals(18, seg.termIndexStatus.totPos);\n\n    assertNotNull(seg.storedFieldStatus);\n    assertNull(seg.storedFieldStatus.error);\n    assertEquals(18, seg.storedFieldStatus.docCount);\n    assertEquals(18, seg.storedFieldStatus.totFields);\n\n    assertNotNull(seg.termVectorStatus);\n    assertNull(seg.termVectorStatus.error);\n    assertEquals(18, seg.termVectorStatus.docCount);\n    assertEquals(18, seg.termVectorStatus.totVectors);\n\n    assertNotNull(seg.diagnostics.get(\"java.vm.version\"));\n    assertNotNull(seg.diagnostics.get(\"java.runtime.version\"));\n\n    assertTrue(seg.diagnostics.size() > 0);\n    final List<String> onlySegments = new ArrayList<>();\n    onlySegments.add(\"_0\");\n    \n    assertTrue(checker.checkIndex(onlySegments).clean == true);\n    checker.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"bd4bc8f43232c31bb2eaa60dbba8bcdc0b4f7724":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"5eb2511ababf862ea11e10761c70ee560cd84510":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","7d89d7e4e5101347833eea558851bf4209218619"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["7312a5134c2e28e06b87256e466da72eadd966d9"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"7312a5134c2e28e06b87256e466da72eadd966d9":["2acf500f78aa12b92e371fd89c719291986b6b90"],"f7523916a1350712e1ae710affd4e88ccd7c431d":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"db4fdbf3d262768eabc027cd8321edca0cd11fa8":["2acf500f78aa12b92e371fd89c719291986b6b90","7312a5134c2e28e06b87256e466da72eadd966d9"],"552952562ab3b98c499d9cbf0b7a1691af0084ed":["f7523916a1350712e1ae710affd4e88ccd7c431d"],"d9a47902d6207303f5ed3e7aaca62ca33433af66":["d0ef034a4f10871667ae75181537775ddcf8ade4","f7523916a1350712e1ae710affd4e88ccd7c431d"],"2acf500f78aa12b92e371fd89c719291986b6b90":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","bd4bc8f43232c31bb2eaa60dbba8bcdc0b4f7724"],"7d89d7e4e5101347833eea558851bf4209218619":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"46d8ada1fff8d18cb197c38c7983225162599948":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","2acf500f78aa12b92e371fd89c719291986b6b90"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","2acf500f78aa12b92e371fd89c719291986b6b90"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["7d89d7e4e5101347833eea558851bf4209218619"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"ca56618660563c407aafdbd4ee4175ba2c73e6dc":["552952562ab3b98c499d9cbf0b7a1691af0084ed"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ca56618660563c407aafdbd4ee4175ba2c73e6dc"]},"commit2Childs":{"bd4bc8f43232c31bb2eaa60dbba8bcdc0b4f7724":["2acf500f78aa12b92e371fd89c719291986b6b90"],"5eb2511ababf862ea11e10761c70ee560cd84510":[],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["5eb2511ababf862ea11e10761c70ee560cd84510","7d89d7e4e5101347833eea558851bf4209218619"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"7312a5134c2e28e06b87256e466da72eadd966d9":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","db4fdbf3d262768eabc027cd8321edca0cd11fa8"],"f7523916a1350712e1ae710affd4e88ccd7c431d":["552952562ab3b98c499d9cbf0b7a1691af0084ed","d9a47902d6207303f5ed3e7aaca62ca33433af66"],"db4fdbf3d262768eabc027cd8321edca0cd11fa8":[],"552952562ab3b98c499d9cbf0b7a1691af0084ed":["ca56618660563c407aafdbd4ee4175ba2c73e6dc"],"d9a47902d6207303f5ed3e7aaca62ca33433af66":[],"2acf500f78aa12b92e371fd89c719291986b6b90":["7312a5134c2e28e06b87256e466da72eadd966d9","db4fdbf3d262768eabc027cd8321edca0cd11fa8","46d8ada1fff8d18cb197c38c7983225162599948","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"7d89d7e4e5101347833eea558851bf4209218619":["5eb2511ababf862ea11e10761c70ee560cd84510","ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"46d8ada1fff8d18cb197c38c7983225162599948":[],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["f7523916a1350712e1ae710affd4e88ccd7c431d","d9a47902d6207303f5ed3e7aaca62ca33433af66"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["bd4bc8f43232c31bb2eaa60dbba8bcdc0b4f7724","2acf500f78aa12b92e371fd89c719291986b6b90","46d8ada1fff8d18cb197c38c7983225162599948","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"ca56618660563c407aafdbd4ee4175ba2c73e6dc":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5eb2511ababf862ea11e10761c70ee560cd84510","db4fdbf3d262768eabc027cd8321edca0cd11fa8","d9a47902d6207303f5ed3e7aaca62ca33433af66","46d8ada1fff8d18cb197c38c7983225162599948","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}