{"path":"solr/core/src/test/org/apache/solr/cloud/DistribDocExpirationUpdateProcessorTest#runTest().mjava","commits":[{"id":"c92ac83d1c2f8811300bb0df797465cca0aa8e92","date":1579710745,"type":0,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DistribDocExpirationUpdateProcessorTest#runTest().mjava","pathOld":"/dev/null","sourceNew":"  private void runTest() throws Exception {\n    final int totalNumDocs = atLeast(50);\n    \n    // Add a bunch of docs; some with extremely short expiration, some with no expiration\n    // these should be randomly distributed to each shard\n    long numDocsThatNeverExpire = 0;\n    {\n      final UpdateRequest req = setAuthIfNeeded(new UpdateRequest());\n      for (int i = 1; i <= totalNumDocs; i++) {\n        final SolrInputDocument doc = sdoc(\"id\", i);\n\n        if (random().nextBoolean()) {\n          doc.addField(\"should_expire_s\",\"yup\");\n          doc.addField(\"tTl_s\",\"+1SECONDS\");\n        } else {\n          numDocsThatNeverExpire++;\n        }\n        \n        req.add(doc);\n      }\n      req.commit(cluster.getSolrClient(), COLLECTION);\n    }\n    \n    // NOTE: don't assume we can find exactly totalNumDocs right now, some may have already been deleted...\n    \n    // it should not take long for us to get to the point where all 'should_expire_s:yup' docs are gone\n    waitForNoResults(30, params(\"q\",\"should_expire_s:yup\",\"rows\",\"0\",\"_trace\",\"init_batch_check\"));\n\n    {\n      // ...*NOW* we can assert that exactly numDocsThatNeverExpire should exist...\n      final QueryRequest req = setAuthIfNeeded(new QueryRequest\n                                               (params(\"q\", \"*:*\",\n                                                       \"rows\", \"0\",\n                                                       \"_trace\", \"count_non_expire_docs\")));\n\n      // NOTE: it's possible that replicas could be out of sync but this query may get lucky and\n      // only hit leaders.  we'll compare the counts of every replica in every shard later on...\n      assertEquals(numDocsThatNeverExpire,\n                   req.process(cluster.getSolrClient(), COLLECTION).getResults().getNumFound());\n    }\n    \n    //\n    // now that we've confrmed the basics work, let's check some fine grain stuff...\n    //\n    \n    // first off, sanity check that this special docId doesn't some how already exist\n    waitForNoResults(0, params(\"q\",\"id:special99\",\"rows\",\"0\",\"_trace\",\"sanity_check99\"));\n\n    {\n      // force a hard commit on all shards (the prior auto-expire would have only done a soft commit)\n      // so we can ensure our indexVersion won't change uncessisarily on the un-affected\n      // shard when we add & (hard) commit our special doc...\n      final UpdateRequest req = setAuthIfNeeded(new UpdateRequest());\n      req.commit(cluster.getSolrClient(), COLLECTION);\n    }\n    \n    \n    // record important data for each replica core so we can check later\n    // that it only changes for the replicas of a single shard after we add/expire a single special doc\n    log.info(\"Fetching ReplicaData BEFORE special doc addition/expiration\");\n    final Map<String,ReplicaData> initReplicaData = getTestDataForAllReplicas();\n    assertTrue(\"WTF? no replica data?\", 0 < initReplicaData.size());\n\n    // add & hard commit a special doc with a short TTL \n    setAuthIfNeeded(new UpdateRequest()).add(sdoc(\"id\", \"special99\", \"should_expire_s\",\"yup\",\"tTl_s\",\"+30SECONDS\"))\n      .commit(cluster.getSolrClient(), COLLECTION);\n\n    // wait for our special docId to be deleted\n    waitForNoResults(180, params(\"q\",\"id:special99\",\"rows\",\"0\",\"_trace\",\"did_special_doc_expire_yet\"));\n\n    // now check all of the replicas to verify a few things:\n    // - only the replicas of one shard changed -- no unneccessary churn on other shards\n    // - every replica of each single shard should have the same number of docs\n    // - the total number of docs should match numDocsThatNeverExpire\n    log.info(\"Fetching ReplicaData AFTER special doc addition/expiration\");\n    final Map<String,ReplicaData> finalReplicaData = getTestDataForAllReplicas();\n    assertEquals(\"WTF? not same num replicas?\", \n                 initReplicaData.size(),\n                 finalReplicaData.size());\n\n    final Set<String> coresThatChange = new HashSet<>();\n    final Set<String> shardsThatChange = new HashSet<>();\n    \n    int coresCompared = 0;\n    int totalDocsOnAllShards = 0;\n    final DocCollection collectionState = cluster.getSolrClient().getZkStateReader().getClusterState().getCollection(COLLECTION);\n    for (Slice shard : collectionState) {\n      boolean firstReplica = true;\n      for (Replica replica : shard) {\n        coresCompared++;\n        assertEquals(shard.getName(), replica.getSlice()); // sanity check\n        final String core = replica.getCoreName();\n        final ReplicaData initData = initReplicaData.get(core);\n        final ReplicaData finalData = finalReplicaData.get(core);\n        assertNotNull(shard.getName() + \": no init data for core: \" + core, initData);\n        assertNotNull(shard.getName() + \": no final data for core: \" + core, finalData);\n\n        if (!initData.equals(finalData)) {\n          log.error(\"ReplicaData changed: {} != {}\", initData, finalData);\n          coresThatChange.add(core + \"(\"+shard.getName()+\")\");\n          shardsThatChange.add(shard.getName());\n        }\n        \n        if (firstReplica) {\n          totalDocsOnAllShards += finalData.numDocs;\n          firstReplica = false;\n        }\n      }\n    }\n\n    assertEquals(\"Exactly one shard should have changed, instead: \" + shardsThatChange\n                 + \" cores=(\" + coresThatChange + \")\",\n                 1, shardsThatChange.size());\n    assertEquals(\"somehow we missed some cores?\", \n                 initReplicaData.size(), coresCompared);\n\n    assertEquals(\"Final tally has incorrect numDocsThatNeverExpire\",\n                 numDocsThatNeverExpire, totalDocsOnAllShards);\n    \n    // TODO: above logic verifies that deleteByQuery happens on all nodes, and ...\n    // doesn't affect searcher re-open on shards w/o expired docs ... can we also verify \n    // that *only* one node is sending the deletes ?\n    // (ie: no flood of redundant deletes?)\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd","date":1594731683,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/DistribDocExpirationUpdateProcessorTest#runTest().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/DistribDocExpirationUpdateProcessorTest#runTest().mjava","sourceNew":"  private void runTest() throws Exception {\n    final int totalNumDocs = atLeast(50);\n    \n    // Add a bunch of docs; some with extremely short expiration, some with no expiration\n    // these should be randomly distributed to each shard\n    long numDocsThatNeverExpire = 0;\n    {\n      final UpdateRequest req = setAuthIfNeeded(new UpdateRequest());\n      for (int i = 1; i <= totalNumDocs; i++) {\n        final SolrInputDocument doc = sdoc(\"id\", i);\n\n        if (random().nextBoolean()) {\n          doc.addField(\"should_expire_s\",\"yup\");\n          doc.addField(\"tTl_s\",\"+1SECONDS\");\n        } else {\n          numDocsThatNeverExpire++;\n        }\n        \n        req.add(doc);\n      }\n      req.commit(cluster.getSolrClient(), COLLECTION);\n    }\n    \n    // NOTE: don't assume we can find exactly totalNumDocs right now, some may have already been deleted...\n    \n    // it should not take long for us to get to the point where all 'should_expire_s:yup' docs are gone\n    waitForNoResults(30, params(\"q\",\"should_expire_s:yup\",\"rows\",\"0\",\"_trace\",\"init_batch_check\"));\n\n    {\n      // ...*NOW* we can assert that exactly numDocsThatNeverExpire should exist...\n      final QueryRequest req = setAuthIfNeeded(new QueryRequest\n                                               (params(\"q\", \"*:*\",\n                                                       \"rows\", \"0\",\n                                                       \"_trace\", \"count_non_expire_docs\")));\n\n      // NOTE: it's possible that replicas could be out of sync but this query may get lucky and\n      // only hit leaders.  we'll compare the counts of every replica in every shard later on...\n      assertEquals(numDocsThatNeverExpire,\n                   req.process(cluster.getSolrClient(), COLLECTION).getResults().getNumFound());\n    }\n    \n    //\n    // now that we've confrmed the basics work, let's check some fine grain stuff...\n    //\n    \n    // first off, sanity check that this special docId doesn't some how already exist\n    waitForNoResults(0, params(\"q\",\"id:special99\",\"rows\",\"0\",\"_trace\",\"sanity_check99\"));\n\n    {\n      // force a hard commit on all shards (the prior auto-expire would have only done a soft commit)\n      // so we can ensure our indexVersion won't change uncessisarily on the un-affected\n      // shard when we add & (hard) commit our special doc...\n      final UpdateRequest req = setAuthIfNeeded(new UpdateRequest());\n      req.commit(cluster.getSolrClient(), COLLECTION);\n    }\n    \n    \n    // record important data for each replica core so we can check later\n    // that it only changes for the replicas of a single shard after we add/expire a single special doc\n    log.info(\"Fetching ReplicaData BEFORE special doc addition/expiration\");\n    final Map<String,ReplicaData> initReplicaData = getTestDataForAllReplicas();\n    assertTrue(\"WTF? no replica data?\", 0 < initReplicaData.size());\n\n    // add & hard commit a special doc with a short TTL \n    setAuthIfNeeded(new UpdateRequest()).add(sdoc(\"id\", \"special99\", \"should_expire_s\",\"yup\",\"tTl_s\",\"+30SECONDS\"))\n      .commit(cluster.getSolrClient(), COLLECTION);\n\n    // wait for our special docId to be deleted\n    waitForNoResults(180, params(\"q\",\"id:special99\",\"rows\",\"0\",\"_trace\",\"did_special_doc_expire_yet\"));\n\n    // now check all of the replicas to verify a few things:\n    // - only the replicas of one shard changed -- no unneccessary churn on other shards\n    // - every replica of each single shard should have the same number of docs\n    // - the total number of docs should match numDocsThatNeverExpire\n    log.info(\"Fetching ReplicaData AFTER special doc addition/expiration\");\n    final Map<String,ReplicaData> finalReplicaData = getTestDataForAllReplicas();\n    assertEquals(\"WTF? not same num replicas?\", \n                 initReplicaData.size(),\n                 finalReplicaData.size());\n\n    final Set<String> coresThatChange = new HashSet<>();\n    final Set<String> shardsThatChange = new HashSet<>();\n    \n    int coresCompared = 0;\n    int totalDocsOnAllShards = 0;\n    final DocCollection collectionState = cluster.getSolrClient().getZkStateReader().getClusterState().getCollection(COLLECTION);\n    for (Slice shard : collectionState) {\n      boolean firstReplica = true;\n      for (Replica replica : shard) {\n        coresCompared++;\n        assertEquals(shard.getName(), replica.getShard()); // sanity check\n        final String core = replica.getCoreName();\n        final ReplicaData initData = initReplicaData.get(core);\n        final ReplicaData finalData = finalReplicaData.get(core);\n        assertNotNull(shard.getName() + \": no init data for core: \" + core, initData);\n        assertNotNull(shard.getName() + \": no final data for core: \" + core, finalData);\n\n        if (!initData.equals(finalData)) {\n          log.error(\"ReplicaData changed: {} != {}\", initData, finalData);\n          coresThatChange.add(core + \"(\"+shard.getName()+\")\");\n          shardsThatChange.add(shard.getName());\n        }\n        \n        if (firstReplica) {\n          totalDocsOnAllShards += finalData.numDocs;\n          firstReplica = false;\n        }\n      }\n    }\n\n    assertEquals(\"Exactly one shard should have changed, instead: \" + shardsThatChange\n                 + \" cores=(\" + coresThatChange + \")\",\n                 1, shardsThatChange.size());\n    assertEquals(\"somehow we missed some cores?\", \n                 initReplicaData.size(), coresCompared);\n\n    assertEquals(\"Final tally has incorrect numDocsThatNeverExpire\",\n                 numDocsThatNeverExpire, totalDocsOnAllShards);\n    \n    // TODO: above logic verifies that deleteByQuery happens on all nodes, and ...\n    // doesn't affect searcher re-open on shards w/o expired docs ... can we also verify \n    // that *only* one node is sending the deletes ?\n    // (ie: no flood of redundant deletes?)\n\n  }\n\n","sourceOld":"  private void runTest() throws Exception {\n    final int totalNumDocs = atLeast(50);\n    \n    // Add a bunch of docs; some with extremely short expiration, some with no expiration\n    // these should be randomly distributed to each shard\n    long numDocsThatNeverExpire = 0;\n    {\n      final UpdateRequest req = setAuthIfNeeded(new UpdateRequest());\n      for (int i = 1; i <= totalNumDocs; i++) {\n        final SolrInputDocument doc = sdoc(\"id\", i);\n\n        if (random().nextBoolean()) {\n          doc.addField(\"should_expire_s\",\"yup\");\n          doc.addField(\"tTl_s\",\"+1SECONDS\");\n        } else {\n          numDocsThatNeverExpire++;\n        }\n        \n        req.add(doc);\n      }\n      req.commit(cluster.getSolrClient(), COLLECTION);\n    }\n    \n    // NOTE: don't assume we can find exactly totalNumDocs right now, some may have already been deleted...\n    \n    // it should not take long for us to get to the point where all 'should_expire_s:yup' docs are gone\n    waitForNoResults(30, params(\"q\",\"should_expire_s:yup\",\"rows\",\"0\",\"_trace\",\"init_batch_check\"));\n\n    {\n      // ...*NOW* we can assert that exactly numDocsThatNeverExpire should exist...\n      final QueryRequest req = setAuthIfNeeded(new QueryRequest\n                                               (params(\"q\", \"*:*\",\n                                                       \"rows\", \"0\",\n                                                       \"_trace\", \"count_non_expire_docs\")));\n\n      // NOTE: it's possible that replicas could be out of sync but this query may get lucky and\n      // only hit leaders.  we'll compare the counts of every replica in every shard later on...\n      assertEquals(numDocsThatNeverExpire,\n                   req.process(cluster.getSolrClient(), COLLECTION).getResults().getNumFound());\n    }\n    \n    //\n    // now that we've confrmed the basics work, let's check some fine grain stuff...\n    //\n    \n    // first off, sanity check that this special docId doesn't some how already exist\n    waitForNoResults(0, params(\"q\",\"id:special99\",\"rows\",\"0\",\"_trace\",\"sanity_check99\"));\n\n    {\n      // force a hard commit on all shards (the prior auto-expire would have only done a soft commit)\n      // so we can ensure our indexVersion won't change uncessisarily on the un-affected\n      // shard when we add & (hard) commit our special doc...\n      final UpdateRequest req = setAuthIfNeeded(new UpdateRequest());\n      req.commit(cluster.getSolrClient(), COLLECTION);\n    }\n    \n    \n    // record important data for each replica core so we can check later\n    // that it only changes for the replicas of a single shard after we add/expire a single special doc\n    log.info(\"Fetching ReplicaData BEFORE special doc addition/expiration\");\n    final Map<String,ReplicaData> initReplicaData = getTestDataForAllReplicas();\n    assertTrue(\"WTF? no replica data?\", 0 < initReplicaData.size());\n\n    // add & hard commit a special doc with a short TTL \n    setAuthIfNeeded(new UpdateRequest()).add(sdoc(\"id\", \"special99\", \"should_expire_s\",\"yup\",\"tTl_s\",\"+30SECONDS\"))\n      .commit(cluster.getSolrClient(), COLLECTION);\n\n    // wait for our special docId to be deleted\n    waitForNoResults(180, params(\"q\",\"id:special99\",\"rows\",\"0\",\"_trace\",\"did_special_doc_expire_yet\"));\n\n    // now check all of the replicas to verify a few things:\n    // - only the replicas of one shard changed -- no unneccessary churn on other shards\n    // - every replica of each single shard should have the same number of docs\n    // - the total number of docs should match numDocsThatNeverExpire\n    log.info(\"Fetching ReplicaData AFTER special doc addition/expiration\");\n    final Map<String,ReplicaData> finalReplicaData = getTestDataForAllReplicas();\n    assertEquals(\"WTF? not same num replicas?\", \n                 initReplicaData.size(),\n                 finalReplicaData.size());\n\n    final Set<String> coresThatChange = new HashSet<>();\n    final Set<String> shardsThatChange = new HashSet<>();\n    \n    int coresCompared = 0;\n    int totalDocsOnAllShards = 0;\n    final DocCollection collectionState = cluster.getSolrClient().getZkStateReader().getClusterState().getCollection(COLLECTION);\n    for (Slice shard : collectionState) {\n      boolean firstReplica = true;\n      for (Replica replica : shard) {\n        coresCompared++;\n        assertEquals(shard.getName(), replica.getSlice()); // sanity check\n        final String core = replica.getCoreName();\n        final ReplicaData initData = initReplicaData.get(core);\n        final ReplicaData finalData = finalReplicaData.get(core);\n        assertNotNull(shard.getName() + \": no init data for core: \" + core, initData);\n        assertNotNull(shard.getName() + \": no final data for core: \" + core, finalData);\n\n        if (!initData.equals(finalData)) {\n          log.error(\"ReplicaData changed: {} != {}\", initData, finalData);\n          coresThatChange.add(core + \"(\"+shard.getName()+\")\");\n          shardsThatChange.add(shard.getName());\n        }\n        \n        if (firstReplica) {\n          totalDocsOnAllShards += finalData.numDocs;\n          firstReplica = false;\n        }\n      }\n    }\n\n    assertEquals(\"Exactly one shard should have changed, instead: \" + shardsThatChange\n                 + \" cores=(\" + coresThatChange + \")\",\n                 1, shardsThatChange.size());\n    assertEquals(\"somehow we missed some cores?\", \n                 initReplicaData.size(), coresCompared);\n\n    assertEquals(\"Final tally has incorrect numDocsThatNeverExpire\",\n                 numDocsThatNeverExpire, totalDocsOnAllShards);\n    \n    // TODO: above logic verifies that deleteByQuery happens on all nodes, and ...\n    // doesn't affect searcher re-open on shards w/o expired docs ... can we also verify \n    // that *only* one node is sending the deletes ?\n    // (ie: no flood of redundant deletes?)\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd":["c92ac83d1c2f8811300bb0df797465cca0aa8e92"],"c92ac83d1c2f8811300bb0df797465cca0aa8e92":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd"]},"commit2Childs":{"7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c92ac83d1c2f8811300bb0df797465cca0aa8e92":["7e8ce2f9d2ddfcf5cfa7e73b8b2af287a2a276fd"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c92ac83d1c2f8811300bb0df797465cca0aa8e92"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}