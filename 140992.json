{"path":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState,Sorter.DocMap,NormsProducer).mjava","commits":[{"id":"622a708571e534680618b3c5e0c28ac539a47776","date":1517406892,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState,Sorter.DocMap,NormsProducer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState,Sorter.DocMap).mjava","sourceNew":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state,\n      Sorter.DocMap sortMap, NormsProducer norms) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap, norms);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.getIndexOptions() != IndexOptions.NONE;\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n    applyDeletes(state, fields);\n    if (sortMap != null) {\n      fields = new SortingLeafReader.SortingFields(fields, state.fieldInfos, sortMap);\n    }\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields, norms);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","sourceOld":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.getIndexOptions() != IndexOptions.NONE;\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n    applyDeletes(state, fields);\n    if (sortMap != null) {\n      fields = new SortingLeafReader.SortingFields(fields, state.fieldInfos, sortMap);\n    }\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d3cc3fa1ecad75b99ec55169e44628808f9866ad","date":1592311545,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState,Sorter.DocMap,NormsProducer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState,Sorter.DocMap,NormsProducer).mjava","sourceNew":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state,\n      Sorter.DocMap sortMap, NormsProducer norms) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap, norms);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.getNumTerms() > 0) {\n        perField.sortTerms();\n        assert perField.indexOptions != IndexOptions.NONE;\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n    applyDeletes(state, fields);\n    if (sortMap != null) {\n      fields = new SortingLeafReader.SortingFields(fields, state.fieldInfos, sortMap);\n    }\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields, norms);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","sourceOld":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state,\n      Sorter.DocMap sortMap, NormsProducer norms) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap, norms);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.bytesHash.size() > 0) {\n        perField.sortPostings();\n        assert perField.fieldInfo.getIndexOptions() != IndexOptions.NONE;\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n    applyDeletes(state, fields);\n    if (sortMap != null) {\n      fields = new SortingLeafReader.SortingFields(fields, state.fieldInfos, sortMap);\n    }\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields, norms);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"19d8bfe2b34f3ba4420efc1f441e4145a2ad6c63","date":1599130480,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState,Sorter.DocMap,NormsProducer).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/FreqProxTermsWriter#flush(Map[String,TermsHashPerField],SegmentWriteState,Sorter.DocMap,NormsProducer).mjava","sourceNew":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state,\n      Sorter.DocMap sortMap, NormsProducer norms) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap, norms);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.getNumTerms() > 0) {\n        perField.sortTerms();\n        assert perField.indexOptions != IndexOptions.NONE;\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n    applyDeletes(state, fields);\n    if (sortMap != null) {\n      final Sorter.DocMap docMap = sortMap;\n      final FieldInfos infos = state.fieldInfos;\n      fields = new FilterLeafReader.FilterFields(fields) {\n\n        @Override\n        public Terms terms(final String field) throws IOException {\n          Terms terms = in.terms(field);\n          if (terms == null) {\n            return null;\n          } else {\n            return new SortingTerms(terms, infos.fieldInfo(field).getIndexOptions(), docMap);\n          }\n        }\n      };\n    }\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields, norms);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","sourceOld":"  @Override\n  public void flush(Map<String,TermsHashPerField> fieldsToFlush, final SegmentWriteState state,\n      Sorter.DocMap sortMap, NormsProducer norms) throws IOException {\n    super.flush(fieldsToFlush, state, sortMap, norms);\n\n    // Gather all fields that saw any postings:\n    List<FreqProxTermsWriterPerField> allFields = new ArrayList<>();\n\n    for (TermsHashPerField f : fieldsToFlush.values()) {\n      final FreqProxTermsWriterPerField perField = (FreqProxTermsWriterPerField) f;\n      if (perField.getNumTerms() > 0) {\n        perField.sortTerms();\n        assert perField.indexOptions != IndexOptions.NONE;\n        allFields.add(perField);\n      }\n    }\n\n    // Sort by field name\n    CollectionUtil.introSort(allFields);\n\n    Fields fields = new FreqProxFields(allFields);\n    applyDeletes(state, fields);\n    if (sortMap != null) {\n      fields = new SortingLeafReader.SortingFields(fields, state.fieldInfos, sortMap);\n    }\n\n    FieldsConsumer consumer = state.segmentInfo.getCodec().postingsFormat().fieldsConsumer(state);\n    boolean success = false;\n    try {\n      consumer.write(fields, norms);\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(consumer);\n      } else {\n        IOUtils.closeWhileHandlingException(consumer);\n      }\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"622a708571e534680618b3c5e0c28ac539a47776":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"19d8bfe2b34f3ba4420efc1f441e4145a2ad6c63":["d3cc3fa1ecad75b99ec55169e44628808f9866ad"],"d3cc3fa1ecad75b99ec55169e44628808f9866ad":["622a708571e534680618b3c5e0c28ac539a47776"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["19d8bfe2b34f3ba4420efc1f441e4145a2ad6c63"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["622a708571e534680618b3c5e0c28ac539a47776"],"622a708571e534680618b3c5e0c28ac539a47776":["d3cc3fa1ecad75b99ec55169e44628808f9866ad"],"19d8bfe2b34f3ba4420efc1f441e4145a2ad6c63":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"d3cc3fa1ecad75b99ec55169e44628808f9866ad":["19d8bfe2b34f3ba4420efc1f441e4145a2ad6c63"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}