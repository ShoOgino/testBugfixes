{"path":"src/java/org/apache/lucene/index/IndexWriter#maybeApplyDeletes(boolean).mjava","commits":[{"id":"42a18cb0bca2c4ac9747f31c7a74fac90c661f39","date":1171363388,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#maybeApplyDeletes(boolean).mjava","pathOld":"src/java/org/apache/lucene/index/NewIndexModifier#doAfterFlushRamSegments(boolean).mjava","sourceNew":"  // Called during flush to apply any buffered deletes.  If\n  // doMerge is true then a new segment was just created and\n  // flushed from the ram segments.\n  private final void maybeApplyDeletes(boolean doMerge) throws IOException {\n\n    if (bufferedDeleteTerms.size() > 0) {\n      if (infoStream != null)\n        infoStream.println(\"flush \" + numBufferedDeleteTerms + \" buffered deleted terms on \"\n                           + segmentInfos.size() + \" segments.\");\n\n      if (doMerge) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(segmentInfos.size() - 1));\n          reader.setDeleter(deleter);\n\n          // Apply delete terms to the segment just flushed from ram\n          // apply appropriately so that a delete term is only applied to\n          // the documents buffered before it, not those buffered after it.\n          applyDeletesSelectively(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null)\n            reader.close();\n        }\n      }\n\n      int infosEnd = segmentInfos.size();\n      if (doMerge) {\n        infosEnd--;\n      }\n\n      for (int i = 0; i < infosEnd; i++) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(i));\n          reader.setDeleter(deleter);\n\n          // Apply delete terms to disk segments\n          // except the one just flushed from ram.\n          applyDeletes(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null)\n            reader.close();\n        }\n      }\n\n      // Clean up bufferedDeleteTerms.\n      bufferedDeleteTerms.clear();\n      numBufferedDeleteTerms = 0;\n    }\n  }\n\n","sourceOld":"  protected void doAfterFlushRamSegments(boolean flushedRamSegments)\n      throws IOException {\n    if (bufferedDeleteTerms.size() > 0) {\n      if (getInfoStream() != null)\n        getInfoStream().println(\n            \"flush \" + numBufferedDeleteTerms + \" buffered terms on \"\n                + segmentInfos.size() + \" segments.\");\n\n      if (flushedRamSegments) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(segmentInfos.size() - 1));\n          reader.setDeleter(getDeleter());\n\n          // apply delete terms to the segment just flushed from ram\n          // apply appropriately so that a delete term is only applied to\n          // the documents buffered before it, not those buffered after it\n          applyDeletesSelectively(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null)\n            reader.close();\n        }\n      }\n\n      int infosEnd = segmentInfos.size();\n      if (flushedRamSegments) {\n        infosEnd--;\n      }\n\n      for (int i = 0; i < infosEnd; i++) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(i));\n          reader.setDeleter(getDeleter());\n\n          // apply delete terms to disk segments\n          // except the one just flushed from ram\n          applyDeletes(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null)\n            reader.close();\n        }\n      }\n\n      // clean up bufferedDeleteTerms\n      bufferedDeleteTerms.clear();\n      numBufferedDeleteTerms = 0;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1b54a9bc667895a2095a886184bf69a3179e63df","date":1172088096,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#maybeApplyDeletes(boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#maybeApplyDeletes(boolean).mjava","sourceNew":"  // Called during flush to apply any buffered deletes.  If\n  // doMerge is true then a new segment was just created and\n  // flushed from the ram segments.\n  private final void maybeApplyDeletes(boolean doMerge) throws CorruptIndexException, IOException {\n\n    if (bufferedDeleteTerms.size() > 0) {\n      if (infoStream != null)\n        infoStream.println(\"flush \" + numBufferedDeleteTerms + \" buffered deleted terms on \"\n                           + segmentInfos.size() + \" segments.\");\n\n      if (doMerge) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(segmentInfos.size() - 1));\n          reader.setDeleter(deleter);\n\n          // Apply delete terms to the segment just flushed from ram\n          // apply appropriately so that a delete term is only applied to\n          // the documents buffered before it, not those buffered after it.\n          applyDeletesSelectively(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null)\n            reader.close();\n        }\n      }\n\n      int infosEnd = segmentInfos.size();\n      if (doMerge) {\n        infosEnd--;\n      }\n\n      for (int i = 0; i < infosEnd; i++) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(i));\n          reader.setDeleter(deleter);\n\n          // Apply delete terms to disk segments\n          // except the one just flushed from ram.\n          applyDeletes(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null)\n            reader.close();\n        }\n      }\n\n      // Clean up bufferedDeleteTerms.\n      bufferedDeleteTerms.clear();\n      numBufferedDeleteTerms = 0;\n    }\n  }\n\n","sourceOld":"  // Called during flush to apply any buffered deletes.  If\n  // doMerge is true then a new segment was just created and\n  // flushed from the ram segments.\n  private final void maybeApplyDeletes(boolean doMerge) throws IOException {\n\n    if (bufferedDeleteTerms.size() > 0) {\n      if (infoStream != null)\n        infoStream.println(\"flush \" + numBufferedDeleteTerms + \" buffered deleted terms on \"\n                           + segmentInfos.size() + \" segments.\");\n\n      if (doMerge) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(segmentInfos.size() - 1));\n          reader.setDeleter(deleter);\n\n          // Apply delete terms to the segment just flushed from ram\n          // apply appropriately so that a delete term is only applied to\n          // the documents buffered before it, not those buffered after it.\n          applyDeletesSelectively(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null)\n            reader.close();\n        }\n      }\n\n      int infosEnd = segmentInfos.size();\n      if (doMerge) {\n        infosEnd--;\n      }\n\n      for (int i = 0; i < infosEnd; i++) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(i));\n          reader.setDeleter(deleter);\n\n          // Apply delete terms to disk segments\n          // except the one just flushed from ram.\n          applyDeletes(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null)\n            reader.close();\n        }\n      }\n\n      // Clean up bufferedDeleteTerms.\n      bufferedDeleteTerms.clear();\n      numBufferedDeleteTerms = 0;\n    }\n  }\n\n","bugFix":["42a18cb0bca2c4ac9747f31c7a74fac90c661f39"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d72db039743bd6a2da9be6306f57c71654ca1bf6","date":1173217255,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#maybeApplyDeletes(boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#maybeApplyDeletes(boolean).mjava","sourceNew":"  // Called during flush to apply any buffered deletes.  If\n  // doMerge is true then a new segment was just created and\n  // flushed from the ram segments.\n  private final void maybeApplyDeletes(boolean doMerge) throws CorruptIndexException, IOException {\n\n    if (bufferedDeleteTerms.size() > 0) {\n      if (infoStream != null)\n        infoStream.println(\"flush \" + numBufferedDeleteTerms + \" buffered deleted terms on \"\n                           + segmentInfos.size() + \" segments.\");\n\n      if (doMerge) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(segmentInfos.size() - 1));\n          reader.setDeleter(deleter);\n\n          // Apply delete terms to the segment just flushed from ram\n          // apply appropriately so that a delete term is only applied to\n          // the documents buffered before it, not those buffered after it.\n          applyDeletesSelectively(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null) {\n            try {\n              reader.doCommit();\n            } finally {\n              reader.doClose();\n            }\n          }\n        }\n      }\n\n      int infosEnd = segmentInfos.size();\n      if (doMerge) {\n        infosEnd--;\n      }\n\n      for (int i = 0; i < infosEnd; i++) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(i));\n          reader.setDeleter(deleter);\n\n          // Apply delete terms to disk segments\n          // except the one just flushed from ram.\n          applyDeletes(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null) {\n            try {\n              reader.doCommit();\n            } finally {\n              reader.doClose();\n            }\n          }\n        }\n      }\n\n      // Clean up bufferedDeleteTerms.\n      bufferedDeleteTerms.clear();\n      numBufferedDeleteTerms = 0;\n    }\n  }\n\n","sourceOld":"  // Called during flush to apply any buffered deletes.  If\n  // doMerge is true then a new segment was just created and\n  // flushed from the ram segments.\n  private final void maybeApplyDeletes(boolean doMerge) throws CorruptIndexException, IOException {\n\n    if (bufferedDeleteTerms.size() > 0) {\n      if (infoStream != null)\n        infoStream.println(\"flush \" + numBufferedDeleteTerms + \" buffered deleted terms on \"\n                           + segmentInfos.size() + \" segments.\");\n\n      if (doMerge) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(segmentInfos.size() - 1));\n          reader.setDeleter(deleter);\n\n          // Apply delete terms to the segment just flushed from ram\n          // apply appropriately so that a delete term is only applied to\n          // the documents buffered before it, not those buffered after it.\n          applyDeletesSelectively(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null)\n            reader.close();\n        }\n      }\n\n      int infosEnd = segmentInfos.size();\n      if (doMerge) {\n        infosEnd--;\n      }\n\n      for (int i = 0; i < infosEnd; i++) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(i));\n          reader.setDeleter(deleter);\n\n          // Apply delete terms to disk segments\n          // except the one just flushed from ram.\n          applyDeletes(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null)\n            reader.close();\n        }\n      }\n\n      // Clean up bufferedDeleteTerms.\n      bufferedDeleteTerms.clear();\n      numBufferedDeleteTerms = 0;\n    }\n  }\n\n","bugFix":["42a18cb0bca2c4ac9747f31c7a74fac90c661f39"],"bugIntro":["5a251aa47d1808cbae42c0e172d698c377430e60"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8b6187898fc4413ccd18229711786550a280383c","date":1173776782,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#maybeApplyDeletes(boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#maybeApplyDeletes(boolean).mjava","sourceNew":"  // Called during flush to apply any buffered deletes.  If\n  // doMerge is true then a new segment was just created and\n  // flushed from the ram segments.\n  private final void maybeApplyDeletes(boolean doMerge) throws CorruptIndexException, IOException {\n\n    if (bufferedDeleteTerms.size() > 0) {\n      if (infoStream != null)\n        infoStream.println(\"flush \" + numBufferedDeleteTerms + \" buffered deleted terms on \"\n                           + segmentInfos.size() + \" segments.\");\n\n      if (doMerge) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(segmentInfos.size() - 1));\n\n          // Apply delete terms to the segment just flushed from ram\n          // apply appropriately so that a delete term is only applied to\n          // the documents buffered before it, not those buffered after it.\n          applyDeletesSelectively(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null) {\n            try {\n              reader.doCommit();\n            } finally {\n              reader.doClose();\n            }\n          }\n        }\n      }\n\n      int infosEnd = segmentInfos.size();\n      if (doMerge) {\n        infosEnd--;\n      }\n\n      for (int i = 0; i < infosEnd; i++) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(i));\n\n          // Apply delete terms to disk segments\n          // except the one just flushed from ram.\n          applyDeletes(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null) {\n            try {\n              reader.doCommit();\n            } finally {\n              reader.doClose();\n            }\n          }\n        }\n      }\n\n      // Clean up bufferedDeleteTerms.\n      bufferedDeleteTerms.clear();\n      numBufferedDeleteTerms = 0;\n    }\n  }\n\n","sourceOld":"  // Called during flush to apply any buffered deletes.  If\n  // doMerge is true then a new segment was just created and\n  // flushed from the ram segments.\n  private final void maybeApplyDeletes(boolean doMerge) throws CorruptIndexException, IOException {\n\n    if (bufferedDeleteTerms.size() > 0) {\n      if (infoStream != null)\n        infoStream.println(\"flush \" + numBufferedDeleteTerms + \" buffered deleted terms on \"\n                           + segmentInfos.size() + \" segments.\");\n\n      if (doMerge) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(segmentInfos.size() - 1));\n          reader.setDeleter(deleter);\n\n          // Apply delete terms to the segment just flushed from ram\n          // apply appropriately so that a delete term is only applied to\n          // the documents buffered before it, not those buffered after it.\n          applyDeletesSelectively(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null) {\n            try {\n              reader.doCommit();\n            } finally {\n              reader.doClose();\n            }\n          }\n        }\n      }\n\n      int infosEnd = segmentInfos.size();\n      if (doMerge) {\n        infosEnd--;\n      }\n\n      for (int i = 0; i < infosEnd; i++) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(i));\n          reader.setDeleter(deleter);\n\n          // Apply delete terms to disk segments\n          // except the one just flushed from ram.\n          applyDeletes(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null) {\n            try {\n              reader.doCommit();\n            } finally {\n              reader.doClose();\n            }\n          }\n        }\n      }\n\n      // Clean up bufferedDeleteTerms.\n      bufferedDeleteTerms.clear();\n      numBufferedDeleteTerms = 0;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4350b17bd363cd13a95171b8df1ca62ea4c3e71c","date":1183562198,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/IndexWriter#applyDeletes(boolean).mjava","pathOld":"src/java/org/apache/lucene/index/IndexWriter#maybeApplyDeletes(boolean).mjava","sourceNew":"  // Called during flush to apply any buffered deletes.  If\n  // flushedNewSegment is true then a new segment was just\n  // created and flushed from the ram segments, so we will\n  // selectively apply the deletes to that new segment.\n  private final void applyDeletes(boolean flushedNewSegment) throws CorruptIndexException, IOException {\n\n    if (bufferedDeleteTerms.size() > 0) {\n      if (infoStream != null)\n        infoStream.println(\"flush \" + numBufferedDeleteTerms + \" buffered deleted terms on \"\n                           + segmentInfos.size() + \" segments.\");\n\n      if (flushedNewSegment) {\n        IndexReader reader = null;\n        try {\n          // Open readers w/o opening the stored fields /\n          // vectors because these files may still be held\n          // open for writing by docWriter\n          reader = SegmentReader.get(segmentInfos.info(segmentInfos.size() - 1), false);\n\n          // Apply delete terms to the segment just flushed from ram\n          // apply appropriately so that a delete term is only applied to\n          // the documents buffered before it, not those buffered after it.\n          applyDeletesSelectively(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null) {\n            try {\n              reader.doCommit();\n            } finally {\n              reader.doClose();\n            }\n          }\n        }\n      }\n\n      int infosEnd = segmentInfos.size();\n      if (flushedNewSegment) {\n        infosEnd--;\n      }\n\n      for (int i = 0; i < infosEnd; i++) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(i), false);\n\n          // Apply delete terms to disk segments\n          // except the one just flushed from ram.\n          applyDeletes(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null) {\n            try {\n              reader.doCommit();\n            } finally {\n              reader.doClose();\n            }\n          }\n        }\n      }\n\n      // Clean up bufferedDeleteTerms.\n      bufferedDeleteTerms.clear();\n      numBufferedDeleteTerms = 0;\n    }\n  }\n\n","sourceOld":"  // Called during flush to apply any buffered deletes.  If\n  // doMerge is true then a new segment was just created and\n  // flushed from the ram segments.\n  private final void maybeApplyDeletes(boolean doMerge) throws CorruptIndexException, IOException {\n\n    if (bufferedDeleteTerms.size() > 0) {\n      if (infoStream != null)\n        infoStream.println(\"flush \" + numBufferedDeleteTerms + \" buffered deleted terms on \"\n                           + segmentInfos.size() + \" segments.\");\n\n      if (doMerge) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(segmentInfos.size() - 1));\n\n          // Apply delete terms to the segment just flushed from ram\n          // apply appropriately so that a delete term is only applied to\n          // the documents buffered before it, not those buffered after it.\n          applyDeletesSelectively(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null) {\n            try {\n              reader.doCommit();\n            } finally {\n              reader.doClose();\n            }\n          }\n        }\n      }\n\n      int infosEnd = segmentInfos.size();\n      if (doMerge) {\n        infosEnd--;\n      }\n\n      for (int i = 0; i < infosEnd; i++) {\n        IndexReader reader = null;\n        try {\n          reader = SegmentReader.get(segmentInfos.info(i));\n\n          // Apply delete terms to disk segments\n          // except the one just flushed from ram.\n          applyDeletes(bufferedDeleteTerms, reader);\n        } finally {\n          if (reader != null) {\n            try {\n              reader.doCommit();\n            } finally {\n              reader.doClose();\n            }\n          }\n        }\n      }\n\n      // Clean up bufferedDeleteTerms.\n      bufferedDeleteTerms.clear();\n      numBufferedDeleteTerms = 0;\n    }\n  }\n\n","bugFix":null,"bugIntro":["fde68de507dbf344495d7b5e8052866fe5f254ab","5a251aa47d1808cbae42c0e172d698c377430e60"],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"42a18cb0bca2c4ac9747f31c7a74fac90c661f39":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1b54a9bc667895a2095a886184bf69a3179e63df":["42a18cb0bca2c4ac9747f31c7a74fac90c661f39"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d72db039743bd6a2da9be6306f57c71654ca1bf6":["1b54a9bc667895a2095a886184bf69a3179e63df"],"8b6187898fc4413ccd18229711786550a280383c":["d72db039743bd6a2da9be6306f57c71654ca1bf6"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["8b6187898fc4413ccd18229711786550a280383c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"]},"commit2Childs":{"42a18cb0bca2c4ac9747f31c7a74fac90c661f39":["1b54a9bc667895a2095a886184bf69a3179e63df"],"1b54a9bc667895a2095a886184bf69a3179e63df":["d72db039743bd6a2da9be6306f57c71654ca1bf6"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["42a18cb0bca2c4ac9747f31c7a74fac90c661f39"],"d72db039743bd6a2da9be6306f57c71654ca1bf6":["8b6187898fc4413ccd18229711786550a280383c"],"8b6187898fc4413ccd18229711786550a280383c":["4350b17bd363cd13a95171b8df1ca62ea4c3e71c"],"4350b17bd363cd13a95171b8df1ca62ea4c3e71c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}