{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilter#generatePart(boolean).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilter#generatePart(boolean).mjava","pathOld":"modules/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilter#generatePart(boolean).mjava","sourceNew":"  /**\n   * Generates a word/number part, updating the appropriate attributes\n   *\n   * @param isSingleWord {@code true} if the generation is occurring from a single word, {@code false} otherwise\n   */\n  private void generatePart(boolean isSingleWord) {\n    clearAttributes();\n    termAttribute.copyBuffer(savedBuffer, iterator.current, iterator.end - iterator.current);\n\n    int startOffset = savedStartOffset + iterator.current;\n    int endOffset = savedStartOffset + iterator.end;\n    \n    if (hasIllegalOffsets) {\n      // historically this filter did this regardless for 'isSingleWord', \n      // but we must do a sanity check:\n      if (isSingleWord && startOffset <= savedEndOffset) {\n        offsetAttribute.setOffset(startOffset, savedEndOffset);\n      } else {\n        offsetAttribute.setOffset(savedStartOffset, savedEndOffset);\n      }\n    } else {\n      offsetAttribute.setOffset(startOffset, endOffset);\n    }\n    posIncAttribute.setPositionIncrement(position(false));\n    typeAttribute.setType(savedType);\n  }\n\n","sourceOld":"  /**\n   * Generates a word/number part, updating the appropriate attributes\n   *\n   * @param isSingleWord {@code true} if the generation is occurring from a single word, {@code false} otherwise\n   */\n  private void generatePart(boolean isSingleWord) {\n    clearAttributes();\n    termAttribute.copyBuffer(savedBuffer, iterator.current, iterator.end - iterator.current);\n\n    int startOffset = savedStartOffset + iterator.current;\n    int endOffset = savedStartOffset + iterator.end;\n    \n    if (hasIllegalOffsets) {\n      // historically this filter did this regardless for 'isSingleWord', \n      // but we must do a sanity check:\n      if (isSingleWord && startOffset <= savedEndOffset) {\n        offsetAttribute.setOffset(startOffset, savedEndOffset);\n      } else {\n        offsetAttribute.setOffset(savedStartOffset, savedEndOffset);\n      }\n    } else {\n      offsetAttribute.setOffset(startOffset, endOffset);\n    }\n    posIncAttribute.setPositionIncrement(position(false));\n    typeAttribute.setType(savedType);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"098528909bb70948871fd7ed865fafb87ed73964","date":1484667487,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilter#generatePart(boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilter#generatePart(boolean).mjava","sourceNew":"  /**\n   * Generates a word/number part, updating the appropriate attributes\n   *\n   * @param isSingleWord {@code true} if the generation is occurring from a single word, {@code false} otherwise\n   */\n  private void generatePart(boolean isSingleWord) {\n    clearAttributes();\n    termAttribute.copyBuffer(savedBuffer, iterator.current, iterator.end - iterator.current);\n    int startOffset = savedStartOffset + iterator.current;\n    int endOffset = savedStartOffset + iterator.end;\n    \n    if (hasIllegalOffsets) {\n      // historically this filter did this regardless for 'isSingleWord', \n      // but we must do a sanity check:\n      if (isSingleWord && startOffset <= savedEndOffset) {\n        offsetAttribute.setOffset(startOffset, savedEndOffset);\n      } else {\n        offsetAttribute.setOffset(savedStartOffset, savedEndOffset);\n      }\n    } else {\n      offsetAttribute.setOffset(startOffset, endOffset);\n    }\n    posIncAttribute.setPositionIncrement(position(false));\n    typeAttribute.setType(savedType);\n  }\n\n","sourceOld":"  /**\n   * Generates a word/number part, updating the appropriate attributes\n   *\n   * @param isSingleWord {@code true} if the generation is occurring from a single word, {@code false} otherwise\n   */\n  private void generatePart(boolean isSingleWord) {\n    clearAttributes();\n    termAttribute.copyBuffer(savedBuffer, iterator.current, iterator.end - iterator.current);\n\n    int startOffset = savedStartOffset + iterator.current;\n    int endOffset = savedStartOffset + iterator.end;\n    \n    if (hasIllegalOffsets) {\n      // historically this filter did this regardless for 'isSingleWord', \n      // but we must do a sanity check:\n      if (isSingleWord && startOffset <= savedEndOffset) {\n        offsetAttribute.setOffset(startOffset, savedEndOffset);\n      } else {\n        offsetAttribute.setOffset(savedStartOffset, savedEndOffset);\n      }\n    } else {\n      offsetAttribute.setOffset(startOffset, endOffset);\n    }\n    posIncAttribute.setPositionIncrement(position(false));\n    typeAttribute.setType(savedType);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"302d34f2c66e8d489ee13078305c330cbf67b226","date":1484754357,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilter#generatePart(boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/miscellaneous/WordDelimiterFilter#generatePart(boolean).mjava","sourceNew":"  /**\n   * Generates a word/number part, updating the appropriate attributes\n   *\n   * @param isSingleWord {@code true} if the generation is occurring from a single word, {@code false} otherwise\n   */\n  private void generatePart(boolean isSingleWord) {\n    clearAttributes();\n    termAttribute.copyBuffer(savedBuffer, iterator.current, iterator.end - iterator.current);\n    int startOffset = savedStartOffset + iterator.current;\n    int endOffset = savedStartOffset + iterator.end;\n    \n    if (hasIllegalOffsets) {\n      // historically this filter did this regardless for 'isSingleWord', \n      // but we must do a sanity check:\n      if (isSingleWord && startOffset <= savedEndOffset) {\n        offsetAttribute.setOffset(startOffset, savedEndOffset);\n      } else {\n        offsetAttribute.setOffset(savedStartOffset, savedEndOffset);\n      }\n    } else {\n      offsetAttribute.setOffset(startOffset, endOffset);\n    }\n    posIncAttribute.setPositionIncrement(position(false));\n    typeAttribute.setType(savedType);\n  }\n\n","sourceOld":"  /**\n   * Generates a word/number part, updating the appropriate attributes\n   *\n   * @param isSingleWord {@code true} if the generation is occurring from a single word, {@code false} otherwise\n   */\n  private void generatePart(boolean isSingleWord) {\n    clearAttributes();\n    termAttribute.copyBuffer(savedBuffer, iterator.current, iterator.end - iterator.current);\n\n    int startOffset = savedStartOffset + iterator.current;\n    int endOffset = savedStartOffset + iterator.end;\n    \n    if (hasIllegalOffsets) {\n      // historically this filter did this regardless for 'isSingleWord', \n      // but we must do a sanity check:\n      if (isSingleWord && startOffset <= savedEndOffset) {\n        offsetAttribute.setOffset(startOffset, savedEndOffset);\n      } else {\n        offsetAttribute.setOffset(savedStartOffset, savedEndOffset);\n      }\n    } else {\n      offsetAttribute.setOffset(startOffset, endOffset);\n    }\n    posIncAttribute.setPositionIncrement(position(false));\n    typeAttribute.setType(savedType);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"098528909bb70948871fd7ed865fafb87ed73964":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["098528909bb70948871fd7ed865fafb87ed73964"],"302d34f2c66e8d489ee13078305c330cbf67b226":["b89678825b68eccaf09e6ab71675fc0b0af1e099","098528909bb70948871fd7ed865fafb87ed73964"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["098528909bb70948871fd7ed865fafb87ed73964","302d34f2c66e8d489ee13078305c330cbf67b226"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"098528909bb70948871fd7ed865fafb87ed73964":["cd5edd1f2b162a5cfa08efd17851a07373a96817","302d34f2c66e8d489ee13078305c330cbf67b226"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"302d34f2c66e8d489ee13078305c330cbf67b226":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","302d34f2c66e8d489ee13078305c330cbf67b226"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}