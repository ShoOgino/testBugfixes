{"path":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40SegmentInfosReader#readSegmentInfo(Directory,int,ChecksumIndexInput).mjava","commits":[{"id":"a0ae5e3ed1232483b7b8a014f175a5fe43595982","date":1324062192,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40SegmentInfosReader#readSegmentInfo(Directory,int,ChecksumIndexInput).mjava","pathOld":"lucene/src/java/org/apache/lucene/index/codecs/lucene40/Lucene40SegmentInfosReader#readSegmentInfo(Directory,int,ChecksumIndexInput).mjava","sourceNew":"  // if we make a preflex impl we can remove a lot of this hair...\n  public SegmentInfo readSegmentInfo(Directory dir, int format, ChecksumIndexInput input) throws IOException {\n    final String version;\n    if (format <= SegmentInfos.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n    final String name = input.readString();\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    if (format > SegmentInfos.FORMAT_4_0) {\n      // pre-4.0 indexes write a byte if there is a single norms file\n      byte b = input.readByte();\n      assert 1 == b;\n    }\n\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        int fieldNumber = j;\n        if (format <= SegmentInfos.FORMAT_4_0) {\n          fieldNumber = input.readInt();\n        }\n\n        normGen.put(fieldNumber, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final int hasProx = input.readByte();\n\n    final Codec codec;\n    // note: if the codec is not available: Codec.forName will throw an exception.\n    if (format <= SegmentInfos.FORMAT_4_0) {\n      codec = Codec.forName(input.readString());\n    } else {\n      codec = Codec.forName(\"Lucene3x\");\n    }\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    final int hasVectors;\n    if (format <= SegmentInfos.FORMAT_HAS_VECTORS) {\n      hasVectors = input.readByte();\n    } else {\n      final String storesSegment;\n      final String ext;\n      final boolean storeIsCompoundFile;\n      if (docStoreOffset != -1) {\n        storesSegment = docStoreSegment;\n        storeIsCompoundFile = docStoreIsCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_STORE_EXTENSION;\n      } else {\n        storesSegment = name;\n        storeIsCompoundFile = isCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_EXTENSION;\n      }\n      final Directory dirToTest;\n      if (storeIsCompoundFile) {\n        dirToTest = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(storesSegment, \"\", ext), IOContext.READONCE, false);\n      } else {\n        dirToTest = dir;\n      }\n      try {\n        // TODO: remove this manual file check or push to preflex codec\n        hasVectors = dirToTest.fileExists(IndexFileNames.segmentFileName(storesSegment, \"\", Lucene40TermVectorsReader.VECTORS_INDEX_EXTENSION)) ? SegmentInfo.YES : SegmentInfo.NO;\n      } finally {\n        if (isCompoundFile) {\n          dirToTest.close();\n        }\n      }\n    }\n    \n    return new SegmentInfo(dir, version, name, docCount, delGen, docStoreOffset,\n      docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n      delCount, hasProx, codec, diagnostics, hasVectors);\n  }\n\n","sourceOld":"  // if we make a preflex impl we can remove a lot of this hair...\n  public SegmentInfo readSegmentInfo(Directory dir, int format, ChecksumIndexInput input) throws IOException {\n    final String version;\n    if (format <= SegmentInfos.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n    final String name = input.readString();\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    if (format > SegmentInfos.FORMAT_4_0) {\n      // pre-4.0 indexes write a byte if there is a single norms file\n      byte b = input.readByte();\n      assert 1 == b;\n    }\n\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        int fieldNumber = j;\n        if (format <= SegmentInfos.FORMAT_4_0) {\n          fieldNumber = input.readInt();\n        }\n\n        normGen.put(fieldNumber, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final int hasProx = input.readByte();\n\n    final Codec codec;\n    // note: if the codec is not available: Codec.forName will throw an exception.\n    if (format <= SegmentInfos.FORMAT_4_0) {\n      codec = Codec.forName(input.readString());\n    } else {\n      codec = Codec.forName(\"Lucene3x\");\n    }\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    final int hasVectors;\n    if (format <= SegmentInfos.FORMAT_HAS_VECTORS) {\n      hasVectors = input.readByte();\n    } else {\n      final String storesSegment;\n      final String ext;\n      final boolean storeIsCompoundFile;\n      if (docStoreOffset != -1) {\n        storesSegment = docStoreSegment;\n        storeIsCompoundFile = docStoreIsCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_STORE_EXTENSION;\n      } else {\n        storesSegment = name;\n        storeIsCompoundFile = isCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_EXTENSION;\n      }\n      final Directory dirToTest;\n      if (storeIsCompoundFile) {\n        dirToTest = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(storesSegment, \"\", ext), IOContext.READONCE, false);\n      } else {\n        dirToTest = dir;\n      }\n      try {\n        // TODO: remove this manual file check or push to preflex codec\n        hasVectors = dirToTest.fileExists(IndexFileNames.segmentFileName(storesSegment, \"\", Lucene40TermVectorsReader.VECTORS_INDEX_EXTENSION)) ? SegmentInfo.YES : SegmentInfo.NO;\n      } finally {\n        if (isCompoundFile) {\n          dirToTest.close();\n        }\n      }\n    }\n    \n    return new SegmentInfo(dir, version, name, docCount, delGen, docStoreOffset,\n      docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n      delCount, hasProx, codec, diagnostics, hasVectors);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7e0127a0bf2a1895ba6109cbbd451359b9c0653d","date":1326981970,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40SegmentInfosReader#readSegmentInfo(Directory,int,ChecksumIndexInput).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40SegmentInfosReader#readSegmentInfo(Directory,int,ChecksumIndexInput).mjava","sourceNew":"  public SegmentInfo readSegmentInfo(Directory dir, int format, ChecksumIndexInput input) throws IOException {\n    final String version = input.readString();\n    final String name = input.readString();\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    // this is still written in 4.0 if we open a 3.x and upgrade the SI\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) { \n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(input.readInt(), input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n    final int hasProx = input.readByte();\n    final Codec codec = Codec.forName(input.readString());\n    final Map<String,String> diagnostics = input.readStringStringMap();\n    final int hasVectors = input.readByte();\n    \n    return new SegmentInfo(dir, version, name, docCount, delGen, docStoreOffset,\n      docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n      delCount, hasProx, codec, diagnostics, hasVectors);\n  }\n\n","sourceOld":"  // if we make a preflex impl we can remove a lot of this hair...\n  public SegmentInfo readSegmentInfo(Directory dir, int format, ChecksumIndexInput input) throws IOException {\n    final String version;\n    if (format <= SegmentInfos.FORMAT_3_1) {\n      version = input.readString();\n    } else {\n      version = null;\n    }\n    final String name = input.readString();\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) {\n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n\n    if (format > SegmentInfos.FORMAT_4_0) {\n      // pre-4.0 indexes write a byte if there is a single norms file\n      byte b = input.readByte();\n      assert 1 == b;\n    }\n\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        int fieldNumber = j;\n        if (format <= SegmentInfos.FORMAT_4_0) {\n          fieldNumber = input.readInt();\n        }\n\n        normGen.put(fieldNumber, input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n\n    final int hasProx = input.readByte();\n\n    final Codec codec;\n    // note: if the codec is not available: Codec.forName will throw an exception.\n    if (format <= SegmentInfos.FORMAT_4_0) {\n      codec = Codec.forName(input.readString());\n    } else {\n      codec = Codec.forName(\"Lucene3x\");\n    }\n    final Map<String,String> diagnostics = input.readStringStringMap();\n\n    final int hasVectors;\n    if (format <= SegmentInfos.FORMAT_HAS_VECTORS) {\n      hasVectors = input.readByte();\n    } else {\n      final String storesSegment;\n      final String ext;\n      final boolean storeIsCompoundFile;\n      if (docStoreOffset != -1) {\n        storesSegment = docStoreSegment;\n        storeIsCompoundFile = docStoreIsCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_STORE_EXTENSION;\n      } else {\n        storesSegment = name;\n        storeIsCompoundFile = isCompoundFile;\n        ext = IndexFileNames.COMPOUND_FILE_EXTENSION;\n      }\n      final Directory dirToTest;\n      if (storeIsCompoundFile) {\n        dirToTest = new CompoundFileDirectory(dir, IndexFileNames.segmentFileName(storesSegment, \"\", ext), IOContext.READONCE, false);\n      } else {\n        dirToTest = dir;\n      }\n      try {\n        // TODO: remove this manual file check or push to preflex codec\n        hasVectors = dirToTest.fileExists(IndexFileNames.segmentFileName(storesSegment, \"\", Lucene40TermVectorsReader.VECTORS_INDEX_EXTENSION)) ? SegmentInfo.YES : SegmentInfo.NO;\n      } finally {\n        if (isCompoundFile) {\n          dirToTest.close();\n        }\n      }\n    }\n    \n    return new SegmentInfo(dir, version, name, docCount, delGen, docStoreOffset,\n      docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n      delCount, hasProx, codec, diagnostics, hasVectors);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/Lucene40SegmentInfosReader#readSegmentInfo(Directory,int,ChecksumIndexInput).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene40/Lucene40SegmentInfosReader#readSegmentInfo(Directory,int,ChecksumIndexInput).mjava","sourceNew":"  public SegmentInfo readSegmentInfo(Directory dir, int format, ChecksumIndexInput input) throws IOException {\n    final String version = input.readString();\n    final String name = input.readString();\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    // this is still written in 4.0 if we open a 3.x and upgrade the SI\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) { \n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(input.readInt(), input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n    final int hasProx = input.readByte();\n    final Codec codec = Codec.forName(input.readString());\n    final Map<String,String> diagnostics = input.readStringStringMap();\n    final int hasVectors = input.readByte();\n    \n    return new SegmentInfo(dir, version, name, docCount, delGen, docStoreOffset,\n      docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n      delCount, hasProx, codec, diagnostics, hasVectors);\n  }\n\n","sourceOld":"  public SegmentInfo readSegmentInfo(Directory dir, int format, ChecksumIndexInput input) throws IOException {\n    final String version = input.readString();\n    final String name = input.readString();\n    final int docCount = input.readInt();\n    final long delGen = input.readLong();\n    // this is still written in 4.0 if we open a 3.x and upgrade the SI\n    final int docStoreOffset = input.readInt();\n    final String docStoreSegment;\n    final boolean docStoreIsCompoundFile;\n    if (docStoreOffset != -1) { \n      docStoreSegment = input.readString();\n      docStoreIsCompoundFile = input.readByte() == SegmentInfo.YES;\n    } else {\n      docStoreSegment = name;\n      docStoreIsCompoundFile = false;\n    }\n    final int numNormGen = input.readInt();\n    final Map<Integer,Long> normGen;\n    if (numNormGen == SegmentInfo.NO) {\n      normGen = null;\n    } else {\n      normGen = new HashMap<Integer, Long>();\n      for(int j=0;j<numNormGen;j++) {\n        normGen.put(input.readInt(), input.readLong());\n      }\n    }\n    final boolean isCompoundFile = input.readByte() == SegmentInfo.YES;\n\n    final int delCount = input.readInt();\n    assert delCount <= docCount;\n    final int hasProx = input.readByte();\n    final Codec codec = Codec.forName(input.readString());\n    final Map<String,String> diagnostics = input.readStringStringMap();\n    final int hasVectors = input.readByte();\n    \n    return new SegmentInfo(dir, version, name, docCount, delGen, docStoreOffset,\n      docStoreSegment, docStoreIsCompoundFile, normGen, isCompoundFile,\n      delCount, hasProx, codec, diagnostics, hasVectors);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["7e0127a0bf2a1895ba6109cbbd451359b9c0653d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7e0127a0bf2a1895ba6109cbbd451359b9c0653d":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"]},"commit2Childs":{"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0ae5e3ed1232483b7b8a014f175a5fe43595982"],"7e0127a0bf2a1895ba6109cbbd451359b9c0653d":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"a0ae5e3ed1232483b7b8a014f175a5fe43595982":["7e0127a0bf2a1895ba6109cbbd451359b9c0653d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}