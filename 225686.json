{"path":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","pathOld":"lucene/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","sourceNew":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, false);\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, \n        newIndexWriterConfig( Version.LUCENE_40, stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newField(\"field\", \"the stop words are here\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random, query,searcher);\n\n\n    // StopAnalyzer as of 2.4 does not leave \"holes\", so this matches.\n    query = new PhraseQuery();\n    query.add(new Term(\"field\", \"words\"));\n    query.add(new Term(\"field\", \"here\"));\n    hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random, query,searcher);\n\n\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, false);\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, \n        newIndexWriterConfig( Version.LUCENE_40, stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newField(\"field\", \"the stop words are here\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random, query,searcher);\n\n\n    // StopAnalyzer as of 2.4 does not leave \"holes\", so this matches.\n    query = new PhraseQuery();\n    query.add(new Term(\"field\", \"words\"));\n    query.add(new Term(\"field\", \"here\"));\n    hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random, query,searcher);\n\n\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","sourceNew":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, false);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig( Version.LUCENE_40, stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newField(\"field\", \"the stop words are here\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n\n    // StopAnalyzer as of 2.4 does not leave \"holes\", so this matches.\n    query = new PhraseQuery();\n    query.add(new Term(\"field\", \"words\"));\n    query.add(new Term(\"field\", \"here\"));\n    hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random, MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, false);\n    RandomIndexWriter writer = new RandomIndexWriter(random, directory, \n        newIndexWriterConfig( Version.LUCENE_40, stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newField(\"field\", \"the stop words are here\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random, query,searcher);\n\n\n    // StopAnalyzer as of 2.4 does not leave \"holes\", so this matches.\n    query = new PhraseQuery();\n    query.add(new Term(\"field\", \"words\"));\n    query.add(new Term(\"field\", \"here\"));\n    hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random, query,searcher);\n\n\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","sourceNew":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, false);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig( Version.LUCENE_40, stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the stop words are here\", Field.Store.YES));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n\n    // StopAnalyzer as of 2.4 does not leave \"holes\", so this matches.\n    query = new PhraseQuery();\n    query.add(new Term(\"field\", \"words\"));\n    query.add(new Term(\"field\", \"here\"));\n    hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, false);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig( Version.LUCENE_40, stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newField(\"field\", \"the stop words are here\", TextField.TYPE_STORED));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n\n    // StopAnalyzer as of 2.4 does not leave \"holes\", so this matches.\n    query = new PhraseQuery();\n    query.add(new Term(\"field\", \"words\"));\n    query.add(new Term(\"field\", \"here\"));\n    hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"eafa8c5eabc3dacd34680054e6a33bda024080ac","date":1367691488,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","sourceNew":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig( Version.LUCENE_40, stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the stop words are here\", Field.Store.YES));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET, false);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig( Version.LUCENE_40, stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the stop words are here\", Field.Store.YES));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n\n    // StopAnalyzer as of 2.4 does not leave \"holes\", so this matches.\n    query = new PhraseQuery();\n    query.add(new Term(\"field\", \"words\"));\n    query.add(new Term(\"field\", \"here\"));\n    hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0bf41419d452997826ec5f17684993377be77f49","date":1386629618,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","sourceNew":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the stop words are here\", Field.Store.YES));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig( Version.LUCENE_40, stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the stop words are here\", Field.Store.YES));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":["4e8cc373c801e54cec75daf9f52792cb4b17f536"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"74f45af4339b0daf7a95c820ab88c1aea74fbce0","date":1387475327,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","sourceNew":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the stop words are here\", Field.Store.YES));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig( Version.LUCENE_40, stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the stop words are here\", Field.Store.YES));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","sourceNew":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the stop words are here\", Field.Store.YES));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the stop words are here\", Field.Store.YES));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","sourceNew":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig(stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the stop words are here\", Field.Store.YES));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig(TEST_VERSION_CURRENT, stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the stop words are here\", Field.Store.YES));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","sourceNew":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig(stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the stop words are here\", Field.Store.YES));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig(stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the stop words are here\", Field.Store.YES));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","date":1424799790,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","sourceNew":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig(stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the stop words are here\", Field.Store.YES));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig(stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the stop words are here\", Field.Store.YES));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, null, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e9e1499c5d26c936238506df90a3c02c76707722","date":1434449920,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/search/TestPhraseQuery#testPhraseQueryWithStopAnalyzer().mjava","sourceNew":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig(stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the stop words are here\", Field.Store.YES));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery(\"field\", \"stop\", \"words\");\n    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n    reader.close();\n    directory.close();\n  }\n\n","sourceOld":"  public void testPhraseQueryWithStopAnalyzer() throws Exception {\n    Directory directory = newDirectory();\n    Analyzer stopAnalyzer = new MockAnalyzer(random(), MockTokenizer.SIMPLE, true, MockTokenFilter.ENGLISH_STOPSET);\n    RandomIndexWriter writer = new RandomIndexWriter(random(), directory, \n        newIndexWriterConfig(stopAnalyzer));\n    Document doc = new Document();\n    doc.add(newTextField(\"field\", \"the stop words are here\", Field.Store.YES));\n    writer.addDocument(doc);\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    IndexSearcher searcher = newSearcher(reader);\n\n    // valid exact phrase query\n    PhraseQuery query = new PhraseQuery();\n    query.add(new Term(\"field\",\"stop\"));\n    query.add(new Term(\"field\",\"words\"));\n    ScoreDoc[] hits = searcher.search(query, 1000).scoreDocs;\n    assertEquals(1, hits.length);\n    QueryUtils.check(random(), query,searcher);\n\n    reader.close();\n    directory.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"eafa8c5eabc3dacd34680054e6a33bda024080ac":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"0bf41419d452997826ec5f17684993377be77f49":["eafa8c5eabc3dacd34680054e6a33bda024080ac"],"e9e1499c5d26c936238506df90a3c02c76707722":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":["eafa8c5eabc3dacd34680054e6a33bda024080ac","0bf41419d452997826ec5f17684993377be77f49"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["0bf41419d452997826ec5f17684993377be77f49"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e9e1499c5d26c936238506df90a3c02c76707722"]},"commit2Childs":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"eafa8c5eabc3dacd34680054e6a33bda024080ac":["0bf41419d452997826ec5f17684993377be77f49","74f45af4339b0daf7a95c820ab88c1aea74fbce0"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["eafa8c5eabc3dacd34680054e6a33bda024080ac"],"0bf41419d452997826ec5f17684993377be77f49":["74f45af4339b0daf7a95c820ab88c1aea74fbce0","ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"e9e1499c5d26c936238506df90a3c02c76707722":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["e9e1499c5d26c936238506df90a3c02c76707722"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"74f45af4339b0daf7a95c820ab88c1aea74fbce0":[],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["74f45af4339b0daf7a95c820ab88c1aea74fbce0","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}