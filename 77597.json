{"path":"src/test/org/apache/lucene/search/TestSearchHitsWithDeletions#doTestSearchHitsDeleteEvery(int,boolean).mjava","commits":[{"id":"c2c83c79d9533a60d006b2de372c8726d203ff53","date":1198443029,"type":0,"author":"Doron Cohen","isMerge":false,"pathNew":"src/test/org/apache/lucene/search/TestSearchHitsWithDeletions#doTestSearchHitsDeleteEvery(int,boolean).mjava","pathOld":"/dev/null","sourceNew":"  private void doTestSearchHitsDeleteEvery(int k, boolean deleteInFront) throws Exception {\n    boolean intermittent = k<0;\n    log(\"Test search hits with \"+(intermittent ? \"intermittent deletions.\" : \"deletions of every \"+k+\" hit.\"));\n    IndexSearcher searcher = new IndexSearcher(directory);\n    IndexReader reader = searcher.getIndexReader();\n    Query q = new TermQuery(new Term(TEXT_FIELD,\"text\")); // matching all docs\n    Hits hits = searcher.search(q);\n    log(\"Got \"+hits.length()+\" results\");\n    assertEquals(\"must match all \"+N+\" docs, not only \"+hits.length()+\" docs!\",N,hits.length());\n    if (deleteInFront) {\n      log(\"deleting hits that was not yet retrieved!\");\n      reader.deleteDocument(reader.maxDoc()-1);\n      reader.deleteDocument(reader.maxDoc()-2);\n      reader.deleteDocument(reader.maxDoc()-3);\n    }\n    try {\n      for (int i = 0; i < hits.length(); i++) {\n        int id = hits.id(i);\n        assertEquals(\"Hit \"+i+\" has doc id \"+hits.id(i)+\" instead of \"+i,i,hits.id(i));\n        if ((intermittent && (i==50 || i==250 || i==950)) || //100-yes, 200-no, 400-yes, 800-no, 1600-yes \n            (!intermittent && (k<2 || (i>0 && i%k==0)))) {\n          Document doc = hits.doc(id);\n          log(\"Deleting hit \"+i+\" - doc \"+doc+\" with id \"+id);\n          reader.deleteDocument(id);\n        }\n        if (intermittent) {\n          // check internal behavior of Hits (go 50 ahead of getMoreDocs points because the deletions cause to use more of the available hits)\n          if (i==150 || i==450 || i==1650) {\n            assertTrue(\"Hit \"+i+\": hits should have checked for deletions in last call to getMoreDocs()\",hits.debugCheckedForDeletions);\n          } else if (i==50 || i==250 || i==850) {\n            assertFalse(\"Hit \"+i+\": hits should have NOT checked for deletions in last call to getMoreDocs()\",hits.debugCheckedForDeletions);\n          }\n        }\n      }\n    } catch (ConcurrentModificationException e) {\n      // this is the only valid exception, and only when deletng in front.\n      assertTrue(e.getMessage()+\" not expected unless deleting hits that were not yet seen!\",deleteInFront);\n    }\n    searcher.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e8d1458a2543cbd30cbfe7929be4dcb5c5251659","date":1254582241,"type":4,"author":"Uwe Schindler","isMerge":false,"pathNew":"/dev/null","pathOld":"src/test/org/apache/lucene/search/TestSearchHitsWithDeletions#doTestSearchHitsDeleteEvery(int,boolean).mjava","sourceNew":null,"sourceOld":"  private void doTestSearchHitsDeleteEvery(int k, boolean deleteInFront) throws Exception {\n    boolean intermittent = k<0;\n    log(\"Test search hits with \"+(intermittent ? \"intermittent deletions.\" : \"deletions of every \"+k+\" hit.\"));\n    IndexSearcher searcher = new IndexSearcher(directory);\n    IndexReader reader = searcher.getIndexReader();\n    Query q = new TermQuery(new Term(TEXT_FIELD,\"text\")); // matching all docs\n    Hits hits = searcher.search(q);\n    log(\"Got \"+hits.length()+\" results\");\n    assertEquals(\"must match all \"+N+\" docs, not only \"+hits.length()+\" docs!\",N,hits.length());\n    if (deleteInFront) {\n      log(\"deleting hits that was not yet retrieved!\");\n      reader.deleteDocument(reader.maxDoc()-1);\n      reader.deleteDocument(reader.maxDoc()-2);\n      reader.deleteDocument(reader.maxDoc()-3);\n    }\n    try {\n      for (int i = 0; i < hits.length(); i++) {\n        int id = hits.id(i);\n        assertEquals(\"Hit \"+i+\" has doc id \"+hits.id(i)+\" instead of \"+i,i,hits.id(i));\n        if ((intermittent && (i==50 || i==250 || i==950)) || //100-yes, 200-no, 400-yes, 800-no, 1600-yes \n            (!intermittent && (k<2 || (i>0 && i%k==0)))) {\n          Document doc = hits.doc(id);\n          log(\"Deleting hit \"+i+\" - doc \"+doc+\" with id \"+id);\n          reader.deleteDocument(id);\n        }\n        if (intermittent) {\n          // check internal behavior of Hits (go 50 ahead of getMoreDocs points because the deletions cause to use more of the available hits)\n          if (i==150 || i==450 || i==1650) {\n            assertTrue(\"Hit \"+i+\": hits should have checked for deletions in last call to getMoreDocs()\",hits.debugCheckedForDeletions);\n          } else if (i==50 || i==250 || i==850) {\n            assertFalse(\"Hit \"+i+\": hits should have NOT checked for deletions in last call to getMoreDocs()\",hits.debugCheckedForDeletions);\n          }\n        }\n      }\n    } catch (ConcurrentModificationException e) {\n      // this is the only valid exception, and only when deletng in front.\n      assertTrue(e.getMessage()+\" not expected unless deleting hits that were not yet seen!\",deleteInFront);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a046c0c310bc77931fc8441bd920053b607dd14","date":1254584734,"type":4,"author":"Uwe Schindler","isMerge":true,"pathNew":"/dev/null","pathOld":"src/test/org/apache/lucene/search/TestSearchHitsWithDeletions#doTestSearchHitsDeleteEvery(int,boolean).mjava","sourceNew":null,"sourceOld":"  private void doTestSearchHitsDeleteEvery(int k, boolean deleteInFront) throws Exception {\n    boolean intermittent = k<0;\n    log(\"Test search hits with \"+(intermittent ? \"intermittent deletions.\" : \"deletions of every \"+k+\" hit.\"));\n    IndexSearcher searcher = new IndexSearcher(directory);\n    IndexReader reader = searcher.getIndexReader();\n    Query q = new TermQuery(new Term(TEXT_FIELD,\"text\")); // matching all docs\n    Hits hits = searcher.search(q);\n    log(\"Got \"+hits.length()+\" results\");\n    assertEquals(\"must match all \"+N+\" docs, not only \"+hits.length()+\" docs!\",N,hits.length());\n    if (deleteInFront) {\n      log(\"deleting hits that was not yet retrieved!\");\n      reader.deleteDocument(reader.maxDoc()-1);\n      reader.deleteDocument(reader.maxDoc()-2);\n      reader.deleteDocument(reader.maxDoc()-3);\n    }\n    try {\n      for (int i = 0; i < hits.length(); i++) {\n        int id = hits.id(i);\n        assertEquals(\"Hit \"+i+\" has doc id \"+hits.id(i)+\" instead of \"+i,i,hits.id(i));\n        if ((intermittent && (i==50 || i==250 || i==950)) || //100-yes, 200-no, 400-yes, 800-no, 1600-yes \n            (!intermittent && (k<2 || (i>0 && i%k==0)))) {\n          Document doc = hits.doc(id);\n          log(\"Deleting hit \"+i+\" - doc \"+doc+\" with id \"+id);\n          reader.deleteDocument(id);\n        }\n        if (intermittent) {\n          // check internal behavior of Hits (go 50 ahead of getMoreDocs points because the deletions cause to use more of the available hits)\n          if (i==150 || i==450 || i==1650) {\n            assertTrue(\"Hit \"+i+\": hits should have checked for deletions in last call to getMoreDocs()\",hits.debugCheckedForDeletions);\n          } else if (i==50 || i==250 || i==850) {\n            assertFalse(\"Hit \"+i+\": hits should have NOT checked for deletions in last call to getMoreDocs()\",hits.debugCheckedForDeletions);\n          }\n        }\n      }\n    } catch (ConcurrentModificationException e) {\n      // this is the only valid exception, and only when deletng in front.\n      assertTrue(e.getMessage()+\" not expected unless deleting hits that were not yet seen!\",deleteInFront);\n    }\n    searcher.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e8d1458a2543cbd30cbfe7929be4dcb5c5251659":["c2c83c79d9533a60d006b2de372c8726d203ff53"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0a046c0c310bc77931fc8441bd920053b607dd14":["c2c83c79d9533a60d006b2de372c8726d203ff53","e8d1458a2543cbd30cbfe7929be4dcb5c5251659"],"c2c83c79d9533a60d006b2de372c8726d203ff53":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0a046c0c310bc77931fc8441bd920053b607dd14"]},"commit2Childs":{"e8d1458a2543cbd30cbfe7929be4dcb5c5251659":["0a046c0c310bc77931fc8441bd920053b607dd14"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c2c83c79d9533a60d006b2de372c8726d203ff53"],"0a046c0c310bc77931fc8441bd920053b607dd14":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c2c83c79d9533a60d006b2de372c8726d203ff53":["e8d1458a2543cbd30cbfe7929be4dcb5c5251659","0a046c0c310bc77931fc8441bd920053b607dd14"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}