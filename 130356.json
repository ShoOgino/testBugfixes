{"path":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#slowGrouping(GroupDoc[],String,boolean,boolean,boolean,Sort,Sort,int,int,int,int).mjava","commits":[{"id":"04c370507e5521b2eb998530736f1c19b851ed5a","date":1531911305,"type":1,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#slowGrouping(GroupDoc[],String,boolean,boolean,boolean,Sort,Sort,int,int,int,int).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#slowGrouping(GroupDoc[],String,boolean,boolean,boolean,boolean,Sort,Sort,int,int,int,int).mjava","sourceNew":"  private TopGroups<BytesRef> slowGrouping(GroupDoc[] groupDocs,\n                                           String searchTerm,\n                                           boolean getScores,\n                                           boolean getMaxScores,\n                                           boolean doAllGroups,\n                                           Sort groupSort,\n                                           Sort docSort,\n                                           int topNGroups,\n                                           int docsPerGroup,\n                                           int groupOffset,\n                                           int docOffset) {\n\n    final Comparator<GroupDoc> groupSortComp = getComparator(groupSort);\n\n    Arrays.sort(groupDocs, groupSortComp);\n    final HashMap<BytesRef,List<GroupDoc>> groups = new HashMap<>();\n    final List<BytesRef> sortedGroups = new ArrayList<>();\n    final List<Comparable<?>[]> sortedGroupFields = new ArrayList<>();\n\n    int totalHitCount = 0;\n    Set<BytesRef> knownGroups = new HashSet<>();\n\n    //System.out.println(\"TEST: slowGrouping\");\n    for(GroupDoc d : groupDocs) {\n      // TODO: would be better to filter by searchTerm before sorting!\n      if (!d.content.startsWith(searchTerm)) {\n        continue;\n      }\n      totalHitCount++;\n      //System.out.println(\"  match id=\" + d.id + \" score=\" + d.score);\n\n      if (doAllGroups) {\n        if (!knownGroups.contains(d.group)) {\n          knownGroups.add(d.group);\n          //System.out.println(\"    add group=\" + groupToString(d.group));\n        }\n      }\n\n      List<GroupDoc> l = groups.get(d.group);\n      if (l == null) {\n        //System.out.println(\"    add sortedGroup=\" + groupToString(d.group));\n        sortedGroups.add(d.group);\n        sortedGroupFields.add(fillFields(d, groupSort));\n        l = new ArrayList<>();\n        groups.put(d.group, l);\n      }\n      l.add(d);\n    }\n\n    if (groupOffset >= sortedGroups.size()) {\n      // slice is out of bounds\n      return null;\n    }\n\n    final int limit = Math.min(groupOffset + topNGroups, groups.size());\n\n    final Comparator<GroupDoc> docSortComp = getComparator(docSort);\n    @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n    final GroupDocs<BytesRef>[] result = new GroupDocs[limit-groupOffset];\n    int totalGroupedHitCount = 0;\n    for(int idx=groupOffset;idx < limit;idx++) {\n      final BytesRef group = sortedGroups.get(idx);\n      final List<GroupDoc> docs = groups.get(group);\n      totalGroupedHitCount += docs.size();\n      Collections.sort(docs, docSortComp);\n      final ScoreDoc[] hits;\n      if (docs.size() > docOffset) {\n        final int docIDXLimit = Math.min(docOffset + docsPerGroup, docs.size());\n        hits = new ScoreDoc[docIDXLimit - docOffset];\n        for(int docIDX=docOffset; docIDX < docIDXLimit; docIDX++) {\n          final GroupDoc d = docs.get(docIDX);\n          final FieldDoc fd;\n          fd = new FieldDoc(d.id, getScores ? d.score : Float.NaN, fillFields(d, docSort));\n          hits[docIDX-docOffset] = fd;\n        }\n      } else  {\n        hits = new ScoreDoc[0];\n      }\n\n      result[idx-groupOffset] = new GroupDocs<>(Float.NaN,\n                                                        0.0f,\n                                                        docs.size(),\n                                                        hits,\n                                                        group,\n                                                        sortedGroupFields.get(idx));\n    }\n\n    if (doAllGroups) {\n      return new TopGroups<>(\n        new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN),\n          knownGroups.size()\n      );\n    } else {\n      return new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN);\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> slowGrouping(GroupDoc[] groupDocs,\n                                           String searchTerm,\n                                           boolean fillFields,\n                                           boolean getScores,\n                                           boolean getMaxScores,\n                                           boolean doAllGroups,\n                                           Sort groupSort,\n                                           Sort docSort,\n                                           int topNGroups,\n                                           int docsPerGroup,\n                                           int groupOffset,\n                                           int docOffset) {\n\n    final Comparator<GroupDoc> groupSortComp = getComparator(groupSort);\n\n    Arrays.sort(groupDocs, groupSortComp);\n    final HashMap<BytesRef,List<GroupDoc>> groups = new HashMap<>();\n    final List<BytesRef> sortedGroups = new ArrayList<>();\n    final List<Comparable<?>[]> sortedGroupFields = new ArrayList<>();\n\n    int totalHitCount = 0;\n    Set<BytesRef> knownGroups = new HashSet<>();\n\n    //System.out.println(\"TEST: slowGrouping\");\n    for(GroupDoc d : groupDocs) {\n      // TODO: would be better to filter by searchTerm before sorting!\n      if (!d.content.startsWith(searchTerm)) {\n        continue;\n      }\n      totalHitCount++;\n      //System.out.println(\"  match id=\" + d.id + \" score=\" + d.score);\n\n      if (doAllGroups) {\n        if (!knownGroups.contains(d.group)) {\n          knownGroups.add(d.group);\n          //System.out.println(\"    add group=\" + groupToString(d.group));\n        }\n      }\n\n      List<GroupDoc> l = groups.get(d.group);\n      if (l == null) {\n        //System.out.println(\"    add sortedGroup=\" + groupToString(d.group));\n        sortedGroups.add(d.group);\n        if (fillFields) {\n          sortedGroupFields.add(fillFields(d, groupSort));\n        }\n        l = new ArrayList<>();\n        groups.put(d.group, l);\n      }\n      l.add(d);\n    }\n\n    if (groupOffset >= sortedGroups.size()) {\n      // slice is out of bounds\n      return null;\n    }\n\n    final int limit = Math.min(groupOffset + topNGroups, groups.size());\n\n    final Comparator<GroupDoc> docSortComp = getComparator(docSort);\n    @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n    final GroupDocs<BytesRef>[] result = new GroupDocs[limit-groupOffset];\n    int totalGroupedHitCount = 0;\n    for(int idx=groupOffset;idx < limit;idx++) {\n      final BytesRef group = sortedGroups.get(idx);\n      final List<GroupDoc> docs = groups.get(group);\n      totalGroupedHitCount += docs.size();\n      Collections.sort(docs, docSortComp);\n      final ScoreDoc[] hits;\n      if (docs.size() > docOffset) {\n        final int docIDXLimit = Math.min(docOffset + docsPerGroup, docs.size());\n        hits = new ScoreDoc[docIDXLimit - docOffset];\n        for(int docIDX=docOffset; docIDX < docIDXLimit; docIDX++) {\n          final GroupDoc d = docs.get(docIDX);\n          final FieldDoc fd;\n          if (fillFields) {\n            fd = new FieldDoc(d.id, getScores ? d.score : Float.NaN, fillFields(d, docSort));\n          } else {\n            fd = new FieldDoc(d.id, getScores ? d.score : Float.NaN);\n          }\n          hits[docIDX-docOffset] = fd;\n        }\n      } else  {\n        hits = new ScoreDoc[0];\n      }\n\n      result[idx-groupOffset] = new GroupDocs<>(Float.NaN,\n                                                        0.0f,\n                                                        docs.size(),\n                                                        hits,\n                                                        group,\n                                                        fillFields ? sortedGroupFields.get(idx) : null);\n    }\n\n    if (doAllGroups) {\n      return new TopGroups<>(\n        new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN),\n          knownGroups.size()\n      );\n    } else {\n      return new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d3f7ab1a502671bbdb03bcced21e764d2483221","date":1532329609,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#slowGrouping(GroupDoc[],String,boolean,boolean,Sort,Sort,int,int,int,int).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#slowGrouping(GroupDoc[],String,boolean,boolean,boolean,Sort,Sort,int,int,int,int).mjava","sourceNew":"  private TopGroups<BytesRef> slowGrouping(GroupDoc[] groupDocs,\n                                           String searchTerm,\n                                           boolean getMaxScores,\n                                           boolean doAllGroups,\n                                           Sort groupSort,\n                                           Sort docSort,\n                                           int topNGroups,\n                                           int docsPerGroup,\n                                           int groupOffset,\n                                           int docOffset) {\n\n    final Comparator<GroupDoc> groupSortComp = getComparator(groupSort);\n\n    Arrays.sort(groupDocs, groupSortComp);\n    final HashMap<BytesRef,List<GroupDoc>> groups = new HashMap<>();\n    final List<BytesRef> sortedGroups = new ArrayList<>();\n    final List<Comparable<?>[]> sortedGroupFields = new ArrayList<>();\n\n    int totalHitCount = 0;\n    Set<BytesRef> knownGroups = new HashSet<>();\n\n    //System.out.println(\"TEST: slowGrouping\");\n    for(GroupDoc d : groupDocs) {\n      // TODO: would be better to filter by searchTerm before sorting!\n      if (!d.content.startsWith(searchTerm)) {\n        continue;\n      }\n      totalHitCount++;\n      //System.out.println(\"  match id=\" + d.id + \" score=\" + d.score);\n\n      if (doAllGroups) {\n        if (!knownGroups.contains(d.group)) {\n          knownGroups.add(d.group);\n          //System.out.println(\"    add group=\" + groupToString(d.group));\n        }\n      }\n\n      List<GroupDoc> l = groups.get(d.group);\n      if (l == null) {\n        //System.out.println(\"    add sortedGroup=\" + groupToString(d.group));\n        sortedGroups.add(d.group);\n        sortedGroupFields.add(fillFields(d, groupSort));\n        l = new ArrayList<>();\n        groups.put(d.group, l);\n      }\n      l.add(d);\n    }\n\n    if (groupOffset >= sortedGroups.size()) {\n      // slice is out of bounds\n      return null;\n    }\n\n    final int limit = Math.min(groupOffset + topNGroups, groups.size());\n\n    final Comparator<GroupDoc> docSortComp = getComparator(docSort);\n    @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n    final GroupDocs<BytesRef>[] result = new GroupDocs[limit-groupOffset];\n    int totalGroupedHitCount = 0;\n    for(int idx=groupOffset;idx < limit;idx++) {\n      final BytesRef group = sortedGroups.get(idx);\n      final List<GroupDoc> docs = groups.get(group);\n      totalGroupedHitCount += docs.size();\n      Collections.sort(docs, docSortComp);\n      final ScoreDoc[] hits;\n      if (docs.size() > docOffset) {\n        final int docIDXLimit = Math.min(docOffset + docsPerGroup, docs.size());\n        hits = new ScoreDoc[docIDXLimit - docOffset];\n        for(int docIDX=docOffset; docIDX < docIDXLimit; docIDX++) {\n          final GroupDoc d = docs.get(docIDX);\n          final FieldDoc fd;\n          fd = new FieldDoc(d.id, Float.NaN, fillFields(d, docSort));\n          hits[docIDX-docOffset] = fd;\n        }\n      } else  {\n        hits = new ScoreDoc[0];\n      }\n\n      result[idx-groupOffset] = new GroupDocs<>(Float.NaN,\n                                                        0.0f,\n                                                        docs.size(),\n                                                        hits,\n                                                        group,\n                                                        sortedGroupFields.get(idx));\n    }\n\n    if (doAllGroups) {\n      return new TopGroups<>(\n        new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN),\n          knownGroups.size()\n      );\n    } else {\n      return new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN);\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> slowGrouping(GroupDoc[] groupDocs,\n                                           String searchTerm,\n                                           boolean getScores,\n                                           boolean getMaxScores,\n                                           boolean doAllGroups,\n                                           Sort groupSort,\n                                           Sort docSort,\n                                           int topNGroups,\n                                           int docsPerGroup,\n                                           int groupOffset,\n                                           int docOffset) {\n\n    final Comparator<GroupDoc> groupSortComp = getComparator(groupSort);\n\n    Arrays.sort(groupDocs, groupSortComp);\n    final HashMap<BytesRef,List<GroupDoc>> groups = new HashMap<>();\n    final List<BytesRef> sortedGroups = new ArrayList<>();\n    final List<Comparable<?>[]> sortedGroupFields = new ArrayList<>();\n\n    int totalHitCount = 0;\n    Set<BytesRef> knownGroups = new HashSet<>();\n\n    //System.out.println(\"TEST: slowGrouping\");\n    for(GroupDoc d : groupDocs) {\n      // TODO: would be better to filter by searchTerm before sorting!\n      if (!d.content.startsWith(searchTerm)) {\n        continue;\n      }\n      totalHitCount++;\n      //System.out.println(\"  match id=\" + d.id + \" score=\" + d.score);\n\n      if (doAllGroups) {\n        if (!knownGroups.contains(d.group)) {\n          knownGroups.add(d.group);\n          //System.out.println(\"    add group=\" + groupToString(d.group));\n        }\n      }\n\n      List<GroupDoc> l = groups.get(d.group);\n      if (l == null) {\n        //System.out.println(\"    add sortedGroup=\" + groupToString(d.group));\n        sortedGroups.add(d.group);\n        sortedGroupFields.add(fillFields(d, groupSort));\n        l = new ArrayList<>();\n        groups.put(d.group, l);\n      }\n      l.add(d);\n    }\n\n    if (groupOffset >= sortedGroups.size()) {\n      // slice is out of bounds\n      return null;\n    }\n\n    final int limit = Math.min(groupOffset + topNGroups, groups.size());\n\n    final Comparator<GroupDoc> docSortComp = getComparator(docSort);\n    @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n    final GroupDocs<BytesRef>[] result = new GroupDocs[limit-groupOffset];\n    int totalGroupedHitCount = 0;\n    for(int idx=groupOffset;idx < limit;idx++) {\n      final BytesRef group = sortedGroups.get(idx);\n      final List<GroupDoc> docs = groups.get(group);\n      totalGroupedHitCount += docs.size();\n      Collections.sort(docs, docSortComp);\n      final ScoreDoc[] hits;\n      if (docs.size() > docOffset) {\n        final int docIDXLimit = Math.min(docOffset + docsPerGroup, docs.size());\n        hits = new ScoreDoc[docIDXLimit - docOffset];\n        for(int docIDX=docOffset; docIDX < docIDXLimit; docIDX++) {\n          final GroupDoc d = docs.get(docIDX);\n          final FieldDoc fd;\n          fd = new FieldDoc(d.id, getScores ? d.score : Float.NaN, fillFields(d, docSort));\n          hits[docIDX-docOffset] = fd;\n        }\n      } else  {\n        hits = new ScoreDoc[0];\n      }\n\n      result[idx-groupOffset] = new GroupDocs<>(Float.NaN,\n                                                        0.0f,\n                                                        docs.size(),\n                                                        hits,\n                                                        group,\n                                                        sortedGroupFields.get(idx));\n    }\n\n    if (doAllGroups) {\n      return new TopGroups<>(\n        new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN),\n          knownGroups.size()\n      );\n    } else {\n      return new TopGroups<>(groupSort.getSort(), docSort.getSort(), totalHitCount, totalGroupedHitCount, result, Float.NaN);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"04c370507e5521b2eb998530736f1c19b851ed5a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["1d3f7ab1a502671bbdb03bcced21e764d2483221"],"1d3f7ab1a502671bbdb03bcced21e764d2483221":["04c370507e5521b2eb998530736f1c19b851ed5a"]},"commit2Childs":{"04c370507e5521b2eb998530736f1c19b851ed5a":["1d3f7ab1a502671bbdb03bcced21e764d2483221"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["04c370507e5521b2eb998530736f1c19b851ed5a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"1d3f7ab1a502671bbdb03bcced21e764d2483221":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}