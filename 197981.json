{"path":"solr/test-framework/src/java/org/apache/solr/util/SolrSecurityManager#checkExec(String).mjava","commits":[{"id":"cf4186ad2efcdebf9859a7b14723a280571c6587","date":1575575603,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"solr/test-framework/src/java/org/apache/solr/util/SolrSecurityManager#checkExec(String).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/util/TestSecurityManager#checkExec(String).mjava","sourceNew":"  // TODO: move this stuff into a Solr (non-test) SecurityManager!\n  /**\n   * {@inheritDoc}\n   * <p>This method implements hacks to workaround hadoop's garbage Shell and FileUtil code\n   */\n  @Override\n  public void checkExec(String cmd) {\n    // NOTE: it would be tempting to just allow anything from hadoop's Shell class, but then\n    // that would just give an easy vector for RCE (use hadoop Shell instead of e.g. ProcessBuilder)\n    // so we whitelist actual caller impl methods instead.\n    for (StackTraceElement element : Thread.currentThread().getStackTrace()) {\n      // hadoop insists on shelling out to get the user's supplementary groups?\n      if (\"org.apache.hadoop.security.ShellBasedUnixGroupsMapping\".equals(element.getClassName()) &&\n          \"getGroups\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'df' command instead of using FileStore?\n      if (\"org.apache.hadoop.fs.DF\".equals(element.getClassName()) &&\n          \"getFilesystem\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'du' command instead of using FileStore?\n      if (\"org.apache.hadoop.fs.DU\".equals(element.getClassName()) &&\n          \"refresh\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'ls' command instead of java nio apis?\n      if (\"org.apache.hadoop.util.DiskChecker\".equals(element.getClassName()) &&\n          \"checkDir\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'stat' command instead of Files.getAttributes?\n      if (\"org.apache.hadoop.fs.HardLink\".equals(element.getClassName()) &&\n          \"getLinkCount\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop \"canExecute\" method doesn't handle securityexception and fails completely.\n      // so, lie to it, and tell it we will happily execute, so it does not crash.\n      if (\"org.apache.hadoop.fs.FileUtil\".equals(element.getClassName()) &&\n          \"canExecute\".equals(element.getMethodName())) {\n        return;\n      }\n    }\n    super.checkExec(cmd);\n  }\n\n","sourceOld":"  // TODO: move this stuff into a Solr (non-test) SecurityManager!\n  /**\n   * {@inheritDoc}\n   * <p>This method implements hacks to workaround hadoop's garbage Shell and FileUtil code\n   */\n  @Override\n  public void checkExec(String cmd) {\n    // NOTE: it would be tempting to just allow anything from hadoop's Shell class, but then\n    // that would just give an easy vector for RCE (use hadoop Shell instead of e.g. ProcessBuilder)\n    // so we whitelist actual caller impl methods instead.\n    for (StackTraceElement element : Thread.currentThread().getStackTrace()) {\n      // hadoop insists on shelling out to get the user's supplementary groups?\n      if (\"org.apache.hadoop.security.ShellBasedUnixGroupsMapping\".equals(element.getClassName()) &&\n          \"getGroups\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'df' command instead of using FileStore?\n      if (\"org.apache.hadoop.fs.DF\".equals(element.getClassName()) &&\n          \"getFilesystem\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'du' command instead of using FileStore?\n      if (\"org.apache.hadoop.fs.DU\".equals(element.getClassName()) &&\n          \"refresh\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'ls' command instead of java nio apis?\n      if (\"org.apache.hadoop.util.DiskChecker\".equals(element.getClassName()) &&\n          \"checkDir\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'stat' command instead of Files.getAttributes?\n      if (\"org.apache.hadoop.fs.HardLink\".equals(element.getClassName()) &&\n          \"getLinkCount\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop \"canExecute\" method doesn't handle securityexception and fails completely.\n      // so, lie to it, and tell it we will happily execute, so it does not crash.\n      if (\"org.apache.hadoop.fs.FileUtil\".equals(element.getClassName()) &&\n          \"canExecute\".equals(element.getMethodName())) {\n        return;\n      }\n    }\n    super.checkExec(cmd);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2c173aec5dba4a880e26706e8ca1ec9e67b74ed5","date":1575629849,"type":1,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/test-framework/src/java/org/apache/solr/util/SolrSecurityManager#checkExec(String).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/util/TestSecurityManager#checkExec(String).mjava","sourceNew":"  // TODO: move this stuff into a Solr (non-test) SecurityManager!\n  /**\n   * {@inheritDoc}\n   * <p>This method implements hacks to workaround hadoop's garbage Shell and FileUtil code\n   */\n  @Override\n  public void checkExec(String cmd) {\n    // NOTE: it would be tempting to just allow anything from hadoop's Shell class, but then\n    // that would just give an easy vector for RCE (use hadoop Shell instead of e.g. ProcessBuilder)\n    // so we whitelist actual caller impl methods instead.\n    for (StackTraceElement element : Thread.currentThread().getStackTrace()) {\n      // hadoop insists on shelling out to get the user's supplementary groups?\n      if (\"org.apache.hadoop.security.ShellBasedUnixGroupsMapping\".equals(element.getClassName()) &&\n          \"getGroups\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'df' command instead of using FileStore?\n      if (\"org.apache.hadoop.fs.DF\".equals(element.getClassName()) &&\n          \"getFilesystem\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'du' command instead of using FileStore?\n      if (\"org.apache.hadoop.fs.DU\".equals(element.getClassName()) &&\n          \"refresh\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'ls' command instead of java nio apis?\n      if (\"org.apache.hadoop.util.DiskChecker\".equals(element.getClassName()) &&\n          \"checkDir\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'stat' command instead of Files.getAttributes?\n      if (\"org.apache.hadoop.fs.HardLink\".equals(element.getClassName()) &&\n          \"getLinkCount\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop \"canExecute\" method doesn't handle securityexception and fails completely.\n      // so, lie to it, and tell it we will happily execute, so it does not crash.\n      if (\"org.apache.hadoop.fs.FileUtil\".equals(element.getClassName()) &&\n          \"canExecute\".equals(element.getMethodName())) {\n        return;\n      }\n    }\n    super.checkExec(cmd);\n  }\n\n","sourceOld":"  // TODO: move this stuff into a Solr (non-test) SecurityManager!\n  /**\n   * {@inheritDoc}\n   * <p>This method implements hacks to workaround hadoop's garbage Shell and FileUtil code\n   */\n  @Override\n  public void checkExec(String cmd) {\n    // NOTE: it would be tempting to just allow anything from hadoop's Shell class, but then\n    // that would just give an easy vector for RCE (use hadoop Shell instead of e.g. ProcessBuilder)\n    // so we whitelist actual caller impl methods instead.\n    for (StackTraceElement element : Thread.currentThread().getStackTrace()) {\n      // hadoop insists on shelling out to get the user's supplementary groups?\n      if (\"org.apache.hadoop.security.ShellBasedUnixGroupsMapping\".equals(element.getClassName()) &&\n          \"getGroups\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'df' command instead of using FileStore?\n      if (\"org.apache.hadoop.fs.DF\".equals(element.getClassName()) &&\n          \"getFilesystem\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'du' command instead of using FileStore?\n      if (\"org.apache.hadoop.fs.DU\".equals(element.getClassName()) &&\n          \"refresh\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'ls' command instead of java nio apis?\n      if (\"org.apache.hadoop.util.DiskChecker\".equals(element.getClassName()) &&\n          \"checkDir\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'stat' command instead of Files.getAttributes?\n      if (\"org.apache.hadoop.fs.HardLink\".equals(element.getClassName()) &&\n          \"getLinkCount\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop \"canExecute\" method doesn't handle securityexception and fails completely.\n      // so, lie to it, and tell it we will happily execute, so it does not crash.\n      if (\"org.apache.hadoop.fs.FileUtil\".equals(element.getClassName()) &&\n          \"canExecute\".equals(element.getMethodName())) {\n        return;\n      }\n    }\n    super.checkExec(cmd);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6bdf107cf16be0f22504ae184fed81596665a244","date":1576012524,"type":4,"author":"Kevin Risden","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/test-framework/src/java/org/apache/solr/util/SolrSecurityManager#checkExec(String).mjava","sourceNew":null,"sourceOld":"  // TODO: move this stuff into a Solr (non-test) SecurityManager!\n  /**\n   * {@inheritDoc}\n   * <p>This method implements hacks to workaround hadoop's garbage Shell and FileUtil code\n   */\n  @Override\n  public void checkExec(String cmd) {\n    // NOTE: it would be tempting to just allow anything from hadoop's Shell class, but then\n    // that would just give an easy vector for RCE (use hadoop Shell instead of e.g. ProcessBuilder)\n    // so we whitelist actual caller impl methods instead.\n    for (StackTraceElement element : Thread.currentThread().getStackTrace()) {\n      // hadoop insists on shelling out to get the user's supplementary groups?\n      if (\"org.apache.hadoop.security.ShellBasedUnixGroupsMapping\".equals(element.getClassName()) &&\n          \"getGroups\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'df' command instead of using FileStore?\n      if (\"org.apache.hadoop.fs.DF\".equals(element.getClassName()) &&\n          \"getFilesystem\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'du' command instead of using FileStore?\n      if (\"org.apache.hadoop.fs.DU\".equals(element.getClassName()) &&\n          \"refresh\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'ls' command instead of java nio apis?\n      if (\"org.apache.hadoop.util.DiskChecker\".equals(element.getClassName()) &&\n          \"checkDir\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'stat' command instead of Files.getAttributes?\n      if (\"org.apache.hadoop.fs.HardLink\".equals(element.getClassName()) &&\n          \"getLinkCount\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop \"canExecute\" method doesn't handle securityexception and fails completely.\n      // so, lie to it, and tell it we will happily execute, so it does not crash.\n      if (\"org.apache.hadoop.fs.FileUtil\".equals(element.getClassName()) &&\n          \"canExecute\".equals(element.getMethodName())) {\n        return;\n      }\n    }\n    super.checkExec(cmd);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a229cb50768e988c50a2106bdae3a92154f428bf","date":1576051038,"type":4,"author":"Dawid Weiss","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/test-framework/src/java/org/apache/solr/util/SolrSecurityManager#checkExec(String).mjava","sourceNew":null,"sourceOld":"  // TODO: move this stuff into a Solr (non-test) SecurityManager!\n  /**\n   * {@inheritDoc}\n   * <p>This method implements hacks to workaround hadoop's garbage Shell and FileUtil code\n   */\n  @Override\n  public void checkExec(String cmd) {\n    // NOTE: it would be tempting to just allow anything from hadoop's Shell class, but then\n    // that would just give an easy vector for RCE (use hadoop Shell instead of e.g. ProcessBuilder)\n    // so we whitelist actual caller impl methods instead.\n    for (StackTraceElement element : Thread.currentThread().getStackTrace()) {\n      // hadoop insists on shelling out to get the user's supplementary groups?\n      if (\"org.apache.hadoop.security.ShellBasedUnixGroupsMapping\".equals(element.getClassName()) &&\n          \"getGroups\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'df' command instead of using FileStore?\n      if (\"org.apache.hadoop.fs.DF\".equals(element.getClassName()) &&\n          \"getFilesystem\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'du' command instead of using FileStore?\n      if (\"org.apache.hadoop.fs.DU\".equals(element.getClassName()) &&\n          \"refresh\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'ls' command instead of java nio apis?\n      if (\"org.apache.hadoop.util.DiskChecker\".equals(element.getClassName()) &&\n          \"checkDir\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop insists on shelling out to parse 'stat' command instead of Files.getAttributes?\n      if (\"org.apache.hadoop.fs.HardLink\".equals(element.getClassName()) &&\n          \"getLinkCount\".equals(element.getMethodName())) {\n        return;\n      }\n      // hadoop \"canExecute\" method doesn't handle securityexception and fails completely.\n      // so, lie to it, and tell it we will happily execute, so it does not crash.\n      if (\"org.apache.hadoop.fs.FileUtil\".equals(element.getClassName()) &&\n          \"canExecute\".equals(element.getMethodName())) {\n        return;\n      }\n    }\n    super.checkExec(cmd);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a229cb50768e988c50a2106bdae3a92154f428bf":["2c173aec5dba4a880e26706e8ca1ec9e67b74ed5","6bdf107cf16be0f22504ae184fed81596665a244"],"cf4186ad2efcdebf9859a7b14723a280571c6587":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"6bdf107cf16be0f22504ae184fed81596665a244":["cf4186ad2efcdebf9859a7b14723a280571c6587"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2c173aec5dba4a880e26706e8ca1ec9e67b74ed5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","cf4186ad2efcdebf9859a7b14723a280571c6587"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["6bdf107cf16be0f22504ae184fed81596665a244"]},"commit2Childs":{"a229cb50768e988c50a2106bdae3a92154f428bf":[],"cf4186ad2efcdebf9859a7b14723a280571c6587":["6bdf107cf16be0f22504ae184fed81596665a244","2c173aec5dba4a880e26706e8ca1ec9e67b74ed5"],"2c173aec5dba4a880e26706e8ca1ec9e67b74ed5":["a229cb50768e988c50a2106bdae3a92154f428bf"],"6bdf107cf16be0f22504ae184fed81596665a244":["a229cb50768e988c50a2106bdae3a92154f428bf","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cf4186ad2efcdebf9859a7b14723a280571c6587","2c173aec5dba4a880e26706e8ca1ec9e67b74ed5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a229cb50768e988c50a2106bdae3a92154f428bf","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}