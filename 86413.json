{"path":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testNoDupCommitFileNames().mjava","commits":[{"id":"83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87","date":1328967626,"type":1,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testNoDupCommitFileNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestIndexReader#testNoDupCommitFileNames().mjava","sourceNew":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n  \n    Directory dir = newDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = DirectoryReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<String>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n  \n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n\n    Directory dir = newDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = DirectoryReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<String>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testNoDupCommitFileNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testNoDupCommitFileNames().mjava","sourceNew":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n  \n    Directory dir = newDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = DirectoryReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<String>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n  \n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n  \n    Directory dir = newDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random))\n        .setMaxBufferedDocs(2));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = DirectoryReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<String>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n  \n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testNoDupCommitFileNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testNoDupCommitFileNames().mjava","sourceNew":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n  \n    Directory dir = newDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = DirectoryReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n  \n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n  \n    Directory dir = newDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = DirectoryReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<String>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n  \n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testNoDupCommitFileNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testNoDupCommitFileNames().mjava","sourceNew":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n  \n    Directory dir = newDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.shutdown();\n    \n    Collection<IndexCommit> commits = DirectoryReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n  \n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n  \n    Directory dir = newDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = DirectoryReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n  \n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testNoDupCommitFileNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testNoDupCommitFileNames().mjava","sourceNew":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n  \n    Directory dir = newDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.shutdown();\n    \n    Collection<IndexCommit> commits = DirectoryReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n  \n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n  \n    Directory dir = newDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(\n        TEST_VERSION_CURRENT, new MockAnalyzer(random()))\n        .setMaxBufferedDocs(2));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.shutdown();\n    \n    Collection<IndexCommit> commits = DirectoryReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n  \n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testNoDupCommitFileNames().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDirectoryReader#testNoDupCommitFileNames().mjava","sourceNew":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n  \n    Directory dir = newDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.close();\n    \n    Collection<IndexCommit> commits = DirectoryReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n  \n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-1509\n  public void testNoDupCommitFileNames() throws Throwable {\n  \n    Directory dir = newDirectory();\n    \n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random()))\n                                                .setMaxBufferedDocs(2));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.addDocument(createDocument(\"a\"));\n    writer.shutdown();\n    \n    Collection<IndexCommit> commits = DirectoryReader.listCommits(dir);\n    for (final IndexCommit commit : commits) {\n      Collection<String> files = commit.getFileNames();\n      HashSet<String> seen = new HashSet<>();\n      for (final String fileName : files) { \n        assertTrue(\"file \" + fileName + \" was duplicated\", !seen.contains(fileName));\n        seen.add(fileName);\n      }\n    }\n  \n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d0ef034a4f10871667ae75181537775ddcf8ade4"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["83e99d44c4a660a48c0fcc7a0108ad0a56dc2f87"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}