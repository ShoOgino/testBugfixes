{"path":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processRestoreAction(ZkNodeProps,NamedList).mjava","commits":[{"id":"c5c99ad021f3da085fcb66220598a8f91dc5e453","date":1462242046,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processRestoreAction(ZkNodeProps,NamedList).mjava","pathOld":"/dev/null","sourceNew":"  private void processRestoreAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME); // of backup\n    String location = message.getStr(\"location\");\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = new HashMap<>();\n\n    Path backupPath = Paths.get(location).resolve(backupName).toAbsolutePath();\n    if (!Files.exists(backupPath)) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't restore since doesn't exist: \" + backupPath);\n    }\n    Path backupZkPath =  backupPath.resolve(\"zk_backup\");\n\n    Properties properties = new Properties();\n    try (Reader in = Files.newBufferedReader(backupPath.resolve(\"backup.properties\"), StandardCharsets.UTF_8)) {\n      properties.load(in);\n    }\n\n    String backupCollection = (String) properties.get(\"collection\");\n    byte[] data = Files.readAllBytes(backupZkPath.resolve(\"collection_state.json\"));\n    ClusterState backupClusterState = ClusterState.load(-1, data, Collections.emptySet());\n    DocCollection backupCollectionState = backupClusterState.getCollection(backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      zkStateReader.getConfigManager().uploadConfigDir(backupZkPath.resolve(\"configs\").resolve(configName), restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        backupPath);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String,Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      createCollection(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice: restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      addPropertyParams(message, propMap);\n\n      addReplica(clusterState, new ZkNodeProps(propMap), new NamedList());\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice: restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(\"location\", backupPath.toString());\n      sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice: restoreCollection.getSlices()) {\n        for(int i=1; i<numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          addPropertyParams(message, propMap);\n\n          addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["d18dd44acd824af8b51a5994c9475b32b094fb76","d18dd44acd824af8b51a5994c9475b32b094fb76","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","69e6520a21709190413a63084ed135271aab1a7c","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1c7a21395bae9e2f61aeb639f47aaca771c426ed","date":1462255690,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processRestoreAction(ZkNodeProps,NamedList).mjava","pathOld":"/dev/null","sourceNew":"  private void processRestoreAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME); // of backup\n    String location = message.getStr(\"location\");\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = new HashMap<>();\n\n    Path backupPath = Paths.get(location).resolve(backupName).toAbsolutePath();\n    if (!Files.exists(backupPath)) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't restore since doesn't exist: \" + backupPath);\n    }\n    Path backupZkPath =  backupPath.resolve(\"zk_backup\");\n\n    Properties properties = new Properties();\n    try (Reader in = Files.newBufferedReader(backupPath.resolve(\"backup.properties\"), StandardCharsets.UTF_8)) {\n      properties.load(in);\n    }\n\n    String backupCollection = (String) properties.get(\"collection\");\n    byte[] data = Files.readAllBytes(backupZkPath.resolve(\"collection_state.json\"));\n    ClusterState backupClusterState = ClusterState.load(-1, data, Collections.emptySet());\n    DocCollection backupCollectionState = backupClusterState.getCollection(backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      zkStateReader.getConfigManager().uploadConfigDir(backupZkPath.resolve(\"configs\").resolve(configName), restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        backupPath);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String,Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      createCollection(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice: restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      addPropertyParams(message, propMap);\n\n      addReplica(clusterState, new ZkNodeProps(propMap), new NamedList());\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice: restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(\"location\", backupPath.toString());\n      sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice: restoreCollection.getSlices()) {\n        for(int i=1; i<numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          addPropertyParams(message, propMap);\n\n          addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"55b50463286869f584cf849d1587a0fcd54d1dfa","date":1462378517,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processRestoreAction(ZkNodeProps,NamedList).mjava","pathOld":"/dev/null","sourceNew":"  private void processRestoreAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME); // of backup\n    String location = message.getStr(\"location\");\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = new HashMap<>();\n\n    Path backupPath = Paths.get(location).resolve(backupName).toAbsolutePath();\n    if (!Files.exists(backupPath)) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't restore since doesn't exist: \" + backupPath);\n    }\n    Path backupZkPath =  backupPath.resolve(\"zk_backup\");\n\n    Properties properties = new Properties();\n    try (Reader in = Files.newBufferedReader(backupPath.resolve(\"backup.properties\"), StandardCharsets.UTF_8)) {\n      properties.load(in);\n    }\n\n    String backupCollection = (String) properties.get(\"collection\");\n    byte[] data = Files.readAllBytes(backupZkPath.resolve(\"collection_state.json\"));\n    ClusterState backupClusterState = ClusterState.load(-1, data, Collections.emptySet());\n    DocCollection backupCollectionState = backupClusterState.getCollection(backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      zkStateReader.getConfigManager().uploadConfigDir(backupZkPath.resolve(\"configs\").resolve(configName), restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        backupPath);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String,Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      createCollection(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice: restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      addPropertyParams(message, propMap);\n\n      addReplica(clusterState, new ZkNodeProps(propMap), new NamedList());\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice: restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(\"location\", backupPath.toString());\n      sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice: restoreCollection.getSlices()) {\n        for(int i=1; i<numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          addPropertyParams(message, propMap);\n\n          addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b","date":1466705968,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processRestoreAction(ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processRestoreAction(ZkNodeProps,NamedList).mjava","sourceNew":"  private void processRestoreAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME); // of backup\n    String location = message.getStr(ZkStateReader.BACKUP_LOCATION);\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = new HashMap<>();\n\n    Path backupPath = Paths.get(location).resolve(backupName).toAbsolutePath();\n    if (!Files.exists(backupPath)) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't restore since doesn't exist: \" + backupPath);\n    }\n    Path backupZkPath =  backupPath.resolve(\"zk_backup\");\n\n    Properties properties = new Properties();\n    try (Reader in = Files.newBufferedReader(backupPath.resolve(\"backup.properties\"), StandardCharsets.UTF_8)) {\n      properties.load(in);\n    }\n\n    String backupCollection = (String) properties.get(\"collection\");\n    byte[] data = Files.readAllBytes(backupZkPath.resolve(\"collection_state.json\"));\n    ClusterState backupClusterState = ClusterState.load(-1, data, Collections.emptySet());\n    DocCollection backupCollectionState = backupClusterState.getCollection(backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      zkStateReader.getConfigManager().uploadConfigDir(backupZkPath.resolve(\"configs\").resolve(configName), restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        backupPath);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String,Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      createCollection(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice: restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      addPropertyParams(message, propMap);\n\n      addReplica(clusterState, new ZkNodeProps(propMap), new NamedList());\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice: restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(\"location\", backupPath.toString());\n      sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice: restoreCollection.getSlices()) {\n        for(int i=1; i<numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          addPropertyParams(message, propMap);\n\n          addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  private void processRestoreAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME); // of backup\n    String location = message.getStr(\"location\");\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = new HashMap<>();\n\n    Path backupPath = Paths.get(location).resolve(backupName).toAbsolutePath();\n    if (!Files.exists(backupPath)) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't restore since doesn't exist: \" + backupPath);\n    }\n    Path backupZkPath =  backupPath.resolve(\"zk_backup\");\n\n    Properties properties = new Properties();\n    try (Reader in = Files.newBufferedReader(backupPath.resolve(\"backup.properties\"), StandardCharsets.UTF_8)) {\n      properties.load(in);\n    }\n\n    String backupCollection = (String) properties.get(\"collection\");\n    byte[] data = Files.readAllBytes(backupZkPath.resolve(\"collection_state.json\"));\n    ClusterState backupClusterState = ClusterState.load(-1, data, Collections.emptySet());\n    DocCollection backupCollectionState = backupClusterState.getCollection(backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      zkStateReader.getConfigManager().uploadConfigDir(backupZkPath.resolve(\"configs\").resolve(configName), restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        backupPath);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String,Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      createCollection(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice: restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      addPropertyParams(message, propMap);\n\n      addReplica(clusterState, new ZkNodeProps(propMap), new NamedList());\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice: restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(\"location\", backupPath.toString());\n      sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice: restoreCollection.getSlices()) {\n        for(int i=1; i<numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          addPropertyParams(message, propMap);\n\n          addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4c623a7f72be34d6c45bee682028c50327d9e4b7","date":1467791293,"type":3,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processRestoreAction(ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processRestoreAction(ZkNodeProps,NamedList).mjava","sourceNew":"  private void processRestoreAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME); // of backup\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = this.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI backupPath = repository.createURI(location, backupName);\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String,Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      createCollection(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice: restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      addPropertyParams(message, propMap);\n\n      addReplica(clusterState, new ZkNodeProps(propMap), new NamedList());\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice: restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice: restoreCollection.getSlices()) {\n        for(int i=1; i<numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          addPropertyParams(message, propMap);\n\n          addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  private void processRestoreAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME); // of backup\n    String location = message.getStr(ZkStateReader.BACKUP_LOCATION);\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = new HashMap<>();\n\n    Path backupPath = Paths.get(location).resolve(backupName).toAbsolutePath();\n    if (!Files.exists(backupPath)) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't restore since doesn't exist: \" + backupPath);\n    }\n    Path backupZkPath =  backupPath.resolve(\"zk_backup\");\n\n    Properties properties = new Properties();\n    try (Reader in = Files.newBufferedReader(backupPath.resolve(\"backup.properties\"), StandardCharsets.UTF_8)) {\n      properties.load(in);\n    }\n\n    String backupCollection = (String) properties.get(\"collection\");\n    byte[] data = Files.readAllBytes(backupZkPath.resolve(\"collection_state.json\"));\n    ClusterState backupClusterState = ClusterState.load(-1, data, Collections.emptySet());\n    DocCollection backupCollectionState = backupClusterState.getCollection(backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      zkStateReader.getConfigManager().uploadConfigDir(backupZkPath.resolve(\"configs\").resolve(configName), restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        backupPath);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String,Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      createCollection(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice: restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      addPropertyParams(message, propMap);\n\n      addReplica(clusterState, new ZkNodeProps(propMap), new NamedList());\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice: restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(\"location\", backupPath.toString());\n      sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice: restoreCollection.getSlices()) {\n        for(int i=1; i<numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          addPropertyParams(message, propMap);\n\n          addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":["af3193c66df8e8324d4bce9f66df967af9e8c602","af3193c66df8e8324d4bce9f66df967af9e8c602"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b1777912fb613f51063554d81f71c1b70d6bcd77","date":1470897768,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processRestoreAction(ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processRestoreAction(ZkNodeProps,NamedList).mjava","sourceNew":"  private void processRestoreAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME); // of backup\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = this.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI backupPath = repository.createURI(location, backupName);\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String,Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      createCollection(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice: restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      addPropertyParams(message, propMap);\n\n      addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice: restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice: restoreCollection.getSlices()) {\n        for(int i=1; i<numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          addPropertyParams(message, propMap);\n\n          addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  private void processRestoreAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME); // of backup\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = this.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI backupPath = repository.createURI(location, backupName);\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String,Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      createCollection(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice: restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      addPropertyParams(message, propMap);\n\n      addReplica(clusterState, new ZkNodeProps(propMap), new NamedList());\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice: restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice: restoreCollection.getSlices()) {\n        for(int i=1; i<numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          addPropertyParams(message, propMap);\n\n          addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"66e0b82bd39567aa2bf534e5282d05fb4a4a2c76","date":1471585465,"type":5,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processRestoreAction(ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI backupPath = repository.createURI(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  private void processRestoreAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME); // of backup\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = this.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI backupPath = repository.createURI(location, backupName);\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String,Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      createCollection(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice: restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      addPropertyParams(message, propMap);\n\n      addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice: restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice: restoreCollection.getSlices()) {\n        for(int i=1; i<numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          addPropertyParams(message, propMap);\n\n          addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"403d05f7f8d69b65659157eff1bc1d2717f04c66","date":1471692961,"type":5,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/RestoreCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processRestoreAction(ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState state, ZkNodeProps message, NamedList results) throws Exception {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName = message.getStr(COLLECTION_PROP);\n    String backupName = message.getStr(NAME); // of backup\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = ocmh.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI backupPath = repository.createURI(location, backupName);\n    ZkStateReader zkStateReader = ocmh.zkStateReader;\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String, Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      ocmh.commandMap.get(CREATE).call(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice : restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      ocmh.addPropertyParams(message, propMap);\n\n      ocmh.addReplica(clusterState, new ZkNodeProps(propMap), new NamedList(), null);\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice : restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    ocmh.processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice : restoreCollection.getSlices()) {\n        for (int i = 1; i < numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          ocmh.addPropertyParams(message, propMap);\n\n          ocmh.addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results, null);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","sourceOld":"  private void processRestoreAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME); // of backup\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    String repo = message.getStr(CoreAdminParams.BACKUP_REPOSITORY);\n    String location = message.getStr(CoreAdminParams.BACKUP_LOCATION);\n    Map<String, String> requestMap = new HashMap<>();\n\n    CoreContainer cc = this.overseer.getZkController().getCoreContainer();\n    BackupRepository repository = cc.newBackupRepository(Optional.ofNullable(repo));\n\n    URI backupPath = repository.createURI(location, backupName);\n    BackupManager backupMgr = new BackupManager(repository, zkStateReader, restoreCollectionName);\n\n    Properties properties = backupMgr.readBackupProperties(location, backupName);\n    String backupCollection = properties.getProperty(BackupManager.COLLECTION_NAME_PROP);\n    DocCollection backupCollectionState = backupMgr.readCollectionState(location, backupName, backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      backupMgr.uploadConfigDir(location, backupName, configName, restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        location);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String,Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      createCollection(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice: restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      addPropertyParams(message, propMap);\n\n      addReplica(clusterState, new ZkNodeProps(propMap), new NamedList());\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice: restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(CoreAdminParams.BACKUP_LOCATION, backupPath.getPath());\n      params.set(CoreAdminParams.BACKUP_REPOSITORY, repo);\n\n      sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice: restoreCollection.getSlices()) {\n        for(int i=1; i<numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          addPropertyParams(message, propMap);\n\n          addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#processRestoreAction(ZkNodeProps,NamedList).mjava","sourceNew":null,"sourceOld":"  private void processRestoreAction(ZkNodeProps message, NamedList results) throws IOException, KeeperException, InterruptedException {\n    // TODO maybe we can inherit createCollection's options/code\n    String restoreCollectionName =  message.getStr(COLLECTION_PROP);\n    String backupName =  message.getStr(NAME); // of backup\n    String location = message.getStr(\"location\");\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = new HashMap<>();\n\n    Path backupPath = Paths.get(location).resolve(backupName).toAbsolutePath();\n    if (!Files.exists(backupPath)) {\n      throw new SolrException(ErrorCode.SERVER_ERROR, \"Couldn't restore since doesn't exist: \" + backupPath);\n    }\n    Path backupZkPath =  backupPath.resolve(\"zk_backup\");\n\n    Properties properties = new Properties();\n    try (Reader in = Files.newBufferedReader(backupPath.resolve(\"backup.properties\"), StandardCharsets.UTF_8)) {\n      properties.load(in);\n    }\n\n    String backupCollection = (String) properties.get(\"collection\");\n    byte[] data = Files.readAllBytes(backupZkPath.resolve(\"collection_state.json\"));\n    ClusterState backupClusterState = ClusterState.load(-1, data, Collections.emptySet());\n    DocCollection backupCollectionState = backupClusterState.getCollection(backupCollection);\n\n    //Upload the configs\n    String configName = (String) properties.get(COLL_CONF);\n    String restoreConfigName = message.getStr(COLL_CONF, configName);\n    if (zkStateReader.getConfigManager().configExists(restoreConfigName)) {\n      log.info(\"Using existing config {}\", restoreConfigName);\n      //TODO add overwrite option?\n    } else {\n      log.info(\"Uploading config {}\", restoreConfigName);\n      zkStateReader.getConfigManager().uploadConfigDir(backupZkPath.resolve(\"configs\").resolve(configName), restoreConfigName);\n    }\n\n    log.info(\"Starting restore into collection={} with backup_name={} at location={}\", restoreCollectionName, backupName,\n        backupPath);\n\n    //Create core-less collection\n    {\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATE.toString());\n      propMap.put(\"fromApi\", \"true\"); // mostly true.  Prevents autoCreated=true in the collection state.\n\n      // inherit settings from input API, defaulting to the backup's setting.  Ex: replicationFactor\n      for (String collProp : COLL_PROPS.keySet()) {\n        Object val = message.getProperties().getOrDefault(collProp, backupCollectionState.get(collProp));\n        if (val != null) {\n          propMap.put(collProp, val);\n        }\n      }\n\n      propMap.put(NAME, restoreCollectionName);\n      propMap.put(CREATE_NODE_SET, CREATE_NODE_SET_EMPTY); //no cores\n      propMap.put(COLL_CONF, restoreConfigName);\n\n      // router.*\n      @SuppressWarnings(\"unchecked\")\n      Map<String, Object> routerProps = (Map<String, Object>) backupCollectionState.getProperties().get(DocCollection.DOC_ROUTER);\n      for (Map.Entry<String, Object> pair : routerProps.entrySet()) {\n        propMap.put(DocCollection.DOC_ROUTER + \".\" + pair.getKey(), pair.getValue());\n      }\n\n      Set<String> sliceNames = backupCollectionState.getActiveSlicesMap().keySet();\n      if (backupCollectionState.getRouter() instanceof ImplicitDocRouter) {\n        propMap.put(SHARDS_PROP, StrUtils.join(sliceNames, ','));\n      } else {\n        propMap.put(NUM_SLICES, sliceNames.size());\n        // ClusterStateMutator.createCollection detects that \"slices\" is in fact a slice structure instead of a\n        //   list of names, and if so uses this instead of building it.  We clear the replica list.\n        Collection<Slice> backupSlices = backupCollectionState.getActiveSlices();\n        Map<String,Slice> newSlices = new LinkedHashMap<>(backupSlices.size());\n        for (Slice backupSlice : backupSlices) {\n          newSlices.put(backupSlice.getName(),\n              new Slice(backupSlice.getName(), Collections.emptyMap(), backupSlice.getProperties()));\n        }\n        propMap.put(SHARDS_PROP, newSlices);\n      }\n\n      createCollection(zkStateReader.getClusterState(), new ZkNodeProps(propMap), new NamedList());\n      // note: when createCollection() returns, the collection exists (no race)\n    }\n\n    DocCollection restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    DistributedQueue inQueue = Overseer.getStateUpdateQueue(zkStateReader.getZkClient());\n\n    //Mark all shards in CONSTRUCTION STATE while we restore the data\n    {\n      //TODO might instead createCollection accept an initial state?  Is there a race?\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.CONSTRUCTION.toString());\n      }\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    // TODO how do we leverage the CREATE_NODE_SET / RULE / SNITCH logic in createCollection?\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    //Create one replica per shard and copy backed up data to it\n    for (Slice slice: restoreCollection.getSlices()) {\n      log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, CREATESHARD);\n      propMap.put(COLLECTION_PROP, restoreCollectionName);\n      propMap.put(SHARD_ID_PROP, slice.getName());\n      // add async param\n      if (asyncId != null) {\n        propMap.put(ASYNC, asyncId);\n      }\n      addPropertyParams(message, propMap);\n\n      addReplica(clusterState, new ZkNodeProps(propMap), new NamedList());\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Copy data from backed up index to each replica\n    for (Slice slice: restoreCollection.getSlices()) {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.RESTORECORE.toString());\n      params.set(NAME, \"snapshot.\" + slice.getName());\n      params.set(\"location\", backupPath.toString());\n      sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n    }\n    processResponses(new NamedList(), shardHandler, true, \"Could not restore core\", asyncId, requestMap);\n\n    //Mark all shards in ACTIVE STATE\n    {\n      HashMap<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(ZkStateReader.COLLECTION_PROP, restoreCollectionName);\n      for (Slice shard : restoreCollection.getSlices()) {\n        propMap.put(shard.getName(), Slice.State.ACTIVE.toString());\n      }\n      inQueue.offer(Utils.toJSON(new ZkNodeProps(propMap)));\n    }\n\n    //refresh the location copy of collection state\n    restoreCollection = zkStateReader.getClusterState().getCollection(restoreCollectionName);\n\n    //Add the remaining replicas for each shard\n    Integer numReplicas = restoreCollection.getReplicationFactor();\n    if (numReplicas != null && numReplicas > 1) {\n      log.info(\"Adding replicas to restored collection={}\", restoreCollection);\n\n      for (Slice slice: restoreCollection.getSlices()) {\n        for(int i=1; i<numReplicas; i++) {\n          log.debug(\"Adding replica for shard={} collection={} \", slice.getName(), restoreCollection);\n          HashMap<String, Object> propMap = new HashMap<>();\n          propMap.put(COLLECTION_PROP, restoreCollectionName);\n          propMap.put(SHARD_ID_PROP, slice.getName());\n          // add async param\n          if (asyncId != null) {\n            propMap.put(ASYNC, asyncId);\n          }\n          addPropertyParams(message, propMap);\n\n          addReplica(zkStateReader.getClusterState(), new ZkNodeProps(propMap), results);\n        }\n      }\n    }\n\n    log.info(\"Completed restoring collection={} backupName={}\", restoreCollection, backupName);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"4c623a7f72be34d6c45bee682028c50327d9e4b7":["a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b"],"c5c99ad021f3da085fcb66220598a8f91dc5e453":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["4c623a7f72be34d6c45bee682028c50327d9e4b7","66e0b82bd39567aa2bf534e5282d05fb4a4a2c76"],"a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b":["1c7a21395bae9e2f61aeb639f47aaca771c426ed"],"1c7a21395bae9e2f61aeb639f47aaca771c426ed":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c5c99ad021f3da085fcb66220598a8f91dc5e453"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"66e0b82bd39567aa2bf534e5282d05fb4a4a2c76":["b1777912fb613f51063554d81f71c1b70d6bcd77"],"b1777912fb613f51063554d81f71c1b70d6bcd77":["4c623a7f72be34d6c45bee682028c50327d9e4b7"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["55b50463286869f584cf849d1587a0fcd54d1dfa","403d05f7f8d69b65659157eff1bc1d2717f04c66"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"55b50463286869f584cf849d1587a0fcd54d1dfa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","1c7a21395bae9e2f61aeb639f47aaca771c426ed"]},"commit2Childs":{"4c623a7f72be34d6c45bee682028c50327d9e4b7":["403d05f7f8d69b65659157eff1bc1d2717f04c66","b1777912fb613f51063554d81f71c1b70d6bcd77"],"c5c99ad021f3da085fcb66220598a8f91dc5e453":["1c7a21395bae9e2f61aeb639f47aaca771c426ed"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b":["4c623a7f72be34d6c45bee682028c50327d9e4b7"],"1c7a21395bae9e2f61aeb639f47aaca771c426ed":["a51ab9b1f1b896f06b7ba61672f0fca2a4fce43b","55b50463286869f584cf849d1587a0fcd54d1dfa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c5c99ad021f3da085fcb66220598a8f91dc5e453","1c7a21395bae9e2f61aeb639f47aaca771c426ed","55b50463286869f584cf849d1587a0fcd54d1dfa"],"66e0b82bd39567aa2bf534e5282d05fb4a4a2c76":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"b1777912fb613f51063554d81f71c1b70d6bcd77":["66e0b82bd39567aa2bf534e5282d05fb4a4a2c76"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"55b50463286869f584cf849d1587a0fcd54d1dfa":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}