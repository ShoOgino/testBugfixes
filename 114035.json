{"path":"lucene/analysis/nori/src/tools/test/org/apache/lucene/analysis/ko/dict/TokenInfoDictionaryTest#newDictionary(String...).mjava","commits":[{"id":"c149f6975379ebb860e93139126a8aabf8e2b66d","date":1562857174,"type":0,"author":"Namgyu Kim","isMerge":false,"pathNew":"lucene/analysis/nori/src/tools/test/org/apache/lucene/analysis/ko/dict/TokenInfoDictionaryTest#newDictionary(String...).mjava","pathOld":"/dev/null","sourceNew":"  private TokenInfoDictionary newDictionary(String... entries) throws Exception {\n    Path dir = createTempDir();\n    try (OutputStream out = Files.newOutputStream(dir.resolve(\"test.csv\"));\n         PrintWriter printer = new PrintWriter(new OutputStreamWriter(out, \"utf-8\"))) {\n      for (String entry : entries) {\n        printer.println(entry);\n      }\n    }\n    TokenInfoDictionaryBuilder builder = new TokenInfoDictionaryBuilder(\"utf-8\", true);\n    TokenInfoDictionaryWriter writer = builder.build(dir.toString());\n    writer.write(dir.toString());\n    String dictionaryPath = TokenInfoDictionary.class.getName().replace('.', separatorChar);\n    // We must also load the other files (in BinaryDictionary) from the correct path\n    return new TokenInfoDictionary(ResourceScheme.FILE, dir.resolve(dictionaryPath).toString());\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e3010cab237afb0b81c042f263115756e3cc6d67","date":1564503244,"type":5,"author":"Namgyu Kim","isMerge":false,"pathNew":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TokenInfoDictionaryTest#newDictionary(String...).mjava","pathOld":"lucene/analysis/nori/src/tools/test/org/apache/lucene/analysis/ko/dict/TokenInfoDictionaryTest#newDictionary(String...).mjava","sourceNew":"  private TokenInfoDictionary newDictionary(String... entries) throws Exception {\n    Path dir = createTempDir();\n    try (OutputStream out = Files.newOutputStream(dir.resolve(\"test.csv\"));\n         PrintWriter printer = new PrintWriter(new OutputStreamWriter(out, StandardCharsets.UTF_8))) {\n      for (String entry : entries) {\n        printer.println(entry);\n      }\n    }\n    Files.createFile(dir.resolve(\"unk.def\"));\n    Files.createFile(dir.resolve(\"char.def\"));\n    try (OutputStream out = Files.newOutputStream(dir.resolve(\"matrix.def\"));\n         PrintWriter printer = new PrintWriter(new OutputStreamWriter(out, StandardCharsets.UTF_8))) {\n      printer.println(\"1 1\");\n    }\n    DictionaryBuilder.build(dir, dir, \"utf-8\", true);\n    String dictionaryPath = TokenInfoDictionary.class.getName().replace('.', '/');\n    // We must also load the other files (in BinaryDictionary) from the correct path\n    return new TokenInfoDictionary(ResourceScheme.FILE, dir.resolve(dictionaryPath).toString());\n  }\n\n","sourceOld":"  private TokenInfoDictionary newDictionary(String... entries) throws Exception {\n    Path dir = createTempDir();\n    try (OutputStream out = Files.newOutputStream(dir.resolve(\"test.csv\"));\n         PrintWriter printer = new PrintWriter(new OutputStreamWriter(out, \"utf-8\"))) {\n      for (String entry : entries) {\n        printer.println(entry);\n      }\n    }\n    TokenInfoDictionaryBuilder builder = new TokenInfoDictionaryBuilder(\"utf-8\", true);\n    TokenInfoDictionaryWriter writer = builder.build(dir.toString());\n    writer.write(dir.toString());\n    String dictionaryPath = TokenInfoDictionary.class.getName().replace('.', separatorChar);\n    // We must also load the other files (in BinaryDictionary) from the correct path\n    return new TokenInfoDictionary(ResourceScheme.FILE, dir.resolve(dictionaryPath).toString());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8061ddd97f3352007d927dae445884a6f3d857b","date":1564988276,"type":5,"author":"Atri Sharma","isMerge":true,"pathNew":"lucene/analysis/nori/src/test/org/apache/lucene/analysis/ko/dict/TokenInfoDictionaryTest#newDictionary(String...).mjava","pathOld":"lucene/analysis/nori/src/tools/test/org/apache/lucene/analysis/ko/dict/TokenInfoDictionaryTest#newDictionary(String...).mjava","sourceNew":"  private TokenInfoDictionary newDictionary(String... entries) throws Exception {\n    Path dir = createTempDir();\n    try (OutputStream out = Files.newOutputStream(dir.resolve(\"test.csv\"));\n         PrintWriter printer = new PrintWriter(new OutputStreamWriter(out, StandardCharsets.UTF_8))) {\n      for (String entry : entries) {\n        printer.println(entry);\n      }\n    }\n    Files.createFile(dir.resolve(\"unk.def\"));\n    Files.createFile(dir.resolve(\"char.def\"));\n    try (OutputStream out = Files.newOutputStream(dir.resolve(\"matrix.def\"));\n         PrintWriter printer = new PrintWriter(new OutputStreamWriter(out, StandardCharsets.UTF_8))) {\n      printer.println(\"1 1\");\n    }\n    DictionaryBuilder.build(dir, dir, \"utf-8\", true);\n    String dictionaryPath = TokenInfoDictionary.class.getName().replace('.', '/');\n    // We must also load the other files (in BinaryDictionary) from the correct path\n    return new TokenInfoDictionary(ResourceScheme.FILE, dir.resolve(dictionaryPath).toString());\n  }\n\n","sourceOld":"  private TokenInfoDictionary newDictionary(String... entries) throws Exception {\n    Path dir = createTempDir();\n    try (OutputStream out = Files.newOutputStream(dir.resolve(\"test.csv\"));\n         PrintWriter printer = new PrintWriter(new OutputStreamWriter(out, \"utf-8\"))) {\n      for (String entry : entries) {\n        printer.println(entry);\n      }\n    }\n    TokenInfoDictionaryBuilder builder = new TokenInfoDictionaryBuilder(\"utf-8\", true);\n    TokenInfoDictionaryWriter writer = builder.build(dir.toString());\n    writer.write(dir.toString());\n    String dictionaryPath = TokenInfoDictionary.class.getName().replace('.', separatorChar);\n    // We must also load the other files (in BinaryDictionary) from the correct path\n    return new TokenInfoDictionary(ResourceScheme.FILE, dir.resolve(dictionaryPath).toString());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c149f6975379ebb860e93139126a8aabf8e2b66d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e3010cab237afb0b81c042f263115756e3cc6d67":["c149f6975379ebb860e93139126a8aabf8e2b66d"],"f8061ddd97f3352007d927dae445884a6f3d857b":["c149f6975379ebb860e93139126a8aabf8e2b66d","e3010cab237afb0b81c042f263115756e3cc6d67"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e3010cab237afb0b81c042f263115756e3cc6d67"]},"commit2Childs":{"c149f6975379ebb860e93139126a8aabf8e2b66d":["e3010cab237afb0b81c042f263115756e3cc6d67","f8061ddd97f3352007d927dae445884a6f3d857b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c149f6975379ebb860e93139126a8aabf8e2b66d"],"e3010cab237afb0b81c042f263115756e3cc6d67":["f8061ddd97f3352007d927dae445884a6f3d857b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"f8061ddd97f3352007d927dae445884a6f3d857b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["f8061ddd97f3352007d927dae445884a6f3d857b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}