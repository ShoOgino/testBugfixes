{"path":"lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldMergeState.FilterFieldInfos#FilterFieldInfos(FieldInfos,Collection[String]).mjava","commits":[{"id":"132f1575a9078b618f9e1c35ac94f06444006662","date":1475595294,"type":0,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldMergeState.FilterFieldInfos#FilterFieldInfos(FieldInfos,Collection[String]).mjava","pathOld":"/dev/null","sourceNew":"    FilterFieldInfos(FieldInfos src, Collection<String> filterFields) {\n      // Copy all the input FieldInfo objects since the field numbering must be kept consistent\n      super(toArray(src));\n\n      boolean hasVectors = false;\n      boolean hasProx = false;\n      boolean hasPayloads = false;\n      boolean hasOffsets = false;\n      boolean hasFreq = false;\n      boolean hasNorms = false;\n      boolean hasDocValues = false;\n      boolean hasPointValues = false;\n\n      this.filteredNames = new HashSet<>(filterFields);\n      this.filtered = new ArrayList<>(filterFields.size());\n      for (FieldInfo fi : src) {\n        if (filterFields.contains(fi.name)) {\n          this.filtered.add(fi);\n          hasVectors |= fi.hasVectors();\n          hasProx |= fi.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n          hasFreq |= fi.getIndexOptions() != IndexOptions.DOCS;\n          hasOffsets |= fi.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n          hasNorms |= fi.hasNorms();\n          hasDocValues |= fi.getDocValuesType() != DocValuesType.NONE;\n          hasPayloads |= fi.hasPayloads();\n          hasPointValues |= (fi.getPointDimensionCount() != 0);\n        }\n      }\n\n      this.filteredHasVectors = hasVectors;\n      this.filteredHasProx = hasProx;\n      this.filteredHasPayloads = hasPayloads;\n      this.filteredHasOffsets = hasOffsets;\n      this.filteredHasFreq = hasFreq;\n      this.filteredHasNorms = hasNorms;\n      this.filteredHasDocValues = hasDocValues;\n      this.filteredHasPointValues = hasPointValues;\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldMergeState.FilterFieldInfos#FilterFieldInfos(FieldInfos,Collection[String]).mjava","pathOld":"/dev/null","sourceNew":"    FilterFieldInfos(FieldInfos src, Collection<String> filterFields) {\n      // Copy all the input FieldInfo objects since the field numbering must be kept consistent\n      super(toArray(src));\n\n      boolean hasVectors = false;\n      boolean hasProx = false;\n      boolean hasPayloads = false;\n      boolean hasOffsets = false;\n      boolean hasFreq = false;\n      boolean hasNorms = false;\n      boolean hasDocValues = false;\n      boolean hasPointValues = false;\n\n      this.filteredNames = new HashSet<>(filterFields);\n      this.filtered = new ArrayList<>(filterFields.size());\n      for (FieldInfo fi : src) {\n        if (filterFields.contains(fi.name)) {\n          this.filtered.add(fi);\n          hasVectors |= fi.hasVectors();\n          hasProx |= fi.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n          hasFreq |= fi.getIndexOptions() != IndexOptions.DOCS;\n          hasOffsets |= fi.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n          hasNorms |= fi.hasNorms();\n          hasDocValues |= fi.getDocValuesType() != DocValuesType.NONE;\n          hasPayloads |= fi.hasPayloads();\n          hasPointValues |= (fi.getPointDimensionCount() != 0);\n        }\n      }\n\n      this.filteredHasVectors = hasVectors;\n      this.filteredHasProx = hasProx;\n      this.filteredHasPayloads = hasPayloads;\n      this.filteredHasOffsets = hasOffsets;\n      this.filteredHasFreq = hasFreq;\n      this.filteredHasNorms = hasNorms;\n      this.filteredHasDocValues = hasDocValues;\n      this.filteredHasPointValues = hasPointValues;\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f6652c943595e92c187ee904c382863013eae28f","date":1539042663,"type":3,"author":"Nicholas Knize","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldMergeState.FilterFieldInfos#FilterFieldInfos(FieldInfos,Collection[String]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldMergeState.FilterFieldInfos#FilterFieldInfos(FieldInfos,Collection[String]).mjava","sourceNew":"    FilterFieldInfos(FieldInfos src, Collection<String> filterFields) {\n      // Copy all the input FieldInfo objects since the field numbering must be kept consistent\n      super(toArray(src));\n\n      boolean hasVectors = false;\n      boolean hasProx = false;\n      boolean hasPayloads = false;\n      boolean hasOffsets = false;\n      boolean hasFreq = false;\n      boolean hasNorms = false;\n      boolean hasDocValues = false;\n      boolean hasPointValues = false;\n\n      this.filteredNames = new HashSet<>(filterFields);\n      this.filtered = new ArrayList<>(filterFields.size());\n      for (FieldInfo fi : src) {\n        if (filterFields.contains(fi.name)) {\n          this.filtered.add(fi);\n          hasVectors |= fi.hasVectors();\n          hasProx |= fi.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n          hasFreq |= fi.getIndexOptions() != IndexOptions.DOCS;\n          hasOffsets |= fi.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n          hasNorms |= fi.hasNorms();\n          hasDocValues |= fi.getDocValuesType() != DocValuesType.NONE;\n          hasPayloads |= fi.hasPayloads();\n          hasPointValues |= (fi.getPointDataDimensionCount() != 0);\n        }\n      }\n\n      this.filteredHasVectors = hasVectors;\n      this.filteredHasProx = hasProx;\n      this.filteredHasPayloads = hasPayloads;\n      this.filteredHasOffsets = hasOffsets;\n      this.filteredHasFreq = hasFreq;\n      this.filteredHasNorms = hasNorms;\n      this.filteredHasDocValues = hasDocValues;\n      this.filteredHasPointValues = hasPointValues;\n    }\n\n","sourceOld":"    FilterFieldInfos(FieldInfos src, Collection<String> filterFields) {\n      // Copy all the input FieldInfo objects since the field numbering must be kept consistent\n      super(toArray(src));\n\n      boolean hasVectors = false;\n      boolean hasProx = false;\n      boolean hasPayloads = false;\n      boolean hasOffsets = false;\n      boolean hasFreq = false;\n      boolean hasNorms = false;\n      boolean hasDocValues = false;\n      boolean hasPointValues = false;\n\n      this.filteredNames = new HashSet<>(filterFields);\n      this.filtered = new ArrayList<>(filterFields.size());\n      for (FieldInfo fi : src) {\n        if (filterFields.contains(fi.name)) {\n          this.filtered.add(fi);\n          hasVectors |= fi.hasVectors();\n          hasProx |= fi.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n          hasFreq |= fi.getIndexOptions() != IndexOptions.DOCS;\n          hasOffsets |= fi.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n          hasNorms |= fi.hasNorms();\n          hasDocValues |= fi.getDocValuesType() != DocValuesType.NONE;\n          hasPayloads |= fi.hasPayloads();\n          hasPointValues |= (fi.getPointDimensionCount() != 0);\n        }\n      }\n\n      this.filteredHasVectors = hasVectors;\n      this.filteredHasProx = hasProx;\n      this.filteredHasPayloads = hasPayloads;\n      this.filteredHasOffsets = hasOffsets;\n      this.filteredHasFreq = hasFreq;\n      this.filteredHasNorms = hasNorms;\n      this.filteredHasDocValues = hasDocValues;\n      this.filteredHasPointValues = hasPointValues;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b2388a3b7774176116f789d7f9fc84cbea4eeefa","date":1541619245,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldMergeState.FilterFieldInfos#FilterFieldInfos(FieldInfos,Collection[String]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldMergeState.FilterFieldInfos#FilterFieldInfos(FieldInfos,Collection[String]).mjava","sourceNew":"    FilterFieldInfos(FieldInfos src, Collection<String> filterFields) {\n      // Copy all the input FieldInfo objects since the field numbering must be kept consistent\n      super(toArray(src));\n\n      boolean hasVectors = false;\n      boolean hasProx = false;\n      boolean hasPayloads = false;\n      boolean hasOffsets = false;\n      boolean hasFreq = false;\n      boolean hasNorms = false;\n      boolean hasDocValues = false;\n      boolean hasPointValues = false;\n\n      this.filteredNames = new HashSet<>(filterFields);\n      this.filtered = new ArrayList<>(filterFields.size());\n      for (FieldInfo fi : src) {\n        if (this.filteredNames.contains(fi.name)) {\n          this.filtered.add(fi);\n          hasVectors |= fi.hasVectors();\n          hasProx |= fi.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n          hasFreq |= fi.getIndexOptions() != IndexOptions.DOCS;\n          hasOffsets |= fi.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n          hasNorms |= fi.hasNorms();\n          hasDocValues |= fi.getDocValuesType() != DocValuesType.NONE;\n          hasPayloads |= fi.hasPayloads();\n          hasPointValues |= (fi.getPointDataDimensionCount() != 0);\n        }\n      }\n\n      this.filteredHasVectors = hasVectors;\n      this.filteredHasProx = hasProx;\n      this.filteredHasPayloads = hasPayloads;\n      this.filteredHasOffsets = hasOffsets;\n      this.filteredHasFreq = hasFreq;\n      this.filteredHasNorms = hasNorms;\n      this.filteredHasDocValues = hasDocValues;\n      this.filteredHasPointValues = hasPointValues;\n    }\n\n","sourceOld":"    FilterFieldInfos(FieldInfos src, Collection<String> filterFields) {\n      // Copy all the input FieldInfo objects since the field numbering must be kept consistent\n      super(toArray(src));\n\n      boolean hasVectors = false;\n      boolean hasProx = false;\n      boolean hasPayloads = false;\n      boolean hasOffsets = false;\n      boolean hasFreq = false;\n      boolean hasNorms = false;\n      boolean hasDocValues = false;\n      boolean hasPointValues = false;\n\n      this.filteredNames = new HashSet<>(filterFields);\n      this.filtered = new ArrayList<>(filterFields.size());\n      for (FieldInfo fi : src) {\n        if (filterFields.contains(fi.name)) {\n          this.filtered.add(fi);\n          hasVectors |= fi.hasVectors();\n          hasProx |= fi.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n          hasFreq |= fi.getIndexOptions() != IndexOptions.DOCS;\n          hasOffsets |= fi.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n          hasNorms |= fi.hasNorms();\n          hasDocValues |= fi.getDocValuesType() != DocValuesType.NONE;\n          hasPayloads |= fi.hasPayloads();\n          hasPointValues |= (fi.getPointDataDimensionCount() != 0);\n        }\n      }\n\n      this.filteredHasVectors = hasVectors;\n      this.filteredHasProx = hasProx;\n      this.filteredHasPayloads = hasPayloads;\n      this.filteredHasOffsets = hasOffsets;\n      this.filteredHasFreq = hasFreq;\n      this.filteredHasNorms = hasNorms;\n      this.filteredHasDocValues = hasDocValues;\n      this.filteredHasPointValues = hasPointValues;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"59ed8c026ba85e3c42fb89605b2032dc6f9cc241","date":1581113294,"type":3,"author":"Nicholas Knize","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldMergeState.FilterFieldInfos#FilterFieldInfos(FieldInfos,Collection[String]).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/perfield/PerFieldMergeState.FilterFieldInfos#FilterFieldInfos(FieldInfos,Collection[String]).mjava","sourceNew":"    FilterFieldInfos(FieldInfos src, Collection<String> filterFields) {\n      // Copy all the input FieldInfo objects since the field numbering must be kept consistent\n      super(toArray(src));\n\n      boolean hasVectors = false;\n      boolean hasProx = false;\n      boolean hasPayloads = false;\n      boolean hasOffsets = false;\n      boolean hasFreq = false;\n      boolean hasNorms = false;\n      boolean hasDocValues = false;\n      boolean hasPointValues = false;\n\n      this.filteredNames = new HashSet<>(filterFields);\n      this.filtered = new ArrayList<>(filterFields.size());\n      for (FieldInfo fi : src) {\n        if (this.filteredNames.contains(fi.name)) {\n          this.filtered.add(fi);\n          hasVectors |= fi.hasVectors();\n          hasProx |= fi.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n          hasFreq |= fi.getIndexOptions() != IndexOptions.DOCS;\n          hasOffsets |= fi.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n          hasNorms |= fi.hasNorms();\n          hasDocValues |= fi.getDocValuesType() != DocValuesType.NONE;\n          hasPayloads |= fi.hasPayloads();\n          hasPointValues |= (fi.getPointDimensionCount() != 0);\n        }\n      }\n\n      this.filteredHasVectors = hasVectors;\n      this.filteredHasProx = hasProx;\n      this.filteredHasPayloads = hasPayloads;\n      this.filteredHasOffsets = hasOffsets;\n      this.filteredHasFreq = hasFreq;\n      this.filteredHasNorms = hasNorms;\n      this.filteredHasDocValues = hasDocValues;\n      this.filteredHasPointValues = hasPointValues;\n    }\n\n","sourceOld":"    FilterFieldInfos(FieldInfos src, Collection<String> filterFields) {\n      // Copy all the input FieldInfo objects since the field numbering must be kept consistent\n      super(toArray(src));\n\n      boolean hasVectors = false;\n      boolean hasProx = false;\n      boolean hasPayloads = false;\n      boolean hasOffsets = false;\n      boolean hasFreq = false;\n      boolean hasNorms = false;\n      boolean hasDocValues = false;\n      boolean hasPointValues = false;\n\n      this.filteredNames = new HashSet<>(filterFields);\n      this.filtered = new ArrayList<>(filterFields.size());\n      for (FieldInfo fi : src) {\n        if (this.filteredNames.contains(fi.name)) {\n          this.filtered.add(fi);\n          hasVectors |= fi.hasVectors();\n          hasProx |= fi.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS) >= 0;\n          hasFreq |= fi.getIndexOptions() != IndexOptions.DOCS;\n          hasOffsets |= fi.getIndexOptions().compareTo(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS) >= 0;\n          hasNorms |= fi.hasNorms();\n          hasDocValues |= fi.getDocValuesType() != DocValuesType.NONE;\n          hasPayloads |= fi.hasPayloads();\n          hasPointValues |= (fi.getPointDataDimensionCount() != 0);\n        }\n      }\n\n      this.filteredHasVectors = hasVectors;\n      this.filteredHasProx = hasProx;\n      this.filteredHasPayloads = hasPayloads;\n      this.filteredHasOffsets = hasOffsets;\n      this.filteredHasFreq = hasFreq;\n      this.filteredHasNorms = hasNorms;\n      this.filteredHasDocValues = hasDocValues;\n      this.filteredHasPointValues = hasPointValues;\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"132f1575a9078b618f9e1c35ac94f06444006662":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"b2388a3b7774176116f789d7f9fc84cbea4eeefa":["f6652c943595e92c187ee904c382863013eae28f"],"59ed8c026ba85e3c42fb89605b2032dc6f9cc241":["b2388a3b7774176116f789d7f9fc84cbea4eeefa"],"f6652c943595e92c187ee904c382863013eae28f":["132f1575a9078b618f9e1c35ac94f06444006662"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","132f1575a9078b618f9e1c35ac94f06444006662"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["59ed8c026ba85e3c42fb89605b2032dc6f9cc241"]},"commit2Childs":{"132f1575a9078b618f9e1c35ac94f06444006662":["f6652c943595e92c187ee904c382863013eae28f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"b2388a3b7774176116f789d7f9fc84cbea4eeefa":["59ed8c026ba85e3c42fb89605b2032dc6f9cc241"],"f6652c943595e92c187ee904c382863013eae28f":["b2388a3b7774176116f789d7f9fc84cbea4eeefa"],"59ed8c026ba85e3c42fb89605b2032dc6f9cc241":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["132f1575a9078b618f9e1c35ac94f06444006662","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}