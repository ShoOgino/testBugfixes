{"path":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean).mjava","commits":[{"id":"4d7e42d2692288d7e3f3e38cbfcc31ef1251054d","date":1461702806,"type":0,"author":"jbernste","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n      return new ConstantScoreWeight(this) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          final Fields fields = reader.fields();\n          Terms terms = fields.terms(field);\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc());\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n      };\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f853d68ca2889f08e165f8f24d21e4b6c6d05a31","date":1461939217,"type":3,"author":"jbernste","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n\n      List<TermContext> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermContext[] termContexts = new TermContext[this.queryTerms.length];\n      collectTermContext(searcher.getIndexReader(), contexts, termContexts, this.queryTerms);\n      for(int i=0; i<termContexts.length; i++) {\n        TermContext termContext = termContexts[i];\n        if(termContext != null && termContext.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(termContext);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          final Fields fields = reader.fields();\n          Terms terms = fields.terms(field);\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc());\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n      return new ConstantScoreWeight(this) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          final Fields fields = reader.fields();\n          Terms terms = fields.terms(field);\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc());\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8e8d5955830d712186a4beb716e797d505af7981","date":1461951189,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n\n      List<TermContext> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermContext[] termContexts = new TermContext[this.queryTerms.length];\n      collectTermContext(searcher.getIndexReader(), contexts, termContexts, this.queryTerms);\n      for(int i=0; i<termContexts.length; i++) {\n        TermContext termContext = termContexts[i];\n        if(termContext != null && termContext.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(termContext);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          final Fields fields = reader.fields();\n          Terms terms = fields.terms(field);\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc());\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n      return new ConstantScoreWeight(this) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          final Fields fields = reader.fields();\n          Terms terms = fields.terms(field);\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc());\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9ee4c03e3ee986704eeeb45c571d001905a6430","date":1462194267,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n\n      List<TermContext> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermContext[] termContexts = new TermContext[this.queryTerms.length];\n      collectTermContext(searcher.getIndexReader(), contexts, termContexts, this.queryTerms);\n      for(int i=0; i<termContexts.length; i++) {\n        TermContext termContext = termContexts[i];\n        if(termContext != null && termContext.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(termContext);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          final Fields fields = reader.fields();\n          Terms terms = fields.terms(field);\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n\n      List<TermContext> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermContext[] termContexts = new TermContext[this.queryTerms.length];\n      collectTermContext(searcher.getIndexReader(), contexts, termContexts, this.queryTerms);\n      for(int i=0; i<termContexts.length; i++) {\n        TermContext termContext = termContexts[i];\n        if(termContext != null && termContext.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(termContext);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          final Fields fields = reader.fields();\n          Terms terms = fields.terms(field);\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc());\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"30540ec27130887a9372c159e8fe971200f37727","date":1462223109,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n\n      List<TermContext> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermContext[] termContexts = new TermContext[this.queryTerms.length];\n      collectTermContext(searcher.getIndexReader(), contexts, termContexts, this.queryTerms);\n      for(int i=0; i<termContexts.length; i++) {\n        TermContext termContext = termContexts[i];\n        if(termContext != null && termContext.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(termContext);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          final Fields fields = reader.fields();\n          Terms terms = fields.terms(field);\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n\n      List<TermContext> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermContext[] termContexts = new TermContext[this.queryTerms.length];\n      collectTermContext(searcher.getIndexReader(), contexts, termContexts, this.queryTerms);\n      for(int i=0; i<termContexts.length; i++) {\n        TermContext termContext = termContexts[i];\n        if(termContext != null && termContext.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(termContext);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          final Fields fields = reader.fields();\n          Terms terms = fields.terms(field);\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc());\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"55b50463286869f584cf849d1587a0fcd54d1dfa","date":1462378517,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n\n      List<TermContext> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermContext[] termContexts = new TermContext[this.queryTerms.length];\n      collectTermContext(searcher.getIndexReader(), contexts, termContexts, this.queryTerms);\n      for(int i=0; i<termContexts.length; i++) {\n        TermContext termContext = termContexts[i];\n        if(termContext != null && termContext.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(termContext);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          final Fields fields = reader.fields();\n          Terms terms = fields.terms(field);\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n      return new ConstantScoreWeight(this) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          final Fields fields = reader.fields();\n          Terms terms = fields.terms(field);\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc());\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"13d1ff9a034b4696634bc52011b68e82d826a8fb","date":1467133414,"type":3,"author":"jbernste","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n\n      List<TermContext> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermContext[] termContexts = new TermContext[this.queryTerms.length];\n      collectTermContext(searcher.getIndexReader(), contexts, termContexts, this.queryTerms);\n      for(int i=0; i<termContexts.length; i++) {\n        TermContext termContext = termContexts[i];\n        if(termContext != null && termContext.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(termContext);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          final Fields fields = reader.fields();\n          Terms terms = fields.terms(field);\n          if(terms == null) {\n            return new WeightOrDocIdSet(new BitDocIdSet(new FixedBitSet(reader.maxDoc()), 0));\n          }\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n\n      List<TermContext> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermContext[] termContexts = new TermContext[this.queryTerms.length];\n      collectTermContext(searcher.getIndexReader(), contexts, termContexts, this.queryTerms);\n      for(int i=0; i<termContexts.length; i++) {\n        TermContext termContext = termContexts[i];\n        if(termContext != null && termContext.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(termContext);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          final Fields fields = reader.fields();\n          Terms terms = fields.terms(field);\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"02e175abd2c4c1611c5a9647486ae8ba249a94c1","date":1468327116,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean,float).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores, float boost) throws IOException {\n\n      List<TermContext> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermContext[] termContexts = new TermContext[this.queryTerms.length];\n      collectTermContext(searcher.getIndexReader(), contexts, termContexts, this.queryTerms);\n      for(int i=0; i<termContexts.length; i++) {\n        TermContext termContext = termContexts[i];\n        if(termContext != null && termContext.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(termContext);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this, boost) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          final Fields fields = reader.fields();\n          Terms terms = fields.terms(field);\n          if(terms == null) {\n            return new WeightOrDocIdSet(new BitDocIdSet(new FixedBitSet(reader.maxDoc()), 0));\n          }\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n      };\n    }\n\n","sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n\n      List<TermContext> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermContext[] termContexts = new TermContext[this.queryTerms.length];\n      collectTermContext(searcher.getIndexReader(), contexts, termContexts, this.queryTerms);\n      for(int i=0; i<termContexts.length; i++) {\n        TermContext termContext = termContexts[i];\n        if(termContext != null && termContext.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(termContext);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          final Fields fields = reader.fields();\n          Terms terms = fields.terms(field);\n          if(terms == null) {\n            return new WeightOrDocIdSet(new BitDocIdSet(new FixedBitSet(reader.maxDoc()), 0));\n          }\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/search/GraphTermsQParserPlugin.GraphTermsQuery#createWeight(IndexSearcher,boolean).mjava","sourceNew":null,"sourceOld":"    @Override\n    public Weight createWeight(IndexSearcher searcher, boolean needsScores) throws IOException {\n\n      List<TermContext> finalContexts = new ArrayList();\n      List<Term> finalTerms = new ArrayList();\n      List<LeafReaderContext> contexts = searcher.getTopReaderContext().leaves();\n      TermContext[] termContexts = new TermContext[this.queryTerms.length];\n      collectTermContext(searcher.getIndexReader(), contexts, termContexts, this.queryTerms);\n      for(int i=0; i<termContexts.length; i++) {\n        TermContext termContext = termContexts[i];\n        if(termContext != null && termContext.docFreq() <= this.maxDocFreq) {\n          finalContexts.add(termContext);\n          finalTerms.add(queryTerms[i]);\n        }\n      }\n\n      return new ConstantScoreWeight(this) {\n\n        @Override\n        public void extractTerms(Set<Term> terms) {\n          // no-op\n          // This query is for abuse cases when the number of terms is too high to\n          // run efficiently as a BooleanQuery. So likewise we hide its terms in\n          // order to protect highlighters\n        }\n\n        private WeightOrDocIdSet rewrite(LeafReaderContext context) throws IOException {\n          final LeafReader reader = context.reader();\n          final Fields fields = reader.fields();\n          Terms terms = fields.terms(field);\n          TermsEnum  termsEnum = terms.iterator();\n          PostingsEnum docs = null;\n          DocIdSetBuilder builder = new DocIdSetBuilder(reader.maxDoc(), terms);\n          for (int i=0; i<finalContexts.size(); i++) {\n            TermContext termContext = finalContexts.get(i);\n            TermState termState = termContext.get(context.ord);\n            if(termState != null) {\n              Term term = finalTerms.get(i);\n              termsEnum.seekExact(term.bytes(), termContext.get(context.ord));\n              docs = termsEnum.postings(docs, PostingsEnum.NONE);\n              builder.add(docs);\n            }\n          }\n          return new WeightOrDocIdSet(builder.build());\n        }\n\n        private Scorer scorer(DocIdSet set) throws IOException {\n          if (set == null) {\n            return null;\n          }\n          final DocIdSetIterator disi = set.iterator();\n          if (disi == null) {\n            return null;\n          }\n          return new ConstantScoreScorer(this, score(), disi);\n        }\n\n        @Override\n        public BulkScorer bulkScorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.bulkScorer(context);\n          } else {\n            final Scorer scorer = scorer(weightOrBitSet.set);\n            if (scorer == null) {\n              return null;\n            }\n            return new DefaultBulkScorer(scorer);\n          }\n        }\n\n        @Override\n        public Scorer scorer(LeafReaderContext context) throws IOException {\n          final WeightOrDocIdSet weightOrBitSet = rewrite(context);\n          if (weightOrBitSet.weight != null) {\n            return weightOrBitSet.weight.scorer(context);\n          } else {\n            return scorer(weightOrBitSet.set);\n          }\n        }\n      };\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f853d68ca2889f08e165f8f24d21e4b6c6d05a31":["4d7e42d2692288d7e3f3e38cbfcc31ef1251054d"],"c9ee4c03e3ee986704eeeb45c571d001905a6430":["8e8d5955830d712186a4beb716e797d505af7981"],"13d1ff9a034b4696634bc52011b68e82d826a8fb":["30540ec27130887a9372c159e8fe971200f37727"],"8e8d5955830d712186a4beb716e797d505af7981":["4d7e42d2692288d7e3f3e38cbfcc31ef1251054d","f853d68ca2889f08e165f8f24d21e4b6c6d05a31"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"02e175abd2c4c1611c5a9647486ae8ba249a94c1":["13d1ff9a034b4696634bc52011b68e82d826a8fb"],"4d7e42d2692288d7e3f3e38cbfcc31ef1251054d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"30540ec27130887a9372c159e8fe971200f37727":["8e8d5955830d712186a4beb716e797d505af7981","c9ee4c03e3ee986704eeeb45c571d001905a6430"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["55b50463286869f584cf849d1587a0fcd54d1dfa","02e175abd2c4c1611c5a9647486ae8ba249a94c1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["02e175abd2c4c1611c5a9647486ae8ba249a94c1"],"55b50463286869f584cf849d1587a0fcd54d1dfa":["4d7e42d2692288d7e3f3e38cbfcc31ef1251054d","30540ec27130887a9372c159e8fe971200f37727"]},"commit2Childs":{"f853d68ca2889f08e165f8f24d21e4b6c6d05a31":["8e8d5955830d712186a4beb716e797d505af7981"],"c9ee4c03e3ee986704eeeb45c571d001905a6430":["30540ec27130887a9372c159e8fe971200f37727"],"13d1ff9a034b4696634bc52011b68e82d826a8fb":["02e175abd2c4c1611c5a9647486ae8ba249a94c1"],"8e8d5955830d712186a4beb716e797d505af7981":["c9ee4c03e3ee986704eeeb45c571d001905a6430","30540ec27130887a9372c159e8fe971200f37727"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4d7e42d2692288d7e3f3e38cbfcc31ef1251054d"],"4d7e42d2692288d7e3f3e38cbfcc31ef1251054d":["f853d68ca2889f08e165f8f24d21e4b6c6d05a31","8e8d5955830d712186a4beb716e797d505af7981","55b50463286869f584cf849d1587a0fcd54d1dfa"],"02e175abd2c4c1611c5a9647486ae8ba249a94c1":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"30540ec27130887a9372c159e8fe971200f37727":["13d1ff9a034b4696634bc52011b68e82d826a8fb","55b50463286869f584cf849d1587a0fcd54d1dfa"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"55b50463286869f584cf849d1587a0fcd54d1dfa":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}