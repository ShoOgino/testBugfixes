{"path":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/AnalysisOffsetStrategy.MultiValueTokenStream#incrementToken().mjava","commits":[{"id":"f2e9861e4a2b724d9fc51b618714c579491b78d7","date":1479244606,"type":0,"author":"David Smiley","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/AnalysisOffsetStrategy.MultiValueTokenStream#incrementToken().mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public boolean incrementToken() throws IOException {\n      while (true) {\n\n        if (input.incrementToken()) {\n          // Position tracking:\n          if (remainingPosInc > 0) {//usually true first token of additional values (not first val)\n            posIncAtt.setPositionIncrement(remainingPosInc + posIncAtt.getPositionIncrement());\n            remainingPosInc = 0;//reset\n          }\n          // Offset tracking:\n          offsetAtt.setOffset(\n              startValIdx + offsetAtt.startOffset(),\n              startValIdx + offsetAtt.endOffset()\n          );\n          return true;\n        }\n\n        if (endValIdx == content.length()) {//no more\n          return false;\n        }\n\n        input.end(); // might adjust position increment\n        remainingPosInc += posIncAtt.getPositionIncrement();\n        input.close();\n        remainingPosInc += indexAnalyzer.getPositionIncrementGap(fieldName);\n\n        // Get new tokenStream based on next segment divided by the splitChar\n        startValIdx = endValIdx + 1;\n        endValIdx = content.indexOf(splitChar, startValIdx);\n        if (endValIdx == -1) {//EOF\n          endValIdx = content.length();\n        }\n        TokenStream tokenStream = indexAnalyzer.tokenStream(fieldName, content.substring(startValIdx, endValIdx));\n        if (tokenStream != input) {// (input is defined in TokenFilter set in the constructor)\n          // This is a grand trick we do -- knowing that the analyzer's re-use strategy is going to produce the\n          // very same tokenStream instance and thus have the same AttributeSource as this wrapping TokenStream\n          // since we used it as our input in the constructor.\n          // Were this not the case, we'd have to copy every attribute of interest since we can't alter the\n          // AttributeSource of this wrapping TokenStream post-construction (it's all private/final).\n          // If this is a problem, we could do that instead; maybe with a custom CharTermAttribute that allows\n          // us to easily set the char[] reference without literally copying char by char.\n          throw new IllegalStateException(\"Require TokenStream re-use.  Unsupported re-use strategy?: \" +\n              indexAnalyzer.getReuseStrategy());\n        }\n        tokenStream.reset();\n      } // while loop to increment token of this new value\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a1ef55e1fff7ff44354432770ad8bc19be1fcc75","date":1479266056,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/uhighlight/AnalysisOffsetStrategy.MultiValueTokenStream#incrementToken().mjava","pathOld":"/dev/null","sourceNew":"    @Override\n    public boolean incrementToken() throws IOException {\n      while (true) {\n\n        if (input.incrementToken()) {\n          // Position tracking:\n          if (remainingPosInc > 0) {//usually true first token of additional values (not first val)\n            posIncAtt.setPositionIncrement(remainingPosInc + posIncAtt.getPositionIncrement());\n            remainingPosInc = 0;//reset\n          }\n          // Offset tracking:\n          offsetAtt.setOffset(\n              startValIdx + offsetAtt.startOffset(),\n              startValIdx + offsetAtt.endOffset()\n          );\n          return true;\n        }\n\n        if (endValIdx == content.length()) {//no more\n          return false;\n        }\n\n        input.end(); // might adjust position increment\n        remainingPosInc += posIncAtt.getPositionIncrement();\n        input.close();\n        remainingPosInc += indexAnalyzer.getPositionIncrementGap(fieldName);\n\n        // Get new tokenStream based on next segment divided by the splitChar\n        startValIdx = endValIdx + 1;\n        endValIdx = content.indexOf(splitChar, startValIdx);\n        if (endValIdx == -1) {//EOF\n          endValIdx = content.length();\n        }\n        TokenStream tokenStream = indexAnalyzer.tokenStream(fieldName, content.substring(startValIdx, endValIdx));\n        if (tokenStream != input) {// (input is defined in TokenFilter set in the constructor)\n          // This is a grand trick we do -- knowing that the analyzer's re-use strategy is going to produce the\n          // very same tokenStream instance and thus have the same AttributeSource as this wrapping TokenStream\n          // since we used it as our input in the constructor.\n          // Were this not the case, we'd have to copy every attribute of interest since we can't alter the\n          // AttributeSource of this wrapping TokenStream post-construction (it's all private/final).\n          // If this is a problem, we could do that instead; maybe with a custom CharTermAttribute that allows\n          // us to easily set the char[] reference without literally copying char by char.\n          throw new IllegalStateException(\"Require TokenStream re-use.  Unsupported re-use strategy?: \" +\n              indexAnalyzer.getReuseStrategy());\n        }\n        tokenStream.reset();\n      } // while loop to increment token of this new value\n    }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"f2e9861e4a2b724d9fc51b618714c579491b78d7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a1ef55e1fff7ff44354432770ad8bc19be1fcc75":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f2e9861e4a2b724d9fc51b618714c579491b78d7"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["f2e9861e4a2b724d9fc51b618714c579491b78d7"]},"commit2Childs":{"f2e9861e4a2b724d9fc51b618714c579491b78d7":["a1ef55e1fff7ff44354432770ad8bc19be1fcc75","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f2e9861e4a2b724d9fc51b618714c579491b78d7","a1ef55e1fff7ff44354432770ad8bc19be1fcc75"],"a1ef55e1fff7ff44354432770ad8bc19be1fcc75":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a1ef55e1fff7ff44354432770ad8bc19be1fcc75","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}