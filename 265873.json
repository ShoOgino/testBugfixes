{"path":"src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField#start(Fieldable[],int).mjava","commits":[{"id":"5350389bf83287111f7760b9e3db3af8e3648474","date":1216372812,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField#start(Fieldable[],int).mjava","pathOld":"/dev/null","sourceNew":"  boolean start(Fieldable[] fields, int count) {\n    doVectors = false;\n    doVectorPositions = false;\n    doVectorOffsets = false;\n\n    for(int i=0;i<count;i++) {\n      Fieldable field = fields[i];\n      if (field.isIndexed() && field.isTermVectorStored()) {\n        doVectors = true;\n        doVectorPositions |= field.isStorePositionWithTermVector();\n        doVectorOffsets |= field.isStoreOffsetWithTermVector();\n      }\n    }\n\n    if (doVectors) {\n      if (perThread.doc == null) {\n        perThread.doc = termsWriter.getPerDoc();\n        perThread.doc.docID = docState.docID;\n        assert perThread.doc.numVectorFields == 0;\n        assert 0 == perThread.doc.tvf.length();\n        assert 0 == perThread.doc.tvf.getFilePointer();\n      } else {\n        assert perThread.doc.docID == docState.docID;\n\n        if (termsHashPerField.numPostings != 0)\n          // Only necessary if previous doc hit a\n          // non-aborting exception while writing vectors in\n          // this field:\n          termsHashPerField.reset();\n      }\n    }\n\n    // TODO: only if needed for performance\n    //perThread.postingsCount = 0;\n\n    return doVectors;\n  }     \n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8a9e385641d717e641408d8fbbc62be8fc766357","date":1256746606,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField#start(Fieldable[],int).mjava","pathOld":"src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField#start(Fieldable[],int).mjava","sourceNew":"  @Override\n  boolean start(Fieldable[] fields, int count) {\n    doVectors = false;\n    doVectorPositions = false;\n    doVectorOffsets = false;\n\n    for(int i=0;i<count;i++) {\n      Fieldable field = fields[i];\n      if (field.isIndexed() && field.isTermVectorStored()) {\n        doVectors = true;\n        doVectorPositions |= field.isStorePositionWithTermVector();\n        doVectorOffsets |= field.isStoreOffsetWithTermVector();\n      }\n    }\n\n    if (doVectors) {\n      if (perThread.doc == null) {\n        perThread.doc = termsWriter.getPerDoc();\n        perThread.doc.docID = docState.docID;\n        assert perThread.doc.numVectorFields == 0;\n        assert 0 == perThread.doc.tvf.length();\n        assert 0 == perThread.doc.tvf.getFilePointer();\n      } else {\n        assert perThread.doc.docID == docState.docID;\n\n        if (termsHashPerField.numPostings != 0)\n          // Only necessary if previous doc hit a\n          // non-aborting exception while writing vectors in\n          // this field:\n          termsHashPerField.reset();\n      }\n    }\n\n    // TODO: only if needed for performance\n    //perThread.postingsCount = 0;\n\n    return doVectors;\n  }     \n\n","sourceOld":"  boolean start(Fieldable[] fields, int count) {\n    doVectors = false;\n    doVectorPositions = false;\n    doVectorOffsets = false;\n\n    for(int i=0;i<count;i++) {\n      Fieldable field = fields[i];\n      if (field.isIndexed() && field.isTermVectorStored()) {\n        doVectors = true;\n        doVectorPositions |= field.isStorePositionWithTermVector();\n        doVectorOffsets |= field.isStoreOffsetWithTermVector();\n      }\n    }\n\n    if (doVectors) {\n      if (perThread.doc == null) {\n        perThread.doc = termsWriter.getPerDoc();\n        perThread.doc.docID = docState.docID;\n        assert perThread.doc.numVectorFields == 0;\n        assert 0 == perThread.doc.tvf.length();\n        assert 0 == perThread.doc.tvf.getFilePointer();\n      } else {\n        assert perThread.doc.docID == docState.docID;\n\n        if (termsHashPerField.numPostings != 0)\n          // Only necessary if previous doc hit a\n          // non-aborting exception while writing vectors in\n          // this field:\n          termsHashPerField.reset();\n      }\n    }\n\n    // TODO: only if needed for performance\n    //perThread.postingsCount = 0;\n\n    return doVectors;\n  }     \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a","date":1267298041,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField#start(Fieldable[],int).mjava","pathOld":"src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField#start(Fieldable[],int).mjava","sourceNew":"  @Override\n  boolean start(Fieldable[] fields, int count) {\n    doVectors = false;\n    doVectorPositions = false;\n    doVectorOffsets = false;\n\n    for(int i=0;i<count;i++) {\n      Fieldable field = fields[i];\n      if (field.isIndexed() && field.isTermVectorStored()) {\n        doVectors = true;\n        doVectorPositions |= field.isStorePositionWithTermVector();\n        doVectorOffsets |= field.isStoreOffsetWithTermVector();\n      }\n    }\n\n    if (doVectors) {\n      if (perThread.doc == null) {\n        perThread.doc = termsWriter.getPerDoc();\n        perThread.doc.docID = docState.docID;\n        assert perThread.doc.numVectorFields == 0;\n        assert 0 == perThread.doc.perDocTvf.length();\n        assert 0 == perThread.doc.perDocTvf.getFilePointer();\n      } else {\n        assert perThread.doc.docID == docState.docID;\n\n        if (termsHashPerField.numPostings != 0)\n          // Only necessary if previous doc hit a\n          // non-aborting exception while writing vectors in\n          // this field:\n          termsHashPerField.reset();\n      }\n    }\n\n    // TODO: only if needed for performance\n    //perThread.postingsCount = 0;\n\n    return doVectors;\n  }     \n\n","sourceOld":"  @Override\n  boolean start(Fieldable[] fields, int count) {\n    doVectors = false;\n    doVectorPositions = false;\n    doVectorOffsets = false;\n\n    for(int i=0;i<count;i++) {\n      Fieldable field = fields[i];\n      if (field.isIndexed() && field.isTermVectorStored()) {\n        doVectors = true;\n        doVectorPositions |= field.isStorePositionWithTermVector();\n        doVectorOffsets |= field.isStoreOffsetWithTermVector();\n      }\n    }\n\n    if (doVectors) {\n      if (perThread.doc == null) {\n        perThread.doc = termsWriter.getPerDoc();\n        perThread.doc.docID = docState.docID;\n        assert perThread.doc.numVectorFields == 0;\n        assert 0 == perThread.doc.tvf.length();\n        assert 0 == perThread.doc.tvf.getFilePointer();\n      } else {\n        assert perThread.doc.docID == docState.docID;\n\n        if (termsHashPerField.numPostings != 0)\n          // Only necessary if previous doc hit a\n          // non-aborting exception while writing vectors in\n          // this field:\n          termsHashPerField.reset();\n      }\n    }\n\n    // TODO: only if needed for performance\n    //perThread.postingsCount = 0;\n\n    return doVectors;\n  }     \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField#start(Fieldable[],int).mjava","pathOld":"src/java/org/apache/lucene/index/TermVectorsTermsWriterPerField#start(Fieldable[],int).mjava","sourceNew":"  @Override\n  boolean start(Fieldable[] fields, int count) {\n    doVectors = false;\n    doVectorPositions = false;\n    doVectorOffsets = false;\n\n    for(int i=0;i<count;i++) {\n      Fieldable field = fields[i];\n      if (field.isIndexed() && field.isTermVectorStored()) {\n        doVectors = true;\n        doVectorPositions |= field.isStorePositionWithTermVector();\n        doVectorOffsets |= field.isStoreOffsetWithTermVector();\n      }\n    }\n\n    if (doVectors) {\n      if (perThread.doc == null) {\n        perThread.doc = termsWriter.getPerDoc();\n        perThread.doc.docID = docState.docID;\n        assert perThread.doc.numVectorFields == 0;\n        assert 0 == perThread.doc.perDocTvf.length();\n        assert 0 == perThread.doc.perDocTvf.getFilePointer();\n      } else {\n        assert perThread.doc.docID == docState.docID;\n\n        if (termsHashPerField.numPostings != 0)\n          // Only necessary if previous doc hit a\n          // non-aborting exception while writing vectors in\n          // this field:\n          termsHashPerField.reset();\n      }\n    }\n\n    // TODO: only if needed for performance\n    //perThread.postingsCount = 0;\n\n    return doVectors;\n  }     \n\n","sourceOld":"  @Override\n  boolean start(Fieldable[] fields, int count) {\n    doVectors = false;\n    doVectorPositions = false;\n    doVectorOffsets = false;\n\n    for(int i=0;i<count;i++) {\n      Fieldable field = fields[i];\n      if (field.isIndexed() && field.isTermVectorStored()) {\n        doVectors = true;\n        doVectorPositions |= field.isStorePositionWithTermVector();\n        doVectorOffsets |= field.isStoreOffsetWithTermVector();\n      }\n    }\n\n    if (doVectors) {\n      if (perThread.doc == null) {\n        perThread.doc = termsWriter.getPerDoc();\n        perThread.doc.docID = docState.docID;\n        assert perThread.doc.numVectorFields == 0;\n        assert 0 == perThread.doc.perDocTvf.length();\n        assert 0 == perThread.doc.perDocTvf.getFilePointer();\n      } else {\n        assert perThread.doc.docID == docState.docID;\n\n        if (termsHashPerField.numPostings != 0)\n          // Only necessary if previous doc hit a\n          // non-aborting exception while writing vectors in\n          // this field:\n          termsHashPerField.reset();\n      }\n    }\n\n    // TODO: only if needed for performance\n    //perThread.postingsCount = 0;\n\n    return doVectors;\n  }     \n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8a9e385641d717e641408d8fbbc62be8fc766357":["5350389bf83287111f7760b9e3db3af8e3648474"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a":["8a9e385641d717e641408d8fbbc62be8fc766357"],"5350389bf83287111f7760b9e3db3af8e3648474":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a9ac13b5f0ce5ef1b2ce168367d993a79594b23a"]},"commit2Childs":{"8a9e385641d717e641408d8fbbc62be8fc766357":["a9ac13b5f0ce5ef1b2ce168367d993a79594b23a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["5350389bf83287111f7760b9e3db3af8e3648474"],"5350389bf83287111f7760b9e3db3af8e3648474":["8a9e385641d717e641408d8fbbc62be8fc766357"],"a9ac13b5f0ce5ef1b2ce168367d993a79594b23a":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}