{"path":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","commits":[{"id":"ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d","date":1426480823,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","pathOld":"/dev/null","sourceNew":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = freq.limit > 0 ?  off + lim : Integer.MAX_VALUE - 1;\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    int effectiveMincount = (int)(fcontext.isShard() ? Math.min(1 , freq.mincount) : freq.mincount);\n    for (int i = (startTermIndex == -1) ? 1 : 0; i < nTerms; i++) {\n      if (countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      for (SlotAcc acc : accs) {\n        countAcc.setValues(allBuckets, allBucketsSlot);\n        acc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n      // add stats for this bucket\n      addStats(bucket, slotNum);\n\n      // handle sub-facets for this bucket\n      if (freq.getSubFacets().size() > 0) {\n        FacetContext subContext = fcontext.sub();\n        subContext.base = fcontext.searcher.getDocSet(new TermQuery(new Term(sf.getName(), br.clone())), fcontext.base);\n        try {\n          fillBucketSubs(bucket, subContext);\n        } finally {\n          // subContext.base.decref();  // OFF-HEAP\n          // subContext.base = null;  // do not modify context after creation... there may be deferred execution (i.e. streaming)\n        }\n      }\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      DocSet missingDocSet = null;\n      try {\n        if (startTermIndex == -1) {\n          addStats(missingBucket, 0);\n        } else {\n          missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n          // an extra slot was added to the end for this missing bucket\n          countAcc.incrementCount(nTerms, missingDocSet.size());\n          collect(missingDocSet, nTerms);\n          addStats(missingBucket, nTerms);\n        }\n\n        if (freq.getSubFacets().size() > 0) {\n          FacetContext subContext = fcontext.sub();\n          // TODO: we can do better than this!\n          if (missingDocSet == null) {\n            missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n          }\n          subContext.base = missingDocSet;\n          fillBucketSubs(missingBucket, subContext);\n        }\n\n        res.add(\"missing\", missingBucket);\n      } finally {\n        if (missingDocSet != null) {\n          // missingDocSet.decref(); // OFF-HEAP\n          missingDocSet = null;\n        }\n      }\n    }\n\n    return res;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["b834e175d4d6b99680745b76417f082cfad6b76f","dd0759e8803a09424422a329163d5900f6b10c42"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4a7c13535572b8e97cc477fc3388a57321a7751a","date":1427500960,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","sourceNew":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = freq.limit > 0 ?  off + lim : Integer.MAX_VALUE - 1;\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = (startTermIndex == -1) ? 1 : 0; i < nTerms; i++) {\n      if (countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      countAcc.setValues(allBuckets, allBucketsSlot);\n      for (SlotAcc acc : accs) {\n        acc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n      // add stats for this bucket\n      addStats(bucket, slotNum);\n\n      // handle sub-facets for this bucket\n      if (freq.getSubFacets().size() > 0) {\n        FacetContext subContext = fcontext.sub();\n        subContext.base = fcontext.searcher.getDocSet(new TermQuery(new Term(sf.getName(), br.clone())), fcontext.base);\n        try {\n          fillBucketSubs(bucket, subContext);\n        } finally {\n          // subContext.base.decref();  // OFF-HEAP\n          // subContext.base = null;  // do not modify context after creation... there may be deferred execution (i.e. streaming)\n        }\n      }\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      DocSet missingDocSet = null;\n      try {\n        if (startTermIndex == -1) {\n          addStats(missingBucket, 0);\n        } else {\n          missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n          // an extra slot was added to the end for this missing bucket\n          countAcc.incrementCount(nTerms, missingDocSet.size());\n          collect(missingDocSet, nTerms);\n          addStats(missingBucket, nTerms);\n        }\n\n        if (freq.getSubFacets().size() > 0) {\n          FacetContext subContext = fcontext.sub();\n          // TODO: we can do better than this!\n          if (missingDocSet == null) {\n            missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n          }\n          subContext.base = missingDocSet;\n          fillBucketSubs(missingBucket, subContext);\n        }\n\n        res.add(\"missing\", missingBucket);\n      } finally {\n        if (missingDocSet != null) {\n          // missingDocSet.decref(); // OFF-HEAP\n          missingDocSet = null;\n        }\n      }\n    }\n\n    return res;\n  }\n\n","sourceOld":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = freq.limit > 0 ?  off + lim : Integer.MAX_VALUE - 1;\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    int effectiveMincount = (int)(fcontext.isShard() ? Math.min(1 , freq.mincount) : freq.mincount);\n    for (int i = (startTermIndex == -1) ? 1 : 0; i < nTerms; i++) {\n      if (countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      for (SlotAcc acc : accs) {\n        countAcc.setValues(allBuckets, allBucketsSlot);\n        acc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n      // add stats for this bucket\n      addStats(bucket, slotNum);\n\n      // handle sub-facets for this bucket\n      if (freq.getSubFacets().size() > 0) {\n        FacetContext subContext = fcontext.sub();\n        subContext.base = fcontext.searcher.getDocSet(new TermQuery(new Term(sf.getName(), br.clone())), fcontext.base);\n        try {\n          fillBucketSubs(bucket, subContext);\n        } finally {\n          // subContext.base.decref();  // OFF-HEAP\n          // subContext.base = null;  // do not modify context after creation... there may be deferred execution (i.e. streaming)\n        }\n      }\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      DocSet missingDocSet = null;\n      try {\n        if (startTermIndex == -1) {\n          addStats(missingBucket, 0);\n        } else {\n          missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n          // an extra slot was added to the end for this missing bucket\n          countAcc.incrementCount(nTerms, missingDocSet.size());\n          collect(missingDocSet, nTerms);\n          addStats(missingBucket, nTerms);\n        }\n\n        if (freq.getSubFacets().size() > 0) {\n          FacetContext subContext = fcontext.sub();\n          // TODO: we can do better than this!\n          if (missingDocSet == null) {\n            missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n          }\n          subContext.base = missingDocSet;\n          fillBucketSubs(missingBucket, subContext);\n        }\n\n        res.add(\"missing\", missingBucket);\n      } finally {\n        if (missingDocSet != null) {\n          // missingDocSet.decref(); // OFF-HEAP\n          missingDocSet = null;\n        }\n      }\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":0,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","pathOld":"/dev/null","sourceNew":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = freq.limit > 0 ?  off + lim : Integer.MAX_VALUE - 1;\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = (startTermIndex == -1) ? 1 : 0; i < nTerms; i++) {\n      if (countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      countAcc.setValues(allBuckets, allBucketsSlot);\n      for (SlotAcc acc : accs) {\n        acc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n      // add stats for this bucket\n      addStats(bucket, slotNum);\n\n      // handle sub-facets for this bucket\n      if (freq.getSubFacets().size() > 0) {\n        FacetContext subContext = fcontext.sub();\n        subContext.base = fcontext.searcher.getDocSet(new TermQuery(new Term(sf.getName(), br.clone())), fcontext.base);\n        try {\n          fillBucketSubs(bucket, subContext);\n        } finally {\n          // subContext.base.decref();  // OFF-HEAP\n          // subContext.base = null;  // do not modify context after creation... there may be deferred execution (i.e. streaming)\n        }\n      }\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      DocSet missingDocSet = null;\n      try {\n        if (startTermIndex == -1) {\n          addStats(missingBucket, 0);\n        } else {\n          missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n          // an extra slot was added to the end for this missing bucket\n          countAcc.incrementCount(nTerms, missingDocSet.size());\n          collect(missingDocSet, nTerms);\n          addStats(missingBucket, nTerms);\n        }\n\n        if (freq.getSubFacets().size() > 0) {\n          FacetContext subContext = fcontext.sub();\n          // TODO: we can do better than this!\n          if (missingDocSet == null) {\n            missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n          }\n          subContext.base = missingDocSet;\n          fillBucketSubs(missingBucket, subContext);\n        }\n\n        res.add(\"missing\", missingBucket);\n      } finally {\n        if (missingDocSet != null) {\n          // missingDocSet.decref(); // OFF-HEAP\n          missingDocSet = null;\n        }\n      }\n    }\n\n    return res;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"faf1236ae092482293a7e0659e347d172185ef6f","date":1430314113,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","sourceNew":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = freq.limit > 0 ?  off + lim : Integer.MAX_VALUE - 1;\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = (startTermIndex == -1) ? 1 : 0; i < nTerms; i++) {\n      if (countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      countAcc.setValues(allBuckets, allBucketsSlot);\n      for (SlotAcc acc : accs) {\n        acc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n      // add stats for this bucket\n      addStats(bucket, slotNum);\n\n      // handle sub-facets for this bucket\n      if (freq.getSubFacets().size() > 0) {\n        TermQuery filter = new TermQuery(new Term(sf.getName(), br.clone()));\n        try {\n          processSubs(bucket, filter, fcontext.searcher.getDocSet(filter, fcontext.base) );\n        } finally {\n          // subContext.base.decref();  // OFF-HEAP\n          // subContext.base = null;  // do not modify context after creation... there may be deferred execution (i.e. streaming)\n        }\n      }\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      DocSet missingDocSet = null;\n      try {\n        if (startTermIndex == -1) {\n          addStats(missingBucket, 0);\n        } else {\n          missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n          // an extra slot was added to the end for this missing bucket\n          countAcc.incrementCount(nTerms, missingDocSet.size());\n          collect(missingDocSet, nTerms);\n          addStats(missingBucket, nTerms);\n        }\n\n        if (freq.getSubFacets().size() > 0) {\n          // TODO: we can do better than this!\n          if (missingDocSet == null) {\n            missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n          }\n          processSubs(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), missingDocSet);\n        }\n\n        res.add(\"missing\", missingBucket);\n      } finally {\n        if (missingDocSet != null) {\n          // missingDocSet.decref(); // OFF-HEAP\n          missingDocSet = null;\n        }\n      }\n    }\n\n    return res;\n  }\n\n","sourceOld":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = freq.limit > 0 ?  off + lim : Integer.MAX_VALUE - 1;\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = (startTermIndex == -1) ? 1 : 0; i < nTerms; i++) {\n      if (countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      countAcc.setValues(allBuckets, allBucketsSlot);\n      for (SlotAcc acc : accs) {\n        acc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n      // add stats for this bucket\n      addStats(bucket, slotNum);\n\n      // handle sub-facets for this bucket\n      if (freq.getSubFacets().size() > 0) {\n        FacetContext subContext = fcontext.sub();\n        subContext.base = fcontext.searcher.getDocSet(new TermQuery(new Term(sf.getName(), br.clone())), fcontext.base);\n        try {\n          fillBucketSubs(bucket, subContext);\n        } finally {\n          // subContext.base.decref();  // OFF-HEAP\n          // subContext.base = null;  // do not modify context after creation... there may be deferred execution (i.e. streaming)\n        }\n      }\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      DocSet missingDocSet = null;\n      try {\n        if (startTermIndex == -1) {\n          addStats(missingBucket, 0);\n        } else {\n          missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n          // an extra slot was added to the end for this missing bucket\n          countAcc.incrementCount(nTerms, missingDocSet.size());\n          collect(missingDocSet, nTerms);\n          addStats(missingBucket, nTerms);\n        }\n\n        if (freq.getSubFacets().size() > 0) {\n          FacetContext subContext = fcontext.sub();\n          // TODO: we can do better than this!\n          if (missingDocSet == null) {\n            missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n          }\n          subContext.base = missingDocSet;\n          fillBucketSubs(missingBucket, subContext);\n        }\n\n        res.add(\"missing\", missingBucket);\n      } finally {\n        if (missingDocSet != null) {\n          // missingDocSet.decref(); // OFF-HEAP\n          missingDocSet = null;\n        }\n      }\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"dd0759e8803a09424422a329163d5900f6b10c42","date":1431227616,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","sourceNew":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit > 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = (startTermIndex == -1) ? 1 : 0; i < nTerms; i++) {\n      if (countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      countAcc.setValues(allBuckets, allBucketsSlot);\n      for (SlotAcc acc : accs) {\n        acc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n      // add stats for this bucket\n      addStats(bucket, slotNum);\n\n      // handle sub-facets for this bucket\n      if (freq.getSubFacets().size() > 0) {\n        TermQuery filter = new TermQuery(new Term(sf.getName(), br.clone()));\n        try {\n          processSubs(bucket, filter, fcontext.searcher.getDocSet(filter, fcontext.base) );\n        } finally {\n          // subContext.base.decref();  // OFF-HEAP\n          // subContext.base = null;  // do not modify context after creation... there may be deferred execution (i.e. streaming)\n        }\n      }\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      DocSet missingDocSet = null;\n      try {\n        if (startTermIndex == -1) {\n          addStats(missingBucket, 0);\n        } else {\n          missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n          // an extra slot was added to the end for this missing bucket\n          countAcc.incrementCount(nTerms, missingDocSet.size());\n          collect(missingDocSet, nTerms);\n          addStats(missingBucket, nTerms);\n        }\n\n        if (freq.getSubFacets().size() > 0) {\n          // TODO: we can do better than this!\n          if (missingDocSet == null) {\n            missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n          }\n          processSubs(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), missingDocSet);\n        }\n\n        res.add(\"missing\", missingBucket);\n      } finally {\n        if (missingDocSet != null) {\n          // missingDocSet.decref(); // OFF-HEAP\n          missingDocSet = null;\n        }\n      }\n    }\n\n    return res;\n  }\n\n","sourceOld":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = freq.limit > 0 ?  off + lim : Integer.MAX_VALUE - 1;\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = (startTermIndex == -1) ? 1 : 0; i < nTerms; i++) {\n      if (countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      countAcc.setValues(allBuckets, allBucketsSlot);\n      for (SlotAcc acc : accs) {\n        acc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n      // add stats for this bucket\n      addStats(bucket, slotNum);\n\n      // handle sub-facets for this bucket\n      if (freq.getSubFacets().size() > 0) {\n        TermQuery filter = new TermQuery(new Term(sf.getName(), br.clone()));\n        try {\n          processSubs(bucket, filter, fcontext.searcher.getDocSet(filter, fcontext.base) );\n        } finally {\n          // subContext.base.decref();  // OFF-HEAP\n          // subContext.base = null;  // do not modify context after creation... there may be deferred execution (i.e. streaming)\n        }\n      }\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      DocSet missingDocSet = null;\n      try {\n        if (startTermIndex == -1) {\n          addStats(missingBucket, 0);\n        } else {\n          missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n          // an extra slot was added to the end for this missing bucket\n          countAcc.incrementCount(nTerms, missingDocSet.size());\n          collect(missingDocSet, nTerms);\n          addStats(missingBucket, nTerms);\n        }\n\n        if (freq.getSubFacets().size() > 0) {\n          // TODO: we can do better than this!\n          if (missingDocSet == null) {\n            missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n          }\n          processSubs(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), missingDocSet);\n        }\n\n        res.add(\"missing\", missingBucket);\n      } finally {\n        if (missingDocSet != null) {\n          // missingDocSet.decref(); // OFF-HEAP\n          missingDocSet = null;\n        }\n      }\n    }\n\n    return res;\n  }\n\n","bugFix":["ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d"],"bugIntro":["b834e175d4d6b99680745b76417f082cfad6b76f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9e13d0d4d8b6dc352cb304974502b9a36c153f78","date":1436492687,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","sourceNew":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit > 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = (startTermIndex == -1) ? 1 : 0; i < nTerms; i++) {\n      // screen out buckets not matching mincount immediately (i.e. don't even increment numBuckets)\n      if (effectiveMincount > 0 && countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      allBuckets.add(\"count\", allBucketsAcc.getSpecialCount());\n      if (allBucketsAcc != null) {\n        allBucketsAcc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    // TODO: do this with a callback instead?\n    boolean needFilter = deferredAggs != null || freq.getSubFacets().size() > 0;\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n\n      TermQuery filter = needFilter ? new TermQuery(new Term(sf.getName(), br.clone())) : null;\n      fillBucket(bucket, countAcc.getCount(slotNum), slotNum, null, filter);\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      fillBucket(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field));\n      res.add(\"missing\", missingBucket);\n\n      /*** TODO - OPTIMIZE\n      DocSet missingDocSet = null;\n      if (startTermIndex == -1) {\n        fillBucket(missingBucket, countAcc.getCount(0), null);\n      } else {\n        missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n        // an extra slot was added to the end for this missing bucket\n        countAcc.incrementCount(nTerms, missingDocSet.size());\n        collect(missingDocSet, nTerms);\n        addStats(missingBucket, nTerms);\n      }\n\n      if (freq.getSubFacets().size() > 0) {\n        // TODO: we can do better than this!\n        if (missingDocSet == null) {\n          missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n        }\n        processSubs(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), missingDocSet);\n      }\n       ***/\n    }\n\n    return res;\n  }\n\n","sourceOld":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit > 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = (startTermIndex == -1) ? 1 : 0; i < nTerms; i++) {\n      if (countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      countAcc.setValues(allBuckets, allBucketsSlot);\n      for (SlotAcc acc : accs) {\n        acc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n      // add stats for this bucket\n      addStats(bucket, slotNum);\n\n      // handle sub-facets for this bucket\n      if (freq.getSubFacets().size() > 0) {\n        TermQuery filter = new TermQuery(new Term(sf.getName(), br.clone()));\n        try {\n          processSubs(bucket, filter, fcontext.searcher.getDocSet(filter, fcontext.base) );\n        } finally {\n          // subContext.base.decref();  // OFF-HEAP\n          // subContext.base = null;  // do not modify context after creation... there may be deferred execution (i.e. streaming)\n        }\n      }\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      DocSet missingDocSet = null;\n      try {\n        if (startTermIndex == -1) {\n          addStats(missingBucket, 0);\n        } else {\n          missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n          // an extra slot was added to the end for this missing bucket\n          countAcc.incrementCount(nTerms, missingDocSet.size());\n          collect(missingDocSet, nTerms);\n          addStats(missingBucket, nTerms);\n        }\n\n        if (freq.getSubFacets().size() > 0) {\n          // TODO: we can do better than this!\n          if (missingDocSet == null) {\n            missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n          }\n          processSubs(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), missingDocSet);\n        }\n\n        res.add(\"missing\", missingBucket);\n      } finally {\n        if (missingDocSet != null) {\n          // missingDocSet.decref(); // OFF-HEAP\n          missingDocSet = null;\n        }\n      }\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":["67e0d8ccf24ea95997da68450b6eb7143ae29a0d"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"67e0d8ccf24ea95997da68450b6eb7143ae29a0d","date":1436740493,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","sourceNew":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit > 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = (startTermIndex == -1) ? 1 : 0; i < nTerms; i++) {\n      // screen out buckets not matching mincount immediately (i.e. don't even increment numBuckets)\n      if (effectiveMincount > 0 && countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      allBuckets.add(\"count\", allBucketsAcc.getSpecialCount());\n      if (allBucketsAcc != null) {\n        allBucketsAcc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    // TODO: do this with a callback instead?\n    boolean needFilter = deferredAggs != null || freq.getSubFacets().size() > 0;\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n\n      TermQuery filter = needFilter ? new TermQuery(new Term(sf.getName(), BytesRef.deepCopyOf(br))) : null;\n      fillBucket(bucket, countAcc.getCount(slotNum), slotNum, null, filter);\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      fillBucket(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field));\n      res.add(\"missing\", missingBucket);\n\n      /*** TODO - OPTIMIZE\n      DocSet missingDocSet = null;\n      if (startTermIndex == -1) {\n        fillBucket(missingBucket, countAcc.getCount(0), null);\n      } else {\n        missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n        // an extra slot was added to the end for this missing bucket\n        countAcc.incrementCount(nTerms, missingDocSet.size());\n        collect(missingDocSet, nTerms);\n        addStats(missingBucket, nTerms);\n      }\n\n      if (freq.getSubFacets().size() > 0) {\n        // TODO: we can do better than this!\n        if (missingDocSet == null) {\n          missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n        }\n        processSubs(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), missingDocSet);\n      }\n       ***/\n    }\n\n    return res;\n  }\n\n","sourceOld":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit > 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = (startTermIndex == -1) ? 1 : 0; i < nTerms; i++) {\n      // screen out buckets not matching mincount immediately (i.e. don't even increment numBuckets)\n      if (effectiveMincount > 0 && countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      allBuckets.add(\"count\", allBucketsAcc.getSpecialCount());\n      if (allBucketsAcc != null) {\n        allBucketsAcc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    // TODO: do this with a callback instead?\n    boolean needFilter = deferredAggs != null || freq.getSubFacets().size() > 0;\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n\n      TermQuery filter = needFilter ? new TermQuery(new Term(sf.getName(), br.clone())) : null;\n      fillBucket(bucket, countAcc.getCount(slotNum), slotNum, null, filter);\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      fillBucket(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field));\n      res.add(\"missing\", missingBucket);\n\n      /*** TODO - OPTIMIZE\n      DocSet missingDocSet = null;\n      if (startTermIndex == -1) {\n        fillBucket(missingBucket, countAcc.getCount(0), null);\n      } else {\n        missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n        // an extra slot was added to the end for this missing bucket\n        countAcc.incrementCount(nTerms, missingDocSet.size());\n        collect(missingDocSet, nTerms);\n        addStats(missingBucket, nTerms);\n      }\n\n      if (freq.getSubFacets().size() > 0) {\n        // TODO: we can do better than this!\n        if (missingDocSet == null) {\n          missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n        }\n        processSubs(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), missingDocSet);\n      }\n       ***/\n    }\n\n    return res;\n  }\n\n","bugFix":["9e13d0d4d8b6dc352cb304974502b9a36c153f78"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"168f749bbf9022a1ba5fea29c54baa1c00883d1d","date":1437587676,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","sourceNew":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit > 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = 0; i < nTerms; i++) {\n      // screen out buckets not matching mincount immediately (i.e. don't even increment numBuckets)\n      if (effectiveMincount > 0 && countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      allBuckets.add(\"count\", allBucketsAcc.getSpecialCount());\n      if (allBucketsAcc != null) {\n        allBucketsAcc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    // TODO: do this with a callback instead?\n    boolean needFilter = deferredAggs != null || freq.getSubFacets().size() > 0;\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n\n      TermQuery filter = needFilter ? new TermQuery(new Term(sf.getName(), BytesRef.deepCopyOf(br))) : null;\n      fillBucket(bucket, countAcc.getCount(slotNum), slotNum, null, filter);\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      fillBucket(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), null);\n      res.add(\"missing\", missingBucket);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit > 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = (startTermIndex == -1) ? 1 : 0; i < nTerms; i++) {\n      // screen out buckets not matching mincount immediately (i.e. don't even increment numBuckets)\n      if (effectiveMincount > 0 && countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      allBuckets.add(\"count\", allBucketsAcc.getSpecialCount());\n      if (allBucketsAcc != null) {\n        allBucketsAcc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    // TODO: do this with a callback instead?\n    boolean needFilter = deferredAggs != null || freq.getSubFacets().size() > 0;\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n\n      TermQuery filter = needFilter ? new TermQuery(new Term(sf.getName(), BytesRef.deepCopyOf(br))) : null;\n      fillBucket(bucket, countAcc.getCount(slotNum), slotNum, null, filter);\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      fillBucket(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field));\n      res.add(\"missing\", missingBucket);\n\n      /*** TODO - OPTIMIZE\n      DocSet missingDocSet = null;\n      if (startTermIndex == -1) {\n        fillBucket(missingBucket, countAcc.getCount(0), null);\n      } else {\n        missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n        // an extra slot was added to the end for this missing bucket\n        countAcc.incrementCount(nTerms, missingDocSet.size());\n        collect(missingDocSet, nTerms);\n        addStats(missingBucket, nTerms);\n      }\n\n      if (freq.getSubFacets().size() > 0) {\n        // TODO: we can do better than this!\n        if (missingDocSet == null) {\n          missingDocSet = getFieldMissing(fcontext.searcher, fcontext.base, freq.field);\n        }\n        processSubs(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), missingDocSet);\n      }\n       ***/\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"38b5bd3ae837751f57f363e9a41b833794222814","date":1445342257,"type":3,"author":"Tommaso Teofili","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","sourceNew":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit > 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = 0; i < nTerms; i++) {\n      // screen out buckets not matching mincount immediately (i.e. don't even increment numBuckets)\n      if (effectiveMincount > 0 && countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      allBuckets.add(\"count\", allBucketsAcc.getSpecialCount());\n      if (allBucketsAcc != null) {\n        allBucketsAcc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    // TODO: do this with a callback instead?\n    boolean needFilter = deferredAggs != null || freq.getSubFacets().size() > 0;\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n\n      TermQuery filter = needFilter ? new TermQuery(new Term(sf.getName(), br)) : null;\n      fillBucket(bucket, countAcc.getCount(slotNum), slotNum, null, filter);\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      fillBucket(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), null);\n      res.add(\"missing\", missingBucket);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit > 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = 0; i < nTerms; i++) {\n      // screen out buckets not matching mincount immediately (i.e. don't even increment numBuckets)\n      if (effectiveMincount > 0 && countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      allBuckets.add(\"count\", allBucketsAcc.getSpecialCount());\n      if (allBucketsAcc != null) {\n        allBucketsAcc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    // TODO: do this with a callback instead?\n    boolean needFilter = deferredAggs != null || freq.getSubFacets().size() > 0;\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n\n      TermQuery filter = needFilter ? new TermQuery(new Term(sf.getName(), BytesRef.deepCopyOf(br))) : null;\n      fillBucket(bucket, countAcc.getCount(slotNum), slotNum, null, filter);\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      fillBucket(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), null);\n      res.add(\"missing\", missingBucket);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b834e175d4d6b99680745b76417f082cfad6b76f","date":1445799013,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","sourceNew":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit >= 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = 0; i < nTerms; i++) {\n      // screen out buckets not matching mincount immediately (i.e. don't even increment numBuckets)\n      if (effectiveMincount > 0 && countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else if (lim > 0) {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      allBuckets.add(\"count\", allBucketsAcc.getSpecialCount());\n      if (allBucketsAcc != null) {\n        allBucketsAcc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    // TODO: do this with a callback instead?\n    boolean needFilter = deferredAggs != null || freq.getSubFacets().size() > 0;\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n\n      TermQuery filter = needFilter ? new TermQuery(new Term(sf.getName(), br)) : null;\n      fillBucket(bucket, countAcc.getCount(slotNum), slotNum, null, filter);\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      fillBucket(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), null);\n      res.add(\"missing\", missingBucket);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit > 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = 0; i < nTerms; i++) {\n      // screen out buckets not matching mincount immediately (i.e. don't even increment numBuckets)\n      if (effectiveMincount > 0 && countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      allBuckets.add(\"count\", allBucketsAcc.getSpecialCount());\n      if (allBucketsAcc != null) {\n        allBucketsAcc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    // TODO: do this with a callback instead?\n    boolean needFilter = deferredAggs != null || freq.getSubFacets().size() > 0;\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n\n      TermQuery filter = needFilter ? new TermQuery(new Term(sf.getName(), br)) : null;\n      fillBucket(bucket, countAcc.getCount(slotNum), slotNum, null, filter);\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      fillBucket(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), null);\n      res.add(\"missing\", missingBucket);\n    }\n\n    return res;\n  }\n\n","bugFix":["dd0759e8803a09424422a329163d5900f6b10c42","ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1480a9d175b147e15628e77342c4175ad3fc4611","date":1452646257,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","sourceNew":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit >= 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = 0; i < nTerms; i++) {\n      // screen out buckets not matching mincount immediately (i.e. don't even increment numBuckets)\n      if (effectiveMincount > 0 && countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else if (lim > 0) {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    FacetDebugInfo fdebug = fcontext.getDebugInfo();\n    if (fdebug != null) fdebug.putInfoItem(\"numBuckets\", new Long(numBuckets));\n    \n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      allBuckets.add(\"count\", allBucketsAcc.getSpecialCount());\n      if (allBucketsAcc != null) {\n        allBucketsAcc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    // TODO: do this with a callback instead?\n    boolean needFilter = deferredAggs != null || freq.getSubFacets().size() > 0;\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n\n      TermQuery filter = needFilter ? new TermQuery(new Term(sf.getName(), br)) : null;\n      fillBucket(bucket, countAcc.getCount(slotNum), slotNum, null, filter);\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      fillBucket(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), null);\n      res.add(\"missing\", missingBucket);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit >= 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = 0; i < nTerms; i++) {\n      // screen out buckets not matching mincount immediately (i.e. don't even increment numBuckets)\n      if (effectiveMincount > 0 && countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else if (lim > 0) {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      allBuckets.add(\"count\", allBucketsAcc.getSpecialCount());\n      if (allBucketsAcc != null) {\n        allBucketsAcc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    // TODO: do this with a callback instead?\n    boolean needFilter = deferredAggs != null || freq.getSubFacets().size() > 0;\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n\n      TermQuery filter = needFilter ? new TermQuery(new Term(sf.getName(), br)) : null;\n      fillBucket(bucket, countAcc.getCount(slotNum), slotNum, null, filter);\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      fillBucket(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), null);\n      res.add(\"missing\", missingBucket);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79759974460bc59933cd169acc94f5c6b16368d5","date":1471318443,"type":5,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByArray#findTopSlots().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","sourceNew":"  private SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList<>(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit >= 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = 0; i < nTerms; i++) {\n      // screen out buckets not matching mincount immediately (i.e. don't even increment numBuckets)\n      if (effectiveMincount > 0 && countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else if (lim > 0) {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap<Object> map = new SimpleOrderedMap<>(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    FacetDebugInfo fdebug = fcontext.getDebugInfo();\n    if (fdebug != null) fdebug.putInfoItem(\"numBuckets\", (long) numBuckets);\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      allBuckets.add(\"count\", allBucketsAcc.getSpecialCount());\n      if (allBucketsAcc != null) {\n        allBucketsAcc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList<SimpleOrderedMap<Object>> bucketList = new ArrayList<>(collectCount);\n    res.add(\"buckets\", bucketList);\n\n    // TODO: do this with a callback instead?\n    boolean needFilter = deferredAggs != null || freq.getSubFacets().size() > 0;\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n\n      TermQuery filter = needFilter ? new TermQuery(new Term(sf.getName(), br)) : null;\n      fillBucket(bucket, countAcc.getCount(slotNum), slotNum, null, filter);\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      fillBucket(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), null);\n      res.add(\"missing\", missingBucket);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit >= 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = 0; i < nTerms; i++) {\n      // screen out buckets not matching mincount immediately (i.e. don't even increment numBuckets)\n      if (effectiveMincount > 0 && countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else if (lim > 0) {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    FacetDebugInfo fdebug = fcontext.getDebugInfo();\n    if (fdebug != null) fdebug.putInfoItem(\"numBuckets\", new Long(numBuckets));\n    \n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      allBuckets.add(\"count\", allBucketsAcc.getSpecialCount());\n      if (allBucketsAcc != null) {\n        allBucketsAcc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    // TODO: do this with a callback instead?\n    boolean needFilter = deferredAggs != null || freq.getSubFacets().size() > 0;\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n\n      TermQuery filter = needFilter ? new TermQuery(new Term(sf.getName(), br)) : null;\n      fillBucket(bucket, countAcc.getCount(slotNum), slotNum, null, filter);\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      fillBucket(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), null);\n      res.add(\"missing\", missingBucket);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6","date":1471496851,"type":5,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByArray#findTopSlots().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","sourceNew":"  private SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList<>(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit >= 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = 0; i < nTerms; i++) {\n      // screen out buckets not matching mincount immediately (i.e. don't even increment numBuckets)\n      if (effectiveMincount > 0 && countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else if (lim > 0) {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap<Object> map = new SimpleOrderedMap<>(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    FacetDebugInfo fdebug = fcontext.getDebugInfo();\n    if (fdebug != null) fdebug.putInfoItem(\"numBuckets\", (long) numBuckets);\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      allBuckets.add(\"count\", allBucketsAcc.getSpecialCount());\n      if (allBucketsAcc != null) {\n        allBucketsAcc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList<SimpleOrderedMap<Object>> bucketList = new ArrayList<>(collectCount);\n    res.add(\"buckets\", bucketList);\n\n    // TODO: do this with a callback instead?\n    boolean needFilter = deferredAggs != null || freq.getSubFacets().size() > 0;\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n\n      TermQuery filter = needFilter ? new TermQuery(new Term(sf.getName(), br)) : null;\n      fillBucket(bucket, countAcc.getCount(slotNum), slotNum, null, filter);\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      fillBucket(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), null);\n      res.add(\"missing\", missingBucket);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit >= 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = 0; i < nTerms; i++) {\n      // screen out buckets not matching mincount immediately (i.e. don't even increment numBuckets)\n      if (effectiveMincount > 0 && countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else if (lim > 0) {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    FacetDebugInfo fdebug = fcontext.getDebugInfo();\n    if (fdebug != null) fdebug.putInfoItem(\"numBuckets\", new Long(numBuckets));\n    \n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      allBuckets.add(\"count\", allBucketsAcc.getSpecialCount());\n      if (allBucketsAcc != null) {\n        allBucketsAcc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    // TODO: do this with a callback instead?\n    boolean needFilter = deferredAggs != null || freq.getSubFacets().size() > 0;\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n\n      TermQuery filter = needFilter ? new TermQuery(new Term(sf.getName(), br)) : null;\n      fillBucket(bucket, countAcc.getCount(slotNum), slotNum, null, filter);\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      fillBucket(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), null);\n      res.add(\"missing\", missingBucket);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"403d05f7f8d69b65659157eff1bc1d2717f04c66","date":1471692961,"type":5,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorByArray#findTopSlots().mjava","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","sourceNew":"  private SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList<>(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit >= 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = 0; i < nTerms; i++) {\n      // screen out buckets not matching mincount immediately (i.e. don't even increment numBuckets)\n      if (effectiveMincount > 0 && countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else if (lim > 0) {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap<Object> map = new SimpleOrderedMap<>(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    FacetDebugInfo fdebug = fcontext.getDebugInfo();\n    if (fdebug != null) fdebug.putInfoItem(\"numBuckets\", (long) numBuckets);\n\n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      allBuckets.add(\"count\", allBucketsAcc.getSpecialCount());\n      if (allBucketsAcc != null) {\n        allBucketsAcc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList<SimpleOrderedMap<Object>> bucketList = new ArrayList<>(collectCount);\n    res.add(\"buckets\", bucketList);\n\n    // TODO: do this with a callback instead?\n    boolean needFilter = deferredAggs != null || freq.getSubFacets().size() > 0;\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n\n      TermQuery filter = needFilter ? new TermQuery(new Term(sf.getName(), br)) : null;\n      fillBucket(bucket, countAcc.getCount(slotNum), slotNum, null, filter);\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      fillBucket(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), null);\n      res.add(\"missing\", missingBucket);\n    }\n\n    return res;\n  }\n\n","sourceOld":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit >= 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = 0; i < nTerms; i++) {\n      // screen out buckets not matching mincount immediately (i.e. don't even increment numBuckets)\n      if (effectiveMincount > 0 && countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else if (lim > 0) {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    FacetDebugInfo fdebug = fcontext.getDebugInfo();\n    if (fdebug != null) fdebug.putInfoItem(\"numBuckets\", new Long(numBuckets));\n    \n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      allBuckets.add(\"count\", allBucketsAcc.getSpecialCount());\n      if (allBucketsAcc != null) {\n        allBucketsAcc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    // TODO: do this with a callback instead?\n    boolean needFilter = deferredAggs != null || freq.getSubFacets().size() > 0;\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n\n      TermQuery filter = needFilter ? new TermQuery(new Term(sf.getName(), br)) : null;\n      fillBucket(bucket, countAcc.getCount(slotNum), slotNum, null, filter);\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      fillBucket(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), null);\n      res.add(\"missing\", missingBucket);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"solr/core/src/java/org/apache/solr/search/facet/FacetFieldProcessorFCBase[FacetField]#findTopSlots().mjava","sourceNew":null,"sourceOld":"  protected SimpleOrderedMap<Object> findTopSlots() throws IOException {\n    SimpleOrderedMap<Object> res = new SimpleOrderedMap<>();\n\n    int numBuckets = 0;\n    List<Object> bucketVals = null;\n    if (freq.numBuckets && fcontext.isShard()) {\n      bucketVals = new ArrayList(100);\n    }\n\n    int off = fcontext.isShard() ? 0 : (int) freq.offset;\n    // add a modest amount of over-request if this is a shard request\n    int lim = freq.limit >= 0 ? (fcontext.isShard() ? (int)(freq.limit*1.1+4) : (int)freq.limit) : Integer.MAX_VALUE;\n\n    int maxsize = (int)(freq.limit >= 0 ?  freq.offset + lim : Integer.MAX_VALUE - 1);\n    maxsize = Math.min(maxsize, nTerms);\n\n    final int sortMul = freq.sortDirection.getMultiplier();\n    final SlotAcc sortAcc = this.sortAcc;\n\n    PriorityQueue<Slot> queue = new PriorityQueue<Slot>(maxsize) {\n      @Override\n      protected boolean lessThan(Slot a, Slot b) {\n        int cmp = sortAcc.compare(a.slot, b.slot) * sortMul;\n        return cmp == 0 ? b.slot < a.slot : cmp < 0;\n      }\n    };\n\n    Slot bottom = null;\n    for (int i = 0; i < nTerms; i++) {\n      // screen out buckets not matching mincount immediately (i.e. don't even increment numBuckets)\n      if (effectiveMincount > 0 && countAcc.getCount(i) < effectiveMincount) {\n        continue;\n      }\n\n      numBuckets++;\n      if (bucketVals != null && bucketVals.size()<100) {\n        int ord = startTermIndex + i;\n        BytesRef br = lookupOrd(ord);\n        Object val = sf.getType().toObject(sf, br);\n        bucketVals.add(val);\n      }\n\n\n      if (bottom != null) {\n        if (sortAcc.compare(bottom.slot, i) * sortMul < 0) {\n          bottom.slot = i;\n          bottom = queue.updateTop();\n        }\n      } else if (lim > 0) {\n        // queue not full\n        Slot s = new Slot();\n        s.slot = i;\n        queue.add(s);\n        if (queue.size() >= maxsize) {\n          bottom = queue.top();\n        }\n      }\n    }\n\n    if (freq.numBuckets) {\n      if (!fcontext.isShard()) {\n        res.add(\"numBuckets\", numBuckets);\n      } else {\n        SimpleOrderedMap map = new SimpleOrderedMap(2);\n        map.add(\"numBuckets\", numBuckets);\n        map.add(\"vals\", bucketVals);\n        res.add(\"numBuckets\", map);\n      }\n    }\n\n    FacetDebugInfo fdebug = fcontext.getDebugInfo();\n    if (fdebug != null) fdebug.putInfoItem(\"numBuckets\", new Long(numBuckets));\n    \n    // if we are deep paging, we don't have to order the highest \"offset\" counts.\n    int collectCount = Math.max(0, queue.size() - off);\n    assert collectCount <= lim;\n    int[] sortedSlots = new int[collectCount];\n    for (int i = collectCount - 1; i >= 0; i--) {\n      sortedSlots[i] = queue.pop().slot;\n    }\n\n    if (freq.allBuckets) {\n      SimpleOrderedMap<Object> allBuckets = new SimpleOrderedMap<>();\n      allBuckets.add(\"count\", allBucketsAcc.getSpecialCount());\n      if (allBucketsAcc != null) {\n        allBucketsAcc.setValues(allBuckets, allBucketsSlot);\n      }\n      res.add(\"allBuckets\", allBuckets);\n    }\n\n    ArrayList bucketList = new ArrayList(collectCount);\n    res.add(\"buckets\", bucketList);\n\n\n    // TODO: do this with a callback instead?\n    boolean needFilter = deferredAggs != null || freq.getSubFacets().size() > 0;\n\n    for (int slotNum : sortedSlots) {\n      SimpleOrderedMap<Object> bucket = new SimpleOrderedMap<>();\n\n      // get the ord of the slot...\n      int ord = startTermIndex + slotNum;\n\n      BytesRef br = lookupOrd(ord);\n      Object val = sf.getType().toObject(sf, br);\n\n      bucket.add(\"val\", val);\n\n      TermQuery filter = needFilter ? new TermQuery(new Term(sf.getName(), br)) : null;\n      fillBucket(bucket, countAcc.getCount(slotNum), slotNum, null, filter);\n\n      bucketList.add(bucket);\n    }\n\n    if (freq.missing) {\n      SimpleOrderedMap<Object> missingBucket = new SimpleOrderedMap<>();\n      fillBucket(missingBucket, getFieldMissingQuery(fcontext.searcher, freq.field), null);\n      res.add(\"missing\", missingBucket);\n    }\n\n    return res;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b834e175d4d6b99680745b76417f082cfad6b76f":["38b5bd3ae837751f57f363e9a41b833794222814"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["1480a9d175b147e15628e77342c4175ad3fc4611","2c8bedceb91e64a3f0e831450058fc4a76d2c0a6"],"1480a9d175b147e15628e77342c4175ad3fc4611":["b834e175d4d6b99680745b76417f082cfad6b76f"],"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6":["1480a9d175b147e15628e77342c4175ad3fc4611","79759974460bc59933cd169acc94f5c6b16368d5"],"dd0759e8803a09424422a329163d5900f6b10c42":["faf1236ae092482293a7e0659e347d172185ef6f"],"faf1236ae092482293a7e0659e347d172185ef6f":["4a7c13535572b8e97cc477fc3388a57321a7751a"],"4a7c13535572b8e97cc477fc3388a57321a7751a":["ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["1480a9d175b147e15628e77342c4175ad3fc4611","403d05f7f8d69b65659157eff1bc1d2717f04c66"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4a7c13535572b8e97cc477fc3388a57321a7751a"],"9e13d0d4d8b6dc352cb304974502b9a36c153f78":["dd0759e8803a09424422a329163d5900f6b10c42"],"67e0d8ccf24ea95997da68450b6eb7143ae29a0d":["9e13d0d4d8b6dc352cb304974502b9a36c153f78"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"38b5bd3ae837751f57f363e9a41b833794222814":["168f749bbf9022a1ba5fea29c54baa1c00883d1d"],"ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"79759974460bc59933cd169acc94f5c6b16368d5":["1480a9d175b147e15628e77342c4175ad3fc4611"],"168f749bbf9022a1ba5fea29c54baa1c00883d1d":["67e0d8ccf24ea95997da68450b6eb7143ae29a0d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["403d05f7f8d69b65659157eff1bc1d2717f04c66"]},"commit2Childs":{"b834e175d4d6b99680745b76417f082cfad6b76f":["1480a9d175b147e15628e77342c4175ad3fc4611"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"1480a9d175b147e15628e77342c4175ad3fc4611":["403d05f7f8d69b65659157eff1bc1d2717f04c66","2c8bedceb91e64a3f0e831450058fc4a76d2c0a6","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","79759974460bc59933cd169acc94f5c6b16368d5"],"2c8bedceb91e64a3f0e831450058fc4a76d2c0a6":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"dd0759e8803a09424422a329163d5900f6b10c42":["9e13d0d4d8b6dc352cb304974502b9a36c153f78"],"faf1236ae092482293a7e0659e347d172185ef6f":["dd0759e8803a09424422a329163d5900f6b10c42"],"4a7c13535572b8e97cc477fc3388a57321a7751a":["faf1236ae092482293a7e0659e347d172185ef6f","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"9e13d0d4d8b6dc352cb304974502b9a36c153f78":["67e0d8ccf24ea95997da68450b6eb7143ae29a0d"],"67e0d8ccf24ea95997da68450b6eb7143ae29a0d":["168f749bbf9022a1ba5fea29c54baa1c00883d1d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d"],"38b5bd3ae837751f57f363e9a41b833794222814":["b834e175d4d6b99680745b76417f082cfad6b76f"],"ac53eb8ed1d40ceac7330e9dc2e5c258e8fc155d":["4a7c13535572b8e97cc477fc3388a57321a7751a"],"79759974460bc59933cd169acc94f5c6b16368d5":["2c8bedceb91e64a3f0e831450058fc4a76d2c0a6"],"168f749bbf9022a1ba5fea29c54baa1c00883d1d":["38b5bd3ae837751f57f363e9a41b833794222814"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}