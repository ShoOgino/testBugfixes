{"path":"lucene/test-framework/src/java/org/apache/lucene/analysis/VocabularyAssert#assertVocabulary(Analyzer,InputStream,InputStream).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/VocabularyAssert#assertVocabulary(Analyzer,InputStream,InputStream).mjava","pathOld":"lucene/src/test-framework/java/org/apache/lucene/analysis/VocabularyAssert#assertVocabulary(Analyzer,InputStream,InputStream).mjava","sourceNew":"  /** Run a vocabulary test against two data files. */\n  public static void assertVocabulary(Analyzer a, InputStream voc, InputStream out)\n  throws IOException {\n    BufferedReader vocReader = new BufferedReader(\n        new InputStreamReader(voc, \"UTF-8\"));\n    BufferedReader outputReader = new BufferedReader(\n        new InputStreamReader(out, \"UTF-8\"));\n    String inputWord = null;\n    while ((inputWord = vocReader.readLine()) != null) {\n      String expectedWord = outputReader.readLine();\n      Assert.assertNotNull(expectedWord);\n      BaseTokenStreamTestCase.checkOneTermReuse(a, inputWord, expectedWord);\n    }\n  }\n\n","sourceOld":"  /** Run a vocabulary test against two data files. */\n  public static void assertVocabulary(Analyzer a, InputStream voc, InputStream out)\n  throws IOException {\n    BufferedReader vocReader = new BufferedReader(\n        new InputStreamReader(voc, \"UTF-8\"));\n    BufferedReader outputReader = new BufferedReader(\n        new InputStreamReader(out, \"UTF-8\"));\n    String inputWord = null;\n    while ((inputWord = vocReader.readLine()) != null) {\n      String expectedWord = outputReader.readLine();\n      Assert.assertNotNull(expectedWord);\n      BaseTokenStreamTestCase.checkOneTermReuse(a, inputWord, expectedWord);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"df1b735b811bfe6055a98336ee8dfd1e43cf2dc0","date":1379858263,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/VocabularyAssert#assertVocabulary(Analyzer,InputStream,InputStream).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/VocabularyAssert#assertVocabulary(Analyzer,InputStream,InputStream).mjava","sourceNew":"  /** Run a vocabulary test against two data files. */\n  public static void assertVocabulary(Analyzer a, InputStream voc, InputStream out)\n  throws IOException {\n    BufferedReader vocReader = new BufferedReader(\n        new InputStreamReader(voc, \"UTF-8\"));\n    BufferedReader outputReader = new BufferedReader(\n        new InputStreamReader(out, \"UTF-8\"));\n    String inputWord = null;\n    while ((inputWord = vocReader.readLine()) != null) {\n      String expectedWord = outputReader.readLine();\n      Assert.assertNotNull(expectedWord);\n      BaseTokenStreamTestCase.checkOneTerm(a, inputWord, expectedWord);\n    }\n  }\n\n","sourceOld":"  /** Run a vocabulary test against two data files. */\n  public static void assertVocabulary(Analyzer a, InputStream voc, InputStream out)\n  throws IOException {\n    BufferedReader vocReader = new BufferedReader(\n        new InputStreamReader(voc, \"UTF-8\"));\n    BufferedReader outputReader = new BufferedReader(\n        new InputStreamReader(out, \"UTF-8\"));\n    String inputWord = null;\n    while ((inputWord = vocReader.readLine()) != null) {\n      String expectedWord = outputReader.readLine();\n      Assert.assertNotNull(expectedWord);\n      BaseTokenStreamTestCase.checkOneTermReuse(a, inputWord, expectedWord);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7d89d7e4e5101347833eea558851bf4209218619","date":1396265641,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/VocabularyAssert#assertVocabulary(Analyzer,InputStream,InputStream).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/VocabularyAssert#assertVocabulary(Analyzer,InputStream,InputStream).mjava","sourceNew":"  /** Run a vocabulary test against two data files. */\n  public static void assertVocabulary(Analyzer a, InputStream voc, InputStream out)\n  throws IOException {\n    BufferedReader vocReader = new BufferedReader(\n        new InputStreamReader(voc, StandardCharsets.UTF_8));\n    BufferedReader outputReader = new BufferedReader(\n        new InputStreamReader(out, StandardCharsets.UTF_8));\n    String inputWord = null;\n    while ((inputWord = vocReader.readLine()) != null) {\n      String expectedWord = outputReader.readLine();\n      Assert.assertNotNull(expectedWord);\n      BaseTokenStreamTestCase.checkOneTerm(a, inputWord, expectedWord);\n    }\n  }\n\n","sourceOld":"  /** Run a vocabulary test against two data files. */\n  public static void assertVocabulary(Analyzer a, InputStream voc, InputStream out)\n  throws IOException {\n    BufferedReader vocReader = new BufferedReader(\n        new InputStreamReader(voc, \"UTF-8\"));\n    BufferedReader outputReader = new BufferedReader(\n        new InputStreamReader(out, \"UTF-8\"));\n    String inputWord = null;\n    while ((inputWord = vocReader.readLine()) != null) {\n      String expectedWord = outputReader.readLine();\n      Assert.assertNotNull(expectedWord);\n      BaseTokenStreamTestCase.checkOneTerm(a, inputWord, expectedWord);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/test-framework/src/java/org/apache/lucene/analysis/VocabularyAssert#assertVocabulary(Analyzer,InputStream,InputStream).mjava","pathOld":"lucene/test-framework/src/java/org/apache/lucene/analysis/VocabularyAssert#assertVocabulary(Analyzer,InputStream,InputStream).mjava","sourceNew":"  /** Run a vocabulary test against two data files. */\n  public static void assertVocabulary(Analyzer a, InputStream voc, InputStream out)\n  throws IOException {\n    BufferedReader vocReader = new BufferedReader(\n        new InputStreamReader(voc, StandardCharsets.UTF_8));\n    BufferedReader outputReader = new BufferedReader(\n        new InputStreamReader(out, StandardCharsets.UTF_8));\n    String inputWord = null;\n    while ((inputWord = vocReader.readLine()) != null) {\n      String expectedWord = outputReader.readLine();\n      Assert.assertNotNull(expectedWord);\n      BaseTokenStreamTestCase.checkOneTerm(a, inputWord, expectedWord);\n    }\n  }\n\n","sourceOld":"  /** Run a vocabulary test against two data files. */\n  public static void assertVocabulary(Analyzer a, InputStream voc, InputStream out)\n  throws IOException {\n    BufferedReader vocReader = new BufferedReader(\n        new InputStreamReader(voc, \"UTF-8\"));\n    BufferedReader outputReader = new BufferedReader(\n        new InputStreamReader(out, \"UTF-8\"));\n    String inputWord = null;\n    while ((inputWord = vocReader.readLine()) != null) {\n      String expectedWord = outputReader.readLine();\n      Assert.assertNotNull(expectedWord);\n      BaseTokenStreamTestCase.checkOneTerm(a, inputWord, expectedWord);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5eb2511ababf862ea11e10761c70ee560cd84510":["df1b735b811bfe6055a98336ee8dfd1e43cf2dc0","7d89d7e4e5101347833eea558851bf4209218619"],"df1b735b811bfe6055a98336ee8dfd1e43cf2dc0":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7d89d7e4e5101347833eea558851bf4209218619":["df1b735b811bfe6055a98336ee8dfd1e43cf2dc0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["7d89d7e4e5101347833eea558851bf4209218619"]},"commit2Childs":{"5eb2511ababf862ea11e10761c70ee560cd84510":[],"df1b735b811bfe6055a98336ee8dfd1e43cf2dc0":["5eb2511ababf862ea11e10761c70ee560cd84510","7d89d7e4e5101347833eea558851bf4209218619"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["df1b735b811bfe6055a98336ee8dfd1e43cf2dc0"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"7d89d7e4e5101347833eea558851bf4209218619":["5eb2511ababf862ea11e10761c70ee560cd84510","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5eb2511ababf862ea11e10761c70ee560cd84510","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}