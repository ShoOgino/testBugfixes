{"path":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","commits":[{"id":"d37a93776a91f5c653f7975d29bdb028d643790c","date":1107701519,"type":1,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"contrib/ant/src/main/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *@todo refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.setMergeFactor(mergeFactor);\n\n      for (int i = 0; i < filesets.size(); i++) {\n        FileSet fs = (FileSet) filesets.get(i);\n        if (fs != null) {\n          DirectoryScanner ds =\n            fs.getDirectoryScanner(getProject());\n          String[] dsfiles = ds.getIncludedFiles();\n          File baseDir = ds.getBasedir();\n\n          for (int j = 0; j < dsfiles.length; j++) {\n            File file = new File(baseDir, dsfiles[j]);\n            totalFiles++;\n\n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  if (DateField.stringToTime(indexModified)\n                    == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(new Field(\"modified\", DateField.timeToString(file.lastModified()), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *@todo refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.setMergeFactor(mergeFactor);\n\n      for (int i = 0; i < filesets.size(); i++) {\n        FileSet fs = (FileSet) filesets.get(i);\n        if (fs != null) {\n          DirectoryScanner ds =\n            fs.getDirectoryScanner(getProject());\n          String[] dsfiles = ds.getIncludedFiles();\n          File baseDir = ds.getBasedir();\n\n          for (int j = 0; j < dsfiles.length; j++) {\n            File file = new File(baseDir, dsfiles[j]);\n            totalFiles++;\n\n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  if (DateField.stringToTime(indexModified)\n                    == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(new Field(\"modified\", DateField.timeToString(file.lastModified()), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5b7724d8c6ec391f16d6d62c971dbfe170239028","date":1141853524,"type":3,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *@todo refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.setMergeFactor(mergeFactor);\n\n      for (int i = 0; i < filesets.size(); i++) {\n        FileSet fs = (FileSet) filesets.get(i);\n        if (fs != null) {\n          DirectoryScanner ds =\n            fs.getDirectoryScanner(getProject());\n          String[] dsfiles = ds.getIncludedFiles();\n          File baseDir = ds.getBasedir();\n\n          for (int j = 0; j < dsfiles.length; j++) {\n            File file = new File(baseDir, dsfiles[j]);\n            totalFiles++;\n\n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  long lastModified = 0;\n                  try {\n                    lastModified = DateTools.stringToTime(indexModified);\n                  } catch (ParseException e) {\n                    // if modified time is not parsable, skip\n                  }\n                  if (lastModified == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *@todo refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.setMergeFactor(mergeFactor);\n\n      for (int i = 0; i < filesets.size(); i++) {\n        FileSet fs = (FileSet) filesets.get(i);\n        if (fs != null) {\n          DirectoryScanner ds =\n            fs.getDirectoryScanner(getProject());\n          String[] dsfiles = ds.getIncludedFiles();\n          File baseDir = ds.getBasedir();\n\n          for (int j = 0; j < dsfiles.length; j++) {\n            File file = new File(baseDir, dsfiles[j]);\n            totalFiles++;\n\n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  if (DateField.stringToTime(indexModified)\n                    == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(new Field(\"modified\", DateField.timeToString(file.lastModified()), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0018e7a0579df5d3de71d0bd878322a7abef04d9","date":1202242049,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *@todo refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create, IndexWriter.MaxFieldLength.LIMITED);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.setMergeFactor(mergeFactor);\n\n      for (int i = 0; i < filesets.size(); i++) {\n        FileSet fs = (FileSet) filesets.get(i);\n        if (fs != null) {\n          DirectoryScanner ds =\n            fs.getDirectoryScanner(getProject());\n          String[] dsfiles = ds.getIncludedFiles();\n          File baseDir = ds.getBasedir();\n\n          for (int j = 0; j < dsfiles.length; j++) {\n            File file = new File(baseDir, dsfiles[j]);\n            totalFiles++;\n\n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  long lastModified = 0;\n                  try {\n                    lastModified = DateTools.stringToTime(indexModified);\n                  } catch (ParseException e) {\n                    // if modified time is not parsable, skip\n                  }\n                  if (lastModified == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *@todo refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.setMergeFactor(mergeFactor);\n\n      for (int i = 0; i < filesets.size(); i++) {\n        FileSet fs = (FileSet) filesets.get(i);\n        if (fs != null) {\n          DirectoryScanner ds =\n            fs.getDirectoryScanner(getProject());\n          String[] dsfiles = ds.getIncludedFiles();\n          File baseDir = ds.getBasedir();\n\n          for (int j = 0; j < dsfiles.length; j++) {\n            File file = new File(baseDir, dsfiles[j]);\n            totalFiles++;\n\n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  long lastModified = 0;\n                  try {\n                    lastModified = DateTools.stringToTime(indexModified);\n                  } catch (ParseException e) {\n                    // if modified time is not parsable, skip\n                  }\n                  if (lastModified == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a","date":1221082732,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *@todo refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create, IndexWriter.MaxFieldLength.LIMITED);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.setMergeFactor(mergeFactor);\n\n      for (int i = 0; i < filesets.size(); i++) {\n        FileSet fs = (FileSet) filesets.get(i);\n        if (fs != null) {\n          DirectoryScanner ds =\n            fs.getDirectoryScanner(getProject());\n          String[] dsfiles = ds.getIncludedFiles();\n          File baseDir = ds.getBasedir();\n\n          for (int j = 0; j < dsfiles.length; j++) {\n            File file = new File(baseDir, dsfiles[j]);\n            totalFiles++;\n\n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  long lastModified = 0;\n                  try {\n                    lastModified = DateTools.stringToTime(indexModified);\n                  } catch (ParseException e) {\n                    // if modified time is not parsable, skip\n                  }\n                  if (lastModified == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *@todo refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create, IndexWriter.MaxFieldLength.LIMITED);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.setMergeFactor(mergeFactor);\n\n      for (int i = 0; i < filesets.size(); i++) {\n        FileSet fs = (FileSet) filesets.get(i);\n        if (fs != null) {\n          DirectoryScanner ds =\n            fs.getDirectoryScanner(getProject());\n          String[] dsfiles = ds.getIncludedFiles();\n          File baseDir = ds.getBasedir();\n\n          for (int j = 0; j < dsfiles.length; j++) {\n            File file = new File(baseDir, dsfiles[j]);\n            totalFiles++;\n\n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  long lastModified = 0;\n                  try {\n                    lastModified = DateTools.stringToTime(indexModified);\n                  } catch (ParseException e) {\n                    // if modified time is not parsable, skip\n                  }\n                  if (lastModified == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.UN_TOKENIZED));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c9143c0d82628c50fe778bfc616e41e3992ccd2","date":1245435859,"type":3,"author":"Erik Hatcher","isMerge":false,"pathNew":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *@todo refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create, IndexWriter.MaxFieldLength.LIMITED);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.setMergeFactor(mergeFactor);\n\n      for (int i = 0; i < rcs.size(); i++) {\n      \tResourceCollection rc = (ResourceCollection) rcs.elementAt(i);\n        if (rc.isFilesystemOnly()) {\n          Iterator resources = rc.iterator();\n          while (resources.hasNext()) {\n            Resource r = (Resource) resources.next();\n            if (!r.isExists() || !(r instanceof FileResource)) {\n              continue;\n            }\n            \n            totalFiles++;\n\n            File file = ((FileResource) r).getFile();\n            \n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  long lastModified = 0;\n                  try {\n                    lastModified = DateTools.stringToTime(indexModified);\n                  } catch (ParseException e) {\n                    // if modified time is not parsable, skip\n                  }\n                  if (lastModified == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *@todo refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create, IndexWriter.MaxFieldLength.LIMITED);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.setMergeFactor(mergeFactor);\n\n      for (int i = 0; i < filesets.size(); i++) {\n        FileSet fs = (FileSet) filesets.get(i);\n        if (fs != null) {\n          DirectoryScanner ds =\n            fs.getDirectoryScanner(getProject());\n          String[] dsfiles = ds.getIncludedFiles();\n          File baseDir = ds.getBasedir();\n\n          for (int j = 0; j < dsfiles.length; j++) {\n            File file = new File(baseDir, dsfiles[j]);\n            totalFiles++;\n\n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  long lastModified = 0;\n                  try {\n                    lastModified = DateTools.stringToTime(indexModified);\n                  } catch (ParseException e) {\n                    // if modified time is not parsable, skip\n                  }\n                  if (lastModified == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2f573a38b5b129663e19cdf55adc5d12330c0504","date":1251326380,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create, IndexWriter.MaxFieldLength.LIMITED);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.setMergeFactor(mergeFactor);\n\n      for (int i = 0; i < rcs.size(); i++) {\n      \tResourceCollection rc = (ResourceCollection) rcs.elementAt(i);\n        if (rc.isFilesystemOnly()) {\n          Iterator resources = rc.iterator();\n          while (resources.hasNext()) {\n            Resource r = (Resource) resources.next();\n            if (!r.isExists() || !(r instanceof FileResource)) {\n              continue;\n            }\n            \n            totalFiles++;\n\n            File file = ((FileResource) r).getFile();\n            \n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  long lastModified = 0;\n                  try {\n                    lastModified = DateTools.stringToTime(indexModified);\n                  } catch (ParseException e) {\n                    // if modified time is not parsable, skip\n                  }\n                  if (lastModified == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *@todo refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create, IndexWriter.MaxFieldLength.LIMITED);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.setMergeFactor(mergeFactor);\n\n      for (int i = 0; i < rcs.size(); i++) {\n      \tResourceCollection rc = (ResourceCollection) rcs.elementAt(i);\n        if (rc.isFilesystemOnly()) {\n          Iterator resources = rc.iterator();\n          while (resources.hasNext()) {\n            Resource r = (Resource) resources.next();\n            if (!r.isExists() || !(r instanceof FileResource)) {\n              continue;\n            }\n            \n            totalFiles++;\n\n            File file = ((FileResource) r).getFile();\n            \n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  long lastModified = 0;\n                  try {\n                    lastModified = DateTools.stringToTime(indexModified);\n                  } catch (ParseException e) {\n                    // if modified time is not parsable, skip\n                  }\n                  if (lastModified == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4256bc1b3c94786287ccdfc751230374521843cf","date":1254612273,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriter writer =\n        new IndexWriter(dir, analyzer, create, IndexWriter.MaxFieldLength.LIMITED);\n\n      writer.setUseCompoundFile(useCompoundIndex);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n        writer.setMergeFactor(mergeFactor);\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = (ResourceCollection) rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                Hits hits = searcher.search(query);\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length() > 0) {\n                  Document doc = hits.doc(0);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    Searcher searcher = null;\n    boolean checkLastModified = false;\n    if (!create) {\n      try {\n        searcher = new IndexSearcher(indexDir.getAbsolutePath());\n        checkLastModified = true;\n      } catch (IOException ioe) {\n        log(\"IOException: \" + ioe.getMessage());\n        // Empty - ignore, which indicates to index all\n        // documents\n      }\n    }\n\n    log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n    IndexWriter writer =\n      new IndexWriter(indexDir, analyzer, create, IndexWriter.MaxFieldLength.LIMITED);\n\n    writer.setUseCompoundFile(useCompoundIndex);\n    int totalFiles = 0;\n    int totalIndexed = 0;\n    int totalIgnored = 0;\n    try {\n      writer.setMergeFactor(mergeFactor);\n\n      for (int i = 0; i < rcs.size(); i++) {\n      \tResourceCollection rc = (ResourceCollection) rcs.elementAt(i);\n        if (rc.isFilesystemOnly()) {\n          Iterator resources = rc.iterator();\n          while (resources.hasNext()) {\n            Resource r = (Resource) resources.next();\n            if (!r.isExists() || !(r instanceof FileResource)) {\n              continue;\n            }\n            \n            totalFiles++;\n\n            File file = ((FileResource) r).getFile();\n            \n            if (!file.exists() || !file.canRead()) {\n              throw new BuildException(\"File \\\"\" +\n                                       file.getAbsolutePath()\n                                       + \"\\\" does not exist or is not readable.\");\n            }\n\n            boolean indexIt = true;\n\n            if (checkLastModified) {\n              Term pathTerm =\n                new Term(\"path\", file.getPath());\n              TermQuery query =\n                new TermQuery(pathTerm);\n              Hits hits = searcher.search(query);\n\n              // if document is found, compare the\n              // indexed last modified time with the\n              // current file\n              // - don't index if up to date\n              if (hits.length() > 0) {\n                Document doc = hits.doc(0);\n                String indexModified =\n                  doc.get(\"modified\").trim();\n                if (indexModified != null) {\n                  long lastModified = 0;\n                  try {\n                    lastModified = DateTools.stringToTime(indexModified);\n                  } catch (ParseException e) {\n                    // if modified time is not parsable, skip\n                  }\n                  if (lastModified == file.lastModified()) {\n                    // TODO: remove existing document\n                    indexIt = false;\n                  }\n                }\n              }\n            }\n\n            if (indexIt) {\n              try {\n                log(\"Indexing \" + file.getPath(),\n                    Project.MSG_VERBOSE);\n                Document doc =\n                  handler.getDocument(file);\n\n                if (doc == null) {\n                  totalIgnored++;\n                } else {\n                  // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                  // that the index stores the path, and so that the path is searchable\n                  doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                  // Add the last modified date of the file a field named \"modified\".  Use a\n                  // Keyword field, so that it's searchable, but so that no attempt is made\n                  // to tokenize the field into words.\n                  doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                  writer.addDocument(doc);\n                  totalIndexed++;\n                }\n              } catch (DocumentHandlerException e) {\n                throw new BuildException(e);\n              }\n            }\n          }\n          // for j\n        }\n        // if (fs != null)\n      }\n      // for i\n\n      writer.optimize();\n    }\n      //try\n    finally {\n      // always make sure everything gets closed,\n      // no matter how we exit.\n      writer.close();\n      if (searcher != null) {\n        searcher.close();\n      }\n    }\n\n    Date end = new Date();\n\n    log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n        totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n        \" milliseconds\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f148c02ddd6ba981c65ca685d0e56c3a98368e1","date":1254892102,"type":3,"author":"Michael Busch","isMerge":false,"pathNew":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriter writer =\n        new IndexWriter(dir, analyzer, create, IndexWriter.MaxFieldLength.LIMITED);\n\n      writer.setUseCompoundFile(useCompoundIndex);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n        writer.setMergeFactor(mergeFactor);\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = (ResourceCollection) rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriter writer =\n        new IndexWriter(dir, analyzer, create, IndexWriter.MaxFieldLength.LIMITED);\n\n      writer.setUseCompoundFile(useCompoundIndex);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n        writer.setMergeFactor(mergeFactor);\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = (ResourceCollection) rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                Hits hits = searcher.search(query);\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length() > 0) {\n                  Document doc = hits.doc(0);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"60cdc0e643184821eb066795a8791cd82559f46e","date":1257941914,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriter writer =\n        new IndexWriter(dir, analyzer, create, IndexWriter.MaxFieldLength.LIMITED);\n\n      writer.setUseCompoundFile(useCompoundIndex);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n        writer.setMergeFactor(mergeFactor);\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriter writer =\n        new IndexWriter(dir, analyzer, create, IndexWriter.MaxFieldLength.LIMITED);\n\n      writer.setUseCompoundFile(useCompoundIndex);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n        writer.setMergeFactor(mergeFactor);\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = (ResourceCollection) rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1cedb00d2dd44640194401179358a2e3ba6051bf","date":1268243626,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n          Version.LUCENE_CURRENT).setAnalyzer(analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND));\n      LogMergePolicy lmp = (LogMergePolicy) writer.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setUseCompoundDocStore(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriter writer =\n        new IndexWriter(dir, analyzer, create, IndexWriter.MaxFieldLength.LIMITED);\n\n      writer.setUseCompoundFile(useCompoundIndex);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n        writer.setMergeFactor(mergeFactor);\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e52fea2c4081a1e552b98506691990be59503168","date":1268250331,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriter writer =\n        new IndexWriter(dir, analyzer, create, IndexWriter.MaxFieldLength.LIMITED);\n\n      writer.setUseCompoundFile(useCompoundIndex);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n        writer.setMergeFactor(mergeFactor);\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n          Version.LUCENE_CURRENT).setAnalyzer(analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND));\n      LogMergePolicy lmp = (LogMergePolicy) writer.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setUseCompoundDocStore(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8","date":1268494368,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND));\n      LogMergePolicy lmp = (LogMergePolicy) writer.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setUseCompoundDocStore(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriter writer =\n        new IndexWriter(dir, analyzer, create, IndexWriter.MaxFieldLength.LIMITED);\n\n      writer.setUseCompoundFile(useCompoundIndex);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n        writer.setMergeFactor(mergeFactor);\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","pathOld":"contrib/ant/src/java/org/apache/lucene/ant/IndexTask#indexDocs().mjava","sourceNew":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND));\n      LogMergePolicy lmp = (LogMergePolicy) writer.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setUseCompoundDocStore(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","sourceOld":"  /**\n   * Index the fileset.\n   *\n   *@exception  IOException if Lucene I/O exception\n   *TODO: refactor!!!!!\n   */\n  private void indexDocs() throws IOException {\n    Date start = new Date();\n\n    boolean create = overwrite;\n    // If the index directory doesn't exist,\n    // create it and force create mode\n    if (indexDir.mkdirs() && !overwrite) {\n      create = true;\n    }\n\n    FSDirectory dir = FSDirectory.open(indexDir);\n    try {\n      Searcher searcher = null;\n      boolean checkLastModified = false;\n      if (!create) {\n        try {\n          searcher = new IndexSearcher(dir, true);\n          checkLastModified = true;\n        } catch (IOException ioe) {\n          log(\"IOException: \" + ioe.getMessage());\n          // Empty - ignore, which indicates to index all\n          // documents\n        }\n      }\n\n      log(\"checkLastModified = \" + checkLastModified, Project.MSG_VERBOSE);\n\n      IndexWriter writer = new IndexWriter(dir, new IndexWriterConfig(\n          Version.LUCENE_CURRENT, analyzer).setOpenMode(\n          create ? OpenMode.CREATE : OpenMode.APPEND));\n      LogMergePolicy lmp = (LogMergePolicy) writer.getMergePolicy();\n      lmp.setUseCompoundFile(useCompoundIndex);\n      lmp.setUseCompoundDocStore(useCompoundIndex);\n      lmp.setMergeFactor(mergeFactor);\n      int totalFiles = 0;\n      int totalIndexed = 0;\n      int totalIgnored = 0;\n      try {\n\n        for (int i = 0; i < rcs.size(); i++) {\n          ResourceCollection rc = rcs.elementAt(i);\n          if (rc.isFilesystemOnly()) {\n            Iterator resources = rc.iterator();\n            while (resources.hasNext()) {\n              Resource r = (Resource) resources.next();\n              if (!r.isExists() || !(r instanceof FileResource)) {\n                continue;\n              }\n              \n              totalFiles++;\n\n              File file = ((FileResource) r).getFile();\n              \n              if (!file.exists() || !file.canRead()) {\n                throw new BuildException(\"File \\\"\" +\n                                         file.getAbsolutePath()\n                                         + \"\\\" does not exist or is not readable.\");\n              }\n\n              boolean indexIt = true;\n\n              if (checkLastModified) {\n                Term pathTerm =\n                  new Term(\"path\", file.getPath());\n                TermQuery query =\n                  new TermQuery(pathTerm);\n                ScoreDoc[] hits = searcher.search(query, null, 1).scoreDocs;\n\n                // if document is found, compare the\n                // indexed last modified time with the\n                // current file\n                // - don't index if up to date\n                if (hits.length > 0) {\n                  Document doc = searcher.doc(hits[0].doc);\n                  String indexModified =\n                    doc.get(\"modified\").trim();\n                  if (indexModified != null) {\n                    long lastModified = 0;\n                    try {\n                      lastModified = DateTools.stringToTime(indexModified);\n                    } catch (ParseException e) {\n                      // if modified time is not parsable, skip\n                    }\n                    if (lastModified == file.lastModified()) {\n                      // TODO: remove existing document\n                      indexIt = false;\n                    }\n                  }\n                }\n              }\n\n              if (indexIt) {\n                try {\n                  log(\"Indexing \" + file.getPath(),\n                      Project.MSG_VERBOSE);\n                  Document doc =\n                    handler.getDocument(file);\n\n                  if (doc == null) {\n                    totalIgnored++;\n                  } else {\n                    // Add the path of the file as a field named \"path\".  Use a Keyword field, so\n                    // that the index stores the path, and so that the path is searchable\n                    doc.add(new Field(\"path\", file.getPath(), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    // Add the last modified date of the file a field named \"modified\".  Use a\n                    // Keyword field, so that it's searchable, but so that no attempt is made\n                    // to tokenize the field into words.\n                    doc.add(new Field(\"modified\", DateTools.timeToString(file.lastModified(), DateTools.Resolution.MILLISECOND), Field.Store.YES, Field.Index.NOT_ANALYZED));\n\n                    writer.addDocument(doc);\n                    totalIndexed++;\n                  }\n                } catch (DocumentHandlerException e) {\n                  throw new BuildException(e);\n                }\n              }\n            }\n            // for j\n          }\n          // if (fs != null)\n        }\n        // for i\n\n        writer.optimize();\n      }\n        //try\n      finally {\n        // always make sure everything gets closed,\n        // no matter how we exit.\n        writer.close();\n        if (searcher != null) {\n          searcher.close();\n        }\n      }\n\n      Date end = new Date();\n\n      log(totalIndexed + \" out of \" + totalFiles + \" indexed (\" +\n          totalIgnored + \" ignored) in \" + (end.getTime() - start.getTime()) +\n          \" milliseconds\");\n    } finally {\n      dir.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"60cdc0e643184821eb066795a8791cd82559f46e":["0f148c02ddd6ba981c65ca685d0e56c3a98368e1"],"1cedb00d2dd44640194401179358a2e3ba6051bf":["60cdc0e643184821eb066795a8791cd82559f46e"],"b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a":["0018e7a0579df5d3de71d0bd878322a7abef04d9"],"e52fea2c4081a1e552b98506691990be59503168":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"0018e7a0579df5d3de71d0bd878322a7abef04d9":["5b7724d8c6ec391f16d6d62c971dbfe170239028"],"4256bc1b3c94786287ccdfc751230374521843cf":["2f573a38b5b129663e19cdf55adc5d12330c0504"],"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["e52fea2c4081a1e552b98506691990be59503168"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2f573a38b5b129663e19cdf55adc5d12330c0504":["1c9143c0d82628c50fe778bfc616e41e3992ccd2"],"0f148c02ddd6ba981c65ca685d0e56c3a98368e1":["4256bc1b3c94786287ccdfc751230374521843cf"],"d37a93776a91f5c653f7975d29bdb028d643790c":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1c9143c0d82628c50fe778bfc616e41e3992ccd2":["b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a"],"5b7724d8c6ec391f16d6d62c971dbfe170239028":["d37a93776a91f5c653f7975d29bdb028d643790c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"]},"commit2Childs":{"60cdc0e643184821eb066795a8791cd82559f46e":["1cedb00d2dd44640194401179358a2e3ba6051bf"],"1cedb00d2dd44640194401179358a2e3ba6051bf":["e52fea2c4081a1e552b98506691990be59503168"],"b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a":["1c9143c0d82628c50fe778bfc616e41e3992ccd2"],"0018e7a0579df5d3de71d0bd878322a7abef04d9":["b5015bd4c211c4f399ae66ee20fe6841ba5b0b6a"],"e52fea2c4081a1e552b98506691990be59503168":["84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8"],"4256bc1b3c94786287ccdfc751230374521843cf":["0f148c02ddd6ba981c65ca685d0e56c3a98368e1"],"84080a7d7dbdaa3e6a4a1c9f1bb6221be40f47e8":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d37a93776a91f5c653f7975d29bdb028d643790c"],"2f573a38b5b129663e19cdf55adc5d12330c0504":["4256bc1b3c94786287ccdfc751230374521843cf"],"0f148c02ddd6ba981c65ca685d0e56c3a98368e1":["60cdc0e643184821eb066795a8791cd82559f46e"],"d37a93776a91f5c653f7975d29bdb028d643790c":["5b7724d8c6ec391f16d6d62c971dbfe170239028"],"5b7724d8c6ec391f16d6d62c971dbfe170239028":["0018e7a0579df5d3de71d0bd878322a7abef04d9"],"1c9143c0d82628c50fe778bfc616e41e3992ccd2":["2f573a38b5b129663e19cdf55adc5d12330c0504"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}