{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","commits":[{"id":"dc3f094cafa4a87b4066e1d6710fa4e6afe6260e","date":1393532367,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell2/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","sourceNew":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n  }\n\n","sourceOld":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba791bce8103c79e38f957e9c5a53a75871bd918","date":1393539206,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellDictionary#readAffixFile(InputStream,CharsetDecoder,boolean).mjava","sourceNew":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n  }\n\n","sourceOld":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder, boolean strict) throws IOException, ParseException {\n    prefixes = new CharArrayMap<List<HunspellAffix>>(version, 8, ignoreCase);\n    suffixes = new CharArrayMap<List<HunspellAffix>>(version, 8, ignoreCase);\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, strict);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, strict);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7","date":1393724838,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","sourceNew":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n  }\n\n","sourceOld":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"38e7d0aeceab994177a0a6b52f475611b52f09bf","date":1393856424,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","sourceNew":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n  }\n\n","sourceOld":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5ae9942cbee38a49d234c2f022e3a265133d1914","date":1393952688,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","sourceNew":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(IGNORE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal IGNORE declaration\", reader.getLineNumber());\n        }\n        ignore = parts[1].toCharArray();\n        Arrays.sort(ignore);\n        needsInputCleaning = true;\n      } else if (line.startsWith(ICONV_KEY) || line.startsWith(OCONV_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        String type = parts[0];\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal \" + type + \" declaration\", reader.getLineNumber());\n        }\n        int num = Integer.parseInt(parts[1]);\n        FST<CharsRef> res = parseConversions(reader, num);\n        if (type.equals(\"ICONV\")) {\n          iconv = res;\n          needsInputCleaning |= iconv != null;\n        } else {\n          oconv = res;\n          needsOutputCleaning |= oconv != null;\n        }\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n  }\n\n","sourceOld":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"96ea64d994d340044e0d57aeb6a5871539d10ca5","date":1394225445,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","sourceNew":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(IGNORE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal IGNORE declaration\", reader.getLineNumber());\n        }\n        ignore = parts[1].toCharArray();\n        Arrays.sort(ignore);\n        needsInputCleaning = true;\n      } else if (line.startsWith(ICONV_KEY) || line.startsWith(OCONV_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        String type = parts[0];\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal \" + type + \" declaration\", reader.getLineNumber());\n        }\n        int num = Integer.parseInt(parts[1]);\n        FST<CharsRef> res = parseConversions(reader, num);\n        if (type.equals(\"ICONV\")) {\n          iconv = res;\n          needsInputCleaning |= iconv != null;\n        } else {\n          oconv = res;\n          needsOutputCleaning |= oconv != null;\n        }\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n  }\n\n","sourceOld":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d2676f60312754dc25ef542551cb2623527013a4","date":1394298418,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","sourceNew":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      // ignore any BOM marker on first line\n      if (reader.getLineNumber() == 1 && line.startsWith(\"\\uFEFF\")) {\n        line = line.substring(1);\n      }\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(IGNORE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal IGNORE declaration\", reader.getLineNumber());\n        }\n        ignore = parts[1].toCharArray();\n        Arrays.sort(ignore);\n        needsInputCleaning = true;\n      } else if (line.startsWith(ICONV_KEY) || line.startsWith(OCONV_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        String type = parts[0];\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal \" + type + \" declaration\", reader.getLineNumber());\n        }\n        int num = Integer.parseInt(parts[1]);\n        FST<CharsRef> res = parseConversions(reader, num);\n        if (type.equals(\"ICONV\")) {\n          iconv = res;\n          needsInputCleaning |= iconv != null;\n        } else {\n          oconv = res;\n          needsOutputCleaning |= oconv != null;\n        }\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n  }\n\n","sourceOld":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(IGNORE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal IGNORE declaration\", reader.getLineNumber());\n        }\n        ignore = parts[1].toCharArray();\n        Arrays.sort(ignore);\n        needsInputCleaning = true;\n      } else if (line.startsWith(ICONV_KEY) || line.startsWith(OCONV_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        String type = parts[0];\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal \" + type + \" declaration\", reader.getLineNumber());\n        }\n        int num = Integer.parseInt(parts[1]);\n        FST<CharsRef> res = parseConversions(reader, num);\n        if (type.equals(\"ICONV\")) {\n          iconv = res;\n          needsInputCleaning |= iconv != null;\n        } else {\n          oconv = res;\n          needsOutputCleaning |= oconv != null;\n        }\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","date":1394564625,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","sourceNew":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      // ignore any BOM marker on first line\n      if (reader.getLineNumber() == 1 && line.startsWith(\"\\uFEFF\")) {\n        line = line.substring(1);\n      }\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(IGNORE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal IGNORE declaration\", reader.getLineNumber());\n        }\n        ignore = parts[1].toCharArray();\n        Arrays.sort(ignore);\n        needsInputCleaning = true;\n      } else if (line.startsWith(ICONV_KEY) || line.startsWith(OCONV_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        String type = parts[0];\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal \" + type + \" declaration\", reader.getLineNumber());\n        }\n        int num = Integer.parseInt(parts[1]);\n        FST<CharsRef> res = parseConversions(reader, num);\n        if (type.equals(\"ICONV\")) {\n          iconv = res;\n          needsInputCleaning |= iconv != null;\n        } else {\n          oconv = res;\n          needsOutputCleaning |= oconv != null;\n        }\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n  }\n\n","sourceOld":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(IGNORE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal IGNORE declaration\", reader.getLineNumber());\n        }\n        ignore = parts[1].toCharArray();\n        Arrays.sort(ignore);\n        needsInputCleaning = true;\n      } else if (line.startsWith(ICONV_KEY) || line.startsWith(OCONV_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        String type = parts[0];\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal \" + type + \" declaration\", reader.getLineNumber());\n        }\n        int num = Integer.parseInt(parts[1]);\n        FST<CharsRef> res = parseConversions(reader, num);\n        if (type.equals(\"ICONV\")) {\n          iconv = res;\n          needsInputCleaning |= iconv != null;\n        } else {\n          oconv = res;\n          needsOutputCleaning |= oconv != null;\n        }\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09fb4238d56f62faff1f0c866bee53facad482ec","date":1394631888,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","sourceNew":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n    \n    // zero condition -> 0 ord\n    seenPatterns.put(\".*\", 0);\n    patterns.add(null);\n    \n    // zero strip -> 0 ord\n    Map<String,Integer> seenStrips = new LinkedHashMap<>();\n    seenStrips.put(\"\", 0);\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      // ignore any BOM marker on first line\n      if (reader.getLineNumber() == 1 && line.startsWith(\"\\uFEFF\")) {\n        line = line.substring(1);\n      }\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(IGNORE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal IGNORE declaration\", reader.getLineNumber());\n        }\n        ignore = parts[1].toCharArray();\n        Arrays.sort(ignore);\n        needsInputCleaning = true;\n      } else if (line.startsWith(ICONV_KEY) || line.startsWith(OCONV_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        String type = parts[0];\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal \" + type + \" declaration\", reader.getLineNumber());\n        }\n        int num = Integer.parseInt(parts[1]);\n        FST<CharsRef> res = parseConversions(reader, num);\n        if (type.equals(\"ICONV\")) {\n          iconv = res;\n          needsInputCleaning |= iconv != null;\n        } else {\n          oconv = res;\n          needsOutputCleaning |= oconv != null;\n        }\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n    \n    int totalChars = 0;\n    for (String strip : seenStrips.keySet()) {\n      totalChars += strip.length();\n    }\n    stripData = new char[totalChars];\n    stripOffsets = new int[seenStrips.size()+1];\n    int currentOffset = 0;\n    int currentIndex = 0;\n    for (String strip : seenStrips.keySet()) {\n      stripOffsets[currentIndex++] = currentOffset;\n      strip.getChars(0, strip.length(), stripData, currentOffset);\n      currentOffset += strip.length();\n    }\n    assert currentIndex == seenStrips.size();\n    stripOffsets[currentIndex] = currentOffset;\n  }\n\n","sourceOld":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      // ignore any BOM marker on first line\n      if (reader.getLineNumber() == 1 && line.startsWith(\"\\uFEFF\")) {\n        line = line.substring(1);\n      }\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(IGNORE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal IGNORE declaration\", reader.getLineNumber());\n        }\n        ignore = parts[1].toCharArray();\n        Arrays.sort(ignore);\n        needsInputCleaning = true;\n      } else if (line.startsWith(ICONV_KEY) || line.startsWith(OCONV_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        String type = parts[0];\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal \" + type + \" declaration\", reader.getLineNumber());\n        }\n        int num = Integer.parseInt(parts[1]);\n        FST<CharsRef> res = parseConversions(reader, num);\n        if (type.equals(\"ICONV\")) {\n          iconv = res;\n          needsInputCleaning |= iconv != null;\n        } else {\n          oconv = res;\n          needsOutputCleaning |= oconv != null;\n        }\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5916de6e2f6deb9da923b2710f6451668e94a20c","date":1403356557,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","sourceNew":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n    \n    // zero condition -> 0 ord\n    seenPatterns.put(\".*\", 0);\n    patterns.add(null);\n    \n    // zero strip -> 0 ord\n    Map<String,Integer> seenStrips = new LinkedHashMap<>();\n    seenStrips.put(\"\", 0);\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      // ignore any BOM marker on first line\n      if (reader.getLineNumber() == 1 && line.startsWith(\"\\uFEFF\")) {\n        line = line.substring(1);\n      }\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(MORPH_ALIAS_KEY)) {\n        parseMorphAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(IGNORE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal IGNORE declaration\", reader.getLineNumber());\n        }\n        ignore = parts[1].toCharArray();\n        Arrays.sort(ignore);\n        needsInputCleaning = true;\n      } else if (line.startsWith(ICONV_KEY) || line.startsWith(OCONV_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        String type = parts[0];\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal \" + type + \" declaration\", reader.getLineNumber());\n        }\n        int num = Integer.parseInt(parts[1]);\n        FST<CharsRef> res = parseConversions(reader, num);\n        if (type.equals(\"ICONV\")) {\n          iconv = res;\n          needsInputCleaning |= iconv != null;\n        } else {\n          oconv = res;\n          needsOutputCleaning |= oconv != null;\n        }\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n    \n    int totalChars = 0;\n    for (String strip : seenStrips.keySet()) {\n      totalChars += strip.length();\n    }\n    stripData = new char[totalChars];\n    stripOffsets = new int[seenStrips.size()+1];\n    int currentOffset = 0;\n    int currentIndex = 0;\n    for (String strip : seenStrips.keySet()) {\n      stripOffsets[currentIndex++] = currentOffset;\n      strip.getChars(0, strip.length(), stripData, currentOffset);\n      currentOffset += strip.length();\n    }\n    assert currentIndex == seenStrips.size();\n    stripOffsets[currentIndex] = currentOffset;\n  }\n\n","sourceOld":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n    \n    // zero condition -> 0 ord\n    seenPatterns.put(\".*\", 0);\n    patterns.add(null);\n    \n    // zero strip -> 0 ord\n    Map<String,Integer> seenStrips = new LinkedHashMap<>();\n    seenStrips.put(\"\", 0);\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      // ignore any BOM marker on first line\n      if (reader.getLineNumber() == 1 && line.startsWith(\"\\uFEFF\")) {\n        line = line.substring(1);\n      }\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(IGNORE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal IGNORE declaration\", reader.getLineNumber());\n        }\n        ignore = parts[1].toCharArray();\n        Arrays.sort(ignore);\n        needsInputCleaning = true;\n      } else if (line.startsWith(ICONV_KEY) || line.startsWith(OCONV_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        String type = parts[0];\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal \" + type + \" declaration\", reader.getLineNumber());\n        }\n        int num = Integer.parseInt(parts[1]);\n        FST<CharsRef> res = parseConversions(reader, num);\n        if (type.equals(\"ICONV\")) {\n          iconv = res;\n          needsInputCleaning |= iconv != null;\n        } else {\n          oconv = res;\n          needsOutputCleaning |= oconv != null;\n        }\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n    \n    int totalChars = 0;\n    for (String strip : seenStrips.keySet()) {\n      totalChars += strip.length();\n    }\n    stripData = new char[totalChars];\n    stripOffsets = new int[seenStrips.size()+1];\n    int currentOffset = 0;\n    int currentIndex = 0;\n    for (String strip : seenStrips.keySet()) {\n      stripOffsets[currentIndex++] = currentOffset;\n      strip.getChars(0, strip.length(), stripData, currentOffset);\n      currentOffset += strip.length();\n    }\n    assert currentIndex == seenStrips.size();\n    stripOffsets[currentIndex] = currentOffset;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fb75b56e1e392fea98e3903ee95b063c8a5c14b3","date":1405421969,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","sourceNew":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n    \n    // zero condition -> 0 ord\n    seenPatterns.put(\".*\", 0);\n    patterns.add(null);\n    \n    // zero strip -> 0 ord\n    Map<String,Integer> seenStrips = new LinkedHashMap<>();\n    seenStrips.put(\"\", 0);\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      // ignore any BOM marker on first line\n      if (reader.getLineNumber() == 1 && line.startsWith(\"\\uFEFF\")) {\n        line = line.substring(1);\n      }\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(MORPH_ALIAS_KEY)) {\n        parseMorphAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(IGNORE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal IGNORE declaration\", reader.getLineNumber());\n        }\n        ignore = parts[1].toCharArray();\n        Arrays.sort(ignore);\n        needsInputCleaning = true;\n      } else if (line.startsWith(ICONV_KEY) || line.startsWith(OCONV_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        String type = parts[0];\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal \" + type + \" declaration\", reader.getLineNumber());\n        }\n        int num = Integer.parseInt(parts[1]);\n        FST<CharsRef> res = parseConversions(reader, num);\n        if (type.equals(\"ICONV\")) {\n          iconv = res;\n          needsInputCleaning |= iconv != null;\n        } else {\n          oconv = res;\n          needsOutputCleaning |= oconv != null;\n        }\n      } else if (line.startsWith(FULLSTRIP_KEY)) {\n        fullStrip = true;\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n    \n    int totalChars = 0;\n    for (String strip : seenStrips.keySet()) {\n      totalChars += strip.length();\n    }\n    stripData = new char[totalChars];\n    stripOffsets = new int[seenStrips.size()+1];\n    int currentOffset = 0;\n    int currentIndex = 0;\n    for (String strip : seenStrips.keySet()) {\n      stripOffsets[currentIndex++] = currentOffset;\n      strip.getChars(0, strip.length(), stripData, currentOffset);\n      currentOffset += strip.length();\n    }\n    assert currentIndex == seenStrips.size();\n    stripOffsets[currentIndex] = currentOffset;\n  }\n\n","sourceOld":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n    \n    // zero condition -> 0 ord\n    seenPatterns.put(\".*\", 0);\n    patterns.add(null);\n    \n    // zero strip -> 0 ord\n    Map<String,Integer> seenStrips = new LinkedHashMap<>();\n    seenStrips.put(\"\", 0);\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      // ignore any BOM marker on first line\n      if (reader.getLineNumber() == 1 && line.startsWith(\"\\uFEFF\")) {\n        line = line.substring(1);\n      }\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(MORPH_ALIAS_KEY)) {\n        parseMorphAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(IGNORE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal IGNORE declaration\", reader.getLineNumber());\n        }\n        ignore = parts[1].toCharArray();\n        Arrays.sort(ignore);\n        needsInputCleaning = true;\n      } else if (line.startsWith(ICONV_KEY) || line.startsWith(OCONV_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        String type = parts[0];\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal \" + type + \" declaration\", reader.getLineNumber());\n        }\n        int num = Integer.parseInt(parts[1]);\n        FST<CharsRef> res = parseConversions(reader, num);\n        if (type.equals(\"ICONV\")) {\n          iconv = res;\n          needsInputCleaning |= iconv != null;\n        } else {\n          oconv = res;\n          needsOutputCleaning |= oconv != null;\n        }\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n    \n    int totalChars = 0;\n    for (String strip : seenStrips.keySet()) {\n      totalChars += strip.length();\n    }\n    stripData = new char[totalChars];\n    stripOffsets = new int[seenStrips.size()+1];\n    int currentOffset = 0;\n    int currentIndex = 0;\n    for (String strip : seenStrips.keySet()) {\n      stripOffsets[currentIndex++] = currentOffset;\n      strip.getChars(0, strip.length(), stripData, currentOffset);\n      currentOffset += strip.length();\n    }\n    assert currentIndex == seenStrips.size();\n    stripOffsets[currentIndex] = currentOffset;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"422da43e6414338103dfc37b7c8c68dcbe309d87","date":1405540909,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","sourceNew":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n    \n    // zero condition -> 0 ord\n    seenPatterns.put(\".*\", 0);\n    patterns.add(null);\n    \n    // zero strip -> 0 ord\n    Map<String,Integer> seenStrips = new LinkedHashMap<>();\n    seenStrips.put(\"\", 0);\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      // ignore any BOM marker on first line\n      if (reader.getLineNumber() == 1 && line.startsWith(\"\\uFEFF\")) {\n        line = line.substring(1);\n      }\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(MORPH_ALIAS_KEY)) {\n        parseMorphAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(KEEPCASE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal KEEPCASE declaration\", reader.getLineNumber());\n        }\n        keepcase = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(NEEDAFFIX_KEY) || line.startsWith(PSEUDOROOT_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal NEEDAFFIX declaration\", reader.getLineNumber());\n        }\n        needaffix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(ONLYINCOMPOUND_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal ONLYINCOMPOUND declaration\", reader.getLineNumber());\n        }\n        onlyincompound = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(IGNORE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal IGNORE declaration\", reader.getLineNumber());\n        }\n        ignore = parts[1].toCharArray();\n        Arrays.sort(ignore);\n        needsInputCleaning = true;\n      } else if (line.startsWith(ICONV_KEY) || line.startsWith(OCONV_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        String type = parts[0];\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal \" + type + \" declaration\", reader.getLineNumber());\n        }\n        int num = Integer.parseInt(parts[1]);\n        FST<CharsRef> res = parseConversions(reader, num);\n        if (type.equals(\"ICONV\")) {\n          iconv = res;\n          needsInputCleaning |= iconv != null;\n        } else {\n          oconv = res;\n          needsOutputCleaning |= oconv != null;\n        }\n      } else if (line.startsWith(FULLSTRIP_KEY)) {\n        fullStrip = true;\n      } else if (line.startsWith(LANG_KEY)) {\n        language = line.substring(LANG_KEY.length()).trim();\n        alternateCasing = \"tr_TR\".equals(language) || \"az_AZ\".equals(language);\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n    \n    int totalChars = 0;\n    for (String strip : seenStrips.keySet()) {\n      totalChars += strip.length();\n    }\n    stripData = new char[totalChars];\n    stripOffsets = new int[seenStrips.size()+1];\n    int currentOffset = 0;\n    int currentIndex = 0;\n    for (String strip : seenStrips.keySet()) {\n      stripOffsets[currentIndex++] = currentOffset;\n      strip.getChars(0, strip.length(), stripData, currentOffset);\n      currentOffset += strip.length();\n    }\n    assert currentIndex == seenStrips.size();\n    stripOffsets[currentIndex] = currentOffset;\n  }\n\n","sourceOld":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n    \n    // zero condition -> 0 ord\n    seenPatterns.put(\".*\", 0);\n    patterns.add(null);\n    \n    // zero strip -> 0 ord\n    Map<String,Integer> seenStrips = new LinkedHashMap<>();\n    seenStrips.put(\"\", 0);\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      // ignore any BOM marker on first line\n      if (reader.getLineNumber() == 1 && line.startsWith(\"\\uFEFF\")) {\n        line = line.substring(1);\n      }\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(MORPH_ALIAS_KEY)) {\n        parseMorphAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(IGNORE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal IGNORE declaration\", reader.getLineNumber());\n        }\n        ignore = parts[1].toCharArray();\n        Arrays.sort(ignore);\n        needsInputCleaning = true;\n      } else if (line.startsWith(ICONV_KEY) || line.startsWith(OCONV_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        String type = parts[0];\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal \" + type + \" declaration\", reader.getLineNumber());\n        }\n        int num = Integer.parseInt(parts[1]);\n        FST<CharsRef> res = parseConversions(reader, num);\n        if (type.equals(\"ICONV\")) {\n          iconv = res;\n          needsInputCleaning |= iconv != null;\n        } else {\n          oconv = res;\n          needsOutputCleaning |= oconv != null;\n        }\n      } else if (line.startsWith(FULLSTRIP_KEY)) {\n        fullStrip = true;\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n    \n    int totalChars = 0;\n    for (String strip : seenStrips.keySet()) {\n      totalChars += strip.length();\n    }\n    stripData = new char[totalChars];\n    stripOffsets = new int[seenStrips.size()+1];\n    int currentOffset = 0;\n    int currentIndex = 0;\n    for (String strip : seenStrips.keySet()) {\n      stripOffsets[currentIndex++] = currentOffset;\n      strip.getChars(0, strip.length(), stripData, currentOffset);\n      currentOffset += strip.length();\n    }\n    assert currentIndex == seenStrips.size();\n    stripOffsets[currentIndex] = currentOffset;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"79cce2ac13867412e1a9dfd8c8df36833fba0d6a","date":1405962468,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#readAffixFile(InputStream,CharsetDecoder).mjava","sourceNew":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Integer>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Integer>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n    \n    // zero condition -> 0 ord\n    seenPatterns.put(\".*\", 0);\n    patterns.add(null);\n    \n    // zero strip -> 0 ord\n    Map<String,Integer> seenStrips = new LinkedHashMap<>();\n    seenStrips.put(\"\", 0);\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      // ignore any BOM marker on first line\n      if (reader.getLineNumber() == 1 && line.startsWith(\"\\uFEFF\")) {\n        line = line.substring(1);\n      }\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(MORPH_ALIAS_KEY)) {\n        parseMorphAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(KEEPCASE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal KEEPCASE declaration\", reader.getLineNumber());\n        }\n        keepcase = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(NEEDAFFIX_KEY) || line.startsWith(PSEUDOROOT_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal NEEDAFFIX declaration\", reader.getLineNumber());\n        }\n        needaffix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(ONLYINCOMPOUND_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal ONLYINCOMPOUND declaration\", reader.getLineNumber());\n        }\n        onlyincompound = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(IGNORE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal IGNORE declaration\", reader.getLineNumber());\n        }\n        ignore = parts[1].toCharArray();\n        Arrays.sort(ignore);\n        needsInputCleaning = true;\n      } else if (line.startsWith(ICONV_KEY) || line.startsWith(OCONV_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        String type = parts[0];\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal \" + type + \" declaration\", reader.getLineNumber());\n        }\n        int num = Integer.parseInt(parts[1]);\n        FST<CharsRef> res = parseConversions(reader, num);\n        if (type.equals(\"ICONV\")) {\n          iconv = res;\n          needsInputCleaning |= iconv != null;\n        } else {\n          oconv = res;\n          needsOutputCleaning |= oconv != null;\n        }\n      } else if (line.startsWith(FULLSTRIP_KEY)) {\n        fullStrip = true;\n      } else if (line.startsWith(LANG_KEY)) {\n        language = line.substring(LANG_KEY.length()).trim();\n        alternateCasing = \"tr_TR\".equals(language) || \"az_AZ\".equals(language);\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n    \n    int totalChars = 0;\n    for (String strip : seenStrips.keySet()) {\n      totalChars += strip.length();\n    }\n    stripData = new char[totalChars];\n    stripOffsets = new int[seenStrips.size()+1];\n    int currentOffset = 0;\n    int currentIndex = 0;\n    for (String strip : seenStrips.keySet()) {\n      stripOffsets[currentIndex++] = currentOffset;\n      strip.getChars(0, strip.length(), stripData, currentOffset);\n      currentOffset += strip.length();\n    }\n    assert currentIndex == seenStrips.size();\n    stripOffsets[currentIndex] = currentOffset;\n  }\n\n","sourceOld":"  /**\n   * Reads the affix file through the provided InputStream, building up the prefix and suffix maps\n   *\n   * @param affixStream InputStream to read the content of the affix file from\n   * @param decoder CharsetDecoder to decode the content of the file\n   * @throws IOException Can be thrown while reading from the InputStream\n   */\n  private void readAffixFile(InputStream affixStream, CharsetDecoder decoder) throws IOException, ParseException {\n    TreeMap<String, List<Character>> prefixes = new TreeMap<>();\n    TreeMap<String, List<Character>> suffixes = new TreeMap<>();\n    Map<String,Integer> seenPatterns = new HashMap<>();\n    \n    // zero condition -> 0 ord\n    seenPatterns.put(\".*\", 0);\n    patterns.add(null);\n    \n    // zero strip -> 0 ord\n    Map<String,Integer> seenStrips = new LinkedHashMap<>();\n    seenStrips.put(\"\", 0);\n\n    LineNumberReader reader = new LineNumberReader(new InputStreamReader(affixStream, decoder));\n    String line = null;\n    while ((line = reader.readLine()) != null) {\n      // ignore any BOM marker on first line\n      if (reader.getLineNumber() == 1 && line.startsWith(\"\\uFEFF\")) {\n        line = line.substring(1);\n      }\n      if (line.startsWith(ALIAS_KEY)) {\n        parseAlias(line);\n      } else if (line.startsWith(MORPH_ALIAS_KEY)) {\n        parseMorphAlias(line);\n      } else if (line.startsWith(PREFIX_KEY)) {\n        parseAffix(prefixes, line, reader, PREFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(SUFFIX_KEY)) {\n        parseAffix(suffixes, line, reader, SUFFIX_CONDITION_REGEX_PATTERN, seenPatterns, seenStrips);\n      } else if (line.startsWith(FLAG_KEY)) {\n        // Assume that the FLAG line comes before any prefix or suffixes\n        // Store the strategy so it can be used when parsing the dic file\n        flagParsingStrategy = getFlagParsingStrategy(line);\n      } else if (line.equals(COMPLEXPREFIXES_KEY)) {\n        complexPrefixes = true; // 2-stage prefix+1-stage suffix instead of 2-stage suffix+1-stage prefix\n      } else if (line.startsWith(CIRCUMFIX_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal CIRCUMFIX declaration\", reader.getLineNumber());\n        }\n        circumfix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(KEEPCASE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal KEEPCASE declaration\", reader.getLineNumber());\n        }\n        keepcase = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(NEEDAFFIX_KEY) || line.startsWith(PSEUDOROOT_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal NEEDAFFIX declaration\", reader.getLineNumber());\n        }\n        needaffix = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(ONLYINCOMPOUND_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal ONLYINCOMPOUND declaration\", reader.getLineNumber());\n        }\n        onlyincompound = flagParsingStrategy.parseFlag(parts[1]);\n      } else if (line.startsWith(IGNORE_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal IGNORE declaration\", reader.getLineNumber());\n        }\n        ignore = parts[1].toCharArray();\n        Arrays.sort(ignore);\n        needsInputCleaning = true;\n      } else if (line.startsWith(ICONV_KEY) || line.startsWith(OCONV_KEY)) {\n        String parts[] = line.split(\"\\\\s+\");\n        String type = parts[0];\n        if (parts.length != 2) {\n          throw new ParseException(\"Illegal \" + type + \" declaration\", reader.getLineNumber());\n        }\n        int num = Integer.parseInt(parts[1]);\n        FST<CharsRef> res = parseConversions(reader, num);\n        if (type.equals(\"ICONV\")) {\n          iconv = res;\n          needsInputCleaning |= iconv != null;\n        } else {\n          oconv = res;\n          needsOutputCleaning |= oconv != null;\n        }\n      } else if (line.startsWith(FULLSTRIP_KEY)) {\n        fullStrip = true;\n      } else if (line.startsWith(LANG_KEY)) {\n        language = line.substring(LANG_KEY.length()).trim();\n        alternateCasing = \"tr_TR\".equals(language) || \"az_AZ\".equals(language);\n      }\n    }\n    \n    this.prefixes = affixFST(prefixes);\n    this.suffixes = affixFST(suffixes);\n    \n    int totalChars = 0;\n    for (String strip : seenStrips.keySet()) {\n      totalChars += strip.length();\n    }\n    stripData = new char[totalChars];\n    stripOffsets = new int[seenStrips.size()+1];\n    int currentOffset = 0;\n    int currentIndex = 0;\n    for (String strip : seenStrips.keySet()) {\n      stripOffsets[currentIndex++] = currentOffset;\n      strip.getChars(0, strip.length(), stripData, currentOffset);\n      currentOffset += strip.length();\n    }\n    assert currentIndex == seenStrips.size();\n    stripOffsets[currentIndex] = currentOffset;\n  }\n\n","bugFix":["26c5ee01d8657497f54f46447208768acc949d51"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"96ea64d994d340044e0d57aeb6a5871539d10ca5":["38e7d0aeceab994177a0a6b52f475611b52f09bf","5ae9942cbee38a49d234c2f022e3a265133d1914"],"79cce2ac13867412e1a9dfd8c8df36833fba0d6a":["422da43e6414338103dfc37b7c8c68dcbe309d87"],"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4":["96ea64d994d340044e0d57aeb6a5871539d10ca5","d2676f60312754dc25ef542551cb2623527013a4"],"09fb4238d56f62faff1f0c866bee53facad482ec":["d2676f60312754dc25ef542551cb2623527013a4"],"fb75b56e1e392fea98e3903ee95b063c8a5c14b3":["5916de6e2f6deb9da923b2710f6451668e94a20c"],"38e7d0aeceab994177a0a6b52f475611b52f09bf":["1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7"],"1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7":["ba791bce8103c79e38f957e9c5a53a75871bd918"],"5916de6e2f6deb9da923b2710f6451668e94a20c":["09fb4238d56f62faff1f0c866bee53facad482ec"],"d2676f60312754dc25ef542551cb2623527013a4":["5ae9942cbee38a49d234c2f022e3a265133d1914"],"ba791bce8103c79e38f957e9c5a53a75871bd918":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","dc3f094cafa4a87b4066e1d6710fa4e6afe6260e"],"dc3f094cafa4a87b4066e1d6710fa4e6afe6260e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5ae9942cbee38a49d234c2f022e3a265133d1914":["38e7d0aeceab994177a0a6b52f475611b52f09bf"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"422da43e6414338103dfc37b7c8c68dcbe309d87":["fb75b56e1e392fea98e3903ee95b063c8a5c14b3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["79cce2ac13867412e1a9dfd8c8df36833fba0d6a"]},"commit2Childs":{"96ea64d994d340044e0d57aeb6a5871539d10ca5":["a58bbbe1c866963764d3f15d3a26a6a85f6c6af4"],"79cce2ac13867412e1a9dfd8c8df36833fba0d6a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4":[],"09fb4238d56f62faff1f0c866bee53facad482ec":["5916de6e2f6deb9da923b2710f6451668e94a20c"],"fb75b56e1e392fea98e3903ee95b063c8a5c14b3":["422da43e6414338103dfc37b7c8c68dcbe309d87"],"38e7d0aeceab994177a0a6b52f475611b52f09bf":["96ea64d994d340044e0d57aeb6a5871539d10ca5","5ae9942cbee38a49d234c2f022e3a265133d1914"],"1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7":["38e7d0aeceab994177a0a6b52f475611b52f09bf"],"d2676f60312754dc25ef542551cb2623527013a4":["a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","09fb4238d56f62faff1f0c866bee53facad482ec"],"5916de6e2f6deb9da923b2710f6451668e94a20c":["fb75b56e1e392fea98e3903ee95b063c8a5c14b3"],"ba791bce8103c79e38f957e9c5a53a75871bd918":["1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7"],"dc3f094cafa4a87b4066e1d6710fa4e6afe6260e":["ba791bce8103c79e38f957e9c5a53a75871bd918"],"5ae9942cbee38a49d234c2f022e3a265133d1914":["96ea64d994d340044e0d57aeb6a5871539d10ca5","d2676f60312754dc25ef542551cb2623527013a4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ba791bce8103c79e38f957e9c5a53a75871bd918","dc3f094cafa4a87b4066e1d6710fa4e6afe6260e"],"422da43e6414338103dfc37b7c8c68dcbe309d87":["79cce2ac13867412e1a9dfd8c8df36833fba0d6a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}