{"path":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","commits":[{"id":"1525b4dfbc0d413b8d7247da232009778e624836","date":1351101135,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    Thread.sleep(1000);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 20;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    Thread.sleep(1000);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 20;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    Thread.sleep(1000);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["add53de9835b2cd1a7a80b4e0036afee171c9fdf","add53de9835b2cd1a7a80b4e0036afee171c9fdf"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5e71cbdfcf34d779dd7e7ba148dfff6022f2005a","date":1351228731,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 20;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 20;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    Thread.sleep(1000);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 20;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    Thread.sleep(1000);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 20;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    Thread.sleep(1000);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d9405f486872f1e416304dfe389741f4ee2f8a4d","date":1351276739,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = solrj.getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 20;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 20;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 20;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 20;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f2126b84bd093fa3d921582a109a0ee578c28126","date":1351522501,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = solrj.getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 20;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 20;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4633b0db54106ee74c4017ba96c00dc3b388ae25","date":1351543323,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = solrj.getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 20;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = solrj.getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 20;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 20;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e2dd71bdeb98b3766cfff8c3c166e172116040c4","date":1353515774,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = solrj.getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = solrj.getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 20;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c5a558d54519c651068ddb202f03befefb1514a7","date":1354382006,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = solrj.getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = solrj.getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c215736a9e29403edd2132d9f0829a287b428df4","date":1354641965,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = solrj.getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = solrj.getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 20;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"56a558aa5aadd60ae850d1ab090098bc63bdfaf9","date":1355245333,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a69439d0df009e0bb0038d1e427159f449dd670d","date":1355704683,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d3fcb70cf561547c7bb1506e0cf32ca7b1287064","date":1357616416,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderProps(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3cdf010554af55229c2ff813322029a1aaa283ec","date":1359915012,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a9cc12873abcfb571113b5c48ffc3475fcf53769","date":1359915820,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3e4d4ec39bf5396230748ca859ff05ab024b6fc5","date":1360112310,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    \n    server = new HttpSolrServer(url1 + \"/unloadcollection\");\n   // System.out.println(server.query(new SolrQuery(\"*:*\")).getResults().getNumFound());\n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"81a4a1810b619aea1d002a09c1878b498e20bf33","date":1361142322,"type":5,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"09c8567c25c02eeeb3e719841606a1269f3538ca","date":1361155063,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/UnloadDistributedZkTest#testCoreUnloadAndLeaders().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/BasicDistributedZkTest#testCoreUnloadAndLeaders().mjava","sourceNew":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","sourceOld":"  /**\n   * @throws Exception on any problem\n   */\n  private void testCoreUnloadAndLeaders() throws Exception {\n    // create a new collection collection\n    SolrServer client = clients.get(0);\n    String url1 = getBaseUrl(client);\n    HttpSolrServer server = new HttpSolrServer(url1);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    Create createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection1\");\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setNumShards(1);\n    String core1DataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_1n\";\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n    \n    ZkStateReader zkStateReader = getCommonCloudSolrServer().getZkStateReader();\n    \n    zkStateReader.updateClusterState(true);\n\n    int slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    client = clients.get(1);\n    String url2 = getBaseUrl(client);\n    server = new HttpSolrServer(url2);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection2\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core2dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection1\" + \"_2n\";\n    createCmd.setDataDir(core2dataDir);\n    server.request(createCmd);\n    \n    zkStateReader.updateClusterState(true);\n    slices = zkStateReader.getClusterState().getCollectionStates().get(\"unloadcollection\").getSlices().size();\n    assertEquals(1, slices);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    ZkCoreNodeProps leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    \n    Random random = random();\n    HttpSolrServer collectionClient;\n    if (random.nextBoolean()) {\n      collectionClient = new HttpSolrServer(leaderProps.getCoreUrl());\n      // lets try and use the solrj client to index and retrieve a couple\n      // documents\n      SolrInputDocument doc1 = getDoc(id, 6, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      SolrInputDocument doc2 = getDoc(id, 7, i1, -600, tlong, 600, t1,\n          \"humpty dumpy3 sat on a walls\");\n      SolrInputDocument doc3 = getDoc(id, 8, i1, -600, tlong, 600, t1,\n          \"humpty dumpy2 sat on a walled\");\n      collectionClient.add(doc1);\n      collectionClient.add(doc2);\n      collectionClient.add(doc3);\n      collectionClient.commit();\n    }\n\n    // create another replica for our collection\n    client = clients.get(2);\n    String url3 = getBaseUrl(client);\n    server = new HttpSolrServer(url3);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection3\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core3dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_3n\";\n    createCmd.setDataDir(core3dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // so that we start with some versions when we reload...\n    DirectUpdateHandler2.commitOnClose = false;\n    \n    HttpSolrServer addClient = new HttpSolrServer(url3 + \"/unloadcollection3\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    // add a few docs\n    for (int x = 20; x < 100; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n\n    // don't commit so they remain in the tran log\n    //collectionClient.commit();\n    \n    // unload the leader\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    Unload unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    ModifiableSolrParams p = (ModifiableSolrParams) unloadCmd.getParams();\n\n    collectionClient.request(unloadCmd);\n\n//    Thread.currentThread().sleep(500);\n//    printLayout();\n    \n    int tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    // ensure there is a leader\n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    addClient = new HttpSolrServer(url2 + \"/unloadcollection2\");\n    addClient.setConnectionTimeout(15000);\n    addClient.setSoTimeout(30000);\n    \n    // add a few docs while the leader is down\n    for (int x = 101; x < 200; x++) {\n      SolrInputDocument doc1 = getDoc(id, x, i1, -600, tlong, 600, t1,\n          \"humpty dumpy sat on a wall\");\n      addClient.add(doc1);\n    }\n    \n    \n    // create another replica for our collection\n    client = clients.get(3);\n    String url4 = getBaseUrl(client);\n    server = new HttpSolrServer(url4);\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(\"unloadcollection4\");\n    createCmd.setCollection(\"unloadcollection\");\n    String core4dataDir = dataDir.getAbsolutePath() + File.separator + System.currentTimeMillis() + \"unloadcollection\" + \"_4n\";\n    createCmd.setDataDir(core4dataDir);\n    server.request(createCmd);\n    \n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    // unload the leader again\n    leaderProps = getLeaderUrlFromZk(\"unloadcollection\", \"shard1\");\n    collectionClient = new HttpSolrServer(leaderProps.getBaseUrl());\n    collectionClient.setConnectionTimeout(15000);\n    collectionClient.setSoTimeout(30000);\n    \n    unloadCmd = new Unload(false);\n    unloadCmd.setCoreName(leaderProps.getCoreName());\n    p = (ModifiableSolrParams) unloadCmd.getParams();\n    collectionClient.request(unloadCmd);\n    \n    tries = 50;\n    while (leaderProps.getCoreUrl().equals(zkStateReader.getLeaderUrl(\"unloadcollection\", \"shard1\", 15000))) {\n      Thread.sleep(100);\n      if (tries-- == 0) {\n        fail(\"Leader never changed\");\n      }\n    }\n    \n    zkStateReader.getLeaderRetry(\"unloadcollection\", \"shard1\", 15000);\n    \n    \n    // set this back\n    DirectUpdateHandler2.commitOnClose = true;\n    \n    // bring the downed leader back as replica\n    server = new HttpSolrServer(leaderProps.getBaseUrl());\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    \n    createCmd = new Create();\n    createCmd.setCoreName(leaderProps.getCoreName());\n    createCmd.setCollection(\"unloadcollection\");\n    createCmd.setDataDir(core1DataDir);\n    server.request(createCmd);\n\n    waitForRecoveriesToFinish(\"unloadcollection\", zkStateReader, false);\n    \n    server = new HttpSolrServer(url2 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    SolrQuery q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found1 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url3 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found3 = server.query(q).getResults().getNumFound();\n    server = new HttpSolrServer(url4 + \"/unloadcollection\");\n    server.setConnectionTimeout(15000);\n    server.setSoTimeout(30000);\n    server.commit();\n    q = new SolrQuery(\"*:*\");\n    q.set(\"distrib\", false);\n    long found4 = server.query(q).getResults().getNumFound();\n    \n    // all 3 shards should now have the same number of docs\n    assertEquals(found1, found3);\n    assertEquals(found3, found4);\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["407687e67faf6e1f02a211ca078d8e3eed631027","a69439d0df009e0bb0038d1e427159f449dd670d"],"81a4a1810b619aea1d002a09c1878b498e20bf33":["a9cc12873abcfb571113b5c48ffc3475fcf53769"],"3e4d4ec39bf5396230748ca859ff05ab024b6fc5":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","a9cc12873abcfb571113b5c48ffc3475fcf53769"],"3cdf010554af55229c2ff813322029a1aaa283ec":["a69439d0df009e0bb0038d1e427159f449dd670d"],"407687e67faf6e1f02a211ca078d8e3eed631027":["4633b0db54106ee74c4017ba96c00dc3b388ae25","c215736a9e29403edd2132d9f0829a287b428df4"],"a69439d0df009e0bb0038d1e427159f449dd670d":["56a558aa5aadd60ae850d1ab090098bc63bdfaf9"],"a9cc12873abcfb571113b5c48ffc3475fcf53769":["3cdf010554af55229c2ff813322029a1aaa283ec"],"d9405f486872f1e416304dfe389741f4ee2f8a4d":["5e71cbdfcf34d779dd7e7ba148dfff6022f2005a"],"4633b0db54106ee74c4017ba96c00dc3b388ae25":["d9405f486872f1e416304dfe389741f4ee2f8a4d"],"5e71cbdfcf34d779dd7e7ba148dfff6022f2005a":["1525b4dfbc0d413b8d7247da232009778e624836"],"09c8567c25c02eeeb3e719841606a1269f3538ca":["a9cc12873abcfb571113b5c48ffc3475fcf53769","81a4a1810b619aea1d002a09c1878b498e20bf33"],"e2dd71bdeb98b3766cfff8c3c166e172116040c4":["4633b0db54106ee74c4017ba96c00dc3b388ae25"],"c215736a9e29403edd2132d9f0829a287b428df4":["c5a558d54519c651068ddb202f03befefb1514a7"],"c5a558d54519c651068ddb202f03befefb1514a7":["e2dd71bdeb98b3766cfff8c3c166e172116040c4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f2126b84bd093fa3d921582a109a0ee578c28126":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","d9405f486872f1e416304dfe389741f4ee2f8a4d"],"56a558aa5aadd60ae850d1ab090098bc63bdfaf9":["c215736a9e29403edd2132d9f0829a287b428df4"],"1525b4dfbc0d413b8d7247da232009778e624836":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["81a4a1810b619aea1d002a09c1878b498e20bf33"]},"commit2Childs":{"d3fcb70cf561547c7bb1506e0cf32ca7b1287064":["3e4d4ec39bf5396230748ca859ff05ab024b6fc5"],"81a4a1810b619aea1d002a09c1878b498e20bf33":["09c8567c25c02eeeb3e719841606a1269f3538ca","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3e4d4ec39bf5396230748ca859ff05ab024b6fc5":[],"407687e67faf6e1f02a211ca078d8e3eed631027":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064"],"3cdf010554af55229c2ff813322029a1aaa283ec":["a9cc12873abcfb571113b5c48ffc3475fcf53769"],"a69439d0df009e0bb0038d1e427159f449dd670d":["d3fcb70cf561547c7bb1506e0cf32ca7b1287064","3cdf010554af55229c2ff813322029a1aaa283ec"],"a9cc12873abcfb571113b5c48ffc3475fcf53769":["81a4a1810b619aea1d002a09c1878b498e20bf33","3e4d4ec39bf5396230748ca859ff05ab024b6fc5","09c8567c25c02eeeb3e719841606a1269f3538ca"],"d9405f486872f1e416304dfe389741f4ee2f8a4d":["4633b0db54106ee74c4017ba96c00dc3b388ae25","f2126b84bd093fa3d921582a109a0ee578c28126"],"4633b0db54106ee74c4017ba96c00dc3b388ae25":["407687e67faf6e1f02a211ca078d8e3eed631027","e2dd71bdeb98b3766cfff8c3c166e172116040c4"],"5e71cbdfcf34d779dd7e7ba148dfff6022f2005a":["d9405f486872f1e416304dfe389741f4ee2f8a4d"],"09c8567c25c02eeeb3e719841606a1269f3538ca":[],"e2dd71bdeb98b3766cfff8c3c166e172116040c4":["c5a558d54519c651068ddb202f03befefb1514a7"],"c215736a9e29403edd2132d9f0829a287b428df4":["407687e67faf6e1f02a211ca078d8e3eed631027","56a558aa5aadd60ae850d1ab090098bc63bdfaf9"],"c5a558d54519c651068ddb202f03befefb1514a7":["c215736a9e29403edd2132d9f0829a287b428df4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["f2126b84bd093fa3d921582a109a0ee578c28126","1525b4dfbc0d413b8d7247da232009778e624836"],"f2126b84bd093fa3d921582a109a0ee578c28126":[],"56a558aa5aadd60ae850d1ab090098bc63bdfaf9":["a69439d0df009e0bb0038d1e427159f449dd670d"],"1525b4dfbc0d413b8d7247da232009778e624836":["5e71cbdfcf34d779dd7e7ba148dfff6022f2005a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["3e4d4ec39bf5396230748ca859ff05ab024b6fc5","09c8567c25c02eeeb3e719841606a1269f3538ca","f2126b84bd093fa3d921582a109a0ee578c28126","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}