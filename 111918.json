{"path":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","commits":[{"id":"e81698e1493f01874d99b769bc4d9fc9f07555d6","date":1453489635,"type":0,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","pathOld":"/dev/null","sourceNew":"  private void testParallelDaemonUpdateStream() throws Exception {\n    CloudSolrClient destinationCollectionClient = createCloudClient(\"parallelDestinationCollection1\");\n    createCollection(\"parallelDestinationCollection1\", destinationCollectionClient, 2, 2);\n\n    indexr(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\");\n    indexr(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\");\n    indexr(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\");\n    indexr(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\");\n    indexr(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\");\n    commit();\n    waitForRecoveriesToFinish(\"parallelDestinationCollection1\", false);\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = zkServer.getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", zkServer.getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", zkServer.getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    Map params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    int workersComplete = 0;\n    for(CloudJettyRunner jetty : this.cloudJettys) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.url, params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assert(workersComplete == 2);\n\n    destinationCollectionClient.commit();\n\n    //Lets stop the daemons\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\", \"stop\");\n    params.put(\"id\", \"test\");\n    for(CloudJettyRunner jetty : this.cloudJettys) {\n      SolrStream solrStream = new SolrStream(jetty.url, params);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    workersComplete = 0;\n    for(CloudJettyRunner jetty : this.cloudJettys) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.url, params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertTrue(workersComplete == 2);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n    destinationCollectionClient.deleteByQuery(\"*:*\");\n    destinationCollectionClient.commit();\n    destinationCollectionClient.close();\n    del(\"*:*\");\n    commit();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b940572a59da1b42b6c20ab5278155b12816807a","date":1462388874,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","sourceNew":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    Map params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    int workersComplete = 0;\n    for(JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n    cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n    //Lets stop the daemons\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\", \"stop\");\n    params.put(\"id\", \"test\");\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", params);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    workersComplete = 0;\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n  }\n\n","sourceOld":"  private void testParallelDaemonUpdateStream() throws Exception {\n    CloudSolrClient destinationCollectionClient = createCloudClient(\"parallelDestinationCollection1\");\n    createCollection(\"parallelDestinationCollection1\", destinationCollectionClient, 2, 2);\n\n    indexr(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\");\n    indexr(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\");\n    indexr(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\");\n    indexr(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\");\n    indexr(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\");\n    commit();\n    waitForRecoveriesToFinish(\"parallelDestinationCollection1\", false);\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = zkServer.getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", zkServer.getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", zkServer.getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    Map params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    int workersComplete = 0;\n    for(CloudJettyRunner jetty : this.cloudJettys) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.url, params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assert(workersComplete == 2);\n\n    destinationCollectionClient.commit();\n\n    //Lets stop the daemons\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\", \"stop\");\n    params.put(\"id\", \"test\");\n    for(CloudJettyRunner jetty : this.cloudJettys) {\n      SolrStream solrStream = new SolrStream(jetty.url, params);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    workersComplete = 0;\n    for(CloudJettyRunner jetty : this.cloudJettys) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.url, params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertTrue(workersComplete == 2);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n    destinationCollectionClient.deleteByQuery(\"*:*\");\n    destinationCollectionClient.commit();\n    destinationCollectionClient.close();\n    del(\"*:*\");\n    commit();\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bd78ba595fa6cdd7fff930f26d154d13a823fa47","date":1462400514,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","sourceNew":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    Map params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    int workersComplete = 0;\n    for(JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n    cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n    //Lets stop the daemons\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\", \"stop\");\n    params.put(\"id\", \"test\");\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", params);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    workersComplete = 0;\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n  }\n\n","sourceOld":"  private void testParallelDaemonUpdateStream() throws Exception {\n    CloudSolrClient destinationCollectionClient = createCloudClient(\"parallelDestinationCollection1\");\n    createCollection(\"parallelDestinationCollection1\", destinationCollectionClient, 2, 2);\n\n    indexr(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\");\n    indexr(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\");\n    indexr(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\");\n    indexr(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\");\n    indexr(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\");\n    commit();\n    waitForRecoveriesToFinish(\"parallelDestinationCollection1\", false);\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = zkServer.getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", zkServer.getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", zkServer.getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    Map params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    int workersComplete = 0;\n    for(CloudJettyRunner jetty : this.cloudJettys) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.url, params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assert(workersComplete == 2);\n\n    destinationCollectionClient.commit();\n\n    //Lets stop the daemons\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\", \"stop\");\n    params.put(\"id\", \"test\");\n    for(CloudJettyRunner jetty : this.cloudJettys) {\n      SolrStream solrStream = new SolrStream(jetty.url, params);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    workersComplete = 0;\n    for(CloudJettyRunner jetty : this.cloudJettys) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.url, params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertTrue(workersComplete == 2);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n    destinationCollectionClient.deleteByQuery(\"*:*\");\n    destinationCollectionClient.commit();\n    destinationCollectionClient.close();\n    del(\"*:*\");\n    commit();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"73450c0955930295d34703e7ddbfc6973b7a121a","date":1462431925,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","sourceNew":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    Map params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    int workersComplete = 0;\n    for(JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n    cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n    //Lets stop the daemons\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\", \"stop\");\n    params.put(\"id\", \"test\");\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", params);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    workersComplete = 0;\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n  }\n\n","sourceOld":"  private void testParallelDaemonUpdateStream() throws Exception {\n    CloudSolrClient destinationCollectionClient = createCloudClient(\"parallelDestinationCollection1\");\n    createCollection(\"parallelDestinationCollection1\", destinationCollectionClient, 2, 2);\n\n    indexr(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\");\n    indexr(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\");\n    indexr(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\");\n    indexr(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\");\n    indexr(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\");\n    commit();\n    waitForRecoveriesToFinish(\"parallelDestinationCollection1\", false);\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = zkServer.getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", zkServer.getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", zkServer.getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    Map params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    int workersComplete = 0;\n    for(CloudJettyRunner jetty : this.cloudJettys) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.url, params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assert(workersComplete == 2);\n\n    destinationCollectionClient.commit();\n\n    //Lets stop the daemons\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\", \"stop\");\n    params.put(\"id\", \"test\");\n    for(CloudJettyRunner jetty : this.cloudJettys) {\n      SolrStream solrStream = new SolrStream(jetty.url, params);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    workersComplete = 0;\n    for(CloudJettyRunner jetty : this.cloudJettys) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.url, params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertTrue(workersComplete == 2);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n    destinationCollectionClient.deleteByQuery(\"*:*\");\n    destinationCollectionClient.commit();\n    destinationCollectionClient.close();\n    del(\"*:*\");\n    commit();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a8ed5da4b0191db6bc7f77f9feb35da6bd76f904","date":1462576651,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","sourceNew":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    Map params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    int workersComplete = 0;\n    for(JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n    cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n    //Lets stop the daemons\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\", \"stop\");\n    params.put(\"id\", \"test\");\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", params);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    workersComplete = 0;\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n  }\n\n","sourceOld":"  private void testParallelDaemonUpdateStream() throws Exception {\n    CloudSolrClient destinationCollectionClient = createCloudClient(\"parallelDestinationCollection1\");\n    createCollection(\"parallelDestinationCollection1\", destinationCollectionClient, 2, 2);\n\n    indexr(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\");\n    indexr(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\");\n    indexr(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\");\n    indexr(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\");\n    indexr(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\");\n    commit();\n    waitForRecoveriesToFinish(\"parallelDestinationCollection1\", false);\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = zkServer.getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", zkServer.getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", zkServer.getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    Map params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    int workersComplete = 0;\n    for(CloudJettyRunner jetty : this.cloudJettys) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.url, params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assert(workersComplete == 2);\n\n    destinationCollectionClient.commit();\n\n    //Lets stop the daemons\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\", \"stop\");\n    params.put(\"id\", \"test\");\n    for(CloudJettyRunner jetty : this.cloudJettys) {\n      SolrStream solrStream = new SolrStream(jetty.url, params);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    workersComplete = 0;\n    for(CloudJettyRunner jetty : this.cloudJettys) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.url, params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertTrue(workersComplete == 2);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n    destinationCollectionClient.deleteByQuery(\"*:*\");\n    destinationCollectionClient.commit();\n    destinationCollectionClient.close();\n    del(\"*:*\");\n    commit();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"826d15444ddf61716dc768c229cd54b2c2ccce1c","date":1462822652,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","sourceNew":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    ModifiableSolrParams sParams = new ModifiableSolrParams(StreamingTest.mapParams(CommonParams.QT, \"/stream\", \"action\", \"list\"));\n\n    int workersComplete = 0;\n    for(JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n    cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n    //Lets stop the daemons\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"stop\");\n    sParams.set(\"id\", \"test\");\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"list\");\n\n    workersComplete = 0;\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n  }\n\n","sourceOld":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    Map params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    int workersComplete = 0;\n    for(JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n    cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n    //Lets stop the daemons\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\", \"stop\");\n    params.put(\"id\", \"test\");\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", params);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    workersComplete = 0;\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e66a459d38c1c4a2f97128433dab546f683a9fed","date":1462873476,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","sourceNew":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    ModifiableSolrParams sParams = new ModifiableSolrParams(StreamingTest.mapParams(CommonParams.QT, \"/stream\", \"action\", \"list\"));\n\n    int workersComplete = 0;\n    for(JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n    cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n    //Lets stop the daemons\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"stop\");\n    sParams.set(\"id\", \"test\");\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"list\");\n\n    workersComplete = 0;\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n  }\n\n","sourceOld":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    Map params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    int workersComplete = 0;\n    for(JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n    cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n    //Lets stop the daemons\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\", \"stop\");\n    params.put(\"id\", \"test\");\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", params);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    workersComplete = 0;\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","sourceNew":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    ModifiableSolrParams sParams = new ModifiableSolrParams(StreamingTest.mapParams(CommonParams.QT, \"/stream\", \"action\", \"list\"));\n\n    int workersComplete = 0;\n    for(JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n    cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n    //Lets stop the daemons\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"stop\");\n    sParams.set(\"id\", \"test\");\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"list\");\n\n    workersComplete = 0;\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n  }\n\n","sourceOld":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    Map params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    int workersComplete = 0;\n    for(JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n    cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n    //Lets stop the daemons\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\", \"stop\");\n    params.put(\"id\", \"test\");\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", params);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    workersComplete = 0;\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f6b1e64caa933f6fb3c0494afd6ca2597f55cc91","date":1470238980,"type":3,"author":"jbernste","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","sourceNew":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    ModifiableSolrParams sParams = new ModifiableSolrParams(StreamingTest.mapParams(CommonParams.QT, \"/stream\", \"action\", \"list\"));\n\n    int workersComplete = 0;\n    for(JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n    cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n    //Lets stop the daemons\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"stop\");\n    sParams.set(\"id\", \"test\");\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"list\");\n\n    workersComplete = 0;\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n    CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection1\").process(cluster.getSolrClient());\n  }\n\n","sourceOld":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    ModifiableSolrParams sParams = new ModifiableSolrParams(StreamingTest.mapParams(CommonParams.QT, \"/stream\", \"action\", \"list\"));\n\n    int workersComplete = 0;\n    for(JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n    cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n    //Lets stop the daemons\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"stop\");\n    sParams.set(\"id\", \"test\");\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"list\");\n\n    workersComplete = 0;\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3b013574eedcdbac35dc7e35b0ee616ffc38895d","date":1470897818,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","sourceNew":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    ModifiableSolrParams sParams = new ModifiableSolrParams(StreamingTest.mapParams(CommonParams.QT, \"/stream\", \"action\", \"list\"));\n\n    int workersComplete = 0;\n    for(JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n    cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n    //Lets stop the daemons\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"stop\");\n    sParams.set(\"id\", \"test\");\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"list\");\n\n    workersComplete = 0;\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n    CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection1\").process(cluster.getSolrClient());\n  }\n\n","sourceOld":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    ModifiableSolrParams sParams = new ModifiableSolrParams(StreamingTest.mapParams(CommonParams.QT, \"/stream\", \"action\", \"list\"));\n\n    int workersComplete = 0;\n    for(JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n    cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n    //Lets stop the daemons\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"stop\");\n    sParams.set(\"id\", \"test\");\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"list\");\n\n    workersComplete = 0;\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","sourceNew":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    ModifiableSolrParams sParams = new ModifiableSolrParams(StreamingTest.mapParams(CommonParams.QT, \"/stream\", \"action\", \"list\"));\n\n    int workersComplete = 0;\n    for(JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n    cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n    //Lets stop the daemons\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"stop\");\n    sParams.set(\"id\", \"test\");\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"list\");\n\n    workersComplete = 0;\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n    CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection1\").process(cluster.getSolrClient());\n  }\n\n","sourceOld":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    Map params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    int workersComplete = 0;\n    for(JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n    cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n    //Lets stop the daemons\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\", \"stop\");\n    params.put(\"id\", \"test\");\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", params);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    params = new HashMap();\n    params.put(CommonParams.QT,\"/stream\");\n    params.put(\"action\",\"list\");\n\n    workersComplete = 0;\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", params);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c405288c4553ffb50ab8ca5adbdde9881bcec4e4","date":1491938682,"type":3,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","sourceNew":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      assert (tuples.size() == 2);\n\n      //Lets sleep long enough for daemon updates to run.\n      //Lets stop the daemons\n      ModifiableSolrParams sParams = new ModifiableSolrParams(StreamingTest.mapParams(CommonParams.QT, \"/stream\", \"action\", \"list\"));\n\n      int workersComplete = 0;\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        int iterations = 0;\n        INNER:\n        while (iterations == 0) {\n          SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", sParams);\n          solrStream.setStreamContext(streamContext);\n          solrStream.open();\n          Tuple tupleResponse = solrStream.read();\n          if (tupleResponse.EOF) {\n            solrStream.close();\n            break INNER;\n          } else {\n            long l = tupleResponse.getLong(\"iterations\");\n            if (l > 0) {\n              ++workersComplete;\n            } else {\n              try {\n                Thread.sleep(1000);\n              } catch (Exception e) {\n\n              }\n            }\n            iterations = (int) l;\n            solrStream.close();\n          }\n        }\n      }\n\n      assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n      cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n      //Lets stop the daemons\n      sParams = new ModifiableSolrParams();\n      sParams.set(CommonParams.QT, \"/stream\");\n      sParams.set(\"action\", \"stop\");\n      sParams.set(\"id\", \"test\");\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n        solrStream.setStreamContext(streamContext);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        solrStream.close();\n      }\n\n      sParams = new ModifiableSolrParams();\n      sParams.set(CommonParams.QT, \"/stream\");\n      sParams.set(\"action\", \"list\");\n\n      workersComplete = 0;\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        long stopTime = 0;\n        INNER:\n        while (stopTime == 0) {\n          SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n          solrStream.setStreamContext(streamContext);\n          solrStream.open();\n          Tuple tupleResponse = solrStream.read();\n          if (tupleResponse.EOF) {\n            solrStream.close();\n            break INNER;\n          } else {\n            stopTime = tupleResponse.getLong(\"stopTime\");\n            if (stopTime > 0) {\n              ++workersComplete;\n            } else {\n              try {\n                Thread.sleep(1000);\n              } catch (Exception e) {\n\n              }\n            }\n            solrStream.close();\n          }\n        }\n      }\n\n      assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection1\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    ModifiableSolrParams sParams = new ModifiableSolrParams(StreamingTest.mapParams(CommonParams.QT, \"/stream\", \"action\", \"list\"));\n\n    int workersComplete = 0;\n    for(JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n    cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n    //Lets stop the daemons\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"stop\");\n    sParams.set(\"id\", \"test\");\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"list\");\n\n    workersComplete = 0;\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n    CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection1\").process(cluster.getSolrClient());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"54ca69905c5d9d1529286f06ab1d12c68f6c13cb","date":1492683554,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","sourceNew":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      assert (tuples.size() == 2);\n\n      //Lets sleep long enough for daemon updates to run.\n      //Lets stop the daemons\n      ModifiableSolrParams sParams = new ModifiableSolrParams(StreamingTest.mapParams(CommonParams.QT, \"/stream\", \"action\", \"list\"));\n\n      int workersComplete = 0;\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        int iterations = 0;\n        INNER:\n        while (iterations == 0) {\n          SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", sParams);\n          solrStream.setStreamContext(streamContext);\n          solrStream.open();\n          Tuple tupleResponse = solrStream.read();\n          if (tupleResponse.EOF) {\n            solrStream.close();\n            break INNER;\n          } else {\n            long l = tupleResponse.getLong(\"iterations\");\n            if (l > 0) {\n              ++workersComplete;\n            } else {\n              try {\n                Thread.sleep(1000);\n              } catch (Exception e) {\n\n              }\n            }\n            iterations = (int) l;\n            solrStream.close();\n          }\n        }\n      }\n\n      assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n      cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n      //Lets stop the daemons\n      sParams = new ModifiableSolrParams();\n      sParams.set(CommonParams.QT, \"/stream\");\n      sParams.set(\"action\", \"stop\");\n      sParams.set(\"id\", \"test\");\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n        solrStream.setStreamContext(streamContext);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        solrStream.close();\n      }\n\n      sParams = new ModifiableSolrParams();\n      sParams.set(CommonParams.QT, \"/stream\");\n      sParams.set(\"action\", \"list\");\n\n      workersComplete = 0;\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        long stopTime = 0;\n        INNER:\n        while (stopTime == 0) {\n          SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n          solrStream.setStreamContext(streamContext);\n          solrStream.open();\n          Tuple tupleResponse = solrStream.read();\n          if (tupleResponse.EOF) {\n            solrStream.close();\n            break INNER;\n          } else {\n            stopTime = tupleResponse.getLong(\"stopTime\");\n            if (stopTime > 0) {\n              ++workersComplete;\n            } else {\n              try {\n                Thread.sleep(1000);\n              } catch (Exception e) {\n\n              }\n            }\n            solrStream.close();\n          }\n        }\n      }\n\n      assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection1\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    //Copy all docs to destinationCollection\n    String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n    TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\"+zkHost+\"\\\", sort=\\\"batchNumber asc\\\")\");\n    List<Tuple> tuples = getTuples(parallelUpdateStream);\n    assert(tuples.size() == 2);\n\n    //Lets sleep long enough for daemon updates to run.\n    //Lets stop the daemons\n    ModifiableSolrParams sParams = new ModifiableSolrParams(StreamingTest.mapParams(CommonParams.QT, \"/stream\", \"action\", \"list\"));\n\n    int workersComplete = 0;\n    for(JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      int iterations = 0;\n      INNER:\n      while(iterations == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          long l = tupleResponse.getLong(\"iterations\");\n          if(l > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          iterations = (int) l;\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n    cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n    //Lets stop the daemons\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"stop\");\n    sParams.set(\"id\", \"test\");\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n      solrStream.open();\n      Tuple tupleResponse = solrStream.read();\n      solrStream.close();\n    }\n\n    sParams = new ModifiableSolrParams();\n    sParams.set(CommonParams.QT, \"/stream\");\n    sParams.set(\"action\", \"list\");\n\n    workersComplete = 0;\n    for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n      long stopTime = 0;\n      INNER:\n      while(stopTime == 0) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        if (tupleResponse.EOF) {\n          solrStream.close();\n          break INNER;\n        } else {\n          stopTime = tupleResponse.getLong(\"stopTime\");\n          if (stopTime > 0) {\n            ++workersComplete;\n          } else {\n            try {\n              Thread.sleep(1000);\n            } catch(Exception e) {\n\n            }\n          }\n          solrStream.close();\n        }\n      }\n    }\n\n    assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n    //Ensure that destinationCollection actually has the new docs.\n    expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n    stream = new CloudSolrStream(expression, factory);\n    tuples = getTuples(stream);\n    assertEquals(5, tuples.size());\n\n    Tuple tuple = tuples.get(0);\n    assert(tuple.getLong(\"id\") == 0);\n    assert(tuple.get(\"a_s\").equals(\"hello0\"));\n    assert(tuple.getLong(\"a_i\") == 0);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n    tuple = tuples.get(1);\n    assert(tuple.getLong(\"id\") == 1);\n    assert(tuple.get(\"a_s\").equals(\"hello1\"));\n    assert(tuple.getLong(\"a_i\") == 1);\n    assert(tuple.getDouble(\"a_f\") == 1.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n    tuple = tuples.get(2);\n    assert(tuple.getLong(\"id\") == 2);\n    assert(tuple.get(\"a_s\").equals(\"hello2\"));\n    assert(tuple.getLong(\"a_i\") == 2);\n    assert(tuple.getDouble(\"a_f\") == 0.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n    tuple = tuples.get(3);\n    assert(tuple.getLong(\"id\") == 3);\n    assert(tuple.get(\"a_s\").equals(\"hello3\"));\n    assert(tuple.getLong(\"a_i\") == 3);\n    assert(tuple.getDouble(\"a_f\") == 3.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n    tuple = tuples.get(4);\n    assert(tuple.getLong(\"id\") == 4);\n    assert(tuple.get(\"a_s\").equals(\"hello4\"));\n    assert(tuple.getLong(\"a_i\") == 4);\n    assert(tuple.getDouble(\"a_f\") == 4.0);\n    assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n    assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n\n    CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection1\").process(cluster.getSolrClient());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"807005c99d2f1db14e67f84c60b9a5be2ce93974","date":1494295491,"type":3,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","sourceNew":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\", \"s_multi\", \"bbbb\", \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      assert (tuples.size() == 2);\n\n      //Lets sleep long enough for daemon updates to run.\n      //Lets stop the daemons\n      ModifiableSolrParams sParams = new ModifiableSolrParams(StreamingTest.mapParams(CommonParams.QT, \"/stream\", \"action\", \"list\"));\n\n      int workersComplete = 0;\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        int iterations = 0;\n        INNER:\n        while (iterations == 0) {\n          SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", sParams);\n          solrStream.setStreamContext(streamContext);\n          solrStream.open();\n          Tuple tupleResponse = solrStream.read();\n          if (tupleResponse.EOF) {\n            solrStream.close();\n            break INNER;\n          } else {\n            long l = tupleResponse.getLong(\"iterations\");\n            if (l > 0) {\n              ++workersComplete;\n            } else {\n              try {\n                Thread.sleep(1000);\n              } catch (Exception e) {\n\n              }\n            }\n            iterations = (int) l;\n            solrStream.close();\n          }\n        }\n      }\n\n      assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n      cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n      //Lets stop the daemons\n      sParams = new ModifiableSolrParams();\n      sParams.set(CommonParams.QT, \"/stream\");\n      sParams.set(\"action\", \"stop\");\n      sParams.set(\"id\", \"test\");\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n        solrStream.setStreamContext(streamContext);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        solrStream.close();\n      }\n\n      sParams = new ModifiableSolrParams();\n      sParams.set(CommonParams.QT, \"/stream\");\n      sParams.set(\"action\", \"list\");\n\n      workersComplete = 0;\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        long stopTime = 0;\n        INNER:\n        while (stopTime == 0) {\n          SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n          solrStream.setStreamContext(streamContext);\n          solrStream.open();\n          Tuple tupleResponse = solrStream.read();\n          if (tupleResponse.EOF) {\n            solrStream.close();\n            break INNER;\n          } else {\n            stopTime = tupleResponse.getLong(\"stopTime\");\n            if (stopTime > 0) {\n              ++workersComplete;\n            } else {\n              try {\n                Thread.sleep(1000);\n              } catch (Exception e) {\n\n              }\n            }\n            solrStream.close();\n          }\n        }\n      }\n\n      assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection1\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      assert (tuples.size() == 2);\n\n      //Lets sleep long enough for daemon updates to run.\n      //Lets stop the daemons\n      ModifiableSolrParams sParams = new ModifiableSolrParams(StreamingTest.mapParams(CommonParams.QT, \"/stream\", \"action\", \"list\"));\n\n      int workersComplete = 0;\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        int iterations = 0;\n        INNER:\n        while (iterations == 0) {\n          SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", sParams);\n          solrStream.setStreamContext(streamContext);\n          solrStream.open();\n          Tuple tupleResponse = solrStream.read();\n          if (tupleResponse.EOF) {\n            solrStream.close();\n            break INNER;\n          } else {\n            long l = tupleResponse.getLong(\"iterations\");\n            if (l > 0) {\n              ++workersComplete;\n            } else {\n              try {\n                Thread.sleep(1000);\n              } catch (Exception e) {\n\n              }\n            }\n            iterations = (int) l;\n            solrStream.close();\n          }\n        }\n      }\n\n      assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n      cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n      //Lets stop the daemons\n      sParams = new ModifiableSolrParams();\n      sParams.set(CommonParams.QT, \"/stream\");\n      sParams.set(\"action\", \"stop\");\n      sParams.set(\"id\", \"test\");\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n        solrStream.setStreamContext(streamContext);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        solrStream.close();\n      }\n\n      sParams = new ModifiableSolrParams();\n      sParams.set(CommonParams.QT, \"/stream\");\n      sParams.set(\"action\", \"list\");\n\n      workersComplete = 0;\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        long stopTime = 0;\n        INNER:\n        while (stopTime == 0) {\n          SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n          solrStream.setStreamContext(streamContext);\n          solrStream.open();\n          Tuple tupleResponse = solrStream.read();\n          if (tupleResponse.EOF) {\n            solrStream.close();\n            break INNER;\n          } else {\n            stopTime = tupleResponse.getLong(\"stopTime\");\n            if (stopTime > 0) {\n              ++workersComplete;\n            } else {\n              try {\n                Thread.sleep(1000);\n              } catch (Exception e) {\n\n              }\n            }\n            solrStream.close();\n          }\n        }\n      }\n\n      assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection1\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9017cf144952056066919f1ebc7897ff9bd71b1","date":1496757600,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","sourceNew":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\", \"s_multi\", \"bbbb\", \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      assert (tuples.size() == 2);\n\n      //Lets sleep long enough for daemon updates to run.\n      //Lets stop the daemons\n      ModifiableSolrParams sParams = new ModifiableSolrParams(StreamingTest.mapParams(CommonParams.QT, \"/stream\", \"action\", \"list\"));\n\n      int workersComplete = 0;\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        int iterations = 0;\n        INNER:\n        while (iterations == 0) {\n          SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", sParams);\n          solrStream.setStreamContext(streamContext);\n          solrStream.open();\n          Tuple tupleResponse = solrStream.read();\n          if (tupleResponse.EOF) {\n            solrStream.close();\n            break INNER;\n          } else {\n            long l = tupleResponse.getLong(\"iterations\");\n            if (l > 0) {\n              ++workersComplete;\n            } else {\n              try {\n                Thread.sleep(1000);\n              } catch (Exception e) {\n\n              }\n            }\n            iterations = (int) l;\n            solrStream.close();\n          }\n        }\n      }\n\n      assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n      cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n      //Lets stop the daemons\n      sParams = new ModifiableSolrParams();\n      sParams.set(CommonParams.QT, \"/stream\");\n      sParams.set(\"action\", \"stop\");\n      sParams.set(\"id\", \"test\");\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n        solrStream.setStreamContext(streamContext);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        solrStream.close();\n      }\n\n      sParams = new ModifiableSolrParams();\n      sParams.set(CommonParams.QT, \"/stream\");\n      sParams.set(\"action\", \"list\");\n\n      workersComplete = 0;\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        long stopTime = 0;\n        INNER:\n        while (stopTime == 0) {\n          SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n          solrStream.setStreamContext(streamContext);\n          solrStream.open();\n          Tuple tupleResponse = solrStream.read();\n          if (tupleResponse.EOF) {\n            solrStream.close();\n            break INNER;\n          } else {\n            stopTime = tupleResponse.getLong(\"stopTime\");\n            if (stopTime > 0) {\n              ++workersComplete;\n            } else {\n              try {\n                Thread.sleep(1000);\n              } catch (Exception e) {\n\n              }\n            }\n            solrStream.close();\n          }\n        }\n      }\n\n      assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection1\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\",  \"s_multi\", \"bbbb\",  \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      assert (tuples.size() == 2);\n\n      //Lets sleep long enough for daemon updates to run.\n      //Lets stop the daemons\n      ModifiableSolrParams sParams = new ModifiableSolrParams(StreamingTest.mapParams(CommonParams.QT, \"/stream\", \"action\", \"list\"));\n\n      int workersComplete = 0;\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        int iterations = 0;\n        INNER:\n        while (iterations == 0) {\n          SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", sParams);\n          solrStream.setStreamContext(streamContext);\n          solrStream.open();\n          Tuple tupleResponse = solrStream.read();\n          if (tupleResponse.EOF) {\n            solrStream.close();\n            break INNER;\n          } else {\n            long l = tupleResponse.getLong(\"iterations\");\n            if (l > 0) {\n              ++workersComplete;\n            } else {\n              try {\n                Thread.sleep(1000);\n              } catch (Exception e) {\n\n              }\n            }\n            iterations = (int) l;\n            solrStream.close();\n          }\n        }\n      }\n\n      assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n      cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n      //Lets stop the daemons\n      sParams = new ModifiableSolrParams();\n      sParams.set(CommonParams.QT, \"/stream\");\n      sParams.set(\"action\", \"stop\");\n      sParams.set(\"id\", \"test\");\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n        solrStream.setStreamContext(streamContext);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        solrStream.close();\n      }\n\n      sParams = new ModifiableSolrParams();\n      sParams.set(CommonParams.QT, \"/stream\");\n      sParams.set(\"action\", \"list\");\n\n      workersComplete = 0;\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        long stopTime = 0;\n        INNER:\n        while (stopTime == 0) {\n          SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n          solrStream.setStreamContext(streamContext);\n          solrStream.open();\n          Tuple tupleResponse = solrStream.read();\n          if (tupleResponse.EOF) {\n            solrStream.close();\n            break INNER;\n          } else {\n            stopTime = tupleResponse.getLong(\"stopTime\");\n            if (stopTime > 0) {\n              ++workersComplete;\n            } else {\n              try {\n                Thread.sleep(1000);\n              } catch (Exception e) {\n\n              }\n            }\n            solrStream.close();\n          }\n        }\n      }\n\n      assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection1\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf","date":1522951207,"type":5,"author":"Joel Bernstein","isMerge":false,"pathNew":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamDecoratorTest#testParallelDaemonUpdateStream().mjava","pathOld":"solr/solrj/src/test/org/apache/solr/client/solrj/io/stream/StreamExpressionTest#testParallelDaemonUpdateStream().mjava","sourceNew":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\", \"s_multi\", \"bbbb\", \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      assert (tuples.size() == 2);\n\n      //Lets sleep long enough for daemon updates to run.\n      //Lets stop the daemons\n      ModifiableSolrParams sParams = new ModifiableSolrParams(StreamingTest.mapParams(CommonParams.QT, \"/stream\", \"action\", \"list\"));\n\n      int workersComplete = 0;\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        int iterations = 0;\n        INNER:\n        while (iterations == 0) {\n          SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", sParams);\n          solrStream.setStreamContext(streamContext);\n          solrStream.open();\n          Tuple tupleResponse = solrStream.read();\n          if (tupleResponse.EOF) {\n            solrStream.close();\n            break INNER;\n          } else {\n            long l = tupleResponse.getLong(\"iterations\");\n            if (l > 0) {\n              ++workersComplete;\n            } else {\n              try {\n                Thread.sleep(1000);\n              } catch (Exception e) {\n\n              }\n            }\n            iterations = (int) l;\n            solrStream.close();\n          }\n        }\n      }\n\n      assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n      cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n      //Lets stop the daemons\n      sParams = new ModifiableSolrParams();\n      sParams.set(CommonParams.QT, \"/stream\");\n      sParams.set(\"action\", \"stop\");\n      sParams.set(\"id\", \"test\");\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n        solrStream.setStreamContext(streamContext);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        solrStream.close();\n      }\n\n      sParams = new ModifiableSolrParams();\n      sParams.set(CommonParams.QT, \"/stream\");\n      sParams.set(\"action\", \"list\");\n\n      workersComplete = 0;\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        long stopTime = 0;\n        INNER:\n        while (stopTime == 0) {\n          SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n          solrStream.setStreamContext(streamContext);\n          solrStream.open();\n          Tuple tupleResponse = solrStream.read();\n          if (tupleResponse.EOF) {\n            solrStream.close();\n            break INNER;\n          } else {\n            stopTime = tupleResponse.getLong(\"stopTime\");\n            if (stopTime > 0) {\n              ++workersComplete;\n            } else {\n              try {\n                Thread.sleep(1000);\n              } catch (Exception e) {\n\n              }\n            }\n            solrStream.close();\n          }\n        }\n      }\n\n      assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection1\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testParallelDaemonUpdateStream() throws Exception {\n\n    CollectionAdminRequest.createCollection(\"parallelDestinationCollection1\", \"conf\", 2, 1).process(cluster.getSolrClient());\n    AbstractDistribZkTestBase.waitForRecoveriesToFinish(\"parallelDestinationCollection1\", cluster.getSolrClient().getZkStateReader(),\n        false, true, TIMEOUT);\n\n    new UpdateRequest()\n        .add(id, \"0\", \"a_s\", \"hello0\", \"a_i\", \"0\", \"a_f\", \"0\", \"s_multi\", \"aaaa\", \"s_multi\", \"bbbb\", \"i_multi\", \"4\", \"i_multi\", \"7\")\n        .add(id, \"2\", \"a_s\", \"hello2\", \"a_i\", \"2\", \"a_f\", \"0\", \"s_multi\", \"aaaa1\", \"s_multi\", \"bbbb1\", \"i_multi\", \"44\", \"i_multi\", \"77\")\n        .add(id, \"3\", \"a_s\", \"hello3\", \"a_i\", \"3\", \"a_f\", \"3\", \"s_multi\", \"aaaa2\", \"s_multi\", \"bbbb2\", \"i_multi\", \"444\", \"i_multi\", \"777\")\n        .add(id, \"4\", \"a_s\", \"hello4\", \"a_i\", \"4\", \"a_f\", \"4\", \"s_multi\", \"aaaa3\", \"s_multi\", \"bbbb3\", \"i_multi\", \"4444\", \"i_multi\", \"7777\")\n        .add(id, \"1\", \"a_s\", \"hello1\", \"a_i\", \"1\", \"a_f\", \"1\", \"s_multi\", \"aaaa4\", \"s_multi\", \"bbbb4\", \"i_multi\", \"44444\", \"i_multi\", \"77777\")\n        .commit(cluster.getSolrClient(), \"collection1\");\n\n    StreamExpression expression;\n    TupleStream stream;\n    Tuple t;\n    StreamContext streamContext = new StreamContext();\n    SolrClientCache solrClientCache = new SolrClientCache();\n    streamContext.setSolrClientCache(solrClientCache);\n\n    String zkHost = cluster.getZkServer().getZkAddress();\n    StreamFactory factory = new StreamFactory()\n        .withCollectionZkHost(\"collection1\", cluster.getZkServer().getZkAddress())\n        .withCollectionZkHost(\"parallelDestinationCollection1\", cluster.getZkServer().getZkAddress())\n        .withFunctionName(\"search\", CloudSolrStream.class)\n        .withFunctionName(\"update\", UpdateStream.class)\n        .withFunctionName(\"parallel\", ParallelStream.class)\n        .withFunctionName(\"daemon\", DaemonStream.class);\n\n    try {\n      //Copy all docs to destinationCollection\n      String updateExpression = \"daemon(update(parallelDestinationCollection1, batchSize=2, search(collection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_f asc, a_i asc\\\", partitionKeys=\\\"a_f\\\")), runInterval=\\\"1000\\\", id=\\\"test\\\")\";\n      TupleStream parallelUpdateStream = factory.constructStream(\"parallel(collection1, \" + updateExpression + \", workers=\\\"2\\\", zkHost=\\\"\" + zkHost + \"\\\", sort=\\\"batchNumber asc\\\")\");\n      parallelUpdateStream.setStreamContext(streamContext);\n      List<Tuple> tuples = getTuples(parallelUpdateStream);\n      assert (tuples.size() == 2);\n\n      //Lets sleep long enough for daemon updates to run.\n      //Lets stop the daemons\n      ModifiableSolrParams sParams = new ModifiableSolrParams(StreamingTest.mapParams(CommonParams.QT, \"/stream\", \"action\", \"list\"));\n\n      int workersComplete = 0;\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        int iterations = 0;\n        INNER:\n        while (iterations == 0) {\n          SolrStream solrStream = new SolrStream(jetty.getBaseUrl().toString() + \"/collection1\", sParams);\n          solrStream.setStreamContext(streamContext);\n          solrStream.open();\n          Tuple tupleResponse = solrStream.read();\n          if (tupleResponse.EOF) {\n            solrStream.close();\n            break INNER;\n          } else {\n            long l = tupleResponse.getLong(\"iterations\");\n            if (l > 0) {\n              ++workersComplete;\n            } else {\n              try {\n                Thread.sleep(1000);\n              } catch (Exception e) {\n\n              }\n            }\n            iterations = (int) l;\n            solrStream.close();\n          }\n        }\n      }\n\n      assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n\n      cluster.getSolrClient().commit(\"parallelDestinationCollection1\");\n\n      //Lets stop the daemons\n      sParams = new ModifiableSolrParams();\n      sParams.set(CommonParams.QT, \"/stream\");\n      sParams.set(\"action\", \"stop\");\n      sParams.set(\"id\", \"test\");\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n        solrStream.setStreamContext(streamContext);\n        solrStream.open();\n        Tuple tupleResponse = solrStream.read();\n        solrStream.close();\n      }\n\n      sParams = new ModifiableSolrParams();\n      sParams.set(CommonParams.QT, \"/stream\");\n      sParams.set(\"action\", \"list\");\n\n      workersComplete = 0;\n      for (JettySolrRunner jetty : cluster.getJettySolrRunners()) {\n        long stopTime = 0;\n        INNER:\n        while (stopTime == 0) {\n          SolrStream solrStream = new SolrStream(jetty.getBaseUrl() + \"/collection1\", sParams);\n          solrStream.setStreamContext(streamContext);\n          solrStream.open();\n          Tuple tupleResponse = solrStream.read();\n          if (tupleResponse.EOF) {\n            solrStream.close();\n            break INNER;\n          } else {\n            stopTime = tupleResponse.getLong(\"stopTime\");\n            if (stopTime > 0) {\n              ++workersComplete;\n            } else {\n              try {\n                Thread.sleep(1000);\n              } catch (Exception e) {\n\n              }\n            }\n            solrStream.close();\n          }\n        }\n      }\n\n      assertEquals(cluster.getJettySolrRunners().size(), workersComplete);\n      //Ensure that destinationCollection actually has the new docs.\n      expression = StreamExpressionParser.parse(\"search(parallelDestinationCollection1, q=*:*, fl=\\\"id,a_s,a_i,a_f,s_multi,i_multi\\\", sort=\\\"a_i asc\\\")\");\n      stream = new CloudSolrStream(expression, factory);\n      stream.setStreamContext(streamContext);\n      tuples = getTuples(stream);\n      assertEquals(5, tuples.size());\n\n      Tuple tuple = tuples.get(0);\n      assert (tuple.getLong(\"id\") == 0);\n      assert (tuple.get(\"a_s\").equals(\"hello0\"));\n      assert (tuple.getLong(\"a_i\") == 0);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa\", \"bbbb\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4\"), Long.parseLong(\"7\"));\n\n      tuple = tuples.get(1);\n      assert (tuple.getLong(\"id\") == 1);\n      assert (tuple.get(\"a_s\").equals(\"hello1\"));\n      assert (tuple.getLong(\"a_i\") == 1);\n      assert (tuple.getDouble(\"a_f\") == 1.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa4\", \"bbbb4\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44444\"), Long.parseLong(\"77777\"));\n\n      tuple = tuples.get(2);\n      assert (tuple.getLong(\"id\") == 2);\n      assert (tuple.get(\"a_s\").equals(\"hello2\"));\n      assert (tuple.getLong(\"a_i\") == 2);\n      assert (tuple.getDouble(\"a_f\") == 0.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa1\", \"bbbb1\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"44\"), Long.parseLong(\"77\"));\n\n      tuple = tuples.get(3);\n      assert (tuple.getLong(\"id\") == 3);\n      assert (tuple.get(\"a_s\").equals(\"hello3\"));\n      assert (tuple.getLong(\"a_i\") == 3);\n      assert (tuple.getDouble(\"a_f\") == 3.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa2\", \"bbbb2\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"444\"), Long.parseLong(\"777\"));\n\n      tuple = tuples.get(4);\n      assert (tuple.getLong(\"id\") == 4);\n      assert (tuple.get(\"a_s\").equals(\"hello4\"));\n      assert (tuple.getLong(\"a_i\") == 4);\n      assert (tuple.getDouble(\"a_f\") == 4.0);\n      assertList(tuple.getStrings(\"s_multi\"), \"aaaa3\", \"bbbb3\");\n      assertList(tuple.getLongs(\"i_multi\"), Long.parseLong(\"4444\"), Long.parseLong(\"7777\"));\n    } finally {\n      CollectionAdminRequest.deleteCollection(\"parallelDestinationCollection1\").process(cluster.getSolrClient());\n      solrClientCache.close();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["f6b1e64caa933f6fb3c0494afd6ca2597f55cc91"],"73450c0955930295d34703e7ddbfc6973b7a121a":["e81698e1493f01874d99b769bc4d9fc9f07555d6","b940572a59da1b42b6c20ab5278155b12816807a"],"f6b1e64caa933f6fb3c0494afd6ca2597f55cc91":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"e81698e1493f01874d99b769bc4d9fc9f07555d6":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c405288c4553ffb50ab8ca5adbdde9881bcec4e4":["f6b1e64caa933f6fb3c0494afd6ca2597f55cc91"],"807005c99d2f1db14e67f84c60b9a5be2ce93974":["c405288c4553ffb50ab8ca5adbdde9881bcec4e4"],"b940572a59da1b42b6c20ab5278155b12816807a":["e81698e1493f01874d99b769bc4d9fc9f07555d6"],"826d15444ddf61716dc768c229cd54b2c2ccce1c":["73450c0955930295d34703e7ddbfc6973b7a121a"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["bd78ba595fa6cdd7fff930f26d154d13a823fa47","f6b1e64caa933f6fb3c0494afd6ca2597f55cc91"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["73450c0955930295d34703e7ddbfc6973b7a121a","826d15444ddf61716dc768c229cd54b2c2ccce1c"],"e9017cf144952056066919f1ebc7897ff9bd71b1":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","807005c99d2f1db14e67f84c60b9a5be2ce93974"],"bd78ba595fa6cdd7fff930f26d154d13a823fa47":["e81698e1493f01874d99b769bc4d9fc9f07555d6","b940572a59da1b42b6c20ab5278155b12816807a"],"a8ed5da4b0191db6bc7f77f9feb35da6bd76f904":["e81698e1493f01874d99b769bc4d9fc9f07555d6","73450c0955930295d34703e7ddbfc6973b7a121a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"e66a459d38c1c4a2f97128433dab546f683a9fed":["a8ed5da4b0191db6bc7f77f9feb35da6bd76f904","826d15444ddf61716dc768c229cd54b2c2ccce1c"],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":["d470c8182e92b264680e34081b75e70a9f2b3c89","f6b1e64caa933f6fb3c0494afd6ca2597f55cc91"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf"],"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf":["807005c99d2f1db14e67f84c60b9a5be2ce93974"]},"commit2Childs":{"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["e9017cf144952056066919f1ebc7897ff9bd71b1"],"73450c0955930295d34703e7ddbfc6973b7a121a":["826d15444ddf61716dc768c229cd54b2c2ccce1c","d470c8182e92b264680e34081b75e70a9f2b3c89","a8ed5da4b0191db6bc7f77f9feb35da6bd76f904"],"f6b1e64caa933f6fb3c0494afd6ca2597f55cc91":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","c405288c4553ffb50ab8ca5adbdde9881bcec4e4","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"e81698e1493f01874d99b769bc4d9fc9f07555d6":["73450c0955930295d34703e7ddbfc6973b7a121a","b940572a59da1b42b6c20ab5278155b12816807a","bd78ba595fa6cdd7fff930f26d154d13a823fa47","a8ed5da4b0191db6bc7f77f9feb35da6bd76f904"],"c405288c4553ffb50ab8ca5adbdde9881bcec4e4":["807005c99d2f1db14e67f84c60b9a5be2ce93974"],"807005c99d2f1db14e67f84c60b9a5be2ce93974":["e9017cf144952056066919f1ebc7897ff9bd71b1","8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf"],"b940572a59da1b42b6c20ab5278155b12816807a":["73450c0955930295d34703e7ddbfc6973b7a121a","bd78ba595fa6cdd7fff930f26d154d13a823fa47"],"826d15444ddf61716dc768c229cd54b2c2ccce1c":["d470c8182e92b264680e34081b75e70a9f2b3c89","e66a459d38c1c4a2f97128433dab546f683a9fed"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"d470c8182e92b264680e34081b75e70a9f2b3c89":["f6b1e64caa933f6fb3c0494afd6ca2597f55cc91","3b013574eedcdbac35dc7e35b0ee616ffc38895d"],"bd78ba595fa6cdd7fff930f26d154d13a823fa47":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"e9017cf144952056066919f1ebc7897ff9bd71b1":[],"a8ed5da4b0191db6bc7f77f9feb35da6bd76f904":["e66a459d38c1c4a2f97128433dab546f683a9fed"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["e81698e1493f01874d99b769bc4d9fc9f07555d6"],"e66a459d38c1c4a2f97128433dab546f683a9fed":[],"3b013574eedcdbac35dc7e35b0ee616ffc38895d":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"8ff654a6d1fb7a79aedaa65c23cc052fdc770aaf":["cd5edd1f2b162a5cfa08efd17851a07373a96817"]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","e9017cf144952056066919f1ebc7897ff9bd71b1","e66a459d38c1c4a2f97128433dab546f683a9fed","3b013574eedcdbac35dc7e35b0ee616ffc38895d","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}