{"path":"solr/core/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int,boolean).mjava","commits":[{"id":"0ad9ec888e587ca9a3279368245cdf00aabdc108","date":1338832525,"type":0,"author":"James Dyer","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int,boolean).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * <p>\n   * We assume here that the passed-in inner LinkedHashMaps are already sorted\n   * in order of \"Best Possible Correction\".\n   * </p>\n   * \n   * @param suggestions\n   */\n  public PossibilityIterator(\n      Map<Token,LinkedHashMap<String,Integer>> suggestions,\n      int maximumRequiredSuggestions, int maxEvaluations, boolean overlap) {\n    this.suggestionsMayOverlap = overlap;\n    for (Map.Entry<Token,LinkedHashMap<String,Integer>> entry : suggestions\n        .entrySet()) {\n      Token token = entry.getKey();\n      if (entry.getValue().size() == 0) {\n        continue;\n      }\n      List<SpellCheckCorrection> possibleCorrections = new ArrayList<SpellCheckCorrection>();\n      for (Map.Entry<String,Integer> entry1 : entry.getValue().entrySet()) {\n        SpellCheckCorrection correction = new SpellCheckCorrection();\n        correction.setOriginal(token);\n        correction.setCorrection(entry1.getKey());\n        correction.setNumberOfOccurences(entry1.getValue());\n        possibleCorrections.add(correction);\n      }\n      possibilityList.add(possibleCorrections);\n    }\n    \n    int wrapSize = possibilityList.size();\n    if (wrapSize == 0) {\n      done = true;\n    } else {\n      correctionIndex = new int[wrapSize];\n      for (int i = 0; i < wrapSize; i++) {\n        int suggestSize = possibilityList.get(i).size();\n        if (suggestSize == 0) {\n          done = true;\n          break;\n        }\n        correctionIndex[i] = 0;\n      }\n    }\n    PriorityQueue<RankedSpellPossibility> rankedPossibilities = new PriorityQueue<RankedSpellPossibility>(\n        11, new RankComparator());\n    Set<RankedSpellPossibility> removeDuplicates = null;\n    if (suggestionsMayOverlap) {\n      removeDuplicates = new HashSet<RankedSpellPossibility>();\n    }\n    long numEvaluations = 0;\n    while (numEvaluations < maxEvaluations && internalHasNext()) {\n      RankedSpellPossibility rsp = internalNext();\n      numEvaluations++;\n      if (rankedPossibilities.size() >= maximumRequiredSuggestions\n          && rsp.rank >= rankedPossibilities.peek().rank) {\n        continue;\n      }\n      if (!isSuggestionForReal(rsp)) {\n        continue;\n      }\n      if (removeDuplicates == null) {\n        rankedPossibilities.offer(rsp);\n      } else {\n        // Needs to be in token-offset order so that the match-and-replace\n        // option for collations can work.\n        Collections.sort(rsp.corrections, new StartOffsetComparator());\n        if (removeDuplicates.add(rsp)) {\n          rankedPossibilities.offer(rsp);\n        }\n      }\n      if (rankedPossibilities.size() > maximumRequiredSuggestions) {\n        RankedSpellPossibility removed = rankedPossibilities.poll();\n        if (removeDuplicates != null) {\n          removeDuplicates.remove(removed);\n        }\n      }\n    }\n    \n    RankedSpellPossibility[] rpArr = new RankedSpellPossibility[rankedPossibilities\n        .size()];\n    for (int i = rankedPossibilities.size() - 1; i >= 0; i--) {\n      rpArr[i] = rankedPossibilities.remove();\n    }\n    rankedPossibilityIterator = Arrays.asList(rpArr).iterator();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069","date":1348430063,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int,boolean).mjava","sourceNew":"  /**\n   * <p>\n   * We assume here that the passed-in inner LinkedHashMaps are already sorted\n   * in order of \"Best Possible Correction\".\n   * </p>\n   */\n  public PossibilityIterator(\n      Map<Token,LinkedHashMap<String,Integer>> suggestions,\n      int maximumRequiredSuggestions, int maxEvaluations, boolean overlap) {\n    this.suggestionsMayOverlap = overlap;\n    for (Map.Entry<Token,LinkedHashMap<String,Integer>> entry : suggestions\n        .entrySet()) {\n      Token token = entry.getKey();\n      if (entry.getValue().size() == 0) {\n        continue;\n      }\n      List<SpellCheckCorrection> possibleCorrections = new ArrayList<SpellCheckCorrection>();\n      for (Map.Entry<String,Integer> entry1 : entry.getValue().entrySet()) {\n        SpellCheckCorrection correction = new SpellCheckCorrection();\n        correction.setOriginal(token);\n        correction.setCorrection(entry1.getKey());\n        correction.setNumberOfOccurences(entry1.getValue());\n        possibleCorrections.add(correction);\n      }\n      possibilityList.add(possibleCorrections);\n    }\n    \n    int wrapSize = possibilityList.size();\n    if (wrapSize == 0) {\n      done = true;\n    } else {\n      correctionIndex = new int[wrapSize];\n      for (int i = 0; i < wrapSize; i++) {\n        int suggestSize = possibilityList.get(i).size();\n        if (suggestSize == 0) {\n          done = true;\n          break;\n        }\n        correctionIndex[i] = 0;\n      }\n    }\n    PriorityQueue<RankedSpellPossibility> rankedPossibilities = new PriorityQueue<RankedSpellPossibility>(\n        11, new RankComparator());\n    Set<RankedSpellPossibility> removeDuplicates = null;\n    if (suggestionsMayOverlap) {\n      removeDuplicates = new HashSet<RankedSpellPossibility>();\n    }\n    long numEvaluations = 0;\n    while (numEvaluations < maxEvaluations && internalHasNext()) {\n      RankedSpellPossibility rsp = internalNext();\n      numEvaluations++;\n      if (rankedPossibilities.size() >= maximumRequiredSuggestions\n          && rsp.rank >= rankedPossibilities.peek().rank) {\n        continue;\n      }\n      if (!isSuggestionForReal(rsp)) {\n        continue;\n      }\n      if (removeDuplicates == null) {\n        rankedPossibilities.offer(rsp);\n      } else {\n        // Needs to be in token-offset order so that the match-and-replace\n        // option for collations can work.\n        Collections.sort(rsp.corrections, new StartOffsetComparator());\n        if (removeDuplicates.add(rsp)) {\n          rankedPossibilities.offer(rsp);\n        }\n      }\n      if (rankedPossibilities.size() > maximumRequiredSuggestions) {\n        RankedSpellPossibility removed = rankedPossibilities.poll();\n        if (removeDuplicates != null) {\n          removeDuplicates.remove(removed);\n        }\n      }\n    }\n    \n    RankedSpellPossibility[] rpArr = new RankedSpellPossibility[rankedPossibilities\n        .size()];\n    for (int i = rankedPossibilities.size() - 1; i >= 0; i--) {\n      rpArr[i] = rankedPossibilities.remove();\n    }\n    rankedPossibilityIterator = Arrays.asList(rpArr).iterator();\n  }\n\n","sourceOld":"  /**\n   * <p>\n   * We assume here that the passed-in inner LinkedHashMaps are already sorted\n   * in order of \"Best Possible Correction\".\n   * </p>\n   * \n   * @param suggestions\n   */\n  public PossibilityIterator(\n      Map<Token,LinkedHashMap<String,Integer>> suggestions,\n      int maximumRequiredSuggestions, int maxEvaluations, boolean overlap) {\n    this.suggestionsMayOverlap = overlap;\n    for (Map.Entry<Token,LinkedHashMap<String,Integer>> entry : suggestions\n        .entrySet()) {\n      Token token = entry.getKey();\n      if (entry.getValue().size() == 0) {\n        continue;\n      }\n      List<SpellCheckCorrection> possibleCorrections = new ArrayList<SpellCheckCorrection>();\n      for (Map.Entry<String,Integer> entry1 : entry.getValue().entrySet()) {\n        SpellCheckCorrection correction = new SpellCheckCorrection();\n        correction.setOriginal(token);\n        correction.setCorrection(entry1.getKey());\n        correction.setNumberOfOccurences(entry1.getValue());\n        possibleCorrections.add(correction);\n      }\n      possibilityList.add(possibleCorrections);\n    }\n    \n    int wrapSize = possibilityList.size();\n    if (wrapSize == 0) {\n      done = true;\n    } else {\n      correctionIndex = new int[wrapSize];\n      for (int i = 0; i < wrapSize; i++) {\n        int suggestSize = possibilityList.get(i).size();\n        if (suggestSize == 0) {\n          done = true;\n          break;\n        }\n        correctionIndex[i] = 0;\n      }\n    }\n    PriorityQueue<RankedSpellPossibility> rankedPossibilities = new PriorityQueue<RankedSpellPossibility>(\n        11, new RankComparator());\n    Set<RankedSpellPossibility> removeDuplicates = null;\n    if (suggestionsMayOverlap) {\n      removeDuplicates = new HashSet<RankedSpellPossibility>();\n    }\n    long numEvaluations = 0;\n    while (numEvaluations < maxEvaluations && internalHasNext()) {\n      RankedSpellPossibility rsp = internalNext();\n      numEvaluations++;\n      if (rankedPossibilities.size() >= maximumRequiredSuggestions\n          && rsp.rank >= rankedPossibilities.peek().rank) {\n        continue;\n      }\n      if (!isSuggestionForReal(rsp)) {\n        continue;\n      }\n      if (removeDuplicates == null) {\n        rankedPossibilities.offer(rsp);\n      } else {\n        // Needs to be in token-offset order so that the match-and-replace\n        // option for collations can work.\n        Collections.sort(rsp.corrections, new StartOffsetComparator());\n        if (removeDuplicates.add(rsp)) {\n          rankedPossibilities.offer(rsp);\n        }\n      }\n      if (rankedPossibilities.size() > maximumRequiredSuggestions) {\n        RankedSpellPossibility removed = rankedPossibilities.poll();\n        if (removeDuplicates != null) {\n          removeDuplicates.remove(removed);\n        }\n      }\n    }\n    \n    RankedSpellPossibility[] rpArr = new RankedSpellPossibility[rankedPossibilities\n        .size()];\n    for (int i = rankedPossibilities.size() - 1; i >= 0; i--) {\n      rpArr[i] = rankedPossibilities.remove();\n    }\n    rankedPossibilityIterator = Arrays.asList(rpArr).iterator();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int,boolean).mjava","pathOld":"solr/core/src/java/org/apache/solr/spelling/PossibilityIterator#PossibilityIterator(Map[Token,LinkedHashMap[String,Integer]],int,int,boolean).mjava","sourceNew":"  /**\n   * <p>\n   * We assume here that the passed-in inner LinkedHashMaps are already sorted\n   * in order of \"Best Possible Correction\".\n   * </p>\n   */\n  public PossibilityIterator(\n      Map<Token,LinkedHashMap<String,Integer>> suggestions,\n      int maximumRequiredSuggestions, int maxEvaluations, boolean overlap) {\n    this.suggestionsMayOverlap = overlap;\n    for (Map.Entry<Token,LinkedHashMap<String,Integer>> entry : suggestions\n        .entrySet()) {\n      Token token = entry.getKey();\n      if (entry.getValue().size() == 0) {\n        continue;\n      }\n      List<SpellCheckCorrection> possibleCorrections = new ArrayList<>();\n      for (Map.Entry<String,Integer> entry1 : entry.getValue().entrySet()) {\n        SpellCheckCorrection correction = new SpellCheckCorrection();\n        correction.setOriginal(token);\n        correction.setCorrection(entry1.getKey());\n        correction.setNumberOfOccurences(entry1.getValue());\n        possibleCorrections.add(correction);\n      }\n      possibilityList.add(possibleCorrections);\n    }\n    \n    int wrapSize = possibilityList.size();\n    if (wrapSize == 0) {\n      done = true;\n    } else {\n      correctionIndex = new int[wrapSize];\n      for (int i = 0; i < wrapSize; i++) {\n        int suggestSize = possibilityList.get(i).size();\n        if (suggestSize == 0) {\n          done = true;\n          break;\n        }\n        correctionIndex[i] = 0;\n      }\n    }\n    PriorityQueue<RankedSpellPossibility> rankedPossibilities = new PriorityQueue<>(\n        11, new RankComparator());\n    Set<RankedSpellPossibility> removeDuplicates = null;\n    if (suggestionsMayOverlap) {\n      removeDuplicates = new HashSet<>();\n    }\n    long numEvaluations = 0;\n    while (numEvaluations < maxEvaluations && internalHasNext()) {\n      RankedSpellPossibility rsp = internalNext();\n      numEvaluations++;\n      if (rankedPossibilities.size() >= maximumRequiredSuggestions\n          && rsp.rank >= rankedPossibilities.peek().rank) {\n        continue;\n      }\n      if (!isSuggestionForReal(rsp)) {\n        continue;\n      }\n      if (removeDuplicates == null) {\n        rankedPossibilities.offer(rsp);\n      } else {\n        // Needs to be in token-offset order so that the match-and-replace\n        // option for collations can work.\n        Collections.sort(rsp.corrections, new StartOffsetComparator());\n        if (removeDuplicates.add(rsp)) {\n          rankedPossibilities.offer(rsp);\n        }\n      }\n      if (rankedPossibilities.size() > maximumRequiredSuggestions) {\n        RankedSpellPossibility removed = rankedPossibilities.poll();\n        if (removeDuplicates != null) {\n          removeDuplicates.remove(removed);\n        }\n      }\n    }\n    \n    RankedSpellPossibility[] rpArr = new RankedSpellPossibility[rankedPossibilities\n        .size()];\n    for (int i = rankedPossibilities.size() - 1; i >= 0; i--) {\n      rpArr[i] = rankedPossibilities.remove();\n    }\n    rankedPossibilityIterator = Arrays.asList(rpArr).iterator();\n  }\n\n","sourceOld":"  /**\n   * <p>\n   * We assume here that the passed-in inner LinkedHashMaps are already sorted\n   * in order of \"Best Possible Correction\".\n   * </p>\n   */\n  public PossibilityIterator(\n      Map<Token,LinkedHashMap<String,Integer>> suggestions,\n      int maximumRequiredSuggestions, int maxEvaluations, boolean overlap) {\n    this.suggestionsMayOverlap = overlap;\n    for (Map.Entry<Token,LinkedHashMap<String,Integer>> entry : suggestions\n        .entrySet()) {\n      Token token = entry.getKey();\n      if (entry.getValue().size() == 0) {\n        continue;\n      }\n      List<SpellCheckCorrection> possibleCorrections = new ArrayList<SpellCheckCorrection>();\n      for (Map.Entry<String,Integer> entry1 : entry.getValue().entrySet()) {\n        SpellCheckCorrection correction = new SpellCheckCorrection();\n        correction.setOriginal(token);\n        correction.setCorrection(entry1.getKey());\n        correction.setNumberOfOccurences(entry1.getValue());\n        possibleCorrections.add(correction);\n      }\n      possibilityList.add(possibleCorrections);\n    }\n    \n    int wrapSize = possibilityList.size();\n    if (wrapSize == 0) {\n      done = true;\n    } else {\n      correctionIndex = new int[wrapSize];\n      for (int i = 0; i < wrapSize; i++) {\n        int suggestSize = possibilityList.get(i).size();\n        if (suggestSize == 0) {\n          done = true;\n          break;\n        }\n        correctionIndex[i] = 0;\n      }\n    }\n    PriorityQueue<RankedSpellPossibility> rankedPossibilities = new PriorityQueue<RankedSpellPossibility>(\n        11, new RankComparator());\n    Set<RankedSpellPossibility> removeDuplicates = null;\n    if (suggestionsMayOverlap) {\n      removeDuplicates = new HashSet<RankedSpellPossibility>();\n    }\n    long numEvaluations = 0;\n    while (numEvaluations < maxEvaluations && internalHasNext()) {\n      RankedSpellPossibility rsp = internalNext();\n      numEvaluations++;\n      if (rankedPossibilities.size() >= maximumRequiredSuggestions\n          && rsp.rank >= rankedPossibilities.peek().rank) {\n        continue;\n      }\n      if (!isSuggestionForReal(rsp)) {\n        continue;\n      }\n      if (removeDuplicates == null) {\n        rankedPossibilities.offer(rsp);\n      } else {\n        // Needs to be in token-offset order so that the match-and-replace\n        // option for collations can work.\n        Collections.sort(rsp.corrections, new StartOffsetComparator());\n        if (removeDuplicates.add(rsp)) {\n          rankedPossibilities.offer(rsp);\n        }\n      }\n      if (rankedPossibilities.size() > maximumRequiredSuggestions) {\n        RankedSpellPossibility removed = rankedPossibilities.poll();\n        if (removeDuplicates != null) {\n          removeDuplicates.remove(removed);\n        }\n      }\n    }\n    \n    RankedSpellPossibility[] rpArr = new RankedSpellPossibility[rankedPossibilities\n        .size()];\n    for (int i = rankedPossibilities.size() - 1; i >= 0; i--) {\n      rpArr[i] = rankedPossibilities.remove();\n    }\n    rankedPossibilityIterator = Arrays.asList(rpArr).iterator();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069":["0ad9ec888e587ca9a3279368245cdf00aabdc108"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069"],"0ad9ec888e587ca9a3279368245cdf00aabdc108":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"]},"commit2Childs":{"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"0ad9ec888e587ca9a3279368245cdf00aabdc108":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["0ad9ec888e587ca9a3279368245cdf00aabdc108"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}