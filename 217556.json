{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/bn/BengaliAnalyzer#createComponents(String).mjava","commits":[{"id":"62eea7860808033f1893fbbbe121e77735482870","date":1503576322,"type":0,"author":"Md. Abdulla-Al-Sun","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/bn/BengaliAnalyzer#createComponents(String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Creates\n   * {@link TokenStreamComponents}\n   * used to tokenize all the text in the provided {@link Reader}.\n   * \n   * @return {@link TokenStreamComponents}\n   *         built from a {@link StandardTokenizer} filtered with\n   *         {@link LowerCaseFilter}, {@link DecimalDigitFilter}, {@link IndicNormalizationFilter},\n   *         {@link BengaliNormalizationFilter}, {@link SetKeywordMarkerFilter}\n   *         if a stem exclusion set is provided, {@link BengaliStemFilter}, and\n   *         Bengali Stop words\n   */\n  @Override\n  protected TokenStreamComponents createComponents(String fieldName) {\n    final Tokenizer source = new StandardTokenizer();\n    TokenStream result = new LowerCaseFilter(source);\n    result = new DecimalDigitFilter(result);\n    if (!stemExclusionSet.isEmpty())\n      result = new SetKeywordMarkerFilter(result, stemExclusionSet);\n    result = new IndicNormalizationFilter(result);\n    result = new BengaliNormalizationFilter(result);\n    result = new StopFilter(result, stopwords);\n    result = new BengaliStemFilter(result);\n    return new TokenStreamComponents(source, result);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"18863d01f555b55f9837aacfcd6ca317ee9e4e38","date":1504237743,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/bn/BengaliAnalyzer#createComponents(String).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/bn/BengaliAnalyzer#createComponents(String).mjava","sourceNew":"  /**\n   * Creates\n   * {@link org.apache.lucene.analysis.Analyzer.TokenStreamComponents}\n   * used to tokenize all the text in the provided {@link Reader}.\n   * \n   * @return {@link org.apache.lucene.analysis.Analyzer.TokenStreamComponents}\n   *         built from a {@link StandardTokenizer} filtered with\n   *         {@link LowerCaseFilter}, {@link DecimalDigitFilter}, {@link IndicNormalizationFilter},\n   *         {@link BengaliNormalizationFilter}, {@link SetKeywordMarkerFilter}\n   *         if a stem exclusion set is provided, {@link BengaliStemFilter}, and\n   *         Bengali Stop words\n   */\n  @Override\n  protected TokenStreamComponents createComponents(String fieldName) {\n    final Tokenizer source = new StandardTokenizer();\n    TokenStream result = new LowerCaseFilter(source);\n    result = new DecimalDigitFilter(result);\n    if (!stemExclusionSet.isEmpty())\n      result = new SetKeywordMarkerFilter(result, stemExclusionSet);\n    result = new IndicNormalizationFilter(result);\n    result = new BengaliNormalizationFilter(result);\n    result = new StopFilter(result, stopwords);\n    result = new BengaliStemFilter(result);\n    return new TokenStreamComponents(source, result);\n  }\n\n","sourceOld":"  /**\n   * Creates\n   * {@link TokenStreamComponents}\n   * used to tokenize all the text in the provided {@link Reader}.\n   * \n   * @return {@link TokenStreamComponents}\n   *         built from a {@link StandardTokenizer} filtered with\n   *         {@link LowerCaseFilter}, {@link DecimalDigitFilter}, {@link IndicNormalizationFilter},\n   *         {@link BengaliNormalizationFilter}, {@link SetKeywordMarkerFilter}\n   *         if a stem exclusion set is provided, {@link BengaliStemFilter}, and\n   *         Bengali Stop words\n   */\n  @Override\n  protected TokenStreamComponents createComponents(String fieldName) {\n    final Tokenizer source = new StandardTokenizer();\n    TokenStream result = new LowerCaseFilter(source);\n    result = new DecimalDigitFilter(result);\n    if (!stemExclusionSet.isEmpty())\n      result = new SetKeywordMarkerFilter(result, stemExclusionSet);\n    result = new IndicNormalizationFilter(result);\n    result = new BengaliNormalizationFilter(result);\n    result = new StopFilter(result, stopwords);\n    result = new BengaliStemFilter(result);\n    return new TokenStreamComponents(source, result);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"90f7818241046289c74b5fee75a028e541ba3a4d","date":1504360689,"type":3,"author":"Md.Abdulla-Al-Sun","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/bn/BengaliAnalyzer#createComponents(String).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/bn/BengaliAnalyzer#createComponents(String).mjava","sourceNew":"  /**\n   * Creates\n   * {@link org.apache.lucene.analysis.Analyzer.TokenStreamComponents}\n   * used to tokenize all the text in the provided {@link Reader}.\n   * \n   * @return {@link org.apache.lucene.analysis.Analyzer.TokenStreamComponents}\n   *         built from a {@link StandardTokenizer} filtered with\n   *         {@link LowerCaseFilter}, {@link DecimalDigitFilter}, {@link IndicNormalizationFilter},\n   *         {@link BengaliNormalizationFilter}, {@link SetKeywordMarkerFilter}\n   *         if a stem exclusion set is provided, {@link BengaliStemFilter}, and\n   *         Bengali Stop words\n   */\n  @Override\n  protected TokenStreamComponents createComponents(String fieldName) {\n    final Tokenizer source = new StandardTokenizer();\n    TokenStream result = new LowerCaseFilter(source);\n    result = new DecimalDigitFilter(result);\n    if (!stemExclusionSet.isEmpty())\n      result = new SetKeywordMarkerFilter(result, stemExclusionSet);\n    result = new IndicNormalizationFilter(result);\n    result = new BengaliNormalizationFilter(result);\n    result = new StopFilter(result, stopwords);\n    result = new BengaliStemFilter(result);\n    return new TokenStreamComponents(source, result);\n  }\n\n","sourceOld":"  /**\n   * Creates\n   * {@link TokenStreamComponents}\n   * used to tokenize all the text in the provided {@link Reader}.\n   * \n   * @return {@link TokenStreamComponents}\n   *         built from a {@link StandardTokenizer} filtered with\n   *         {@link LowerCaseFilter}, {@link DecimalDigitFilter}, {@link IndicNormalizationFilter},\n   *         {@link BengaliNormalizationFilter}, {@link SetKeywordMarkerFilter}\n   *         if a stem exclusion set is provided, {@link BengaliStemFilter}, and\n   *         Bengali Stop words\n   */\n  @Override\n  protected TokenStreamComponents createComponents(String fieldName) {\n    final Tokenizer source = new StandardTokenizer();\n    TokenStream result = new LowerCaseFilter(source);\n    result = new DecimalDigitFilter(result);\n    if (!stemExclusionSet.isEmpty())\n      result = new SetKeywordMarkerFilter(result, stemExclusionSet);\n    result = new IndicNormalizationFilter(result);\n    result = new BengaliNormalizationFilter(result);\n    result = new StopFilter(result, stopwords);\n    result = new BengaliStemFilter(result);\n    return new TokenStreamComponents(source, result);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f3268584f93f4a1a69c3a8732a46f665cd15f89b","date":1504651522,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/bn/BengaliAnalyzer#createComponents(String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Creates\n   * {@link org.apache.lucene.analysis.Analyzer.TokenStreamComponents}\n   * used to tokenize all the text in the provided {@link Reader}.\n   * \n   * @return {@link org.apache.lucene.analysis.Analyzer.TokenStreamComponents}\n   *         built from a {@link StandardTokenizer} filtered with\n   *         {@link LowerCaseFilter}, {@link DecimalDigitFilter}, {@link IndicNormalizationFilter},\n   *         {@link BengaliNormalizationFilter}, {@link SetKeywordMarkerFilter}\n   *         if a stem exclusion set is provided, {@link BengaliStemFilter}, and\n   *         Bengali Stop words\n   */\n  @Override\n  protected TokenStreamComponents createComponents(String fieldName) {\n    final Tokenizer source = new StandardTokenizer();\n    TokenStream result = new LowerCaseFilter(source);\n    result = new DecimalDigitFilter(result);\n    if (!stemExclusionSet.isEmpty())\n      result = new SetKeywordMarkerFilter(result, stemExclusionSet);\n    result = new IndicNormalizationFilter(result);\n    result = new BengaliNormalizationFilter(result);\n    result = new StopFilter(result, stopwords);\n    result = new BengaliStemFilter(result);\n    return new TokenStreamComponents(source, result);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b21283ed01203901a7257aa4b7f0a0899c86e56e","date":1504689720,"type":0,"author":"Noble Paul","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/bn/BengaliAnalyzer#createComponents(String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Creates\n   * {@link org.apache.lucene.analysis.Analyzer.TokenStreamComponents}\n   * used to tokenize all the text in the provided {@link Reader}.\n   * \n   * @return {@link org.apache.lucene.analysis.Analyzer.TokenStreamComponents}\n   *         built from a {@link StandardTokenizer} filtered with\n   *         {@link LowerCaseFilter}, {@link DecimalDigitFilter}, {@link IndicNormalizationFilter},\n   *         {@link BengaliNormalizationFilter}, {@link SetKeywordMarkerFilter}\n   *         if a stem exclusion set is provided, {@link BengaliStemFilter}, and\n   *         Bengali Stop words\n   */\n  @Override\n  protected TokenStreamComponents createComponents(String fieldName) {\n    final Tokenizer source = new StandardTokenizer();\n    TokenStream result = new LowerCaseFilter(source);\n    result = new DecimalDigitFilter(result);\n    if (!stemExclusionSet.isEmpty())\n      result = new SetKeywordMarkerFilter(result, stemExclusionSet);\n    result = new IndicNormalizationFilter(result);\n    result = new BengaliNormalizationFilter(result);\n    result = new StopFilter(result, stopwords);\n    result = new BengaliStemFilter(result);\n    return new TokenStreamComponents(source, result);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"104a3f62ee393d48b5596de76ed4d9a4e0ea6de7","date":1504848000,"type":0,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/bn/BengaliAnalyzer#createComponents(String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Creates\n   * {@link org.apache.lucene.analysis.Analyzer.TokenStreamComponents}\n   * used to tokenize all the text in the provided {@link Reader}.\n   * \n   * @return {@link org.apache.lucene.analysis.Analyzer.TokenStreamComponents}\n   *         built from a {@link StandardTokenizer} filtered with\n   *         {@link LowerCaseFilter}, {@link DecimalDigitFilter}, {@link IndicNormalizationFilter},\n   *         {@link BengaliNormalizationFilter}, {@link SetKeywordMarkerFilter}\n   *         if a stem exclusion set is provided, {@link BengaliStemFilter}, and\n   *         Bengali Stop words\n   */\n  @Override\n  protected TokenStreamComponents createComponents(String fieldName) {\n    final Tokenizer source = new StandardTokenizer();\n    TokenStream result = new LowerCaseFilter(source);\n    result = new DecimalDigitFilter(result);\n    if (!stemExclusionSet.isEmpty())\n      result = new SetKeywordMarkerFilter(result, stemExclusionSet);\n    result = new IndicNormalizationFilter(result);\n    result = new BengaliNormalizationFilter(result);\n    result = new StopFilter(result, stopwords);\n    result = new BengaliStemFilter(result);\n    return new TokenStreamComponents(source, result);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"685bd38810c206c93e9058f3c2cfa9827c086c27","date":1505751821,"type":0,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/bn/BengaliAnalyzer#createComponents(String).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Creates\n   * {@link org.apache.lucene.analysis.Analyzer.TokenStreamComponents}\n   * used to tokenize all the text in the provided {@link Reader}.\n   * \n   * @return {@link org.apache.lucene.analysis.Analyzer.TokenStreamComponents}\n   *         built from a {@link StandardTokenizer} filtered with\n   *         {@link LowerCaseFilter}, {@link DecimalDigitFilter}, {@link IndicNormalizationFilter},\n   *         {@link BengaliNormalizationFilter}, {@link SetKeywordMarkerFilter}\n   *         if a stem exclusion set is provided, {@link BengaliStemFilter}, and\n   *         Bengali Stop words\n   */\n  @Override\n  protected TokenStreamComponents createComponents(String fieldName) {\n    final Tokenizer source = new StandardTokenizer();\n    TokenStream result = new LowerCaseFilter(source);\n    result = new DecimalDigitFilter(result);\n    if (!stemExclusionSet.isEmpty())\n      result = new SetKeywordMarkerFilter(result, stemExclusionSet);\n    result = new IndicNormalizationFilter(result);\n    result = new BengaliNormalizationFilter(result);\n    result = new StopFilter(result, stopwords);\n    result = new BengaliStemFilter(result);\n    return new TokenStreamComponents(source, result);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b21283ed01203901a7257aa4b7f0a0899c86e56e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","f3268584f93f4a1a69c3a8732a46f665cd15f89b"],"685bd38810c206c93e9058f3c2cfa9827c086c27":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","104a3f62ee393d48b5596de76ed4d9a4e0ea6de7"],"104a3f62ee393d48b5596de76ed4d9a4e0ea6de7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","b21283ed01203901a7257aa4b7f0a0899c86e56e"],"90f7818241046289c74b5fee75a028e541ba3a4d":["62eea7860808033f1893fbbbe121e77735482870","18863d01f555b55f9837aacfcd6ca317ee9e4e38"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"f3268584f93f4a1a69c3a8732a46f665cd15f89b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","90f7818241046289c74b5fee75a028e541ba3a4d"],"62eea7860808033f1893fbbbe121e77735482870":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"18863d01f555b55f9837aacfcd6ca317ee9e4e38":["62eea7860808033f1893fbbbe121e77735482870"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["104a3f62ee393d48b5596de76ed4d9a4e0ea6de7"]},"commit2Childs":{"b21283ed01203901a7257aa4b7f0a0899c86e56e":["104a3f62ee393d48b5596de76ed4d9a4e0ea6de7"],"685bd38810c206c93e9058f3c2cfa9827c086c27":[],"104a3f62ee393d48b5596de76ed4d9a4e0ea6de7":["685bd38810c206c93e9058f3c2cfa9827c086c27","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"90f7818241046289c74b5fee75a028e541ba3a4d":["f3268584f93f4a1a69c3a8732a46f665cd15f89b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b21283ed01203901a7257aa4b7f0a0899c86e56e","685bd38810c206c93e9058f3c2cfa9827c086c27","104a3f62ee393d48b5596de76ed4d9a4e0ea6de7","f3268584f93f4a1a69c3a8732a46f665cd15f89b","62eea7860808033f1893fbbbe121e77735482870"],"f3268584f93f4a1a69c3a8732a46f665cd15f89b":["b21283ed01203901a7257aa4b7f0a0899c86e56e"],"62eea7860808033f1893fbbbe121e77735482870":["90f7818241046289c74b5fee75a028e541ba3a4d","18863d01f555b55f9837aacfcd6ca317ee9e4e38"],"18863d01f555b55f9837aacfcd6ca317ee9e4e38":["90f7818241046289c74b5fee75a028e541ba3a4d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["685bd38810c206c93e9058f3c2cfa9827c086c27","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}