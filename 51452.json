{"path":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","commits":[{"id":"c6bb01d819ee2a06924d25bb5683fe4dcf8cf1a7","date":1349855720,"type":1,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/IndexWriter#prepareFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (writer.useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        writer.deleteNewFiles(oldFiles);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n        writer.flushFailed(newSegment.info);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Prepares the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}. Use\n   * {@link #publishFlushedSegment(SegmentInfoPerCommit, FrozenBufferedDeletes, FrozenBufferedDeletes)} to\n   * publish the returned {@link SegmentInfo} together with its segment private\n   * delete packet.\n   * \n   * @see #publishFlushedSegment(SegmentInfoPerCommit, FrozenBufferedDeletes, FrozenBufferedDeletes)\n   */\n  SegmentInfoPerCommit prepareFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n\n        synchronized(this) {\n          deleter.deleteNewFiles(oldFiles);\n        }\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"IW\")) {\n          infoStream.message(\"IW\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n\n        synchronized(this) {\n          deleter.refresh(newSegment.info.name);\n        }\n      }\n    }\n    return newSegment;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"641a23a95cee1e280f172cdfe6289ea3d010ebf1","date":1351978859,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (writer.useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        writer.deleteNewFiles(oldFiles);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n        writer.flushFailed(newSegment.info);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (writer.useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        writer.deleteNewFiles(oldFiles);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n        writer.flushFailed(newSegment.info);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b47dabfbaff6449eedcd4321017ab2f73dfa06ab","date":1360797548,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (writer.useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        writer.deleteNewFiles(oldFiles);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n        writer.flushFailed(newSegment.info);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (writer.useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        writer.deleteNewFiles(oldFiles);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n        writer.flushFailed(newSegment.info);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3b41f996b22bd5518650f897d050088ff808ec03","date":1360969107,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (writer.useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        writer.deleteNewFiles(oldFiles);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n        writer.flushFailed(newSegment.info);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.info.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (writer.useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        writer.deleteNewFiles(oldFiles);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n        writer.flushFailed(newSegment.info);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4d1c249f01722fe2de6d60de2f0aade417fbb638","date":1365517193,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (writer.useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        writer.deleteNewFiles(oldFiles);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n        writer.flushFailed(newSegment.info);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, \"flush\");\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (writer.useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        writer.deleteNewFiles(oldFiles);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n        writer.flushFailed(newSegment.info);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"088a7ef694fd43d5d9a4d200c4005865f773d1e7","date":1371136274,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (indexWriterConfig.getUseCompoundFile()) {\n\n        // Now build compound file\n        Collection<String> oldFiles = IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        writer.deleteNewFiles(oldFiles);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n        writer.flushFailed(newSegment.info);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (writer.useCompoundFile(newSegment)) {\n\n        // Now build compound file\n        Collection<String> oldFiles = IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        writer.deleteNewFiles(oldFiles);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n        writer.flushFailed(newSegment.info);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7af110b00ea8df9429309d83e38e0533d82e144f","date":1376924768,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        filesToDelete.addAll(IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context));\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (indexWriterConfig.getUseCompoundFile()) {\n\n        // Now build compound file\n        Collection<String> oldFiles = IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        writer.deleteNewFiles(oldFiles);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n        writer.flushFailed(newSegment.info);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"31d4861802ca404d78ca1d15f4550eec415b9199","date":1376947894,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        filesToDelete.addAll(IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context));\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (indexWriterConfig.getUseCompoundFile()) {\n\n        // Now build compound file\n        Collection<String> oldFiles = IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        writer.deleteNewFiles(oldFiles);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n        writer.flushFailed(newSegment.info);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3dffec77fb8f7d0e9ca4869dddd6af94528b4576","date":1377875202,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        filesToDelete.addAll(IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context));\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      if (indexWriterConfig.getUseCompoundFile()) {\n\n        // Now build compound file\n        Collection<String> oldFiles = IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context);\n        newSegment.info.setUseCompoundFile(true);\n        writer.deleteNewFiles(oldFiles);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n        writer.flushFailed(newSegment.info);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe1d440a8af3adcf6846c5eac6dbf55ff5a2ead6","date":1381077139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        filesToDelete.addAll(IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context));\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        filesToDelete.addAll(IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context));\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"hit exception \" +\n              \"reating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        filesToDelete.addAll(IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context));\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentInfoPerCommit newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        filesToDelete.addAll(IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context));\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentInfoPerCommit info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"2c3c58609ce8cbaa9116c281d30aa3cdc6a87051","date":1412632911,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        filesToDelete.addAll(IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context));\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        filesToDelete.addAll(IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context));\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e2fe60a17a7a0cfd101b1169acf089221bc6c166","date":1412767493,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        filesToDelete.addAll(IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context));\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        filesToDelete.addAll(IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context));\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"55980207f1977bd1463465de1659b821347e2fa8","date":1413336386,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        filesToDelete.addAll(IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context));\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        filesToDelete.addAll(IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context));\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().getSegmentInfoWriter().write(directory, newSegment.info, flushedSegment.fieldInfos, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5faf65b6692f15cca0f87bf8666c87899afc619f","date":1420468108,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        filesToDelete.addAll(IndexWriter.createCompoundFile(infoStream, directory, newSegment.info, context));\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        filesToDelete.addAll(IndexWriter.createCompoundFile(infoStream, directory, MergeState.CheckAbort.NONE, newSegment.info, context));\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3c5705cb93fb3daa46c676cad08b916dd57bf1be","date":1422473298,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        Set<String> originalFiles = newSegment.info.files();\n        // TODO: like addIndexes, we are relying on createCompoundFile to successfully cleanup...\n        IndexWriter.createCompoundFile(infoStream, new TrackingDirectoryWrapper(directory), newSegment.info, context);\n        filesToDelete.addAll(originalFiles);\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        filesToDelete.addAll(IndexWriter.createCompoundFile(infoStream, directory, newSegment.info, context));\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b0267c69e2456a3477a1ad785723f2135da3117e","date":1425317087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.maxDoc(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        Set<String> originalFiles = newSegment.info.files();\n        // TODO: like addIndexes, we are relying on createCompoundFile to successfully cleanup...\n        IndexWriter.createCompoundFile(infoStream, new TrackingDirectoryWrapper(directory), newSegment.info, context);\n        filesToDelete.addAll(originalFiles);\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        Set<String> originalFiles = newSegment.info.files();\n        // TODO: like addIndexes, we are relying on createCompoundFile to successfully cleanup...\n        IndexWriter.createCompoundFile(infoStream, new TrackingDirectoryWrapper(directory), newSegment.info, context);\n        filesToDelete.addAll(originalFiles);\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b06445ae1731e049327712db0454e5643ca9b7fe","date":1425329139,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.maxDoc(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        Set<String> originalFiles = newSegment.info.files();\n        // TODO: like addIndexes, we are relying on createCompoundFile to successfully cleanup...\n        IndexWriter.createCompoundFile(infoStream, new TrackingDirectoryWrapper(directory), newSegment.info, context);\n        filesToDelete.addAll(originalFiles);\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        Set<String> originalFiles = newSegment.info.files();\n        // TODO: like addIndexes, we are relying on createCompoundFile to successfully cleanup...\n        IndexWriter.createCompoundFile(infoStream, new TrackingDirectoryWrapper(directory), newSegment.info, context);\n        filesToDelete.addAll(originalFiles);\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.maxDoc(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        Set<String> originalFiles = newSegment.info.files();\n        // TODO: like addIndexes, we are relying on createCompoundFile to successfully cleanup...\n        IndexWriter.createCompoundFile(infoStream, new TrackingDirectoryWrapper(directory), newSegment.info, context);\n        filesToDelete.addAll(originalFiles);\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.getDocCount(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        Set<String> originalFiles = newSegment.info.files();\n        // TODO: like addIndexes, we are relying on createCompoundFile to successfully cleanup...\n        IndexWriter.createCompoundFile(infoStream, new TrackingDirectoryWrapper(directory), newSegment.info, context);\n        filesToDelete.addAll(originalFiles);\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"950882a2bd2a5f9dc16a154871584eaa643d882a","date":1436366563,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.maxDoc(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        Set<String> originalFiles = newSegment.info.files();\n        // TODO: like addIndexes, we are relying on createCompoundFile to successfully cleanup...\n        indexWriter.createCompoundFile(infoStream, new TrackingDirectoryWrapper(directory), newSegment.info, context);\n        filesToDelete.addAll(originalFiles);\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.maxDoc(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        Set<String> originalFiles = newSegment.info.files();\n        // TODO: like addIndexes, we are relying on createCompoundFile to successfully cleanup...\n        IndexWriter.createCompoundFile(infoStream, new TrackingDirectoryWrapper(directory), newSegment.info, context);\n        filesToDelete.addAll(originalFiles);\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"86a0a50d2d14aaee1e635bbec914468551f7f9a2","date":1482234306,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment,Sorter.DocMap).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment, Sorter.DocMap sortMap) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.maxDoc(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        Set<String> originalFiles = newSegment.info.files();\n        // TODO: like addIndexes, we are relying on createCompoundFile to successfully cleanup...\n        indexWriter.createCompoundFile(infoStream, new TrackingDirectoryWrapper(directory), newSegment.info, context);\n        filesToDelete.addAll(originalFiles);\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        final MutableBits bits;\n        if (sortMap == null) {\n          bits = flushedSegment.liveDocs;\n        } else {\n          bits = sortLiveDocs(flushedSegment.liveDocs, sortMap);\n        }\n        codec.liveDocsFormat().writeLiveDocs(bits, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.maxDoc(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        Set<String> originalFiles = newSegment.info.files();\n        // TODO: like addIndexes, we are relying on createCompoundFile to successfully cleanup...\n        indexWriter.createCompoundFile(infoStream, new TrackingDirectoryWrapper(directory), newSegment.info, context);\n        filesToDelete.addAll(originalFiles);\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","date":1482251961,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/DocumentsWriterPerThread#sealFlushedSegment(FlushedSegment).mjava","sourceNew":null,"sourceOld":"  /**\n   * Seals the {@link SegmentInfo} for the new flushed segment and persists\n   * the deleted documents {@link MutableBits}.\n   */\n  void sealFlushedSegment(FlushedSegment flushedSegment) throws IOException {\n    assert flushedSegment != null;\n\n    SegmentCommitInfo newSegment = flushedSegment.segmentInfo;\n\n    IndexWriter.setDiagnostics(newSegment.info, IndexWriter.SOURCE_FLUSH);\n    \n    IOContext context = new IOContext(new FlushInfo(newSegment.info.maxDoc(), newSegment.sizeInBytes()));\n\n    boolean success = false;\n    try {\n      \n      if (indexWriterConfig.getUseCompoundFile()) {\n        Set<String> originalFiles = newSegment.info.files();\n        // TODO: like addIndexes, we are relying on createCompoundFile to successfully cleanup...\n        indexWriter.createCompoundFile(infoStream, new TrackingDirectoryWrapper(directory), newSegment.info, context);\n        filesToDelete.addAll(originalFiles);\n        newSegment.info.setUseCompoundFile(true);\n      }\n\n      // Have codec write SegmentInfo.  Must do this after\n      // creating CFS so that 1) .si isn't slurped into CFS,\n      // and 2) .si reflects useCompoundFile=true change\n      // above:\n      codec.segmentInfoFormat().write(directory, newSegment.info, context);\n\n      // TODO: ideally we would freeze newSegment here!!\n      // because any changes after writing the .si will be\n      // lost... \n\n      // Must write deleted docs after the CFS so we don't\n      // slurp the del file into CFS:\n      if (flushedSegment.liveDocs != null) {\n        final int delCount = flushedSegment.delCount;\n        assert delCount > 0;\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\", \"flush: write \" + delCount + \" deletes gen=\" + flushedSegment.segmentInfo.getDelGen());\n        }\n\n        // TODO: we should prune the segment if it's 100%\n        // deleted... but merge will also catch it.\n\n        // TODO: in the NRT case it'd be better to hand\n        // this del vector over to the\n        // shortly-to-be-opened SegmentReader and let it\n        // carry the changes; there's no reason to use\n        // filesystem as intermediary here.\n          \n        SegmentCommitInfo info = flushedSegment.segmentInfo;\n        Codec codec = info.info.getCodec();\n        codec.liveDocsFormat().writeLiveDocs(flushedSegment.liveDocs, directory, info, delCount, context);\n        newSegment.setDelCount(delCount);\n        newSegment.advanceDelGen();\n      }\n\n      success = true;\n    } finally {\n      if (!success) {\n        if (infoStream.isEnabled(\"DWPT\")) {\n          infoStream.message(\"DWPT\",\n                             \"hit exception creating compound file for newly flushed segment \" + newSegment.info.name);\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"e2fe60a17a7a0cfd101b1169acf089221bc6c166":["2c3c58609ce8cbaa9116c281d30aa3cdc6a87051"],"fe1d440a8af3adcf6846c5eac6dbf55ff5a2ead6":["7af110b00ea8df9429309d83e38e0533d82e144f"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["fe1d440a8af3adcf6846c5eac6dbf55ff5a2ead6"],"7af110b00ea8df9429309d83e38e0533d82e144f":["088a7ef694fd43d5d9a4d200c4005865f773d1e7"],"55980207f1977bd1463465de1659b821347e2fa8":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","e2fe60a17a7a0cfd101b1169acf089221bc6c166"],"3c5705cb93fb3daa46c676cad08b916dd57bf1be":["5faf65b6692f15cca0f87bf8666c87899afc619f"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":["088a7ef694fd43d5d9a4d200c4005865f773d1e7","7af110b00ea8df9429309d83e38e0533d82e144f"],"31d4861802ca404d78ca1d15f4550eec415b9199":["088a7ef694fd43d5d9a4d200c4005865f773d1e7","7af110b00ea8df9429309d83e38e0533d82e144f"],"b0267c69e2456a3477a1ad785723f2135da3117e":["3c5705cb93fb3daa46c676cad08b916dd57bf1be"],"4d1c249f01722fe2de6d60de2f0aade417fbb638":["b47dabfbaff6449eedcd4321017ab2f73dfa06ab"],"c6bb01d819ee2a06924d25bb5683fe4dcf8cf1a7":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["3c5705cb93fb3daa46c676cad08b916dd57bf1be","b0267c69e2456a3477a1ad785723f2135da3117e"],"2c3c58609ce8cbaa9116c281d30aa3cdc6a87051":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"088a7ef694fd43d5d9a4d200c4005865f773d1e7":["4d1c249f01722fe2de6d60de2f0aade417fbb638"],"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf":["950882a2bd2a5f9dc16a154871584eaa643d882a","86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"b06445ae1731e049327712db0454e5643ca9b7fe":["3c5705cb93fb3daa46c676cad08b916dd57bf1be","b0267c69e2456a3477a1ad785723f2135da3117e"],"3b41f996b22bd5518650f897d050088ff808ec03":["641a23a95cee1e280f172cdfe6289ea3d010ebf1","b47dabfbaff6449eedcd4321017ab2f73dfa06ab"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"950882a2bd2a5f9dc16a154871584eaa643d882a":["b0267c69e2456a3477a1ad785723f2135da3117e"],"5faf65b6692f15cca0f87bf8666c87899afc619f":["e2fe60a17a7a0cfd101b1169acf089221bc6c166"],"86a0a50d2d14aaee1e635bbec914468551f7f9a2":["950882a2bd2a5f9dc16a154871584eaa643d882a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"b47dabfbaff6449eedcd4321017ab2f73dfa06ab":["641a23a95cee1e280f172cdfe6289ea3d010ebf1"],"641a23a95cee1e280f172cdfe6289ea3d010ebf1":["c6bb01d819ee2a06924d25bb5683fe4dcf8cf1a7"]},"commit2Childs":{"e2fe60a17a7a0cfd101b1169acf089221bc6c166":["55980207f1977bd1463465de1659b821347e2fa8","5faf65b6692f15cca0f87bf8666c87899afc619f"],"fe1d440a8af3adcf6846c5eac6dbf55ff5a2ead6":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"7af110b00ea8df9429309d83e38e0533d82e144f":["fe1d440a8af3adcf6846c5eac6dbf55ff5a2ead6","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","31d4861802ca404d78ca1d15f4550eec415b9199"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["55980207f1977bd1463465de1659b821347e2fa8","2c3c58609ce8cbaa9116c281d30aa3cdc6a87051"],"55980207f1977bd1463465de1659b821347e2fa8":[],"3c5705cb93fb3daa46c676cad08b916dd57bf1be":["b0267c69e2456a3477a1ad785723f2135da3117e","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b06445ae1731e049327712db0454e5643ca9b7fe"],"3dffec77fb8f7d0e9ca4869dddd6af94528b4576":[],"31d4861802ca404d78ca1d15f4550eec415b9199":[],"b0267c69e2456a3477a1ad785723f2135da3117e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b06445ae1731e049327712db0454e5643ca9b7fe","950882a2bd2a5f9dc16a154871584eaa643d882a"],"4d1c249f01722fe2de6d60de2f0aade417fbb638":["088a7ef694fd43d5d9a4d200c4005865f773d1e7"],"c6bb01d819ee2a06924d25bb5683fe4dcf8cf1a7":["641a23a95cee1e280f172cdfe6289ea3d010ebf1"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"2c3c58609ce8cbaa9116c281d30aa3cdc6a87051":["e2fe60a17a7a0cfd101b1169acf089221bc6c166"],"088a7ef694fd43d5d9a4d200c4005865f773d1e7":["7af110b00ea8df9429309d83e38e0533d82e144f","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","31d4861802ca404d78ca1d15f4550eec415b9199"],"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf":[],"b06445ae1731e049327712db0454e5643ca9b7fe":[],"3b41f996b22bd5518650f897d050088ff808ec03":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c6bb01d819ee2a06924d25bb5683fe4dcf8cf1a7"],"950882a2bd2a5f9dc16a154871584eaa643d882a":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"5faf65b6692f15cca0f87bf8666c87899afc619f":["3c5705cb93fb3daa46c676cad08b916dd57bf1be"],"86a0a50d2d14aaee1e635bbec914468551f7f9a2":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"b47dabfbaff6449eedcd4321017ab2f73dfa06ab":["4d1c249f01722fe2de6d60de2f0aade417fbb638","3b41f996b22bd5518650f897d050088ff808ec03"],"641a23a95cee1e280f172cdfe6289ea3d010ebf1":["3b41f996b22bd5518650f897d050088ff808ec03","b47dabfbaff6449eedcd4321017ab2f73dfa06ab"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["55980207f1977bd1463465de1659b821347e2fa8","3dffec77fb8f7d0e9ca4869dddd6af94528b4576","31d4861802ca404d78ca1d15f4550eec415b9199","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","b06445ae1731e049327712db0454e5643ca9b7fe","3b41f996b22bd5518650f897d050088ff808ec03","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}