{"path":"lucene/core/src/java/org/apache/lucene/index/TermsHashPerField#add(int,int).mjava","commits":[{"id":"d3cc3fa1ecad75b99ec55169e44628808f9866ad","date":1592311545,"type":0,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/TermsHashPerField#add(int,int).mjava","pathOld":"/dev/null","sourceNew":"  // Secondary entry point (for 2nd & subsequent TermsHash),\n  // because token text has already been \"interned\" into\n  // textStart, so we hash by textStart.  term vectors use\n  // this API.\n  private void add(int textStart, final int docID) throws IOException {\n    int termID = bytesHash.addByPoolOffset(textStart);\n    if (termID >= 0) {      // New posting\n      // First time we are seeing this token since we last\n      // flushed the hash.\n      initStreamSlices(termID, docID);\n    } else {\n      positionStreamSlice(termID, docID);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d3cc3fa1ecad75b99ec55169e44628808f9866ad":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d3cc3fa1ecad75b99ec55169e44628808f9866ad"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["d3cc3fa1ecad75b99ec55169e44628808f9866ad"],"d3cc3fa1ecad75b99ec55169e44628808f9866ad":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}