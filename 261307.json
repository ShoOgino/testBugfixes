{"path":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","commits":[{"id":"474a065e1bf22f3551c2fd2c9e18bde479e5c3c5","date":1361033993,"type":0,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"/dev/null","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<String>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (replica.getNodeName().equals(getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP,\n                replica.getStr(ZkStateReader.COLLECTION_PROP));\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.currentTimeMillis();\n    long timeout = now + 1000 * 300;\n    boolean foundStates = false;\n    while (System.currentTimeMillis() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        break;\n      }\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f","b45b3de994af6de94faad4adab71863ea967d3da"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7bc9c220ff48e045e8bae03a685357491c123389","date":1361042263,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<String>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (replica.getNodeName().equals(getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP,\n                replica.getStr(ZkStateReader.COLLECTION_PROP));\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.currentTimeMillis();\n    long timeout = now + 1000 * 30;\n    boolean foundStates = false;\n    while (System.currentTimeMillis() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<String>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (replica.getNodeName().equals(getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP,\n                replica.getStr(ZkStateReader.COLLECTION_PROP));\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.currentTimeMillis();\n    long timeout = now + 1000 * 300;\n    boolean foundStates = false;\n    while (System.currentTimeMillis() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        break;\n      }\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"95303ff3749680c743b9425f9cf99e6e4065e8a8","date":1361061922,"type":0,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"/dev/null","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<String>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (replica.getNodeName().equals(getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP,\n                replica.getStr(ZkStateReader.COLLECTION_PROP));\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.currentTimeMillis();\n    long timeout = now + 1000 * 30;\n    boolean foundStates = false;\n    while (System.currentTimeMillis() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cb4a195b8dc1808cd01748bd2e0fba26ca915d4d","date":1361851792,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<String>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (replica.getNodeName().equals(getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            assert replica.getStr(ZkStateReader.SHARD_ID_PROP) != null;\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP,\n                replica.getStr(ZkStateReader.COLLECTION_PROP),\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.currentTimeMillis();\n    long timeout = now + 1000 * 30;\n    boolean foundStates = false;\n    while (System.currentTimeMillis() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<String>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (replica.getNodeName().equals(getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP,\n                replica.getStr(ZkStateReader.COLLECTION_PROP));\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.currentTimeMillis();\n    long timeout = now + 1000 * 30;\n    boolean foundStates = false;\n    while (System.currentTimeMillis() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"849494cf2f3a96af5c8c84995108ddd8456fcd04","date":1372277913,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<String>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (replica.getNodeName().equals(getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.currentTimeMillis();\n    long timeout = now + 1000 * 30;\n    boolean foundStates = false;\n    while (System.currentTimeMillis() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<String>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (replica.getNodeName().equals(getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            assert replica.getStr(ZkStateReader.SHARD_ID_PROP) != null;\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP,\n                replica.getStr(ZkStateReader.COLLECTION_PROP),\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.currentTimeMillis();\n    long timeout = now + 1000 * 30;\n    boolean foundStates = false;\n    while (System.currentTimeMillis() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<String>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (replica.getNodeName().equals(getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.currentTimeMillis();\n    long timeout = now + 1000 * 30;\n    boolean foundStates = false;\n    while (System.currentTimeMillis() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<String>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (replica.getNodeName().equals(getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            assert replica.getStr(ZkStateReader.SHARD_ID_PROP) != null;\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP,\n                replica.getStr(ZkStateReader.COLLECTION_PROP),\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.currentTimeMillis();\n    long timeout = now + 1000 * 30;\n    boolean foundStates = false;\n    while (System.currentTimeMillis() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8497bb4f9de61b5520423bd9af88ea11a6e109e7","date":1393245090,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<String>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.currentTimeMillis();\n    long timeout = now + 1000 * 30;\n    boolean foundStates = false;\n    while (System.currentTimeMillis() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<String>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (replica.getNodeName().equals(getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.currentTimeMillis();\n    long timeout = now + 1000 * 30;\n    boolean foundStates = false;\n    while (System.currentTimeMillis() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"13f445c5bd6f19fd57d5a3ca0a35244c96f45aa8","date":1393532551,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<String>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.currentTimeMillis();\n    long timeout = now + 1000 * 30;\n    boolean foundStates = false;\n    while (System.currentTimeMillis() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<String>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (replica.getNodeName().equals(getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.currentTimeMillis();\n    long timeout = now + 1000 * 30;\n    boolean foundStates = false;\n    while (System.currentTimeMillis() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fd5bc858b8426d40bbe90b94120ead37c77d7954","date":1393812525,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<String>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    boolean foundStates = false;\n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<String>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.currentTimeMillis();\n    long timeout = now + 1000 * 30;\n    boolean foundStates = false;\n    while (System.currentTimeMillis() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    boolean foundStates = false;\n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<String>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    boolean foundStates = false;\n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fbcfc050b9f253136eaa5950b57248b2109eac11","date":1427308993,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n              .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n\n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    boolean foundStates = false;\n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n\n            }\n          }\n        }\n      }\n\n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    boolean foundStates = false;\n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n              .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n\n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    boolean foundStates = false;\n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n\n            }\n          }\n        }\n      }\n\n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n    \n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n                  .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    boolean foundStates = false;\n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n              \n            }\n          }\n        }\n      }\n      \n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n    \n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a219f1dcad1700e84807666bdbd2b573e8de7021","date":1428130940,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && replica.getState() != Replica.State.DOWN) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n\n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    boolean foundStates = false;\n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getState() == Replica.State.DOWN) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n\n            }\n          }\n        }\n      }\n\n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && !(replica.getStr(ZkStateReader.STATE_PROP)\n              .equals(ZkStateReader.DOWN))) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, ZkStateReader.DOWN,\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n\n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    boolean foundStates = false;\n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getStr(ZkStateReader.STATE_PROP).equals(\n                ZkStateReader.DOWN)) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n\n            }\n          }\n        }\n      }\n\n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e11b7252d34d00665befca520dee82fd64aed3c2","date":1429595379,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    Set<String> updatedCoreNodeNames = new HashSet<>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && replica.getState() != Replica.State.DOWN) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedCoreNodeNames.add(replica.getName());\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n\n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = false;\n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getState() == Replica.State.DOWN) {\n              updatedCoreNodeNames.remove(replica.getName());\n\n            }\n          }\n        }\n      }\n\n      if (updatedCoreNodeNames.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    List<String> updatedNodes = new ArrayList<>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && replica.getState() != Replica.State.DOWN) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedNodes.add(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n\n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(60, TimeUnit.SECONDS);\n    boolean foundStates = false;\n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getState() == Replica.State.DOWN) {\n              updatedNodes.remove(replica.getStr(ZkStateReader.CORE_NAME_PROP));\n\n            }\n          }\n        }\n      }\n\n      if (updatedNodes.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b693a83132c9e45afcd564fd65a25b60ed80388b","date":1436882146,"type":3,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    Set<String> updatedCoreNodeNames = new HashSet<>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && replica.getState() != Replica.State.DOWN) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedCoreNodeNames.add(replica.getName());\n            overseerJobQueue.offer(Utils.toJSON(m));\n          }\n        }\n      }\n    }\n\n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = false;\n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getState() == Replica.State.DOWN) {\n              updatedCoreNodeNames.remove(replica.getName());\n\n            }\n          }\n        }\n      }\n\n      if (updatedCoreNodeNames.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    Set<String> updatedCoreNodeNames = new HashSet<>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && replica.getState() != Replica.State.DOWN) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedCoreNodeNames.add(replica.getName());\n            overseerJobQueue.offer(ZkStateReader.toJSON(m));\n          }\n        }\n      }\n    }\n\n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = false;\n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getState() == Replica.State.DOWN) {\n              updatedCoreNodeNames.remove(replica.getName());\n\n            }\n          }\n        }\n      }\n\n      if (updatedCoreNodeNames.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"384868ae9e6c9b2c476f72db0c40840f6d6776a2","date":1456257061,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    \n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    Set<String> updatedCoreNodeNames = new HashSet<>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && replica.getState() != Replica.State.DOWN) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedCoreNodeNames.add(replica.getName());\n            overseerJobQueue.offer(Utils.toJSON(m));\n          }\n        }\n      }\n    }\n\n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = false;\n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getState() == Replica.State.DOWN) {\n              updatedCoreNodeNames.remove(replica.getName());\n\n            }\n          }\n        }\n      }\n\n      if (updatedCoreNodeNames.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a5296efc4b319f5647b606629c093a94b23692c6","date":1456267155,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    \n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    Set<String> updatedCoreNodeNames = new HashSet<>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && replica.getState() != Replica.State.DOWN) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedCoreNodeNames.add(replica.getName());\n            overseerJobQueue.offer(Utils.toJSON(m));\n          }\n        }\n      }\n    }\n\n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = false;\n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getState() == Replica.State.DOWN) {\n              updatedCoreNodeNames.remove(replica.getName());\n\n            }\n          }\n        }\n      }\n\n      if (updatedCoreNodeNames.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1ff4a3d0540c1b0f828f19adccd01d1b33c996a6","date":1456306182,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    \n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    Set<String> updatedCoreNodeNames = new HashSet<>();\n    for (String collectionName : collections) {\n      DocCollection collection = clusterState.getCollection(collectionName);\n      Collection<Slice> slices = collection.getSlices();\n      for (Slice slice : slices) {\n        Collection<Replica> replicas = slice.getReplicas();\n        for (Replica replica : replicas) {\n          if (getNodeName().equals(replica.getNodeName())\n              && replica.getState() != Replica.State.DOWN) {\n            ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, \"state\",\n                ZkStateReader.STATE_PROP, Replica.State.DOWN.toString(),\n                ZkStateReader.BASE_URL_PROP, getBaseUrl(),\n                ZkStateReader.CORE_NAME_PROP,\n                replica.getStr(ZkStateReader.CORE_NAME_PROP),\n                ZkStateReader.ROLES_PROP,\n                replica.getStr(ZkStateReader.ROLES_PROP),\n                ZkStateReader.NODE_NAME_PROP, getNodeName(),\n                ZkStateReader.SHARD_ID_PROP,\n                replica.getStr(ZkStateReader.SHARD_ID_PROP),\n                ZkStateReader.COLLECTION_PROP, collectionName,\n                ZkStateReader.CORE_NODE_NAME_PROP, replica.getName());\n            updatedCoreNodeNames.add(replica.getName());\n            overseerJobQueue.offer(Utils.toJSON(m));\n          }\n        }\n      }\n    }\n\n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = false;\n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (replica.getState() == Replica.State.DOWN) {\n              updatedCoreNodeNames.remove(replica.getName());\n\n            }\n          }\n        }\n      }\n\n      if (updatedCoreNodeNames.size() == 0) {\n        foundStates = true;\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"e9974f61802aea1d15849a1053f88f5e89fc32b4","date":1462405923,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n\n    while (System.nanoTime() < timeout) {\n      ClusterState clusterState = zkStateReader.getClusterState();\n      Map<String, DocCollection> collections = clusterState.getCollectionsMap();\n      for (Map.Entry<String, DocCollection> entry : collections.entrySet()) {\n        DocCollection collection = entry.getValue();\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    \n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"73450c0955930295d34703e7ddbfc6973b7a121a","date":1462431925,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n\n    while (System.nanoTime() < timeout) {\n      ClusterState clusterState = zkStateReader.getClusterState();\n      Map<String, DocCollection> collections = clusterState.getCollectionsMap();\n      for (Map.Entry<String, DocCollection> entry : collections.entrySet()) {\n        DocCollection collection = entry.getValue();\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    \n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7dc08f02757dd10637b16a5c65eaaef839a91a9a","date":1462455462,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n\n    while (System.nanoTime() < timeout) {\n      ClusterState clusterState = zkStateReader.getClusterState();\n      Map<String, DocCollection> collections = clusterState.getCollectionsMap();\n      for (Map.Entry<String, DocCollection> entry : collections.entrySet()) {\n        DocCollection collection = entry.getValue();\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    \n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a8ed5da4b0191db6bc7f77f9feb35da6bd76f904","date":1462576651,"type":3,"author":"Mike McCandless","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n\n    while (System.nanoTime() < timeout) {\n      ClusterState clusterState = zkStateReader.getClusterState();\n      Map<String, DocCollection> collections = clusterState.getCollectionsMap();\n      for (Map.Entry<String, DocCollection> entry : collections.entrySet()) {\n        DocCollection collection = entry.getValue();\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n    ClusterState clusterState = zkStateReader.getClusterState();\n    Set<String> collections = clusterState.getCollections();\n    \n    while (System.nanoTime() < timeout) {\n      clusterState = zkStateReader.getClusterState();\n      collections = clusterState.getCollections();\n      for (String collectionName : collections) {\n        DocCollection collection = clusterState.getCollection(collectionName);\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5cd4080fba20c774e4183c2ceb96ede05e5fb779","date":1463477646,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n\n    while (System.nanoTime() < timeout) {\n      ClusterState clusterState = zkStateReader.getClusterState();\n      Map<String, DocCollection> collections = clusterState.getCollectionsMap();\n      for (Map.Entry<String, DocCollection> entry : collections.entrySet()) {\n        DocCollection collection = entry.getValue();\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n\n    while (System.nanoTime() < timeout) {\n      ClusterState clusterState = zkStateReader.getClusterState();\n      Map<String, DocCollection> collections = clusterState.getCollectionsMap();\n      for (Map.Entry<String, DocCollection> entry : collections.entrySet()) {\n        DocCollection collection = entry.getValue();\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d470c8182e92b264680e34081b75e70a9f2b3c89","date":1463985353,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n\n    while (System.nanoTime() < timeout) {\n      ClusterState clusterState = zkStateReader.getClusterState();\n      Map<String, DocCollection> collections = clusterState.getCollectionsMap();\n      for (Map.Entry<String, DocCollection> entry : collections.entrySet()) {\n        DocCollection collection = entry.getValue();\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n\n    while (System.nanoTime() < timeout) {\n      ClusterState clusterState = zkStateReader.getClusterState();\n      Map<String, DocCollection> collections = clusterState.getCollectionsMap();\n      for (Map.Entry<String, DocCollection> entry : collections.entrySet()) {\n        DocCollection collection = entry.getValue();\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"20c56b78a24b25c89b1deb0a1331f7ee7af8ac7e","date":1464965423,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    Set<String> collections = cc.getLocalCollections();\n    CountDownLatch latch = new CountDownLatch(collections.size());\n\n    for (String collection : collections) {\n      zkStateReader.registerCollectionStateWatcher(collection, (nodes, state) -> {\n        for (Replica replica : state.getReplicasOnNode(getNodeName())) {\n          if (replica.getState() != Replica.State.DOWN)\n            return false;\n        }\n        latch.countDown();\n        return true;\n      });\n    }\n\n    if (latch.await(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS) == false) {\n      // TODO should we abort here?\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n\n    while (System.nanoTime() < timeout) {\n      ClusterState clusterState = zkStateReader.getClusterState();\n      Map<String, DocCollection> collections = clusterState.getCollectionsMap();\n      for (Map.Entry<String, DocCollection> entry : collections.entrySet()) {\n        DocCollection collection = entry.getValue();\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"650d17e953fb1d54e644f9928e3202e68b88eeb1","date":1465215234,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n\n    while (System.nanoTime() < timeout) {\n      ClusterState clusterState = zkStateReader.getClusterState();\n      Map<String, DocCollection> collections = clusterState.getCollectionsMap();\n      for (Map.Entry<String, DocCollection> entry : collections.entrySet()) {\n        DocCollection collection = entry.getValue();\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    Set<String> collections = cc.getLocalCollections();\n    CountDownLatch latch = new CountDownLatch(collections.size());\n\n    for (String collection : collections) {\n      zkStateReader.registerCollectionStateWatcher(collection, (nodes, state) -> {\n        for (Replica replica : state.getReplicasOnNode(getNodeName())) {\n          if (replica.getState() != Replica.State.DOWN)\n            return false;\n        }\n        latch.countDown();\n        return true;\n      });\n    }\n\n    if (latch.await(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS) == false) {\n      // TODO should we abort here?\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f","b45b3de994af6de94faad4adab71863ea967d3da"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"191128ac5b85671b1671e2c857437694283b6ebf","date":1465297861,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n\n    while (System.nanoTime() < timeout) {\n      ClusterState clusterState = zkStateReader.getClusterState();\n      Map<String, DocCollection> collections = clusterState.getCollectionsMap();\n      for (Map.Entry<String, DocCollection> entry : collections.entrySet()) {\n        DocCollection collection = entry.getValue();\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    Set<String> collections = cc.getLocalCollections();\n    CountDownLatch latch = new CountDownLatch(collections.size());\n\n    for (String collection : collections) {\n      zkStateReader.registerCollectionStateWatcher(collection, (nodes, state) -> {\n        for (Replica replica : state.getReplicasOnNode(getNodeName())) {\n          if (replica.getState() != Replica.State.DOWN)\n            return false;\n        }\n        latch.countDown();\n        return true;\n      });\n    }\n\n    if (latch.await(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS) == false) {\n      // TODO should we abort here?\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b45b3de994af6de94faad4adab71863ea967d3da","date":1465503869,"type":3,"author":"Gregory Chanan","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n\n    while (System.nanoTime() < timeout) {\n      boolean foundStates = true;\n      ClusterState clusterState = zkStateReader.getClusterState();\n      Map<String, DocCollection> collections = clusterState.getCollectionsMap();\n      for (Map.Entry<String, DocCollection> entry : collections.entrySet()) {\n        DocCollection collection = entry.getValue();\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      Thread.sleep(1000);\n      if (foundStates) {\n        return;\n      }\n    }\n\n    log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n\n    while (System.nanoTime() < timeout) {\n      ClusterState clusterState = zkStateReader.getClusterState();\n      Map<String, DocCollection> collections = clusterState.getCollectionsMap();\n      for (Map.Entry<String, DocCollection> entry : collections.entrySet()) {\n        DocCollection collection = entry.getValue();\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","bugFix":["474a065e1bf22f3551c2fd2c9e18bde479e5c3c5","650d17e953fb1d54e644f9928e3202e68b88eeb1"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"135bbdf5a94499467f683815b3fac8ce4f4eda3c","date":1467280377,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    Set<String> collectionsWithLocalReplica = ConcurrentHashMap.newKeySet();\n    for (SolrCore core : cc.getCores()) {\n      collectionsWithLocalReplica.add(core.getCoreDescriptor().getCloudDescriptor().getCollectionName());\n    }\n\n    CountDownLatch latch = new CountDownLatch(collectionsWithLocalReplica.size());\n    for (String collectionWithLocalReplica : collectionsWithLocalReplica) {\n      zkStateReader.registerCollectionStateWatcher(collectionWithLocalReplica, (liveNodes, collectionState) -> {\n        boolean foundStates = true;\n        for (SolrCore core : cc.getCores()) {\n          if (core.getCoreDescriptor().getCloudDescriptor().getCollectionName().equals(collectionWithLocalReplica))  {\n            Replica replica = collectionState.getReplica(core.getCoreDescriptor().getCloudDescriptor().getCoreNodeName());\n            if (replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n\n        if (foundStates && collectionsWithLocalReplica.remove(collectionWithLocalReplica))  {\n          latch.countDown();\n        }\n        return foundStates;\n      });\n    }\n\n    boolean allPublishedDown = latch.await(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    if (!allPublishedDown) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n\n    while (System.nanoTime() < timeout) {\n      boolean foundStates = true;\n      ClusterState clusterState = zkStateReader.getClusterState();\n      Map<String, DocCollection> collections = clusterState.getCollectionsMap();\n      for (Map.Entry<String, DocCollection> entry : collections.entrySet()) {\n        DocCollection collection = entry.getValue();\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      Thread.sleep(1000);\n      if (foundStates) {\n        return;\n      }\n    }\n\n    log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"56ae3539e829325e80cc0e8d65df4d724cc762d1","date":1467374872,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    Set<String> collectionsWithLocalReplica = ConcurrentHashMap.newKeySet();\n    for (SolrCore core : cc.getCores()) {\n      collectionsWithLocalReplica.add(core.getCoreDescriptor().getCloudDescriptor().getCollectionName());\n    }\n\n    CountDownLatch latch = new CountDownLatch(collectionsWithLocalReplica.size());\n    for (String collectionWithLocalReplica : collectionsWithLocalReplica) {\n      zkStateReader.registerCollectionStateWatcher(collectionWithLocalReplica, (liveNodes, collectionState) -> {\n        boolean foundStates = true;\n        for (SolrCore core : cc.getCores()) {\n          if (core.getCoreDescriptor().getCloudDescriptor().getCollectionName().equals(collectionWithLocalReplica))  {\n            Replica replica = collectionState.getReplica(core.getCoreDescriptor().getCloudDescriptor().getCoreNodeName());\n            if (replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n\n        if (foundStates && collectionsWithLocalReplica.remove(collectionWithLocalReplica))  {\n          latch.countDown();\n        }\n        return foundStates;\n      });\n    }\n\n    boolean allPublishedDown = latch.await(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    if (!allPublishedDown) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n\n    while (System.nanoTime() < timeout) {\n      boolean foundStates = true;\n      ClusterState clusterState = zkStateReader.getClusterState();\n      Map<String, DocCollection> collections = clusterState.getCollectionsMap();\n      for (Map.Entry<String, DocCollection> entry : collections.entrySet()) {\n        DocCollection collection = entry.getValue();\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      Thread.sleep(1000);\n      if (foundStates) {\n        return;\n      }\n    }\n\n    log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    Set<String> collectionsWithLocalReplica = ConcurrentHashMap.newKeySet();\n    for (SolrCore core : cc.getCores()) {\n      collectionsWithLocalReplica.add(core.getCoreDescriptor().getCloudDescriptor().getCollectionName());\n    }\n\n    CountDownLatch latch = new CountDownLatch(collectionsWithLocalReplica.size());\n    for (String collectionWithLocalReplica : collectionsWithLocalReplica) {\n      zkStateReader.registerCollectionStateWatcher(collectionWithLocalReplica, (liveNodes, collectionState) -> {\n        boolean foundStates = true;\n        for (SolrCore core : cc.getCores()) {\n          if (core.getCoreDescriptor().getCloudDescriptor().getCollectionName().equals(collectionWithLocalReplica))  {\n            Replica replica = collectionState.getReplica(core.getCoreDescriptor().getCloudDescriptor().getCoreNodeName());\n            if (replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n\n        if (foundStates && collectionsWithLocalReplica.remove(collectionWithLocalReplica))  {\n          latch.countDown();\n        }\n        return foundStates;\n      });\n    }\n\n    boolean allPublishedDown = latch.await(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    if (!allPublishedDown) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    \n    // now wait till the updates are in our state\n    long now = System.nanoTime();\n    long timeout = now + TimeUnit.NANOSECONDS.convert(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    boolean foundStates = true;\n\n    while (System.nanoTime() < timeout) {\n      ClusterState clusterState = zkStateReader.getClusterState();\n      Map<String, DocCollection> collections = clusterState.getCollectionsMap();\n      for (Map.Entry<String, DocCollection> entry : collections.entrySet()) {\n        DocCollection collection = entry.getValue();\n        Collection<Slice> slices = collection.getSlices();\n        for (Slice slice : slices) {\n          Collection<Replica> replicas = slice.getReplicas();\n          for (Replica replica : replicas) {\n            if (getNodeName().equals(replica.getNodeName()) && replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n      }\n\n      if (foundStates) {\n        Thread.sleep(1000);\n        break;\n      }\n      Thread.sleep(1000);\n    }\n    if (!foundStates) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a92d3a78193c351661c38ed287536e76ebf2a852","date":1522126714,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    Set<String> collectionsWithLocalReplica = ConcurrentHashMap.newKeySet();\n    for (CoreDescriptor descriptor : cc.getCoreDescriptors()) {\n      collectionsWithLocalReplica.add(descriptor.getCloudDescriptor().getCollectionName());\n    }\n\n    CountDownLatch latch = new CountDownLatch(collectionsWithLocalReplica.size());\n    for (String collectionWithLocalReplica : collectionsWithLocalReplica) {\n      zkStateReader.registerCollectionStateWatcher(collectionWithLocalReplica, (liveNodes, collectionState) -> {\n        if (collectionState == null)  return false;\n        boolean foundStates = true;\n        for (CoreDescriptor coreDescriptor : cc.getCoreDescriptors()) {\n          if (coreDescriptor.getCloudDescriptor().getCollectionName().equals(collectionWithLocalReplica))  {\n            Replica replica = collectionState.getReplica(coreDescriptor.getCloudDescriptor().getCoreNodeName());\n            if (replica == null || replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n\n        if (foundStates && collectionsWithLocalReplica.remove(collectionWithLocalReplica))  {\n          latch.countDown();\n        }\n        return foundStates;\n      });\n    }\n\n    boolean allPublishedDown = latch.await(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    if (!allPublishedDown) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    Set<String> collectionsWithLocalReplica = ConcurrentHashMap.newKeySet();\n    for (SolrCore core : cc.getCores()) {\n      collectionsWithLocalReplica.add(core.getCoreDescriptor().getCloudDescriptor().getCollectionName());\n    }\n\n    CountDownLatch latch = new CountDownLatch(collectionsWithLocalReplica.size());\n    for (String collectionWithLocalReplica : collectionsWithLocalReplica) {\n      zkStateReader.registerCollectionStateWatcher(collectionWithLocalReplica, (liveNodes, collectionState) -> {\n        boolean foundStates = true;\n        for (SolrCore core : cc.getCores()) {\n          if (core.getCoreDescriptor().getCloudDescriptor().getCollectionName().equals(collectionWithLocalReplica))  {\n            Replica replica = collectionState.getReplica(core.getCoreDescriptor().getCloudDescriptor().getCoreNodeName());\n            if (replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n\n        if (foundStates && collectionsWithLocalReplica.remove(collectionWithLocalReplica))  {\n          latch.countDown();\n        }\n        return foundStates;\n      });\n    }\n\n    boolean allPublishedDown = latch.await(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    if (!allPublishedDown) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7","date":1522191940,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    Set<String> collectionsWithLocalReplica = ConcurrentHashMap.newKeySet();\n    for (CoreDescriptor descriptor : cc.getCoreDescriptors()) {\n      collectionsWithLocalReplica.add(descriptor.getCloudDescriptor().getCollectionName());\n    }\n\n    CountDownLatch latch = new CountDownLatch(collectionsWithLocalReplica.size());\n    for (String collectionWithLocalReplica : collectionsWithLocalReplica) {\n      zkStateReader.registerCollectionStateWatcher(collectionWithLocalReplica, (liveNodes, collectionState) -> {\n        if (collectionState == null)  return false;\n        boolean foundStates = true;\n        for (CoreDescriptor coreDescriptor : cc.getCoreDescriptors()) {\n          if (coreDescriptor.getCloudDescriptor().getCollectionName().equals(collectionWithLocalReplica))  {\n            Replica replica = collectionState.getReplica(coreDescriptor.getCloudDescriptor().getCoreNodeName());\n            if (replica == null || replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n\n        if (foundStates && collectionsWithLocalReplica.remove(collectionWithLocalReplica))  {\n          latch.countDown();\n        }\n        return foundStates;\n      });\n    }\n\n    boolean allPublishedDown = latch.await(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    if (!allPublishedDown) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    Set<String> collectionsWithLocalReplica = ConcurrentHashMap.newKeySet();\n    for (SolrCore core : cc.getCores()) {\n      collectionsWithLocalReplica.add(core.getCoreDescriptor().getCloudDescriptor().getCollectionName());\n    }\n\n    CountDownLatch latch = new CountDownLatch(collectionsWithLocalReplica.size());\n    for (String collectionWithLocalReplica : collectionsWithLocalReplica) {\n      zkStateReader.registerCollectionStateWatcher(collectionWithLocalReplica, (liveNodes, collectionState) -> {\n        boolean foundStates = true;\n        for (SolrCore core : cc.getCores()) {\n          if (core.getCoreDescriptor().getCloudDescriptor().getCollectionName().equals(collectionWithLocalReplica))  {\n            Replica replica = collectionState.getReplica(core.getCoreDescriptor().getCloudDescriptor().getCoreNodeName());\n            if (replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n\n        if (foundStates && collectionsWithLocalReplica.remove(collectionWithLocalReplica))  {\n          latch.countDown();\n        }\n        return foundStates;\n      });\n    }\n\n    boolean allPublishedDown = latch.await(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    if (!allPublishedDown) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/ZkController#publishAndWaitForDownStates().mjava","sourceNew":"  public void publishAndWaitForDownStates() throws KeeperException,\n  InterruptedException {\n    publishAndWaitForDownStates(WAIT_DOWN_STATES_TIMEOUT_SECONDS);\n  }\n\n","sourceOld":"  public void publishAndWaitForDownStates() throws KeeperException,\n      InterruptedException {\n\n    publishNodeAsDown(getNodeName());\n\n    Set<String> collectionsWithLocalReplica = ConcurrentHashMap.newKeySet();\n    for (CoreDescriptor descriptor : cc.getCoreDescriptors()) {\n      collectionsWithLocalReplica.add(descriptor.getCloudDescriptor().getCollectionName());\n    }\n\n    CountDownLatch latch = new CountDownLatch(collectionsWithLocalReplica.size());\n    for (String collectionWithLocalReplica : collectionsWithLocalReplica) {\n      zkStateReader.registerCollectionStateWatcher(collectionWithLocalReplica, (liveNodes, collectionState) -> {\n        if (collectionState == null)  return false;\n        boolean foundStates = true;\n        for (CoreDescriptor coreDescriptor : cc.getCoreDescriptors()) {\n          if (coreDescriptor.getCloudDescriptor().getCollectionName().equals(collectionWithLocalReplica))  {\n            Replica replica = collectionState.getReplica(coreDescriptor.getCloudDescriptor().getCoreNodeName());\n            if (replica == null || replica.getState() != Replica.State.DOWN) {\n              foundStates = false;\n            }\n          }\n        }\n\n        if (foundStates && collectionsWithLocalReplica.remove(collectionWithLocalReplica))  {\n          latch.countDown();\n        }\n        return foundStates;\n      });\n    }\n\n    boolean allPublishedDown = latch.await(WAIT_DOWN_STATES_TIMEOUT_SECONDS, TimeUnit.SECONDS);\n    if (!allPublishedDown) {\n      log.warn(\"Timed out waiting to see all nodes published as DOWN in our cluster state.\");\n    }\n  }\n\n","bugFix":["384868ae9e6c9b2c476f72db0c40840f6d6776a2","fbcfc050b9f253136eaa5950b57248b2109eac11","135bbdf5a94499467f683815b3fac8ce4f4eda3c","20c56b78a24b25c89b1deb0a1331f7ee7af8ac7e","474a065e1bf22f3551c2fd2c9e18bde479e5c3c5","e9974f61802aea1d15849a1053f88f5e89fc32b4","a92d3a78193c351661c38ed287536e76ebf2a852","650d17e953fb1d54e644f9928e3202e68b88eeb1"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"37a0f60745e53927c4c876cfe5b5a58170f0646c":["cb4a195b8dc1808cd01748bd2e0fba26ca915d4d","849494cf2f3a96af5c8c84995108ddd8456fcd04"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7"],"135bbdf5a94499467f683815b3fac8ce4f4eda3c":["b45b3de994af6de94faad4adab71863ea967d3da"],"7bc9c220ff48e045e8bae03a685357491c123389":["474a065e1bf22f3551c2fd2c9e18bde479e5c3c5"],"1ff4a3d0540c1b0f828f19adccd01d1b33c996a6":["b693a83132c9e45afcd564fd65a25b60ed80388b","a5296efc4b319f5647b606629c093a94b23692c6"],"650d17e953fb1d54e644f9928e3202e68b88eeb1":["20c56b78a24b25c89b1deb0a1331f7ee7af8ac7e"],"191128ac5b85671b1671e2c857437694283b6ebf":["20c56b78a24b25c89b1deb0a1331f7ee7af8ac7e","650d17e953fb1d54e644f9928e3202e68b88eeb1"],"13f445c5bd6f19fd57d5a3ca0a35244c96f45aa8":["849494cf2f3a96af5c8c84995108ddd8456fcd04","8497bb4f9de61b5520423bd9af88ea11a6e109e7"],"fd5bc858b8426d40bbe90b94120ead37c77d7954":["8497bb4f9de61b5520423bd9af88ea11a6e109e7"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["73450c0955930295d34703e7ddbfc6973b7a121a","5cd4080fba20c774e4183c2ceb96ede05e5fb779"],"a219f1dcad1700e84807666bdbd2b573e8de7021":["fbcfc050b9f253136eaa5950b57248b2109eac11"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","fbcfc050b9f253136eaa5950b57248b2109eac11"],"95303ff3749680c743b9425f9cf99e6e4065e8a8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","7bc9c220ff48e045e8bae03a685357491c123389"],"384868ae9e6c9b2c476f72db0c40840f6d6776a2":["b693a83132c9e45afcd564fd65a25b60ed80388b"],"5cd4080fba20c774e4183c2ceb96ede05e5fb779":["73450c0955930295d34703e7ddbfc6973b7a121a"],"a8ed5da4b0191db6bc7f77f9feb35da6bd76f904":["1ff4a3d0540c1b0f828f19adccd01d1b33c996a6","73450c0955930295d34703e7ddbfc6973b7a121a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a5296efc4b319f5647b606629c093a94b23692c6":["b693a83132c9e45afcd564fd65a25b60ed80388b","384868ae9e6c9b2c476f72db0c40840f6d6776a2"],"20c56b78a24b25c89b1deb0a1331f7ee7af8ac7e":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["fd5bc858b8426d40bbe90b94120ead37c77d7954"],"56ae3539e829325e80cc0e8d65df4d724cc762d1":["b45b3de994af6de94faad4adab71863ea967d3da","135bbdf5a94499467f683815b3fac8ce4f4eda3c"],"474a065e1bf22f3551c2fd2c9e18bde479e5c3c5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"73450c0955930295d34703e7ddbfc6973b7a121a":["1ff4a3d0540c1b0f828f19adccd01d1b33c996a6","e9974f61802aea1d15849a1053f88f5e89fc32b4"],"7dc08f02757dd10637b16a5c65eaaef839a91a9a":["1ff4a3d0540c1b0f828f19adccd01d1b33c996a6","73450c0955930295d34703e7ddbfc6973b7a121a"],"b45b3de994af6de94faad4adab71863ea967d3da":["191128ac5b85671b1671e2c857437694283b6ebf"],"b693a83132c9e45afcd564fd65a25b60ed80388b":["e11b7252d34d00665befca520dee82fd64aed3c2"],"d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7":["56ae3539e829325e80cc0e8d65df4d724cc762d1","a92d3a78193c351661c38ed287536e76ebf2a852"],"a92d3a78193c351661c38ed287536e76ebf2a852":["56ae3539e829325e80cc0e8d65df4d724cc762d1"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["7dc08f02757dd10637b16a5c65eaaef839a91a9a","56ae3539e829325e80cc0e8d65df4d724cc762d1"],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["cb4a195b8dc1808cd01748bd2e0fba26ca915d4d"],"e9974f61802aea1d15849a1053f88f5e89fc32b4":["1ff4a3d0540c1b0f828f19adccd01d1b33c996a6"],"e11b7252d34d00665befca520dee82fd64aed3c2":["a219f1dcad1700e84807666bdbd2b573e8de7021"],"8497bb4f9de61b5520423bd9af88ea11a6e109e7":["849494cf2f3a96af5c8c84995108ddd8456fcd04"],"cb4a195b8dc1808cd01748bd2e0fba26ca915d4d":["7bc9c220ff48e045e8bae03a685357491c123389"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"fbcfc050b9f253136eaa5950b57248b2109eac11":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"]},"commit2Childs":{"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"135bbdf5a94499467f683815b3fac8ce4f4eda3c":["56ae3539e829325e80cc0e8d65df4d724cc762d1"],"7bc9c220ff48e045e8bae03a685357491c123389":["95303ff3749680c743b9425f9cf99e6e4065e8a8","cb4a195b8dc1808cd01748bd2e0fba26ca915d4d"],"1ff4a3d0540c1b0f828f19adccd01d1b33c996a6":["a8ed5da4b0191db6bc7f77f9feb35da6bd76f904","73450c0955930295d34703e7ddbfc6973b7a121a","7dc08f02757dd10637b16a5c65eaaef839a91a9a","e9974f61802aea1d15849a1053f88f5e89fc32b4"],"650d17e953fb1d54e644f9928e3202e68b88eeb1":["191128ac5b85671b1671e2c857437694283b6ebf"],"191128ac5b85671b1671e2c857437694283b6ebf":["b45b3de994af6de94faad4adab71863ea967d3da"],"13f445c5bd6f19fd57d5a3ca0a35244c96f45aa8":[],"fd5bc858b8426d40bbe90b94120ead37c77d7954":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"d470c8182e92b264680e34081b75e70a9f2b3c89":["20c56b78a24b25c89b1deb0a1331f7ee7af8ac7e"],"a219f1dcad1700e84807666bdbd2b573e8de7021":["e11b7252d34d00665befca520dee82fd64aed3c2"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"95303ff3749680c743b9425f9cf99e6e4065e8a8":[],"5cd4080fba20c774e4183c2ceb96ede05e5fb779":["d470c8182e92b264680e34081b75e70a9f2b3c89"],"384868ae9e6c9b2c476f72db0c40840f6d6776a2":["a5296efc4b319f5647b606629c093a94b23692c6"],"a8ed5da4b0191db6bc7f77f9feb35da6bd76f904":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["95303ff3749680c743b9425f9cf99e6e4065e8a8","474a065e1bf22f3551c2fd2c9e18bde479e5c3c5"],"a5296efc4b319f5647b606629c093a94b23692c6":["1ff4a3d0540c1b0f828f19adccd01d1b33c996a6"],"20c56b78a24b25c89b1deb0a1331f7ee7af8ac7e":["650d17e953fb1d54e644f9928e3202e68b88eeb1","191128ac5b85671b1671e2c857437694283b6ebf"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","fbcfc050b9f253136eaa5950b57248b2109eac11"],"56ae3539e829325e80cc0e8d65df4d724cc762d1":["d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7","a92d3a78193c351661c38ed287536e76ebf2a852","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"474a065e1bf22f3551c2fd2c9e18bde479e5c3c5":["7bc9c220ff48e045e8bae03a685357491c123389"],"73450c0955930295d34703e7ddbfc6973b7a121a":["d470c8182e92b264680e34081b75e70a9f2b3c89","5cd4080fba20c774e4183c2ceb96ede05e5fb779","a8ed5da4b0191db6bc7f77f9feb35da6bd76f904","7dc08f02757dd10637b16a5c65eaaef839a91a9a"],"7dc08f02757dd10637b16a5c65eaaef839a91a9a":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"b45b3de994af6de94faad4adab71863ea967d3da":["135bbdf5a94499467f683815b3fac8ce4f4eda3c","56ae3539e829325e80cc0e8d65df4d724cc762d1"],"d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"b693a83132c9e45afcd564fd65a25b60ed80388b":["1ff4a3d0540c1b0f828f19adccd01d1b33c996a6","384868ae9e6c9b2c476f72db0c40840f6d6776a2","a5296efc4b319f5647b606629c093a94b23692c6"],"a92d3a78193c351661c38ed287536e76ebf2a852":["d61a3e0821ed080b9b21e1328bbaa91dcf79f7d7"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"849494cf2f3a96af5c8c84995108ddd8456fcd04":["37a0f60745e53927c4c876cfe5b5a58170f0646c","13f445c5bd6f19fd57d5a3ca0a35244c96f45aa8","8497bb4f9de61b5520423bd9af88ea11a6e109e7"],"e9974f61802aea1d15849a1053f88f5e89fc32b4":["73450c0955930295d34703e7ddbfc6973b7a121a"],"cb4a195b8dc1808cd01748bd2e0fba26ca915d4d":["37a0f60745e53927c4c876cfe5b5a58170f0646c","849494cf2f3a96af5c8c84995108ddd8456fcd04"],"8497bb4f9de61b5520423bd9af88ea11a6e109e7":["13f445c5bd6f19fd57d5a3ca0a35244c96f45aa8","fd5bc858b8426d40bbe90b94120ead37c77d7954"],"e11b7252d34d00665befca520dee82fd64aed3c2":["b693a83132c9e45afcd564fd65a25b60ed80388b"],"fbcfc050b9f253136eaa5950b57248b2109eac11":["a219f1dcad1700e84807666bdbd2b573e8de7021","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","13f445c5bd6f19fd57d5a3ca0a35244c96f45aa8","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","95303ff3749680c743b9425f9cf99e6e4065e8a8","a8ed5da4b0191db6bc7f77f9feb35da6bd76f904","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}