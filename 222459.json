{"path":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","commits":[{"id":"4e5e734869d76c22acfc12bc53ecbfcc1606c2f5","date":1347072117,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","pathOld":"/dev/null","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private static final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    IOException priorE = null;\n    IndexInput entriesStream = null;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openInput(entriesFileName, IOContext.READONCE);\n      CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_START);\n      final int numEntries = entriesStream.readVInt();\n      final Map<String, FileEntry> mapping = new HashMap<String,FileEntry>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS: \" + entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      return mapping;\n    } catch (IOException ioe) {\n      priorE = ioe;\n    } finally {\n      IOUtils.closeWhileHandlingException(priorE, entriesStream);\n    }\n    // this is needed until Java 7's real try-with-resources:\n    throw new AssertionError(\"impossible to get here\");\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private static final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    IOException priorE = null;\n    IndexInput entriesStream = null;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openInput(entriesFileName, IOContext.READONCE);\n      CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_START);\n      final int numEntries = entriesStream.readVInt();\n      final Map<String, FileEntry> mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS: \" + entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      return mapping;\n    } catch (IOException ioe) {\n      priorE = ioe;\n    } finally {\n      IOUtils.closeWhileHandlingException(priorE, entriesStream);\n    }\n    // this is needed until Java 7's real try-with-resources:\n    throw new AssertionError(\"impossible to get here\");\n  }\n\n","sourceOld":"  /** Helper method that reads CFS entries from an input stream */\n  private static final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    IOException priorE = null;\n    IndexInput entriesStream = null;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openInput(entriesFileName, IOContext.READONCE);\n      CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_START);\n      final int numEntries = entriesStream.readVInt();\n      final Map<String, FileEntry> mapping = new HashMap<String,FileEntry>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS: \" + entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      return mapping;\n    } catch (IOException ioe) {\n      priorE = ioe;\n    } finally {\n      IOUtils.closeWhileHandlingException(priorE, entriesStream);\n    }\n    // this is needed until Java 7's real try-with-resources:\n    throw new AssertionError(\"impossible to get here\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5ed7a1acc39e7e6f148efd1368265dd1dd8034f8","date":1395430607,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private static final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    IOException priorE = null;\n    IndexInput entriesStream = null;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openInput(entriesFileName, IOContext.READONCE);\n      CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_START);\n      final int numEntries = entriesStream.readVInt();\n      final Map<String, FileEntry> mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS: \" + entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (entriesStream.getFilePointer() != entriesStream.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + entriesFileName + \"\\\": read \" + entriesStream.getFilePointer() + \" vs size \" + entriesStream.length() + \" (resource: \" + entriesStream + \")\");\n      }\n      return mapping;\n    } catch (IOException ioe) {\n      priorE = ioe;\n    } finally {\n      IOUtils.closeWhileHandlingException(priorE, entriesStream);\n    }\n    // this is needed until Java 7's real try-with-resources:\n    throw new AssertionError(\"impossible to get here\");\n  }\n\n","sourceOld":"  /** Helper method that reads CFS entries from an input stream */\n  private static final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    IOException priorE = null;\n    IndexInput entriesStream = null;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openInput(entriesFileName, IOContext.READONCE);\n      CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_START);\n      final int numEntries = entriesStream.readVInt();\n      final Map<String, FileEntry> mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS: \" + entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      return mapping;\n    } catch (IOException ioe) {\n      priorE = ioe;\n    } finally {\n      IOUtils.closeWhileHandlingException(priorE, entriesStream);\n    }\n    // this is needed until Java 7's real try-with-resources:\n    throw new AssertionError(\"impossible to get here\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1f3b037cd083286b2af89f96e768f85dcd8072d6","date":1396337805,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    IOException priorE = null;\n    ChecksumIndexInput entriesStream = null;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE);\n      version = CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_CURRENT);\n      final int numEntries = entriesStream.readVInt();\n      final Map<String, FileEntry> mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS: \" + entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (version >= CompoundFileWriter.VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(entriesStream);\n      } else {\n        CodecUtil.checkEOF(entriesStream);\n      }\n      return mapping;\n    } catch (IOException ioe) {\n      priorE = ioe;\n    } finally {\n      IOUtils.closeWhileHandlingException(priorE, entriesStream);\n    }\n    // this is needed until Java 7's real try-with-resources:\n    throw new AssertionError(\"impossible to get here\");\n  }\n\n","sourceOld":"  /** Helper method that reads CFS entries from an input stream */\n  private static final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    IOException priorE = null;\n    IndexInput entriesStream = null;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openInput(entriesFileName, IOContext.READONCE);\n      CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_START);\n      final int numEntries = entriesStream.readVInt();\n      final Map<String, FileEntry> mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS: \" + entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (entriesStream.getFilePointer() != entriesStream.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + entriesFileName + \"\\\": read \" + entriesStream.getFilePointer() + \" vs size \" + entriesStream.length() + \" (resource: \" + entriesStream + \")\");\n      }\n      return mapping;\n    } catch (IOException ioe) {\n      priorE = ioe;\n    } finally {\n      IOUtils.closeWhileHandlingException(priorE, entriesStream);\n    }\n    // this is needed until Java 7's real try-with-resources:\n    throw new AssertionError(\"impossible to get here\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    IOException priorE = null;\n    ChecksumIndexInput entriesStream = null;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE);\n      version = CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_CURRENT);\n      final int numEntries = entriesStream.readVInt();\n      final Map<String, FileEntry> mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS: \" + entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (version >= CompoundFileWriter.VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(entriesStream);\n      } else {\n        CodecUtil.checkEOF(entriesStream);\n      }\n      return mapping;\n    } catch (IOException ioe) {\n      priorE = ioe;\n    } finally {\n      IOUtils.closeWhileHandlingException(priorE, entriesStream);\n    }\n    // this is needed until Java 7's real try-with-resources:\n    throw new AssertionError(\"impossible to get here\");\n  }\n\n","sourceOld":"  /** Helper method that reads CFS entries from an input stream */\n  private static final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    IOException priorE = null;\n    IndexInput entriesStream = null;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openInput(entriesFileName, IOContext.READONCE);\n      CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_START);\n      final int numEntries = entriesStream.readVInt();\n      final Map<String, FileEntry> mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS: \" + entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (entriesStream.getFilePointer() != entriesStream.length()) {\n        throw new CorruptIndexException(\"did not read all bytes from file \\\"\" + entriesFileName + \"\\\": read \" + entriesStream.getFilePointer() + \" vs size \" + entriesStream.length() + \" (resource: \" + entriesStream + \")\");\n      }\n      return mapping;\n    } catch (IOException ioe) {\n      priorE = ioe;\n    } finally {\n      IOUtils.closeWhileHandlingException(priorE, entriesStream);\n    }\n    // this is needed until Java 7's real try-with-resources:\n    throw new AssertionError(\"impossible to get here\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"43e3527ed736c46c0f0ab28181937b9de5ef7c63","date":1399502658,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    ChecksumIndexInput entriesStream = null;\n    Map<String,FileEntry> mapping = null;\n    boolean success = false;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE);\n      version = CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_CURRENT);\n      final int numEntries = entriesStream.readVInt();\n      mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS: \" + entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (version >= CompoundFileWriter.VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(entriesStream);\n      } else {\n        CodecUtil.checkEOF(entriesStream);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(entriesStream);\n      } else {\n        IOUtils.closeWhileHandlingException(entriesStream);\n      }\n    }\n    return mapping;\n  }\n\n","sourceOld":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    IOException priorE = null;\n    ChecksumIndexInput entriesStream = null;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE);\n      version = CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_CURRENT);\n      final int numEntries = entriesStream.readVInt();\n      final Map<String, FileEntry> mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS: \" + entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (version >= CompoundFileWriter.VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(entriesStream);\n      } else {\n        CodecUtil.checkEOF(entriesStream);\n      }\n      return mapping;\n    } catch (IOException ioe) {\n      priorE = ioe;\n    } finally {\n      IOUtils.closeWhileHandlingException(priorE, entriesStream);\n    }\n    // this is needed until Java 7's real try-with-resources:\n    throw new AssertionError(\"impossible to get here\");\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9a70ce9bddc6f985feb8e5e182aebe20872328d4","date":1411172748,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    ChecksumIndexInput entriesStream = null;\n    Map<String,FileEntry> mapping = null;\n    boolean success = false;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE);\n      version = CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_CURRENT);\n      final int numEntries = entriesStream.readVInt();\n      mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (version >= CompoundFileWriter.VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(entriesStream);\n      } else {\n        CodecUtil.checkEOF(entriesStream);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(entriesStream);\n      } else {\n        IOUtils.closeWhileHandlingException(entriesStream);\n      }\n    }\n    return mapping;\n  }\n\n","sourceOld":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    ChecksumIndexInput entriesStream = null;\n    Map<String,FileEntry> mapping = null;\n    boolean success = false;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE);\n      version = CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_CURRENT);\n      final int numEntries = entriesStream.readVInt();\n      mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS: \" + entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (version >= CompoundFileWriter.VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(entriesStream);\n      } else {\n        CodecUtil.checkEOF(entriesStream);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(entriesStream);\n      } else {\n        IOUtils.closeWhileHandlingException(entriesStream);\n      }\n    }\n    return mapping;\n  }\n\n","bugFix":["4e5e734869d76c22acfc12bc53ecbfcc1606c2f5"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f382b2e9f4ca7dbe98e2f15da70983ecfc02b171","date":1412231650,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    ChecksumIndexInput entriesStream = null;\n    Map<String,FileEntry> mapping = null;\n    boolean success = false;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE);\n      version = CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_CURRENT);\n      if (version >= CompoundFileWriter.VERSION_SEGMENTHEADER) {\n        byte id[] = new byte[StringHelper.ID_LENGTH];\n        entriesStream.readBytes(id, 0, id.length);\n        // nocommit: remove this null \"hack\", its because old rw test codecs cant properly impersonate\n        if (segmentID != null && !Arrays.equals(id, segmentID)) {\n          throw new CorruptIndexException(\"file mismatch, expected segment id=\" + StringHelper.idToString(segmentID) \n                                                                     + \", got=\" + StringHelper.idToString(id), entriesStream);\n        }\n        byte suffixLength = entriesStream.readByte();\n        if (suffixLength != 0) {\n          throw new CorruptIndexException(\"unexpected segment suffix, expected zero-length, got=\" + (suffixLength & 0xFF), entriesStream);\n        }\n      }\n      final int numEntries = entriesStream.readVInt();\n      mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (version >= CompoundFileWriter.VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(entriesStream);\n      } else {\n        CodecUtil.checkEOF(entriesStream);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(entriesStream);\n      } else {\n        IOUtils.closeWhileHandlingException(entriesStream);\n      }\n    }\n    return mapping;\n  }\n\n","sourceOld":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    ChecksumIndexInput entriesStream = null;\n    Map<String,FileEntry> mapping = null;\n    boolean success = false;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE);\n      version = CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_CURRENT);\n      final int numEntries = entriesStream.readVInt();\n      mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (version >= CompoundFileWriter.VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(entriesStream);\n      } else {\n        CodecUtil.checkEOF(entriesStream);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(entriesStream);\n      } else {\n        IOUtils.closeWhileHandlingException(entriesStream);\n      }\n    }\n    return mapping;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"989d940c4bf402188f4f0ae13736836885227383","date":1412263633,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene50/CompoundFileDirectory#readEntries(Directory,String).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    ChecksumIndexInput entriesStream = null;\n    Map<String,FileEntry> mapping = null;\n    boolean success = false;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE);\n      version = CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_CURRENT);\n      if (version >= CompoundFileWriter.VERSION_SEGMENTHEADER) {\n        byte id[] = new byte[StringHelper.ID_LENGTH];\n        entriesStream.readBytes(id, 0, id.length);\n        // nocommit: remove this null \"hack\", its because old rw test codecs cant properly impersonate\n        if (segmentID != null && !Arrays.equals(id, segmentID)) {\n          throw new CorruptIndexException(\"file mismatch, expected segment id=\" + StringHelper.idToString(segmentID) \n                                                                     + \", got=\" + StringHelper.idToString(id), entriesStream);\n        }\n        byte suffixLength = entriesStream.readByte();\n        if (suffixLength != 0) {\n          throw new CorruptIndexException(\"unexpected segment suffix, expected zero-length, got=\" + (suffixLength & 0xFF), entriesStream);\n        }\n      }\n      final int numEntries = entriesStream.readVInt();\n      mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (version >= CompoundFileWriter.VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(entriesStream);\n      } else {\n        CodecUtil.checkEOF(entriesStream);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(entriesStream);\n      } else {\n        IOUtils.closeWhileHandlingException(entriesStream);\n      }\n    }\n    return mapping;\n  }\n\n","sourceOld":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    ChecksumIndexInput entriesStream = null;\n    Map<String,FileEntry> mapping = null;\n    boolean success = false;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE);\n      version = CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_CURRENT);\n      if (version >= CompoundFileWriter.VERSION_SEGMENTHEADER) {\n        byte id[] = new byte[StringHelper.ID_LENGTH];\n        entriesStream.readBytes(id, 0, id.length);\n        // nocommit: remove this null \"hack\", its because old rw test codecs cant properly impersonate\n        if (segmentID != null && !Arrays.equals(id, segmentID)) {\n          throw new CorruptIndexException(\"file mismatch, expected segment id=\" + StringHelper.idToString(segmentID) \n                                                                     + \", got=\" + StringHelper.idToString(id), entriesStream);\n        }\n        byte suffixLength = entriesStream.readByte();\n        if (suffixLength != 0) {\n          throw new CorruptIndexException(\"unexpected segment suffix, expected zero-length, got=\" + (suffixLength & 0xFF), entriesStream);\n        }\n      }\n      final int numEntries = entriesStream.readVInt();\n      mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (version >= CompoundFileWriter.VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(entriesStream);\n      } else {\n        CodecUtil.checkEOF(entriesStream);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(entriesStream);\n      } else {\n        IOUtils.closeWhileHandlingException(entriesStream);\n      }\n    }\n    return mapping;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9bb9a29a5e71a90295f175df8919802993142c9a","date":1412517673,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/backward-codecs/src/java/org/apache/lucene/codecs/lucene40/Lucene40CompoundReader#readEntries(Directory,String).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/store/CompoundFileDirectory#readEntries(Directory,String).mjava","sourceNew":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    ChecksumIndexInput entriesStream = null;\n    Map<String,FileEntry> mapping = null;\n    boolean success = false;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             Lucene40CompoundFormat.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE);\n      version = CodecUtil.checkHeader(entriesStream, Lucene40CompoundWriter.ENTRY_CODEC, Lucene40CompoundWriter.VERSION_START, Lucene40CompoundWriter.VERSION_CURRENT);\n      final int numEntries = entriesStream.readVInt();\n      mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (version >= Lucene40CompoundWriter.VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(entriesStream);\n      } else {\n        CodecUtil.checkEOF(entriesStream);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(entriesStream);\n      } else {\n        IOUtils.closeWhileHandlingException(entriesStream);\n      }\n    }\n    return mapping;\n  }\n\n","sourceOld":"  /** Helper method that reads CFS entries from an input stream */\n  private final Map<String, FileEntry> readEntries(Directory dir, String name) throws IOException {\n    ChecksumIndexInput entriesStream = null;\n    Map<String,FileEntry> mapping = null;\n    boolean success = false;\n    try {\n      final String entriesFileName = IndexFileNames.segmentFileName(\n                                            IndexFileNames.stripExtension(name), \"\",\n                                             IndexFileNames.COMPOUND_FILE_ENTRIES_EXTENSION);\n      entriesStream = dir.openChecksumInput(entriesFileName, IOContext.READONCE);\n      version = CodecUtil.checkHeader(entriesStream, CompoundFileWriter.ENTRY_CODEC, CompoundFileWriter.VERSION_START, CompoundFileWriter.VERSION_CURRENT);\n      final int numEntries = entriesStream.readVInt();\n      mapping = new HashMap<>(numEntries);\n      for (int i = 0; i < numEntries; i++) {\n        final FileEntry fileEntry = new FileEntry();\n        final String id = entriesStream.readString();\n        FileEntry previous = mapping.put(id, fileEntry);\n        if (previous != null) {\n          throw new CorruptIndexException(\"Duplicate cfs entry id=\" + id + \" in CFS \", entriesStream);\n        }\n        fileEntry.offset = entriesStream.readLong();\n        fileEntry.length = entriesStream.readLong();\n      }\n      if (version >= CompoundFileWriter.VERSION_CHECKSUM) {\n        CodecUtil.checkFooter(entriesStream);\n      } else {\n        CodecUtil.checkEOF(entriesStream);\n      }\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(entriesStream);\n      } else {\n        IOUtils.closeWhileHandlingException(entriesStream);\n      }\n    }\n    return mapping;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5eb2511ababf862ea11e10761c70ee560cd84510":["5ed7a1acc39e7e6f148efd1368265dd1dd8034f8","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["5ed7a1acc39e7e6f148efd1368265dd1dd8034f8"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["4e5e734869d76c22acfc12bc53ecbfcc1606c2f5"],"9a70ce9bddc6f985feb8e5e182aebe20872328d4":["43e3527ed736c46c0f0ab28181937b9de5ef7c63"],"4e5e734869d76c22acfc12bc53ecbfcc1606c2f5":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"989d940c4bf402188f4f0ae13736836885227383":["f382b2e9f4ca7dbe98e2f15da70983ecfc02b171"],"f382b2e9f4ca7dbe98e2f15da70983ecfc02b171":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"43e3527ed736c46c0f0ab28181937b9de5ef7c63":["1f3b037cd083286b2af89f96e768f85dcd8072d6"],"9bb9a29a5e71a90295f175df8919802993142c9a":["9a70ce9bddc6f985feb8e5e182aebe20872328d4","989d940c4bf402188f4f0ae13736836885227383"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"5ed7a1acc39e7e6f148efd1368265dd1dd8034f8":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["9bb9a29a5e71a90295f175df8919802993142c9a"]},"commit2Childs":{"5eb2511ababf862ea11e10761c70ee560cd84510":[],"1f3b037cd083286b2af89f96e768f85dcd8072d6":["5eb2511ababf862ea11e10761c70ee560cd84510","43e3527ed736c46c0f0ab28181937b9de5ef7c63"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["5ed7a1acc39e7e6f148efd1368265dd1dd8034f8"],"9a70ce9bddc6f985feb8e5e182aebe20872328d4":["f382b2e9f4ca7dbe98e2f15da70983ecfc02b171","9bb9a29a5e71a90295f175df8919802993142c9a"],"4e5e734869d76c22acfc12bc53ecbfcc1606c2f5":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"989d940c4bf402188f4f0ae13736836885227383":["9bb9a29a5e71a90295f175df8919802993142c9a"],"f382b2e9f4ca7dbe98e2f15da70983ecfc02b171":["989d940c4bf402188f4f0ae13736836885227383"],"43e3527ed736c46c0f0ab28181937b9de5ef7c63":["9a70ce9bddc6f985feb8e5e182aebe20872328d4"],"9bb9a29a5e71a90295f175df8919802993142c9a":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["4e5e734869d76c22acfc12bc53ecbfcc1606c2f5"],"5ed7a1acc39e7e6f148efd1368265dd1dd8034f8":["5eb2511ababf862ea11e10761c70ee560cd84510","1f3b037cd083286b2af89f96e768f85dcd8072d6"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["5eb2511ababf862ea11e10761c70ee560cd84510","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}