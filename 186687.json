{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarSortedBytesImpl.Writer#finishInternal(int).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarSortedBytesImpl.Writer#finishInternal(int).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene40/values/VarSortedBytesImpl.Writer#finishInternal(int).mjava","sourceNew":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int count = hash.size();\n      final IndexOutput datOut = getOrCreateDataOut();\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      long offset = 0;\n      final int[] index = new int[count];\n      final int[] sortedEntries = hash.sort(comp);\n      // total bytes of data\n      idxOut.writeLong(maxBytes);\n      PackedInts.Writer offsetWriter = PackedInts.getWriter(idxOut, count+1,\n          bitsRequired(maxBytes));\n      // first dump bytes data, recording index & write offset as\n      // we go\n      final BytesRef spare = new BytesRef();\n      for (int i = 0; i < count; i++) {\n        final int e = sortedEntries[i];\n        offsetWriter.add(offset);\n        index[e] = i;\n        final BytesRef bytes = hash.get(e, spare);\n        // TODO: we could prefix code...\n        datOut.writeBytes(bytes.bytes, bytes.offset, bytes.length);\n        offset += bytes.length;\n      }\n      // write sentinel\n      offsetWriter.add(offset);\n      offsetWriter.finish();\n      // write index\n      writeIndex(idxOut, docCount, count, index, docToEntry);\n\n    }\n\n","sourceOld":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int count = hash.size();\n      final IndexOutput datOut = getOrCreateDataOut();\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      long offset = 0;\n      final int[] index = new int[count];\n      final int[] sortedEntries = hash.sort(comp);\n      // total bytes of data\n      idxOut.writeLong(maxBytes);\n      PackedInts.Writer offsetWriter = PackedInts.getWriter(idxOut, count+1,\n          bitsRequired(maxBytes));\n      // first dump bytes data, recording index & write offset as\n      // we go\n      final BytesRef spare = new BytesRef();\n      for (int i = 0; i < count; i++) {\n        final int e = sortedEntries[i];\n        offsetWriter.add(offset);\n        index[e] = i;\n        final BytesRef bytes = hash.get(e, spare);\n        // TODO: we could prefix code...\n        datOut.writeBytes(bytes.bytes, bytes.offset, bytes.length);\n        offset += bytes.length;\n      }\n      // write sentinel\n      offsetWriter.add(offset);\n      offsetWriter.finish();\n      // write index\n      writeIndex(idxOut, docCount, count, index, docToEntry);\n\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4a470c93b2b0f8f51241f52705fc110a01f27ad2","date":1337969379,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarSortedBytesImpl.Writer#finishInternal(int).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarSortedBytesImpl.Writer#finishInternal(int).mjava","sourceNew":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int count = hash.size();\n      final IndexOutput datOut = getOrCreateDataOut();\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      long offset = 0;\n      final int[] index = new int[count];\n      final int[] sortedEntries = hash.sort(comp);\n      // total bytes of data\n      idxOut.writeLong(maxBytes);\n      PackedInts.Writer offsetWriter = PackedInts.getWriter(idxOut, count+1,\n          PackedInts.bitsRequired(maxBytes), PackedInts.DEFAULT);\n      // first dump bytes data, recording index & write offset as\n      // we go\n      final BytesRef spare = new BytesRef();\n      for (int i = 0; i < count; i++) {\n        final int e = sortedEntries[i];\n        offsetWriter.add(offset);\n        index[e] = i;\n        final BytesRef bytes = hash.get(e, spare);\n        // TODO: we could prefix code...\n        datOut.writeBytes(bytes.bytes, bytes.offset, bytes.length);\n        offset += bytes.length;\n      }\n      // write sentinel\n      offsetWriter.add(offset);\n      offsetWriter.finish();\n      // write index\n      writeIndex(idxOut, docCount, count, index, docToEntry);\n\n    }\n\n","sourceOld":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int count = hash.size();\n      final IndexOutput datOut = getOrCreateDataOut();\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      long offset = 0;\n      final int[] index = new int[count];\n      final int[] sortedEntries = hash.sort(comp);\n      // total bytes of data\n      idxOut.writeLong(maxBytes);\n      PackedInts.Writer offsetWriter = PackedInts.getWriter(idxOut, count+1,\n          bitsRequired(maxBytes));\n      // first dump bytes data, recording index & write offset as\n      // we go\n      final BytesRef spare = new BytesRef();\n      for (int i = 0; i < count; i++) {\n        final int e = sortedEntries[i];\n        offsetWriter.add(offset);\n        index[e] = i;\n        final BytesRef bytes = hash.get(e, spare);\n        // TODO: we could prefix code...\n        datOut.writeBytes(bytes.bytes, bytes.offset, bytes.length);\n        offset += bytes.length;\n      }\n      // write sentinel\n      offsetWriter.add(offset);\n      offsetWriter.finish();\n      // write index\n      writeIndex(idxOut, docCount, count, index, docToEntry);\n\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0837ab0472feecb3a54260729d845f839e1cbd72","date":1358283639,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarSortedBytesImpl.Writer#finishInternal(int).mjava","sourceNew":null,"sourceOld":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int count = hash.size();\n      final IndexOutput datOut = getOrCreateDataOut();\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      long offset = 0;\n      final int[] index = new int[count];\n      final int[] sortedEntries = hash.sort(comp);\n      // total bytes of data\n      idxOut.writeLong(maxBytes);\n      PackedInts.Writer offsetWriter = PackedInts.getWriter(idxOut, count+1,\n          PackedInts.bitsRequired(maxBytes), PackedInts.DEFAULT);\n      // first dump bytes data, recording index & write offset as\n      // we go\n      final BytesRef spare = new BytesRef();\n      for (int i = 0; i < count; i++) {\n        final int e = sortedEntries[i];\n        offsetWriter.add(offset);\n        index[e] = i;\n        final BytesRef bytes = hash.get(e, spare);\n        // TODO: we could prefix code...\n        datOut.writeBytes(bytes.bytes, bytes.offset, bytes.length);\n        offset += bytes.length;\n      }\n      // write sentinel\n      offsetWriter.add(offset);\n      offsetWriter.finish();\n      // write index\n      writeIndex(idxOut, docCount, count, index, docToEntry);\n\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":4,"author":"Robert Muir","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene40/values/VarSortedBytesImpl.Writer#finishInternal(int).mjava","sourceNew":null,"sourceOld":"    // Important that we get docCount, in case there were\n    // some last docs that we didn't see\n    @Override\n    public void finishInternal(int docCount) throws IOException {\n      fillDefault(docCount);\n      final int count = hash.size();\n      final IndexOutput datOut = getOrCreateDataOut();\n      final IndexOutput idxOut = getOrCreateIndexOut();\n      long offset = 0;\n      final int[] index = new int[count];\n      final int[] sortedEntries = hash.sort(comp);\n      // total bytes of data\n      idxOut.writeLong(maxBytes);\n      PackedInts.Writer offsetWriter = PackedInts.getWriter(idxOut, count+1,\n          PackedInts.bitsRequired(maxBytes), PackedInts.DEFAULT);\n      // first dump bytes data, recording index & write offset as\n      // we go\n      final BytesRef spare = new BytesRef();\n      for (int i = 0; i < count; i++) {\n        final int e = sortedEntries[i];\n        offsetWriter.add(offset);\n        index[e] = i;\n        final BytesRef bytes = hash.get(e, spare);\n        // TODO: we could prefix code...\n        datOut.writeBytes(bytes.bytes, bytes.offset, bytes.length);\n        offset += bytes.length;\n      }\n      // write sentinel\n      offsetWriter.add(offset);\n      offsetWriter.finish();\n      // write index\n      writeIndex(idxOut, docCount, count, index, docToEntry);\n\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"d4d69c535930b5cce125cff868d40f6373dc27d4":["4a470c93b2b0f8f51241f52705fc110a01f27ad2","0837ab0472feecb3a54260729d845f839e1cbd72"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"0837ab0472feecb3a54260729d845f839e1cbd72":["4a470c93b2b0f8f51241f52705fc110a01f27ad2"],"4a470c93b2b0f8f51241f52705fc110a01f27ad2":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d4d69c535930b5cce125cff868d40f6373dc27d4"]},"commit2Childs":{"d4d69c535930b5cce125cff868d40f6373dc27d4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["4a470c93b2b0f8f51241f52705fc110a01f27ad2"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"0837ab0472feecb3a54260729d845f839e1cbd72":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"4a470c93b2b0f8f51241f52705fc110a01f27ad2":["d4d69c535930b5cce125cff868d40f6373dc27d4","0837ab0472feecb3a54260729d845f839e1cbd72"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}