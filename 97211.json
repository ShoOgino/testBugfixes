{"path":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","pathOld":"src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","sourceNew":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  new Field(idTerm.field(), idString, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        Field.TermVector tvVal = Field.TermVector.NO;\n        switch (nextInt(4)) {\n        case 0:\n          tvVal = Field.TermVector.NO;\n          break;\n        case 1:\n          tvVal = Field.TermVector.YES;\n          break;\n        case 2:\n          tvVal = Field.TermVector.WITH_POSITIONS;\n          break;\n        case 3:\n          tvVal = Field.TermVector.WITH_POSITIONS_OFFSETS;\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            fields.add(new Field(\"f\" + nextInt(100), getString(1), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS, tvVal));\n            break;\n          case 1:\n            fields.add(new Field(\"f\" + nextInt(100), getString(0), Field.Store.NO, Field.Index.ANALYZED, tvVal));\n            break;\n          case 2:\n            fields.add(new Field(\"f\" + nextInt(100), getString(0), Field.Store.YES, Field.Index.NO, Field.TermVector.NO));\n            break;\n          case 3:\n            fields.add(new Field(\"f\" + nextInt(100), getString(bigFieldSize), Field.Store.YES, Field.Index.ANALYZED, tvVal));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      w.updateDocument(idTerm.createTerm(idString), d);\n      // System.out.println(\"indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","sourceOld":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  new Field(idTerm.field(), idString, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        Field.TermVector tvVal = Field.TermVector.NO;\n        switch (nextInt(4)) {\n        case 0:\n          tvVal = Field.TermVector.NO;\n          break;\n        case 1:\n          tvVal = Field.TermVector.YES;\n          break;\n        case 2:\n          tvVal = Field.TermVector.WITH_POSITIONS;\n          break;\n        case 3:\n          tvVal = Field.TermVector.WITH_POSITIONS_OFFSETS;\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            fields.add(new Field(\"f\" + nextInt(100), getString(1), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS, tvVal));\n            break;\n          case 1:\n            fields.add(new Field(\"f\" + nextInt(100), getString(0), Field.Store.NO, Field.Index.ANALYZED, tvVal));\n            break;\n          case 2:\n            fields.add(new Field(\"f\" + nextInt(100), getString(0), Field.Store.YES, Field.Index.NO, Field.TermVector.NO));\n            break;\n          case 3:\n            fields.add(new Field(\"f\" + nextInt(100), getString(bigFieldSize), Field.Store.YES, Field.Index.ANALYZED, tvVal));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      w.updateDocument(idTerm.createTerm(idString), d);\n      // System.out.println(\"indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"132903c28af3aa6f67284b78de91c0f0a99488c2","date":1284282129,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","sourceNew":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  newField(idTerm.field(), idString, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        Field.TermVector tvVal = Field.TermVector.NO;\n        switch (nextInt(4)) {\n        case 0:\n          tvVal = Field.TermVector.NO;\n          break;\n        case 1:\n          tvVal = Field.TermVector.YES;\n          break;\n        case 2:\n          tvVal = Field.TermVector.WITH_POSITIONS;\n          break;\n        case 3:\n          tvVal = Field.TermVector.WITH_POSITIONS_OFFSETS;\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            fields.add(newField(\"f\" + nextInt(100), getString(1), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS, tvVal));\n            break;\n          case 1:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.NO, Field.Index.ANALYZED, tvVal));\n            break;\n          case 2:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.YES, Field.Index.NO, Field.TermVector.NO));\n            break;\n          case 3:\n            fields.add(newField(\"f\" + nextInt(100), getString(bigFieldSize), Field.Store.YES, Field.Index.ANALYZED, tvVal));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      w.updateDocument(idTerm.createTerm(idString), d);\n      // System.out.println(\"indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","sourceOld":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  new Field(idTerm.field(), idString, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        Field.TermVector tvVal = Field.TermVector.NO;\n        switch (nextInt(4)) {\n        case 0:\n          tvVal = Field.TermVector.NO;\n          break;\n        case 1:\n          tvVal = Field.TermVector.YES;\n          break;\n        case 2:\n          tvVal = Field.TermVector.WITH_POSITIONS;\n          break;\n        case 3:\n          tvVal = Field.TermVector.WITH_POSITIONS_OFFSETS;\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            fields.add(new Field(\"f\" + nextInt(100), getString(1), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS, tvVal));\n            break;\n          case 1:\n            fields.add(new Field(\"f\" + nextInt(100), getString(0), Field.Store.NO, Field.Index.ANALYZED, tvVal));\n            break;\n          case 2:\n            fields.add(new Field(\"f\" + nextInt(100), getString(0), Field.Store.YES, Field.Index.NO, Field.TermVector.NO));\n            break;\n          case 3:\n            fields.add(new Field(\"f\" + nextInt(100), getString(bigFieldSize), Field.Store.YES, Field.Index.ANALYZED, tvVal));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      w.updateDocument(idTerm.createTerm(idString), d);\n      // System.out.println(\"indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"44fcbde6fb2ac44ee3b45e013e54a42911e689ff","date":1292065621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","sourceNew":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  newField(idTerm.field(), idString, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        Field.TermVector tvVal = Field.TermVector.NO;\n        switch (nextInt(4)) {\n        case 0:\n          tvVal = Field.TermVector.NO;\n          break;\n        case 1:\n          tvVal = Field.TermVector.YES;\n          break;\n        case 2:\n          tvVal = Field.TermVector.WITH_POSITIONS;\n          break;\n        case 3:\n          tvVal = Field.TermVector.WITH_POSITIONS_OFFSETS;\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            fields.add(newField(\"f\" + nextInt(100), getString(1), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS, tvVal));\n            break;\n          case 1:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.NO, Field.Index.ANALYZED, tvVal));\n            break;\n          case 2:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.YES, Field.Index.NO, Field.TermVector.NO));\n            break;\n          case 3:\n            fields.add(newField(\"f\" + nextInt(100), getString(bigFieldSize), Field.Store.YES, Field.Index.ANALYZED, tvVal));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      if (VERBOSE) {\n        System.out.println(Thread.currentThread().getName() + \": indexing id:\" + idString);\n      }\n      w.updateDocument(idTerm.createTerm(idString), d);\n      //System.out.println(Thread.currentThread().getName() + \": indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","sourceOld":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  newField(idTerm.field(), idString, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        Field.TermVector tvVal = Field.TermVector.NO;\n        switch (nextInt(4)) {\n        case 0:\n          tvVal = Field.TermVector.NO;\n          break;\n        case 1:\n          tvVal = Field.TermVector.YES;\n          break;\n        case 2:\n          tvVal = Field.TermVector.WITH_POSITIONS;\n          break;\n        case 3:\n          tvVal = Field.TermVector.WITH_POSITIONS_OFFSETS;\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            fields.add(newField(\"f\" + nextInt(100), getString(1), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS, tvVal));\n            break;\n          case 1:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.NO, Field.Index.ANALYZED, tvVal));\n            break;\n          case 2:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.YES, Field.Index.NO, Field.TermVector.NO));\n            break;\n          case 3:\n            fields.add(newField(\"f\" + nextInt(100), getString(bigFieldSize), Field.Store.YES, Field.Index.ANALYZED, tvVal));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      w.updateDocument(idTerm.createTerm(idString), d);\n      // System.out.println(\"indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab5cb6a74aefb78aa0569857970b9151dfe2e787","date":1292842407,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","sourceNew":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  newField(idTerm.field(), idString, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        Field.TermVector tvVal = Field.TermVector.NO;\n        switch (nextInt(4)) {\n        case 0:\n          tvVal = Field.TermVector.NO;\n          break;\n        case 1:\n          tvVal = Field.TermVector.YES;\n          break;\n        case 2:\n          tvVal = Field.TermVector.WITH_POSITIONS;\n          break;\n        case 3:\n          tvVal = Field.TermVector.WITH_POSITIONS_OFFSETS;\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            fields.add(newField(\"f\" + nextInt(100), getString(1), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS, tvVal));\n            break;\n          case 1:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.NO, Field.Index.ANALYZED, tvVal));\n            break;\n          case 2:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.YES, Field.Index.NO, Field.TermVector.NO));\n            break;\n          case 3:\n            fields.add(newField(\"f\" + nextInt(100), getString(bigFieldSize), Field.Store.YES, Field.Index.ANALYZED, tvVal));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      if (VERBOSE) {\n        System.out.println(Thread.currentThread().getName() + \": indexing id:\" + idString);\n      }\n      w.updateDocument(idTerm.createTerm(idString), d);\n      //System.out.println(Thread.currentThread().getName() + \": indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","sourceOld":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  newField(idTerm.field(), idString, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        Field.TermVector tvVal = Field.TermVector.NO;\n        switch (nextInt(4)) {\n        case 0:\n          tvVal = Field.TermVector.NO;\n          break;\n        case 1:\n          tvVal = Field.TermVector.YES;\n          break;\n        case 2:\n          tvVal = Field.TermVector.WITH_POSITIONS;\n          break;\n        case 3:\n          tvVal = Field.TermVector.WITH_POSITIONS_OFFSETS;\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            fields.add(newField(\"f\" + nextInt(100), getString(1), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS, tvVal));\n            break;\n          case 1:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.NO, Field.Index.ANALYZED, tvVal));\n            break;\n          case 2:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.YES, Field.Index.NO, Field.TermVector.NO));\n            break;\n          case 3:\n            fields.add(newField(\"f\" + nextInt(100), getString(bigFieldSize), Field.Store.YES, Field.Index.ANALYZED, tvVal));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      w.updateDocument(idTerm.createTerm(idString), d);\n      // System.out.println(\"indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","sourceNew":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  newField(idTerm.field(), idString, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        Field.TermVector tvVal = Field.TermVector.NO;\n        switch (nextInt(4)) {\n        case 0:\n          tvVal = Field.TermVector.NO;\n          break;\n        case 1:\n          tvVal = Field.TermVector.YES;\n          break;\n        case 2:\n          tvVal = Field.TermVector.WITH_POSITIONS;\n          break;\n        case 3:\n          tvVal = Field.TermVector.WITH_POSITIONS_OFFSETS;\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            fields.add(newField(\"f\" + nextInt(100), getString(1), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS, tvVal));\n            break;\n          case 1:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.NO, Field.Index.ANALYZED, tvVal));\n            break;\n          case 2:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.YES, Field.Index.NO, Field.TermVector.NO));\n            break;\n          case 3:\n            fields.add(newField(\"f\" + nextInt(100), getString(bigFieldSize), Field.Store.YES, Field.Index.ANALYZED, tvVal));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      if (VERBOSE) {\n        System.out.println(Thread.currentThread().getName() + \": indexing id:\" + idString);\n      }\n      w.updateDocument(idTerm.createTerm(idString), d);\n      //System.out.println(Thread.currentThread().getName() + \": indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","sourceOld":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  new Field(idTerm.field(), idString, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        Field.TermVector tvVal = Field.TermVector.NO;\n        switch (nextInt(4)) {\n        case 0:\n          tvVal = Field.TermVector.NO;\n          break;\n        case 1:\n          tvVal = Field.TermVector.YES;\n          break;\n        case 2:\n          tvVal = Field.TermVector.WITH_POSITIONS;\n          break;\n        case 3:\n          tvVal = Field.TermVector.WITH_POSITIONS_OFFSETS;\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            fields.add(new Field(\"f\" + nextInt(100), getString(1), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS, tvVal));\n            break;\n          case 1:\n            fields.add(new Field(\"f\" + nextInt(100), getString(0), Field.Store.NO, Field.Index.ANALYZED, tvVal));\n            break;\n          case 2:\n            fields.add(new Field(\"f\" + nextInt(100), getString(0), Field.Store.YES, Field.Index.NO, Field.TermVector.NO));\n            break;\n          case 3:\n            fields.add(new Field(\"f\" + nextInt(100), getString(bigFieldSize), Field.Store.YES, Field.Index.ANALYZED, tvVal));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      w.updateDocument(idTerm.createTerm(idString), d);\n      // System.out.println(\"indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153","date":1308670974,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","sourceNew":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  newField(\"id\", idString, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        Field.TermVector tvVal = Field.TermVector.NO;\n        switch (nextInt(4)) {\n        case 0:\n          tvVal = Field.TermVector.NO;\n          break;\n        case 1:\n          tvVal = Field.TermVector.YES;\n          break;\n        case 2:\n          tvVal = Field.TermVector.WITH_POSITIONS;\n          break;\n        case 3:\n          tvVal = Field.TermVector.WITH_POSITIONS_OFFSETS;\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            fields.add(newField(\"f\" + nextInt(100), getString(1), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS, tvVal));\n            break;\n          case 1:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.NO, Field.Index.ANALYZED, tvVal));\n            break;\n          case 2:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.YES, Field.Index.NO, Field.TermVector.NO));\n            break;\n          case 3:\n            fields.add(newField(\"f\" + nextInt(100), getString(bigFieldSize), Field.Store.YES, Field.Index.ANALYZED, tvVal));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      if (VERBOSE) {\n        System.out.println(Thread.currentThread().getName() + \": indexing id:\" + idString);\n      }\n      w.updateDocument(new Term(\"id\", idString), d);\n      //System.out.println(Thread.currentThread().getName() + \": indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","sourceOld":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  newField(idTerm.field(), idString, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        Field.TermVector tvVal = Field.TermVector.NO;\n        switch (nextInt(4)) {\n        case 0:\n          tvVal = Field.TermVector.NO;\n          break;\n        case 1:\n          tvVal = Field.TermVector.YES;\n          break;\n        case 2:\n          tvVal = Field.TermVector.WITH_POSITIONS;\n          break;\n        case 3:\n          tvVal = Field.TermVector.WITH_POSITIONS_OFFSETS;\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            fields.add(newField(\"f\" + nextInt(100), getString(1), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS, tvVal));\n            break;\n          case 1:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.NO, Field.Index.ANALYZED, tvVal));\n            break;\n          case 2:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.YES, Field.Index.NO, Field.TermVector.NO));\n            break;\n          case 3:\n            fields.add(newField(\"f\" + nextInt(100), getString(bigFieldSize), Field.Store.YES, Field.Index.ANALYZED, tvVal));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      if (VERBOSE) {\n        System.out.println(Thread.currentThread().getName() + \": indexing id:\" + idString);\n      }\n      w.updateDocument(idTerm.createTerm(idString), d);\n      //System.out.println(Thread.currentThread().getName() + \": indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2553b00f699380c64959ccb27991289aae87be2e","date":1309290151,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","sourceNew":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  newField(\"id\", idString, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        Field.TermVector tvVal = Field.TermVector.NO;\n        switch (nextInt(4)) {\n        case 0:\n          tvVal = Field.TermVector.NO;\n          break;\n        case 1:\n          tvVal = Field.TermVector.YES;\n          break;\n        case 2:\n          tvVal = Field.TermVector.WITH_POSITIONS;\n          break;\n        case 3:\n          tvVal = Field.TermVector.WITH_POSITIONS_OFFSETS;\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            fields.add(newField(\"f\" + nextInt(100), getString(1), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS, tvVal));\n            break;\n          case 1:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.NO, Field.Index.ANALYZED, tvVal));\n            break;\n          case 2:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.YES, Field.Index.NO, Field.TermVector.NO));\n            break;\n          case 3:\n            fields.add(newField(\"f\" + nextInt(100), getString(bigFieldSize), Field.Store.YES, Field.Index.ANALYZED, tvVal));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      if (VERBOSE) {\n        System.out.println(Thread.currentThread().getName() + \": indexing id:\" + idString);\n      }\n      w.updateDocument(new Term(\"id\", idString), d);\n      //System.out.println(Thread.currentThread().getName() + \": indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","sourceOld":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  newField(idTerm.field(), idString, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        Field.TermVector tvVal = Field.TermVector.NO;\n        switch (nextInt(4)) {\n        case 0:\n          tvVal = Field.TermVector.NO;\n          break;\n        case 1:\n          tvVal = Field.TermVector.YES;\n          break;\n        case 2:\n          tvVal = Field.TermVector.WITH_POSITIONS;\n          break;\n        case 3:\n          tvVal = Field.TermVector.WITH_POSITIONS_OFFSETS;\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            fields.add(newField(\"f\" + nextInt(100), getString(1), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS, tvVal));\n            break;\n          case 1:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.NO, Field.Index.ANALYZED, tvVal));\n            break;\n          case 2:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.YES, Field.Index.NO, Field.TermVector.NO));\n            break;\n          case 3:\n            fields.add(newField(\"f\" + nextInt(100), getString(bigFieldSize), Field.Store.YES, Field.Index.ANALYZED, tvVal));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      if (VERBOSE) {\n        System.out.println(Thread.currentThread().getName() + \": indexing id:\" + idString);\n      }\n      w.updateDocument(idTerm.createTerm(idString), d);\n      //System.out.println(Thread.currentThread().getName() + \": indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d083e83f225b11e5fdd900e83d26ddb385b6955c","date":1310029438,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","sourceNew":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  newField(\"id\", idString, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        Field.TermVector tvVal = Field.TermVector.NO;\n        switch (nextInt(4)) {\n        case 0:\n          tvVal = Field.TermVector.NO;\n          break;\n        case 1:\n          tvVal = Field.TermVector.YES;\n          break;\n        case 2:\n          tvVal = Field.TermVector.WITH_POSITIONS;\n          break;\n        case 3:\n          tvVal = Field.TermVector.WITH_POSITIONS_OFFSETS;\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            fields.add(newField(\"f\" + nextInt(100), getString(1), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS, tvVal));\n            break;\n          case 1:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.NO, Field.Index.ANALYZED, tvVal));\n            break;\n          case 2:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.YES, Field.Index.NO, Field.TermVector.NO));\n            break;\n          case 3:\n            fields.add(newField(\"f\" + nextInt(100), getString(bigFieldSize), Field.Store.YES, Field.Index.ANALYZED, tvVal));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      if (VERBOSE) {\n        System.out.println(Thread.currentThread().getName() + \": indexing id:\" + idString);\n      }\n      w.updateDocument(new Term(\"id\", idString), d);\n      //System.out.println(Thread.currentThread().getName() + \": indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","sourceOld":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  newField(idTerm.field(), idString, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        Field.TermVector tvVal = Field.TermVector.NO;\n        switch (nextInt(4)) {\n        case 0:\n          tvVal = Field.TermVector.NO;\n          break;\n        case 1:\n          tvVal = Field.TermVector.YES;\n          break;\n        case 2:\n          tvVal = Field.TermVector.WITH_POSITIONS;\n          break;\n        case 3:\n          tvVal = Field.TermVector.WITH_POSITIONS_OFFSETS;\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            fields.add(newField(\"f\" + nextInt(100), getString(1), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS, tvVal));\n            break;\n          case 1:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.NO, Field.Index.ANALYZED, tvVal));\n            break;\n          case 2:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.YES, Field.Index.NO, Field.TermVector.NO));\n            break;\n          case 3:\n            fields.add(newField(\"f\" + nextInt(100), getString(bigFieldSize), Field.Store.YES, Field.Index.ANALYZED, tvVal));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      if (VERBOSE) {\n        System.out.println(Thread.currentThread().getName() + \": indexing id:\" + idString);\n      }\n      w.updateDocument(idTerm.createTerm(idString), d);\n      //System.out.println(Thread.currentThread().getName() + \": indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","sourceNew":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      FieldType customType1 = new FieldType(TextField.TYPE_STORED);\n      customType1.setTokenized(false);\n      customType1.setOmitNorms(true);\n      \n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  newField(\"id\", idString, customType1);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        FieldType customType = new FieldType();\n        switch (nextInt(4)) {\n        case 0:\n          break;\n        case 1:\n          customType.setStoreTermVectors(true);\n          break;\n        case 2:\n          customType.setStoreTermVectors(true);\n          customType.setStoreTermVectorPositions(true);\n          break;\n        case 3:\n          customType.setStoreTermVectors(true);\n          customType.setStoreTermVectorOffsets(true);\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            customType.setStored(true);\n            customType.setOmitNorms(true);\n            customType.setIndexed(true);\n            fields.add(newField(\"f\" + nextInt(100), getString(1), customType));\n            break;\n          case 1:\n            customType.setIndexed(true);\n            customType.setTokenized(true);\n            fields.add(newField(\"f\" + nextInt(100), getString(0), customType));\n            break;\n          case 2:\n            customType.setStored(true);\n            customType.setStoreTermVectors(false);\n            customType.setStoreTermVectorOffsets(false);\n            customType.setStoreTermVectorPositions(false);\n            fields.add(newField(\"f\" + nextInt(100), getString(0), customType));\n            break;\n          case 3:\n            customType.setStored(true);\n            customType.setIndexed(true);\n            customType.setTokenized(true);\n            fields.add(newField(\"f\" + nextInt(100), getString(bigFieldSize), customType));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      if (VERBOSE) {\n        System.out.println(Thread.currentThread().getName() + \": indexing id:\" + idString);\n      }\n      w.updateDocument(new Term(\"id\", idString), d);\n      //System.out.println(Thread.currentThread().getName() + \": indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","sourceOld":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  newField(\"id\", idString, Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        Field.TermVector tvVal = Field.TermVector.NO;\n        switch (nextInt(4)) {\n        case 0:\n          tvVal = Field.TermVector.NO;\n          break;\n        case 1:\n          tvVal = Field.TermVector.YES;\n          break;\n        case 2:\n          tvVal = Field.TermVector.WITH_POSITIONS;\n          break;\n        case 3:\n          tvVal = Field.TermVector.WITH_POSITIONS_OFFSETS;\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            fields.add(newField(\"f\" + nextInt(100), getString(1), Field.Store.YES, Field.Index.NOT_ANALYZED_NO_NORMS, tvVal));\n            break;\n          case 1:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.NO, Field.Index.ANALYZED, tvVal));\n            break;\n          case 2:\n            fields.add(newField(\"f\" + nextInt(100), getString(0), Field.Store.YES, Field.Index.NO, Field.TermVector.NO));\n            break;\n          case 3:\n            fields.add(newField(\"f\" + nextInt(100), getString(bigFieldSize), Field.Store.YES, Field.Index.ANALYZED, tvVal));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      if (VERBOSE) {\n        System.out.println(Thread.currentThread().getName() + \": indexing id:\" + idString);\n      }\n      w.updateDocument(new Term(\"id\", idString), d);\n      //System.out.println(Thread.currentThread().getName() + \": indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestStressIndexing2.IndexingThread#indexDoc().mjava","sourceNew":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      FieldType customType1 = new FieldType(TextField.TYPE_STORED);\n      customType1.setTokenized(false);\n      customType1.setOmitNorms(true);\n      \n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  newField(\"id\", idString, customType1);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        FieldType customType = new FieldType();\n        switch (nextInt(4)) {\n        case 0:\n          break;\n        case 1:\n          customType.setStoreTermVectors(true);\n          break;\n        case 2:\n          customType.setStoreTermVectors(true);\n          customType.setStoreTermVectorPositions(true);\n          break;\n        case 3:\n          customType.setStoreTermVectors(true);\n          customType.setStoreTermVectorOffsets(true);\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            customType.setStored(true);\n            customType.setOmitNorms(true);\n            customType.setIndexed(true);\n            fields.add(newField(\"f\" + nextInt(100), getString(1), customType));\n            break;\n          case 1:\n            customType.setIndexed(true);\n            customType.setTokenized(true);\n            fields.add(newField(\"f\" + nextInt(100), getString(0), customType));\n            break;\n          case 2:\n            customType.setStored(true);\n            customType.setStoreTermVectors(false);\n            customType.setStoreTermVectorOffsets(false);\n            customType.setStoreTermVectorPositions(false);\n            fields.add(newField(\"f\" + nextInt(100), getString(0), customType));\n            break;\n          case 3:\n            customType.setStored(true);\n            customType.setIndexed(true);\n            customType.setTokenized(true);\n            fields.add(newField(\"f\" + nextInt(100), getString(bigFieldSize), customType));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      if (VERBOSE) {\n        System.out.println(Thread.currentThread().getName() + \": indexing id:\" + idString);\n      }\n      w.updateDocument(new Term(\"id\", idString), d);\n      //System.out.println(Thread.currentThread().getName() + \": indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","sourceOld":"    public void indexDoc() throws IOException {\n      Document d = new Document();\n\n      FieldType customType1 = new FieldType(TextField.TYPE_STORED);\n      customType1.setTokenized(false);\n      customType1.setOmitNorms(true);\n      \n      ArrayList<Field> fields = new ArrayList<Field>();      \n      String idString = getIdString();\n      Field idField =  newField(\"id\", idString, customType1);\n      fields.add(idField);\n\n      int nFields = nextInt(maxFields);\n      for (int i=0; i<nFields; i++) {\n\n        FieldType customType = new FieldType();\n        switch (nextInt(4)) {\n        case 0:\n          break;\n        case 1:\n          customType.setStoreTermVectors(true);\n          break;\n        case 2:\n          customType.setStoreTermVectors(true);\n          customType.setStoreTermVectorPositions(true);\n          break;\n        case 3:\n          customType.setStoreTermVectors(true);\n          customType.setStoreTermVectorOffsets(true);\n          break;\n        }\n        \n        switch (nextInt(4)) {\n          case 0:\n            customType.setStored(true);\n            customType.setOmitNorms(true);\n            customType.setIndexed(true);\n            fields.add(newField(\"f\" + nextInt(100), getString(1), customType));\n            break;\n          case 1:\n            customType.setIndexed(true);\n            customType.setTokenized(true);\n            fields.add(newField(\"f\" + nextInt(100), getString(0), customType));\n            break;\n          case 2:\n            customType.setStored(true);\n            customType.setStoreTermVectors(false);\n            customType.setStoreTermVectorOffsets(false);\n            customType.setStoreTermVectorPositions(false);\n            fields.add(newField(\"f\" + nextInt(100), getString(0), customType));\n            break;\n          case 3:\n            customType.setStored(true);\n            customType.setIndexed(true);\n            customType.setTokenized(true);\n            fields.add(newField(\"f\" + nextInt(100), getString(bigFieldSize), customType));\n            break;          \n        }\n      }\n\n      if (sameFieldOrder) {\n        Collections.sort(fields, fieldNameComparator);\n      } else {\n        // random placement of id field also\n        Collections.swap(fields,nextInt(fields.size()), 0);\n      }\n\n      for (int i=0; i<fields.size(); i++) {\n        d.add(fields.get(i));\n      }\n      if (VERBOSE) {\n        System.out.println(Thread.currentThread().getName() + \": indexing id:\" + idString);\n      }\n      w.updateDocument(new Term(\"id\", idString), d);\n      //System.out.println(Thread.currentThread().getName() + \": indexing \"+d);\n      docs.put(idString, d);\n    }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["132903c28af3aa6f67284b78de91c0f0a99488c2"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":["132903c28af3aa6f67284b78de91c0f0a99488c2","44fcbde6fb2ac44ee3b45e013e54a42911e689ff"],"132903c28af3aa6f67284b78de91c0f0a99488c2":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"2553b00f699380c64959ccb27991289aae87be2e":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff","fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["9454a6510e2db155fb01faa5c049b06ece95fab9","44fcbde6fb2ac44ee3b45e013e54a42911e689ff"],"d083e83f225b11e5fdd900e83d26ddb385b6955c":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff","fafef7c83fe8e0b3ca9298d5d75d6b943dc28153"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"44fcbde6fb2ac44ee3b45e013e54a42911e689ff":["fafef7c83fe8e0b3ca9298d5d75d6b943dc28153","ab5cb6a74aefb78aa0569857970b9151dfe2e787","2553b00f699380c64959ccb27991289aae87be2e","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fafef7c83fe8e0b3ca9298d5d75d6b943dc28153":["1509f151d7692d84fae414b2b799ac06ba60fcb4","2553b00f699380c64959ccb27991289aae87be2e","d083e83f225b11e5fdd900e83d26ddb385b6955c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"ab5cb6a74aefb78aa0569857970b9151dfe2e787":[],"132903c28af3aa6f67284b78de91c0f0a99488c2":["44fcbde6fb2ac44ee3b45e013e54a42911e689ff","ab5cb6a74aefb78aa0569857970b9151dfe2e787"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"2553b00f699380c64959ccb27991289aae87be2e":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":[],"d083e83f225b11e5fdd900e83d26ddb385b6955c":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["132903c28af3aa6f67284b78de91c0f0a99488c2","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ab5cb6a74aefb78aa0569857970b9151dfe2e787","2553b00f699380c64959ccb27991289aae87be2e","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","d083e83f225b11e5fdd900e83d26ddb385b6955c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}