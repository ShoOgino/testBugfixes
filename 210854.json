{"path":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"lucene/contrib/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","date":1338430031,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = IndexReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a7e4907084808af8fdb14b9809e6dceaccf6867b","date":1343473006,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      StoredDocument doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d028314cced5858683a1bb4741423d0f934257b","date":1346596535,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      StoredDocument doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ad1f7eb1a6bbf19f3d32b3baf2dee3db844eccdc","date":1366056945,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      StoredDocument doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = new IndexSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      StoredDocument doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc","date":1424799790,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      StoredDocument doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, null, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      StoredDocument doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      StoredDocument doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"83788ad129a5154d5c6562c4e8ce3db48793aada","date":1532961485,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, 10);\n    for( int i = 0; i < hits.totalHits.value; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, 10);\n    for( int i = 0; i < hits.totalHits; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d77dafd89756a5161d244985903e3487ca109182","date":1548679743,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","pathOld":"lucene/highlighter/src/test/org/apache/lucene/search/highlight/HighlighterTest#searchIndex().mjava","sourceNew":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = DirectoryReader.open(dir1);\n    IndexSearcher searcher = newSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, 10);\n    for( int i = 0; i < hits.totalHits.value; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","sourceOld":"  private void searchIndex() throws IOException, InvalidTokenOffsetsException {\n    Query query = new TermQuery(new Term(\"t_text1\", \"random\"));\n    IndexReader reader = DirectoryReader.open(dir);\n    IndexSearcher searcher = newSearcher(reader);\n    // This scorer can return negative idf -> null fragment\n    Scorer scorer = new QueryTermScorer( query, searcher.getIndexReader(), \"t_text1\" );\n    // This scorer doesn't use idf (patch version)\n    //Scorer scorer = new QueryTermScorer( query, \"t_text1\" );\n    Highlighter h = new Highlighter( scorer );\n\n    TopDocs hits = searcher.search(query, 10);\n    for( int i = 0; i < hits.totalHits.value; i++ ){\n      Document doc = searcher.doc( hits.scoreDocs[i].doc );\n      String result = h.getBestFragment( a, \"t_text1\", doc.get( \"t_text1\" ));\n      if (VERBOSE) System.out.println(\"result:\" +  result);\n      assertEquals(\"more <B>random</B> words for second field\", result);\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1d028314cced5858683a1bb4741423d0f934257b":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f","a7e4907084808af8fdb14b9809e6dceaccf6867b"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["ad1f7eb1a6bbf19f3d32b3baf2dee3db844eccdc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d77dafd89756a5161d244985903e3487ca109182":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"ad1f7eb1a6bbf19f3d32b3baf2dee3db844eccdc":["1d028314cced5858683a1bb4741423d0f934257b"],"a7e4907084808af8fdb14b9809e6dceaccf6867b":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d77dafd89756a5161d244985903e3487ca109182"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["e7e8d6f15900ee22ac3cb0a503f15dc952a3580f"],"1d028314cced5858683a1bb4741423d0f934257b":["ad1f7eb1a6bbf19f3d32b3baf2dee3db844eccdc"],"e7e8d6f15900ee22ac3cb0a503f15dc952a3580f":["1d028314cced5858683a1bb4741423d0f934257b","a7e4907084808af8fdb14b9809e6dceaccf6867b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"d77dafd89756a5161d244985903e3487ca109182":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"83788ad129a5154d5c6562c4e8ce3db48793aada":["d77dafd89756a5161d244985903e3487ca109182"],"a7e4907084808af8fdb14b9809e6dceaccf6867b":["1d028314cced5858683a1bb4741423d0f934257b"],"ad1f7eb1a6bbf19f3d32b3baf2dee3db844eccdc":["f8ec642b0195d666cf3b5a6a6c2a80bdd3b756bc"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["83788ad129a5154d5c6562c4e8ce3db48793aada"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}