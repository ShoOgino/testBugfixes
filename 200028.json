{"path":"solr/core/src/test/org/apache/solr/cloud/TestSegmentSorting#testAtomicUpdateOfSegmentSortField().mjava","commits":[{"id":"415bbbe7da8065dd3c477bdc3c703c6425622998","date":1485393793,"type":0,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSegmentSorting#testAtomicUpdateOfSegmentSortField().mjava","pathOld":"/dev/null","sourceNew":"  /** \n   * Verify that atomic updates against our (DVO) segment sort field doesn't cause errors.\n   * In this situation, the updates should *NOT* be done inplace, because that would\n   * break the index sorting\n   */\n  public void testAtomicUpdateOfSegmentSortField() throws Exception {\n\n    final CloudSolrClient cloudSolrClient = cluster.getSolrClient();\n    final String updateField = SegmentTerminateEarlyTestState.timestampField;\n\n    // sanity check that updateField is in fact a DocValues only field, meaning it\n    // would normally be eligable for inplace updates -- if it weren't also used for merge sorting\n    final Map<String,Object> schemaOpts\n      = new Field(updateField, params(\"includeDynamic\", \"true\",\n                                      \"showDefaults\",\"true\")).process(cloudSolrClient).getField();\n    assertEquals(true, schemaOpts.get(\"docValues\"));\n    assertEquals(false, schemaOpts.get(\"indexed\"));\n    assertEquals(false, schemaOpts.get(\"stored\"));\n    \n    // add some documents\n    final int numDocs = atLeast(1000);\n    for (int id = 1; id <= numDocs; id++) {\n      cloudSolrClient.add(sdoc(\"id\", id, updateField, random().nextInt(60)));\n                               \n    }\n    cloudSolrClient.commit();\n\n    // do some random iterations of replacing docs, atomic updates against segment sort field, and commits\n    // (at this point we're just sanity checking no serious failures)\n    for (int iter = 0; iter < 20; iter++) {\n      final int iterSize = atLeast(20);\n      for (int i = 0; i < iterSize; i++) {\n        // replace\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, random().nextInt(60)));\n        // atomic update\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, map(\"set\", random().nextInt(60))));\n      }\n      cloudSolrClient.commit();\n    }\n\n    \n    // pick a random doc, and verify that doing an atomic update causes the docid to change\n    // ie: not an inplace update\n    final int id = TestUtil.nextInt(random(), 1, numDocs);\n    final int oldDocId = (Integer) cloudSolrClient.getById(\"\"+id, params(\"fl\",\"[docid]\")).get(\"[docid]\");\n    \n    cloudSolrClient.add(sdoc(\"id\", id, updateField, map(\"inc\",\"666\")));\n    cloudSolrClient.commit();\n    \n    // loop incase we're waiting for a newSearcher to be opened\n    int newDocId = -1;\n    int attempts = 10;\n    while ((newDocId < 0) && (0 < attempts--)) {\n      SolrDocumentList docs = cloudSolrClient.query(params(\"q\", \"id:\"+id,\n                                                           \"fl\",\"[docid]\",\n                                                           \"fq\", updateField + \"[666 TO *]\")).getResults();\n      if (0 < docs.size()) {\n        newDocId = (Integer)docs.get(0).get(\"[docid]\");\n      } else {\n        Thread.sleep(50);\n      }\n    }\n    assertTrue(oldDocId != newDocId);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"598b5d23aa7c9732bf473c21a9cd309c44599394","date":1485530378,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSegmentSorting#testAtomicUpdateOfSegmentSortField().mjava","pathOld":"/dev/null","sourceNew":"  /** \n   * Verify that atomic updates against our (DVO) segment sort field doesn't cause errors.\n   * In this situation, the updates should *NOT* be done inplace, because that would\n   * break the index sorting\n   */\n  public void testAtomicUpdateOfSegmentSortField() throws Exception {\n\n    final CloudSolrClient cloudSolrClient = cluster.getSolrClient();\n    final String updateField = SegmentTerminateEarlyTestState.timestampField;\n\n    // sanity check that updateField is in fact a DocValues only field, meaning it\n    // would normally be eligable for inplace updates -- if it weren't also used for merge sorting\n    final Map<String,Object> schemaOpts\n      = new Field(updateField, params(\"includeDynamic\", \"true\",\n                                      \"showDefaults\",\"true\")).process(cloudSolrClient).getField();\n    assertEquals(true, schemaOpts.get(\"docValues\"));\n    assertEquals(false, schemaOpts.get(\"indexed\"));\n    assertEquals(false, schemaOpts.get(\"stored\"));\n    \n    // add some documents\n    final int numDocs = atLeast(1000);\n    for (int id = 1; id <= numDocs; id++) {\n      cloudSolrClient.add(sdoc(\"id\", id, updateField, random().nextInt(60)));\n                               \n    }\n    cloudSolrClient.commit();\n\n    // do some random iterations of replacing docs, atomic updates against segment sort field, and commits\n    // (at this point we're just sanity checking no serious failures)\n    for (int iter = 0; iter < 20; iter++) {\n      final int iterSize = atLeast(20);\n      for (int i = 0; i < iterSize; i++) {\n        // replace\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, random().nextInt(60)));\n        // atomic update\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, map(\"set\", random().nextInt(60))));\n      }\n      cloudSolrClient.commit();\n    }\n\n    \n    // pick a random doc, and verify that doing an atomic update causes the docid to change\n    // ie: not an inplace update\n    final int id = TestUtil.nextInt(random(), 1, numDocs);\n    final int oldDocId = (Integer) cloudSolrClient.getById(\"\"+id, params(\"fl\",\"[docid]\")).get(\"[docid]\");\n    \n    cloudSolrClient.add(sdoc(\"id\", id, updateField, map(\"inc\",\"666\")));\n    cloudSolrClient.commit();\n    \n    // loop incase we're waiting for a newSearcher to be opened\n    int newDocId = -1;\n    int attempts = 10;\n    while ((newDocId < 0) && (0 < attempts--)) {\n      SolrDocumentList docs = cloudSolrClient.query(params(\"q\", \"id:\"+id,\n                                                           \"fl\",\"[docid]\",\n                                                           \"fq\", updateField + \"[666 TO *]\")).getResults();\n      if (0 < docs.size()) {\n        newDocId = (Integer)docs.get(0).get(\"[docid]\");\n      } else {\n        Thread.sleep(50);\n      }\n    }\n    assertTrue(oldDocId != newDocId);\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5de502b5478255493125e7e801411ba17a6682ec","date":1490974101,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSegmentSorting#testAtomicUpdateOfSegmentSortField().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSegmentSorting#testAtomicUpdateOfSegmentSortField().mjava","sourceNew":"  /** \n   * Verify that atomic updates against our (DVO) segment sort field doesn't cause errors.\n   * In this situation, the updates should *NOT* be done inplace, because that would\n   * break the index sorting\n   */\n  public void testAtomicUpdateOfSegmentSortField() throws Exception {\n\n    final CloudSolrClient cloudSolrClient = cluster.getSolrClient();\n    final String updateField = SegmentTerminateEarlyTestState.TIMESTAMP_FIELD;\n\n    // sanity check that updateField is in fact a DocValues only field, meaning it\n    // would normally be eligable for inplace updates -- if it weren't also used for merge sorting\n    final Map<String,Object> schemaOpts\n      = new Field(updateField, params(\"includeDynamic\", \"true\",\n                                      \"showDefaults\",\"true\")).process(cloudSolrClient).getField();\n    assertEquals(true, schemaOpts.get(\"docValues\"));\n    assertEquals(false, schemaOpts.get(\"indexed\"));\n    assertEquals(false, schemaOpts.get(\"stored\"));\n    \n    // add some documents\n    final int numDocs = atLeast(1000);\n    for (int id = 1; id <= numDocs; id++) {\n      cloudSolrClient.add(sdoc(\"id\", id, updateField, random().nextInt(60)));\n                               \n    }\n    cloudSolrClient.commit();\n\n    // do some random iterations of replacing docs, atomic updates against segment sort field, and commits\n    // (at this point we're just sanity checking no serious failures)\n    for (int iter = 0; iter < 20; iter++) {\n      final int iterSize = atLeast(20);\n      for (int i = 0; i < iterSize; i++) {\n        // replace\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, random().nextInt(60)));\n        // atomic update\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, map(\"set\", random().nextInt(60))));\n      }\n      cloudSolrClient.commit();\n    }\n\n    \n    // pick a random doc, and verify that doing an atomic update causes the docid to change\n    // ie: not an inplace update\n    final int id = TestUtil.nextInt(random(), 1, numDocs);\n    final int oldDocId = (Integer) cloudSolrClient.getById(\"\"+id, params(\"fl\",\"[docid]\")).get(\"[docid]\");\n    \n    cloudSolrClient.add(sdoc(\"id\", id, updateField, map(\"inc\",\"666\")));\n    cloudSolrClient.commit();\n    \n    // loop incase we're waiting for a newSearcher to be opened\n    int newDocId = -1;\n    int attempts = 10;\n    while ((newDocId < 0) && (0 < attempts--)) {\n      SolrDocumentList docs = cloudSolrClient.query(params(\"q\", \"id:\"+id,\n                                                           \"fl\",\"[docid]\",\n                                                           \"fq\", updateField + \"[666 TO *]\")).getResults();\n      if (0 < docs.size()) {\n        newDocId = (Integer)docs.get(0).get(\"[docid]\");\n      } else {\n        Thread.sleep(50);\n      }\n    }\n    assertTrue(oldDocId != newDocId);\n  }\n\n","sourceOld":"  /** \n   * Verify that atomic updates against our (DVO) segment sort field doesn't cause errors.\n   * In this situation, the updates should *NOT* be done inplace, because that would\n   * break the index sorting\n   */\n  public void testAtomicUpdateOfSegmentSortField() throws Exception {\n\n    final CloudSolrClient cloudSolrClient = cluster.getSolrClient();\n    final String updateField = SegmentTerminateEarlyTestState.timestampField;\n\n    // sanity check that updateField is in fact a DocValues only field, meaning it\n    // would normally be eligable for inplace updates -- if it weren't also used for merge sorting\n    final Map<String,Object> schemaOpts\n      = new Field(updateField, params(\"includeDynamic\", \"true\",\n                                      \"showDefaults\",\"true\")).process(cloudSolrClient).getField();\n    assertEquals(true, schemaOpts.get(\"docValues\"));\n    assertEquals(false, schemaOpts.get(\"indexed\"));\n    assertEquals(false, schemaOpts.get(\"stored\"));\n    \n    // add some documents\n    final int numDocs = atLeast(1000);\n    for (int id = 1; id <= numDocs; id++) {\n      cloudSolrClient.add(sdoc(\"id\", id, updateField, random().nextInt(60)));\n                               \n    }\n    cloudSolrClient.commit();\n\n    // do some random iterations of replacing docs, atomic updates against segment sort field, and commits\n    // (at this point we're just sanity checking no serious failures)\n    for (int iter = 0; iter < 20; iter++) {\n      final int iterSize = atLeast(20);\n      for (int i = 0; i < iterSize; i++) {\n        // replace\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, random().nextInt(60)));\n        // atomic update\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, map(\"set\", random().nextInt(60))));\n      }\n      cloudSolrClient.commit();\n    }\n\n    \n    // pick a random doc, and verify that doing an atomic update causes the docid to change\n    // ie: not an inplace update\n    final int id = TestUtil.nextInt(random(), 1, numDocs);\n    final int oldDocId = (Integer) cloudSolrClient.getById(\"\"+id, params(\"fl\",\"[docid]\")).get(\"[docid]\");\n    \n    cloudSolrClient.add(sdoc(\"id\", id, updateField, map(\"inc\",\"666\")));\n    cloudSolrClient.commit();\n    \n    // loop incase we're waiting for a newSearcher to be opened\n    int newDocId = -1;\n    int attempts = 10;\n    while ((newDocId < 0) && (0 < attempts--)) {\n      SolrDocumentList docs = cloudSolrClient.query(params(\"q\", \"id:\"+id,\n                                                           \"fl\",\"[docid]\",\n                                                           \"fq\", updateField + \"[666 TO *]\")).getResults();\n      if (0 < docs.size()) {\n        newDocId = (Integer)docs.get(0).get(\"[docid]\");\n      } else {\n        Thread.sleep(50);\n      }\n    }\n    assertTrue(oldDocId != newDocId);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6f20fd35e3055a0c5b387df0b986a68d65d86441","date":1491045405,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSegmentSorting#testAtomicUpdateOfSegmentSortField().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSegmentSorting#testAtomicUpdateOfSegmentSortField().mjava","sourceNew":"  /** \n   * Verify that atomic updates against our (DVO) segment sort field doesn't cause errors.\n   * In this situation, the updates should *NOT* be done inplace, because that would\n   * break the index sorting\n   */\n  public void testAtomicUpdateOfSegmentSortField() throws Exception {\n\n    final CloudSolrClient cloudSolrClient = cluster.getSolrClient();\n    final String updateField = SegmentTerminateEarlyTestState.TIMESTAMP_FIELD;\n\n    // sanity check that updateField is in fact a DocValues only field, meaning it\n    // would normally be eligable for inplace updates -- if it weren't also used for merge sorting\n    final Map<String,Object> schemaOpts\n      = new Field(updateField, params(\"includeDynamic\", \"true\",\n                                      \"showDefaults\",\"true\")).process(cloudSolrClient).getField();\n    assertEquals(true, schemaOpts.get(\"docValues\"));\n    assertEquals(false, schemaOpts.get(\"indexed\"));\n    assertEquals(false, schemaOpts.get(\"stored\"));\n    \n    // add some documents\n    final int numDocs = atLeast(1000);\n    for (int id = 1; id <= numDocs; id++) {\n      cloudSolrClient.add(sdoc(\"id\", id, updateField, random().nextInt(60)));\n                               \n    }\n    cloudSolrClient.commit();\n\n    // do some random iterations of replacing docs, atomic updates against segment sort field, and commits\n    // (at this point we're just sanity checking no serious failures)\n    for (int iter = 0; iter < 20; iter++) {\n      final int iterSize = atLeast(20);\n      for (int i = 0; i < iterSize; i++) {\n        // replace\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, random().nextInt(60)));\n        // atomic update\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, map(\"set\", random().nextInt(60))));\n      }\n      cloudSolrClient.commit();\n    }\n\n    \n    // pick a random doc, and verify that doing an atomic update causes the docid to change\n    // ie: not an inplace update\n    final int id = TestUtil.nextInt(random(), 1, numDocs);\n    final int oldDocId = (Integer) cloudSolrClient.getById(\"\"+id, params(\"fl\",\"[docid]\")).get(\"[docid]\");\n    \n    cloudSolrClient.add(sdoc(\"id\", id, updateField, map(\"inc\",\"666\")));\n    cloudSolrClient.commit();\n    \n    // loop incase we're waiting for a newSearcher to be opened\n    int newDocId = -1;\n    int attempts = 10;\n    while ((newDocId < 0) && (0 < attempts--)) {\n      SolrDocumentList docs = cloudSolrClient.query(params(\"q\", \"id:\"+id,\n                                                           \"fl\",\"[docid]\",\n                                                           \"fq\", updateField + \"[666 TO *]\")).getResults();\n      if (0 < docs.size()) {\n        newDocId = (Integer)docs.get(0).get(\"[docid]\");\n      } else {\n        Thread.sleep(50);\n      }\n    }\n    assertTrue(oldDocId != newDocId);\n  }\n\n","sourceOld":"  /** \n   * Verify that atomic updates against our (DVO) segment sort field doesn't cause errors.\n   * In this situation, the updates should *NOT* be done inplace, because that would\n   * break the index sorting\n   */\n  public void testAtomicUpdateOfSegmentSortField() throws Exception {\n\n    final CloudSolrClient cloudSolrClient = cluster.getSolrClient();\n    final String updateField = SegmentTerminateEarlyTestState.timestampField;\n\n    // sanity check that updateField is in fact a DocValues only field, meaning it\n    // would normally be eligable for inplace updates -- if it weren't also used for merge sorting\n    final Map<String,Object> schemaOpts\n      = new Field(updateField, params(\"includeDynamic\", \"true\",\n                                      \"showDefaults\",\"true\")).process(cloudSolrClient).getField();\n    assertEquals(true, schemaOpts.get(\"docValues\"));\n    assertEquals(false, schemaOpts.get(\"indexed\"));\n    assertEquals(false, schemaOpts.get(\"stored\"));\n    \n    // add some documents\n    final int numDocs = atLeast(1000);\n    for (int id = 1; id <= numDocs; id++) {\n      cloudSolrClient.add(sdoc(\"id\", id, updateField, random().nextInt(60)));\n                               \n    }\n    cloudSolrClient.commit();\n\n    // do some random iterations of replacing docs, atomic updates against segment sort field, and commits\n    // (at this point we're just sanity checking no serious failures)\n    for (int iter = 0; iter < 20; iter++) {\n      final int iterSize = atLeast(20);\n      for (int i = 0; i < iterSize; i++) {\n        // replace\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, random().nextInt(60)));\n        // atomic update\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, map(\"set\", random().nextInt(60))));\n      }\n      cloudSolrClient.commit();\n    }\n\n    \n    // pick a random doc, and verify that doing an atomic update causes the docid to change\n    // ie: not an inplace update\n    final int id = TestUtil.nextInt(random(), 1, numDocs);\n    final int oldDocId = (Integer) cloudSolrClient.getById(\"\"+id, params(\"fl\",\"[docid]\")).get(\"[docid]\");\n    \n    cloudSolrClient.add(sdoc(\"id\", id, updateField, map(\"inc\",\"666\")));\n    cloudSolrClient.commit();\n    \n    // loop incase we're waiting for a newSearcher to be opened\n    int newDocId = -1;\n    int attempts = 10;\n    while ((newDocId < 0) && (0 < attempts--)) {\n      SolrDocumentList docs = cloudSolrClient.query(params(\"q\", \"id:\"+id,\n                                                           \"fl\",\"[docid]\",\n                                                           \"fq\", updateField + \"[666 TO *]\")).getResults();\n      if (0 < docs.size()) {\n        newDocId = (Integer)docs.get(0).get(\"[docid]\");\n      } else {\n        Thread.sleep(50);\n      }\n    }\n    assertTrue(oldDocId != newDocId);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ab2f54aa3920f7b4a9b92e45334237f6427b20d3","date":1522384863,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSegmentSorting#testAtomicUpdateOfSegmentSortField().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSegmentSorting#testAtomicUpdateOfSegmentSortField().mjava","sourceNew":"  /** \n   * Verify that atomic updates against our (DVO) segment sort field doesn't cause errors.\n   * In this situation, the updates should *NOT* be done inplace, because that would\n   * break the index sorting\n   */\n  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 26-Mar-2018\n  public void testAtomicUpdateOfSegmentSortField() throws Exception {\n\n    final CloudSolrClient cloudSolrClient = cluster.getSolrClient();\n    final String updateField = SegmentTerminateEarlyTestState.TIMESTAMP_FIELD;\n\n    // sanity check that updateField is in fact a DocValues only field, meaning it\n    // would normally be eligable for inplace updates -- if it weren't also used for merge sorting\n    final Map<String,Object> schemaOpts\n      = new Field(updateField, params(\"includeDynamic\", \"true\",\n                                      \"showDefaults\",\"true\")).process(cloudSolrClient).getField();\n    assertEquals(true, schemaOpts.get(\"docValues\"));\n    assertEquals(false, schemaOpts.get(\"indexed\"));\n    assertEquals(false, schemaOpts.get(\"stored\"));\n    \n    // add some documents\n    final int numDocs = atLeast(1000);\n    for (int id = 1; id <= numDocs; id++) {\n      cloudSolrClient.add(sdoc(\"id\", id, updateField, random().nextInt(60)));\n                               \n    }\n    cloudSolrClient.commit();\n\n    // do some random iterations of replacing docs, atomic updates against segment sort field, and commits\n    // (at this point we're just sanity checking no serious failures)\n    for (int iter = 0; iter < 20; iter++) {\n      final int iterSize = atLeast(20);\n      for (int i = 0; i < iterSize; i++) {\n        // replace\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, random().nextInt(60)));\n        // atomic update\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, map(\"set\", random().nextInt(60))));\n      }\n      cloudSolrClient.commit();\n    }\n\n    \n    // pick a random doc, and verify that doing an atomic update causes the docid to change\n    // ie: not an inplace update\n    final int id = TestUtil.nextInt(random(), 1, numDocs);\n    final int oldDocId = (Integer) cloudSolrClient.getById(\"\"+id, params(\"fl\",\"[docid]\")).get(\"[docid]\");\n    \n    cloudSolrClient.add(sdoc(\"id\", id, updateField, map(\"inc\",\"666\")));\n    cloudSolrClient.commit();\n    \n    // loop incase we're waiting for a newSearcher to be opened\n    int newDocId = -1;\n    int attempts = 10;\n    while ((newDocId < 0) && (0 < attempts--)) {\n      SolrDocumentList docs = cloudSolrClient.query(params(\"q\", \"id:\"+id,\n                                                           \"fl\",\"[docid]\",\n                                                           \"fq\", updateField + \"[666 TO *]\")).getResults();\n      if (0 < docs.size()) {\n        newDocId = (Integer)docs.get(0).get(\"[docid]\");\n      } else {\n        Thread.sleep(50);\n      }\n    }\n    assertTrue(oldDocId != newDocId);\n  }\n\n","sourceOld":"  /** \n   * Verify that atomic updates against our (DVO) segment sort field doesn't cause errors.\n   * In this situation, the updates should *NOT* be done inplace, because that would\n   * break the index sorting\n   */\n  public void testAtomicUpdateOfSegmentSortField() throws Exception {\n\n    final CloudSolrClient cloudSolrClient = cluster.getSolrClient();\n    final String updateField = SegmentTerminateEarlyTestState.TIMESTAMP_FIELD;\n\n    // sanity check that updateField is in fact a DocValues only field, meaning it\n    // would normally be eligable for inplace updates -- if it weren't also used for merge sorting\n    final Map<String,Object> schemaOpts\n      = new Field(updateField, params(\"includeDynamic\", \"true\",\n                                      \"showDefaults\",\"true\")).process(cloudSolrClient).getField();\n    assertEquals(true, schemaOpts.get(\"docValues\"));\n    assertEquals(false, schemaOpts.get(\"indexed\"));\n    assertEquals(false, schemaOpts.get(\"stored\"));\n    \n    // add some documents\n    final int numDocs = atLeast(1000);\n    for (int id = 1; id <= numDocs; id++) {\n      cloudSolrClient.add(sdoc(\"id\", id, updateField, random().nextInt(60)));\n                               \n    }\n    cloudSolrClient.commit();\n\n    // do some random iterations of replacing docs, atomic updates against segment sort field, and commits\n    // (at this point we're just sanity checking no serious failures)\n    for (int iter = 0; iter < 20; iter++) {\n      final int iterSize = atLeast(20);\n      for (int i = 0; i < iterSize; i++) {\n        // replace\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, random().nextInt(60)));\n        // atomic update\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, map(\"set\", random().nextInt(60))));\n      }\n      cloudSolrClient.commit();\n    }\n\n    \n    // pick a random doc, and verify that doing an atomic update causes the docid to change\n    // ie: not an inplace update\n    final int id = TestUtil.nextInt(random(), 1, numDocs);\n    final int oldDocId = (Integer) cloudSolrClient.getById(\"\"+id, params(\"fl\",\"[docid]\")).get(\"[docid]\");\n    \n    cloudSolrClient.add(sdoc(\"id\", id, updateField, map(\"inc\",\"666\")));\n    cloudSolrClient.commit();\n    \n    // loop incase we're waiting for a newSearcher to be opened\n    int newDocId = -1;\n    int attempts = 10;\n    while ((newDocId < 0) && (0 < attempts--)) {\n      SolrDocumentList docs = cloudSolrClient.query(params(\"q\", \"id:\"+id,\n                                                           \"fl\",\"[docid]\",\n                                                           \"fq\", updateField + \"[666 TO *]\")).getResults();\n      if (0 < docs.size()) {\n        newDocId = (Integer)docs.get(0).get(\"[docid]\");\n      } else {\n        Thread.sleep(50);\n      }\n    }\n    assertTrue(oldDocId != newDocId);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"acfe8d3b837b6b66eaddf114bb99cf9e2257764d","date":1522406637,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSegmentSorting#testAtomicUpdateOfSegmentSortField().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSegmentSorting#testAtomicUpdateOfSegmentSortField().mjava","sourceNew":"  /** \n   * Verify that atomic updates against our (DVO) segment sort field doesn't cause errors.\n   * In this situation, the updates should *NOT* be done inplace, because that would\n   * break the index sorting\n   */\n  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 26-Mar-2018\n  public void testAtomicUpdateOfSegmentSortField() throws Exception {\n\n    final CloudSolrClient cloudSolrClient = cluster.getSolrClient();\n    final String updateField = SegmentTerminateEarlyTestState.TIMESTAMP_FIELD;\n\n    // sanity check that updateField is in fact a DocValues only field, meaning it\n    // would normally be eligable for inplace updates -- if it weren't also used for merge sorting\n    final Map<String,Object> schemaOpts\n      = new Field(updateField, params(\"includeDynamic\", \"true\",\n                                      \"showDefaults\",\"true\")).process(cloudSolrClient).getField();\n    assertEquals(true, schemaOpts.get(\"docValues\"));\n    assertEquals(false, schemaOpts.get(\"indexed\"));\n    assertEquals(false, schemaOpts.get(\"stored\"));\n    \n    // add some documents\n    final int numDocs = atLeast(1000);\n    for (int id = 1; id <= numDocs; id++) {\n      cloudSolrClient.add(sdoc(\"id\", id, updateField, random().nextInt(60)));\n                               \n    }\n    cloudSolrClient.commit();\n\n    // do some random iterations of replacing docs, atomic updates against segment sort field, and commits\n    // (at this point we're just sanity checking no serious failures)\n    for (int iter = 0; iter < 20; iter++) {\n      final int iterSize = atLeast(20);\n      for (int i = 0; i < iterSize; i++) {\n        // replace\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, random().nextInt(60)));\n        // atomic update\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, map(\"set\", random().nextInt(60))));\n      }\n      cloudSolrClient.commit();\n    }\n\n    \n    // pick a random doc, and verify that doing an atomic update causes the docid to change\n    // ie: not an inplace update\n    final int id = TestUtil.nextInt(random(), 1, numDocs);\n    final int oldDocId = (Integer) cloudSolrClient.getById(\"\"+id, params(\"fl\",\"[docid]\")).get(\"[docid]\");\n    \n    cloudSolrClient.add(sdoc(\"id\", id, updateField, map(\"inc\",\"666\")));\n    cloudSolrClient.commit();\n    \n    // loop incase we're waiting for a newSearcher to be opened\n    int newDocId = -1;\n    int attempts = 10;\n    while ((newDocId < 0) && (0 < attempts--)) {\n      SolrDocumentList docs = cloudSolrClient.query(params(\"q\", \"id:\"+id,\n                                                           \"fl\",\"[docid]\",\n                                                           \"fq\", updateField + \"[666 TO *]\")).getResults();\n      if (0 < docs.size()) {\n        newDocId = (Integer)docs.get(0).get(\"[docid]\");\n      } else {\n        Thread.sleep(50);\n      }\n    }\n    assertTrue(oldDocId != newDocId);\n  }\n\n","sourceOld":"  /** \n   * Verify that atomic updates against our (DVO) segment sort field doesn't cause errors.\n   * In this situation, the updates should *NOT* be done inplace, because that would\n   * break the index sorting\n   */\n  public void testAtomicUpdateOfSegmentSortField() throws Exception {\n\n    final CloudSolrClient cloudSolrClient = cluster.getSolrClient();\n    final String updateField = SegmentTerminateEarlyTestState.TIMESTAMP_FIELD;\n\n    // sanity check that updateField is in fact a DocValues only field, meaning it\n    // would normally be eligable for inplace updates -- if it weren't also used for merge sorting\n    final Map<String,Object> schemaOpts\n      = new Field(updateField, params(\"includeDynamic\", \"true\",\n                                      \"showDefaults\",\"true\")).process(cloudSolrClient).getField();\n    assertEquals(true, schemaOpts.get(\"docValues\"));\n    assertEquals(false, schemaOpts.get(\"indexed\"));\n    assertEquals(false, schemaOpts.get(\"stored\"));\n    \n    // add some documents\n    final int numDocs = atLeast(1000);\n    for (int id = 1; id <= numDocs; id++) {\n      cloudSolrClient.add(sdoc(\"id\", id, updateField, random().nextInt(60)));\n                               \n    }\n    cloudSolrClient.commit();\n\n    // do some random iterations of replacing docs, atomic updates against segment sort field, and commits\n    // (at this point we're just sanity checking no serious failures)\n    for (int iter = 0; iter < 20; iter++) {\n      final int iterSize = atLeast(20);\n      for (int i = 0; i < iterSize; i++) {\n        // replace\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, random().nextInt(60)));\n        // atomic update\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, map(\"set\", random().nextInt(60))));\n      }\n      cloudSolrClient.commit();\n    }\n\n    \n    // pick a random doc, and verify that doing an atomic update causes the docid to change\n    // ie: not an inplace update\n    final int id = TestUtil.nextInt(random(), 1, numDocs);\n    final int oldDocId = (Integer) cloudSolrClient.getById(\"\"+id, params(\"fl\",\"[docid]\")).get(\"[docid]\");\n    \n    cloudSolrClient.add(sdoc(\"id\", id, updateField, map(\"inc\",\"666\")));\n    cloudSolrClient.commit();\n    \n    // loop incase we're waiting for a newSearcher to be opened\n    int newDocId = -1;\n    int attempts = 10;\n    while ((newDocId < 0) && (0 < attempts--)) {\n      SolrDocumentList docs = cloudSolrClient.query(params(\"q\", \"id:\"+id,\n                                                           \"fl\",\"[docid]\",\n                                                           \"fq\", updateField + \"[666 TO *]\")).getResults();\n      if (0 < docs.size()) {\n        newDocId = (Integer)docs.get(0).get(\"[docid]\");\n      } else {\n        Thread.sleep(50);\n      }\n    }\n    assertTrue(oldDocId != newDocId);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a1c374690db69470f6aa4bffc43dcacf1f4e3e49","date":1529007399,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSegmentSorting#testAtomicUpdateOfSegmentSortField().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSegmentSorting#testAtomicUpdateOfSegmentSortField().mjava","sourceNew":"  /** \n   * Verify that atomic updates against our (DVO) segment sort field doesn't cause errors.\n   * In this situation, the updates should *NOT* be done inplace, because that would\n   * break the index sorting\n   */\n  @Test\n  // 12-Jun-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 26-Mar-2018\n  public void testAtomicUpdateOfSegmentSortField() throws Exception {\n\n    final CloudSolrClient cloudSolrClient = cluster.getSolrClient();\n    final String updateField = SegmentTerminateEarlyTestState.TIMESTAMP_FIELD;\n\n    // sanity check that updateField is in fact a DocValues only field, meaning it\n    // would normally be eligable for inplace updates -- if it weren't also used for merge sorting\n    final Map<String,Object> schemaOpts\n      = new Field(updateField, params(\"includeDynamic\", \"true\",\n                                      \"showDefaults\",\"true\")).process(cloudSolrClient).getField();\n    assertEquals(true, schemaOpts.get(\"docValues\"));\n    assertEquals(false, schemaOpts.get(\"indexed\"));\n    assertEquals(false, schemaOpts.get(\"stored\"));\n    \n    // add some documents\n    final int numDocs = atLeast(1000);\n    for (int id = 1; id <= numDocs; id++) {\n      cloudSolrClient.add(sdoc(\"id\", id, updateField, random().nextInt(60)));\n                               \n    }\n    cloudSolrClient.commit();\n\n    // do some random iterations of replacing docs, atomic updates against segment sort field, and commits\n    // (at this point we're just sanity checking no serious failures)\n    for (int iter = 0; iter < 20; iter++) {\n      final int iterSize = atLeast(20);\n      for (int i = 0; i < iterSize; i++) {\n        // replace\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, random().nextInt(60)));\n        // atomic update\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, map(\"set\", random().nextInt(60))));\n      }\n      cloudSolrClient.commit();\n    }\n\n    \n    // pick a random doc, and verify that doing an atomic update causes the docid to change\n    // ie: not an inplace update\n    final int id = TestUtil.nextInt(random(), 1, numDocs);\n    final int oldDocId = (Integer) cloudSolrClient.getById(\"\"+id, params(\"fl\",\"[docid]\")).get(\"[docid]\");\n    \n    cloudSolrClient.add(sdoc(\"id\", id, updateField, map(\"inc\",\"666\")));\n    cloudSolrClient.commit();\n    \n    // loop incase we're waiting for a newSearcher to be opened\n    int newDocId = -1;\n    int attempts = 10;\n    while ((newDocId < 0) && (0 < attempts--)) {\n      SolrDocumentList docs = cloudSolrClient.query(params(\"q\", \"id:\"+id,\n                                                           \"fl\",\"[docid]\",\n                                                           \"fq\", updateField + \"[666 TO *]\")).getResults();\n      if (0 < docs.size()) {\n        newDocId = (Integer)docs.get(0).get(\"[docid]\");\n      } else {\n        Thread.sleep(50);\n      }\n    }\n    assertTrue(oldDocId != newDocId);\n  }\n\n","sourceOld":"  /** \n   * Verify that atomic updates against our (DVO) segment sort field doesn't cause errors.\n   * In this situation, the updates should *NOT* be done inplace, because that would\n   * break the index sorting\n   */\n  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 26-Mar-2018\n  public void testAtomicUpdateOfSegmentSortField() throws Exception {\n\n    final CloudSolrClient cloudSolrClient = cluster.getSolrClient();\n    final String updateField = SegmentTerminateEarlyTestState.TIMESTAMP_FIELD;\n\n    // sanity check that updateField is in fact a DocValues only field, meaning it\n    // would normally be eligable for inplace updates -- if it weren't also used for merge sorting\n    final Map<String,Object> schemaOpts\n      = new Field(updateField, params(\"includeDynamic\", \"true\",\n                                      \"showDefaults\",\"true\")).process(cloudSolrClient).getField();\n    assertEquals(true, schemaOpts.get(\"docValues\"));\n    assertEquals(false, schemaOpts.get(\"indexed\"));\n    assertEquals(false, schemaOpts.get(\"stored\"));\n    \n    // add some documents\n    final int numDocs = atLeast(1000);\n    for (int id = 1; id <= numDocs; id++) {\n      cloudSolrClient.add(sdoc(\"id\", id, updateField, random().nextInt(60)));\n                               \n    }\n    cloudSolrClient.commit();\n\n    // do some random iterations of replacing docs, atomic updates against segment sort field, and commits\n    // (at this point we're just sanity checking no serious failures)\n    for (int iter = 0; iter < 20; iter++) {\n      final int iterSize = atLeast(20);\n      for (int i = 0; i < iterSize; i++) {\n        // replace\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, random().nextInt(60)));\n        // atomic update\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, map(\"set\", random().nextInt(60))));\n      }\n      cloudSolrClient.commit();\n    }\n\n    \n    // pick a random doc, and verify that doing an atomic update causes the docid to change\n    // ie: not an inplace update\n    final int id = TestUtil.nextInt(random(), 1, numDocs);\n    final int oldDocId = (Integer) cloudSolrClient.getById(\"\"+id, params(\"fl\",\"[docid]\")).get(\"[docid]\");\n    \n    cloudSolrClient.add(sdoc(\"id\", id, updateField, map(\"inc\",\"666\")));\n    cloudSolrClient.commit();\n    \n    // loop incase we're waiting for a newSearcher to be opened\n    int newDocId = -1;\n    int attempts = 10;\n    while ((newDocId < 0) && (0 < attempts--)) {\n      SolrDocumentList docs = cloudSolrClient.query(params(\"q\", \"id:\"+id,\n                                                           \"fl\",\"[docid]\",\n                                                           \"fq\", updateField + \"[666 TO *]\")).getResults();\n      if (0 < docs.size()) {\n        newDocId = (Integer)docs.get(0).get(\"[docid]\");\n      } else {\n        Thread.sleep(50);\n      }\n    }\n    assertTrue(oldDocId != newDocId);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26","date":1531589977,"type":3,"author":"Michael Braun","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSegmentSorting#testAtomicUpdateOfSegmentSortField().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSegmentSorting#testAtomicUpdateOfSegmentSortField().mjava","sourceNew":"  /** \n   * Verify that atomic updates against our (DVO) segment sort field doesn't cause errors.\n   * In this situation, the updates should *NOT* be done inplace, because that would\n   * break the index sorting\n   */\n  @Test\n  // 12-Jun-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 26-Mar-2018\n  public void testAtomicUpdateOfSegmentSortField() throws Exception {\n\n    final CloudSolrClient cloudSolrClient = cluster.getSolrClient();\n    final String updateField = SegmentTerminateEarlyTestState.TIMESTAMP_FIELD;\n\n    // sanity check that updateField is in fact a DocValues only field, meaning it\n    // would normally be eligable for inplace updates -- if it weren't also used for merge sorting\n    final Map<String,Object> schemaOpts\n      = new Field(updateField, params(\"includeDynamic\", \"true\",\n                                      \"showDefaults\",\"true\")).process(cloudSolrClient).getField();\n    assertEquals(true, schemaOpts.get(\"docValues\"));\n    assertEquals(false, schemaOpts.get(\"indexed\"));\n    assertEquals(false, schemaOpts.get(\"stored\"));\n    \n    // add some documents\n    final int numDocs = atLeast(1000);\n    for (int id = 1; id <= numDocs; id++) {\n      cloudSolrClient.add(sdoc(\"id\", id, updateField, random().nextInt(60)));\n                               \n    }\n    cloudSolrClient.commit();\n\n    // do some random iterations of replacing docs, atomic updates against segment sort field, and commits\n    // (at this point we're just sanity checking no serious failures)\n    for (int iter = 0; iter < 20; iter++) {\n      final int iterSize = atLeast(20);\n      for (int i = 0; i < iterSize; i++) {\n        // replace\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, random().nextInt(60)));\n        // atomic update\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, map(\"set\", random().nextInt(60))));\n      }\n      cloudSolrClient.commit();\n    }\n\n    \n    // pick a random doc, and verify that doing an atomic update causes the docid to change\n    // ie: not an inplace update\n    final int id = TestUtil.nextInt(random(), 1, numDocs);\n    final int oldDocId = (Integer) cloudSolrClient.getById(\"\"+id, params(\"fl\",\"[docid]\")).get(\"[docid]\");\n    \n    cloudSolrClient.add(sdoc(\"id\", id, updateField, map(\"inc\",\"666\")));\n    cloudSolrClient.commit();\n    \n    // loop incase we're waiting for a newSearcher to be opened\n    int newDocId = -1;\n    int attempts = 10;\n    while ((newDocId < 0) && (0 < attempts--)) {\n      SolrDocumentList docs = cloudSolrClient.query(params(\"q\", \"id:\"+id,\n                                                           \"fl\",\"[docid]\",\n                                                           \"fq\", updateField + \"[666 TO *]\")).getResults();\n      if (0 < docs.size()) {\n        newDocId = (Integer)docs.get(0).get(\"[docid]\");\n      } else {\n        Thread.sleep(50);\n      }\n    }\n    assertTrue(oldDocId != newDocId);\n  }\n\n","sourceOld":"  /** \n   * Verify that atomic updates against our (DVO) segment sort field doesn't cause errors.\n   * In this situation, the updates should *NOT* be done inplace, because that would\n   * break the index sorting\n   */\n  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 26-Mar-2018\n  public void testAtomicUpdateOfSegmentSortField() throws Exception {\n\n    final CloudSolrClient cloudSolrClient = cluster.getSolrClient();\n    final String updateField = SegmentTerminateEarlyTestState.TIMESTAMP_FIELD;\n\n    // sanity check that updateField is in fact a DocValues only field, meaning it\n    // would normally be eligable for inplace updates -- if it weren't also used for merge sorting\n    final Map<String,Object> schemaOpts\n      = new Field(updateField, params(\"includeDynamic\", \"true\",\n                                      \"showDefaults\",\"true\")).process(cloudSolrClient).getField();\n    assertEquals(true, schemaOpts.get(\"docValues\"));\n    assertEquals(false, schemaOpts.get(\"indexed\"));\n    assertEquals(false, schemaOpts.get(\"stored\"));\n    \n    // add some documents\n    final int numDocs = atLeast(1000);\n    for (int id = 1; id <= numDocs; id++) {\n      cloudSolrClient.add(sdoc(\"id\", id, updateField, random().nextInt(60)));\n                               \n    }\n    cloudSolrClient.commit();\n\n    // do some random iterations of replacing docs, atomic updates against segment sort field, and commits\n    // (at this point we're just sanity checking no serious failures)\n    for (int iter = 0; iter < 20; iter++) {\n      final int iterSize = atLeast(20);\n      for (int i = 0; i < iterSize; i++) {\n        // replace\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, random().nextInt(60)));\n        // atomic update\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, map(\"set\", random().nextInt(60))));\n      }\n      cloudSolrClient.commit();\n    }\n\n    \n    // pick a random doc, and verify that doing an atomic update causes the docid to change\n    // ie: not an inplace update\n    final int id = TestUtil.nextInt(random(), 1, numDocs);\n    final int oldDocId = (Integer) cloudSolrClient.getById(\"\"+id, params(\"fl\",\"[docid]\")).get(\"[docid]\");\n    \n    cloudSolrClient.add(sdoc(\"id\", id, updateField, map(\"inc\",\"666\")));\n    cloudSolrClient.commit();\n    \n    // loop incase we're waiting for a newSearcher to be opened\n    int newDocId = -1;\n    int attempts = 10;\n    while ((newDocId < 0) && (0 < attempts--)) {\n      SolrDocumentList docs = cloudSolrClient.query(params(\"q\", \"id:\"+id,\n                                                           \"fl\",\"[docid]\",\n                                                           \"fq\", updateField + \"[666 TO *]\")).getResults();\n      if (0 < docs.size()) {\n        newDocId = (Integer)docs.get(0).get(\"[docid]\");\n      } else {\n        Thread.sleep(50);\n      }\n    }\n    assertTrue(oldDocId != newDocId);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","date":1531905561,"type":3,"author":"Alessandro Benedetti","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/TestSegmentSorting#testAtomicUpdateOfSegmentSortField().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/TestSegmentSorting#testAtomicUpdateOfSegmentSortField().mjava","sourceNew":"  /** \n   * Verify that atomic updates against our (DVO) segment sort field doesn't cause errors.\n   * In this situation, the updates should *NOT* be done inplace, because that would\n   * break the index sorting\n   */\n  @Test\n  // 12-Jun-2018 @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 26-Mar-2018\n  public void testAtomicUpdateOfSegmentSortField() throws Exception {\n\n    final CloudSolrClient cloudSolrClient = cluster.getSolrClient();\n    final String updateField = SegmentTerminateEarlyTestState.TIMESTAMP_FIELD;\n\n    // sanity check that updateField is in fact a DocValues only field, meaning it\n    // would normally be eligable for inplace updates -- if it weren't also used for merge sorting\n    final Map<String,Object> schemaOpts\n      = new Field(updateField, params(\"includeDynamic\", \"true\",\n                                      \"showDefaults\",\"true\")).process(cloudSolrClient).getField();\n    assertEquals(true, schemaOpts.get(\"docValues\"));\n    assertEquals(false, schemaOpts.get(\"indexed\"));\n    assertEquals(false, schemaOpts.get(\"stored\"));\n    \n    // add some documents\n    final int numDocs = atLeast(1000);\n    for (int id = 1; id <= numDocs; id++) {\n      cloudSolrClient.add(sdoc(\"id\", id, updateField, random().nextInt(60)));\n                               \n    }\n    cloudSolrClient.commit();\n\n    // do some random iterations of replacing docs, atomic updates against segment sort field, and commits\n    // (at this point we're just sanity checking no serious failures)\n    for (int iter = 0; iter < 20; iter++) {\n      final int iterSize = atLeast(20);\n      for (int i = 0; i < iterSize; i++) {\n        // replace\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, random().nextInt(60)));\n        // atomic update\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, map(\"set\", random().nextInt(60))));\n      }\n      cloudSolrClient.commit();\n    }\n\n    \n    // pick a random doc, and verify that doing an atomic update causes the docid to change\n    // ie: not an inplace update\n    final int id = TestUtil.nextInt(random(), 1, numDocs);\n    final int oldDocId = (Integer) cloudSolrClient.getById(\"\"+id, params(\"fl\",\"[docid]\")).get(\"[docid]\");\n    \n    cloudSolrClient.add(sdoc(\"id\", id, updateField, map(\"inc\",\"666\")));\n    cloudSolrClient.commit();\n    \n    // loop incase we're waiting for a newSearcher to be opened\n    int newDocId = -1;\n    int attempts = 10;\n    while ((newDocId < 0) && (0 < attempts--)) {\n      SolrDocumentList docs = cloudSolrClient.query(params(\"q\", \"id:\"+id,\n                                                           \"fl\",\"[docid]\",\n                                                           \"fq\", updateField + \"[666 TO *]\")).getResults();\n      if (0 < docs.size()) {\n        newDocId = (Integer)docs.get(0).get(\"[docid]\");\n      } else {\n        Thread.sleep(50);\n      }\n    }\n    assertTrue(oldDocId != newDocId);\n  }\n\n","sourceOld":"  /** \n   * Verify that atomic updates against our (DVO) segment sort field doesn't cause errors.\n   * In this situation, the updates should *NOT* be done inplace, because that would\n   * break the index sorting\n   */\n  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\") // 26-Mar-2018\n  public void testAtomicUpdateOfSegmentSortField() throws Exception {\n\n    final CloudSolrClient cloudSolrClient = cluster.getSolrClient();\n    final String updateField = SegmentTerminateEarlyTestState.TIMESTAMP_FIELD;\n\n    // sanity check that updateField is in fact a DocValues only field, meaning it\n    // would normally be eligable for inplace updates -- if it weren't also used for merge sorting\n    final Map<String,Object> schemaOpts\n      = new Field(updateField, params(\"includeDynamic\", \"true\",\n                                      \"showDefaults\",\"true\")).process(cloudSolrClient).getField();\n    assertEquals(true, schemaOpts.get(\"docValues\"));\n    assertEquals(false, schemaOpts.get(\"indexed\"));\n    assertEquals(false, schemaOpts.get(\"stored\"));\n    \n    // add some documents\n    final int numDocs = atLeast(1000);\n    for (int id = 1; id <= numDocs; id++) {\n      cloudSolrClient.add(sdoc(\"id\", id, updateField, random().nextInt(60)));\n                               \n    }\n    cloudSolrClient.commit();\n\n    // do some random iterations of replacing docs, atomic updates against segment sort field, and commits\n    // (at this point we're just sanity checking no serious failures)\n    for (int iter = 0; iter < 20; iter++) {\n      final int iterSize = atLeast(20);\n      for (int i = 0; i < iterSize; i++) {\n        // replace\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, random().nextInt(60)));\n        // atomic update\n        cloudSolrClient.add(sdoc(\"id\", TestUtil.nextInt(random(), 1, numDocs),\n                                 updateField, map(\"set\", random().nextInt(60))));\n      }\n      cloudSolrClient.commit();\n    }\n\n    \n    // pick a random doc, and verify that doing an atomic update causes the docid to change\n    // ie: not an inplace update\n    final int id = TestUtil.nextInt(random(), 1, numDocs);\n    final int oldDocId = (Integer) cloudSolrClient.getById(\"\"+id, params(\"fl\",\"[docid]\")).get(\"[docid]\");\n    \n    cloudSolrClient.add(sdoc(\"id\", id, updateField, map(\"inc\",\"666\")));\n    cloudSolrClient.commit();\n    \n    // loop incase we're waiting for a newSearcher to be opened\n    int newDocId = -1;\n    int attempts = 10;\n    while ((newDocId < 0) && (0 < attempts--)) {\n      SolrDocumentList docs = cloudSolrClient.query(params(\"q\", \"id:\"+id,\n                                                           \"fl\",\"[docid]\",\n                                                           \"fq\", updateField + \"[666 TO *]\")).getResults();\n      if (0 < docs.size()) {\n        newDocId = (Integer)docs.get(0).get(\"[docid]\");\n      } else {\n        Thread.sleep(50);\n      }\n    }\n    assertTrue(oldDocId != newDocId);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"415bbbe7da8065dd3c477bdc3c703c6425622998":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":["acfe8d3b837b6b66eaddf114bb99cf9e2257764d","a1c374690db69470f6aa4bffc43dcacf1f4e3e49"],"598b5d23aa7c9732bf473c21a9cd309c44599394":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","415bbbe7da8065dd3c477bdc3c703c6425622998"],"5de502b5478255493125e7e801411ba17a6682ec":["415bbbe7da8065dd3c477bdc3c703c6425622998"],"6f20fd35e3055a0c5b387df0b986a68d65d86441":["415bbbe7da8065dd3c477bdc3c703c6425622998"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"acfe8d3b837b6b66eaddf114bb99cf9e2257764d":["5de502b5478255493125e7e801411ba17a6682ec","ab2f54aa3920f7b4a9b92e45334237f6427b20d3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a1c374690db69470f6aa4bffc43dcacf1f4e3e49"],"a1c374690db69470f6aa4bffc43dcacf1f4e3e49":["acfe8d3b837b6b66eaddf114bb99cf9e2257764d"],"ab2f54aa3920f7b4a9b92e45334237f6427b20d3":["5de502b5478255493125e7e801411ba17a6682ec"],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":["acfe8d3b837b6b66eaddf114bb99cf9e2257764d","a1c374690db69470f6aa4bffc43dcacf1f4e3e49"]},"commit2Childs":{"415bbbe7da8065dd3c477bdc3c703c6425622998":["598b5d23aa7c9732bf473c21a9cd309c44599394","5de502b5478255493125e7e801411ba17a6682ec","6f20fd35e3055a0c5b387df0b986a68d65d86441"],"0efc9f2cae117418f13ba9035f5e1d516ea7a2b5":[],"598b5d23aa7c9732bf473c21a9cd309c44599394":[],"5de502b5478255493125e7e801411ba17a6682ec":["acfe8d3b837b6b66eaddf114bb99cf9e2257764d","ab2f54aa3920f7b4a9b92e45334237f6427b20d3"],"6f20fd35e3055a0c5b387df0b986a68d65d86441":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["415bbbe7da8065dd3c477bdc3c703c6425622998","598b5d23aa7c9732bf473c21a9cd309c44599394"],"acfe8d3b837b6b66eaddf114bb99cf9e2257764d":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","a1c374690db69470f6aa4bffc43dcacf1f4e3e49","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"a1c374690db69470f6aa4bffc43dcacf1f4e3e49":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"ab2f54aa3920f7b4a9b92e45334237f6427b20d3":["acfe8d3b837b6b66eaddf114bb99cf9e2257764d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"7eeaaea0106c7d6a2de50acfc8d357121ef8bd26":[]},"heads":["0efc9f2cae117418f13ba9035f5e1d516ea7a2b5","598b5d23aa7c9732bf473c21a9cd309c44599394","6f20fd35e3055a0c5b387df0b986a68d65d86441","cd5edd1f2b162a5cfa08efd17851a07373a96817","7eeaaea0106c7d6a2de50acfc8d357121ef8bd26"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}