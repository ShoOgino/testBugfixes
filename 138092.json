{"path":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","commits":[{"id":"c9f72b4e0953a7ed14ab0430053c1bb65f2ef529","date":1399818681,"type":1,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"93dd449115a9247533e44bab47e8429e5dccbc6d","date":1400258396,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n    if (shardsCanUseIDV && random().nextBoolean()) {\n      groupField += \"_dv\";\n      usedIdvBasedImpl.value = true;\n    }\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"56572ec06f1407c066d6b7399413178b33176cd8","date":1400495675,"type":1,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean,ValueHolder[Boolean]).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex, ValueHolder<Boolean> usedIdvBasedImpl) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n    if (shardsCanUseIDV && random().nextBoolean()) {\n      groupField += \"_dv\";\n      usedIdvBasedImpl.value = true;\n    }\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb17639909a369c1e64866842e5c213440acc17e","date":1423238093,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, true);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"954e59be3da8dc1b046646ad7af4b466852009d3","date":1423482367,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, PostingsEnum.FLAG_FREQS);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, true);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6a47d642ab24da1a811adce4bda9cc52c520ca13","date":1423483323,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, true);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, PostingsEnum.FLAG_FREQS);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7e7cf486535cf187cb3745154ca5dd3de3bd2999","date":1449256632,"type":3,"author":"David Wayne Smiley","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, getScores);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, true);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","date":1457644139,"type":3,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, getScores);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, getScores);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV;\n    if (canUseIDV) {\n      if (SlowCompositeReaderWrapper.class.isAssignableFrom(subSearchers[0].getIndexReader().getClass())) {\n        shardsCanUseIDV = false;\n      } else {\n        shardsCanUseIDV = !preFlex;\n      }\n    } else {\n      shardsCanUseIDV = false;\n    }\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":["e3eb88edd735aec1f42cbe41c478fb4f8d41f0ec","4739c84c362b9673ab5ed3e038ff760c718c30c8"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"20e94e61fe5291647346b70437617e6b6c370408","date":1483783127,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, getScores);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<FirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    FirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final SecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, getScores);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","date":1484239864,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, getScores);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<FirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    FirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final SecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, getScores);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<AbstractFirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    AbstractFirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final AbstractSecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7ae958a739da1866696f442384393ba2f13e33e5","date":1491819018,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, getScores);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<FirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    FirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final TopGroupsCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, getScores);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<FirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    FirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final SecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54ca69905c5d9d1529286f06ab1d12c68f6c13cb","date":1492683554,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, getScores);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<FirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    FirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final TopGroupsCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, getScores);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<FirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    FirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final SecondPassGroupingCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9fc47cb7b4346802411bb432f501ed0673d7119e","date":1512640179,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, getScores || getMaxScores ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<FirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    FirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final TopGroupsCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, getScores);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<FirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    FirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final TopGroupsCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"417142ff08fda9cf0b72d5133e63097a166c6458","date":1512729693,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, getScores || getMaxScores ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<FirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    FirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final TopGroupsCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, getScores);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<FirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    FirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final TopGroupsCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"475584d5e08a22ad3fc7babefe006d77bc744567","date":1523282824,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createWeight(topSearcher.rewrite(query), getScores || getMaxScores ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES, 1);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<FirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    FirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final TopGroupsCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, getScores || getMaxScores ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<FirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    FirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final TopGroupsCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d58e44159788900f4a2113b84463dc3fbbf80f20","date":1523319203,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createWeight(topSearcher.rewrite(query), getScores || getMaxScores ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES, 1);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<FirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    FirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final TopGroupsCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createNormalizedWeight(query, getScores || getMaxScores ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<FirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    FirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final TopGroupsCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"04c370507e5521b2eb998530736f1c19b851ed5a","date":1531911305,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createWeight(topSearcher.rewrite(query), getScores || getMaxScores ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES, 1);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<FirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    FirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final TopGroupsCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createWeight(topSearcher.rewrite(query), getScores || getMaxScores ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES, 1);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<FirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    FirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0, true);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final TopGroupsCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores, true);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d3f7ab1a502671bbdb03bcced21e764d2483221","date":1532329609,"type":5,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean).mjava","pathOld":"lucene/grouping/src/test/org/apache/lucene/search/grouping/TestGrouping#searchShards(IndexSearcher,ShardSearcher[],Query,Sort,Sort,int,int,int,int,boolean,boolean,boolean,boolean).mjava","sourceNew":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createWeight(topSearcher.rewrite(query), groupSort.needsScores() || docSort.needsScores() || getMaxScores ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES, 1);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<FirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    FirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final TopGroupsCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getMaxScores);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","sourceOld":"  private TopGroups<BytesRef> searchShards(IndexSearcher topSearcher, ShardSearcher[] subSearchers, Query query, Sort groupSort, Sort docSort, int groupOffset, int topNGroups, int docOffset,\n                                           int topNDocs, boolean getScores, boolean getMaxScores, boolean canUseIDV, boolean preFlex) throws Exception {\n\n    // TODO: swap in caching, all groups collector hereassertEquals(expected.totalHitCount, actual.totalHitCount);\n    // too...\n    if (VERBOSE) {\n      System.out.println(\"TEST: \" + subSearchers.length + \" shards: \" + Arrays.toString(subSearchers) + \" canUseIDV=\" + canUseIDV);\n    }\n    // Run 1st pass collector to get top groups per shard\n    final Weight w = topSearcher.createWeight(topSearcher.rewrite(query), getScores || getMaxScores ? ScoreMode.COMPLETE : ScoreMode.COMPLETE_NO_SCORES, 1);\n    final List<Collection<SearchGroup<BytesRef>>> shardGroups = new ArrayList<>();\n    List<FirstPassGroupingCollector<?>> firstPassGroupingCollectors = new ArrayList<>();\n    FirstPassGroupingCollector<?> firstPassCollector = null;\n    boolean shardsCanUseIDV = canUseIDV;\n\n    String groupField = \"group\";\n\n    for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n\n      // First shard determines whether we use IDV or not;\n      // all other shards match that:\n      if (firstPassCollector == null) {\n        firstPassCollector = createRandomFirstPassCollector(groupField, groupSort, groupOffset + topNGroups);\n      } else {\n        firstPassCollector = createFirstPassCollector(groupField, groupSort, groupOffset + topNGroups, firstPassCollector);\n      }\n      if (VERBOSE) {\n        System.out.println(\"  shard=\" + shardIDX + \" groupField=\" + groupField);\n        System.out.println(\"    1st pass collector=\" + firstPassCollector);\n      }\n      firstPassGroupingCollectors.add(firstPassCollector);\n      subSearchers[shardIDX].search(w, firstPassCollector);\n      final Collection<SearchGroup<BytesRef>> topGroups = getSearchGroups(firstPassCollector, 0);\n      if (topGroups != null) {\n        if (VERBOSE) {\n          System.out.println(\"  shard \" + shardIDX + \" s=\" + subSearchers[shardIDX] + \" totalGroupedHitCount=?\" + \" \" + topGroups.size() + \" groups:\");\n          for(SearchGroup<BytesRef> group : topGroups) {\n            System.out.println(\"    \" + groupToString(group.groupValue) + \" groupSort=\" + Arrays.toString(group.sortValues));\n          }\n        }\n        shardGroups.add(topGroups);\n      }\n    }\n\n    final Collection<SearchGroup<BytesRef>> mergedTopGroups = SearchGroup.merge(shardGroups, groupOffset, topNGroups, groupSort);\n    if (VERBOSE) {\n      System.out.println(\" top groups merged:\");\n      if (mergedTopGroups == null) {\n        System.out.println(\"    null\");\n      } else {\n        System.out.println(\"    \" + mergedTopGroups.size() + \" top groups:\");\n        for(SearchGroup<BytesRef> group : mergedTopGroups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.sortValues));\n        }\n      }\n    }\n\n    if (mergedTopGroups != null) {\n      // Now 2nd pass:\n      @SuppressWarnings({\"unchecked\",\"rawtypes\"})\n      final TopGroups<BytesRef>[] shardTopGroups = new TopGroups[subSearchers.length];\n      for(int shardIDX=0;shardIDX<subSearchers.length;shardIDX++) {\n        final TopGroupsCollector<?> secondPassCollector = createSecondPassCollector(firstPassGroupingCollectors.get(shardIDX),\n            groupField, mergedTopGroups, groupSort, docSort, docOffset + topNDocs, getScores, getMaxScores);\n        subSearchers[shardIDX].search(w, secondPassCollector);\n        shardTopGroups[shardIDX] = getTopGroups(secondPassCollector, 0);\n        if (VERBOSE) {\n          System.out.println(\" \" + shardTopGroups[shardIDX].groups.length + \" shard[\" + shardIDX + \"] groups:\");\n          for(GroupDocs<BytesRef> group : shardTopGroups[shardIDX].groups) {\n            System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues) + \" numDocs=\" + group.scoreDocs.length);\n          }\n        }\n      }\n\n      TopGroups<BytesRef> mergedGroups = TopGroups.merge(shardTopGroups, groupSort, docSort, docOffset, topNDocs, TopGroups.ScoreMergeMode.None);\n      if (VERBOSE) {\n        System.out.println(\" \" + mergedGroups.groups.length + \" merged groups:\");\n        for(GroupDocs<BytesRef> group : mergedGroups.groups) {\n          System.out.println(\"    [\" + groupToString(group.groupValue) + \"] groupSort=\" + Arrays.toString(group.groupSortValues)  + \" numDocs=\" + group.scoreDocs.length);\n        }\n      }\n      return mergedGroups;\n    } else {\n      return null;\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":["20e94e61fe5291647346b70437617e6b6c370408"],"6a47d642ab24da1a811adce4bda9cc52c520ca13":["954e59be3da8dc1b046646ad7af4b466852009d3"],"fb17639909a369c1e64866842e5c213440acc17e":["93dd449115a9247533e44bab47e8429e5dccbc6d"],"475584d5e08a22ad3fc7babefe006d77bc744567":["417142ff08fda9cf0b72d5133e63097a166c6458"],"20e94e61fe5291647346b70437617e6b6c370408":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"04c370507e5521b2eb998530736f1c19b851ed5a":["d58e44159788900f4a2113b84463dc3fbbf80f20"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1","20e94e61fe5291647346b70437617e6b6c370408"],"56572ec06f1407c066d6b7399413178b33176cd8":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","93dd449115a9247533e44bab47e8429e5dccbc6d"],"954e59be3da8dc1b046646ad7af4b466852009d3":["fb17639909a369c1e64866842e5c213440acc17e"],"1d3f7ab1a502671bbdb03bcced21e764d2483221":["04c370507e5521b2eb998530736f1c19b851ed5a"],"417142ff08fda9cf0b72d5133e63097a166c6458":["7ae958a739da1866696f442384393ba2f13e33e5","9fc47cb7b4346802411bb432f501ed0673d7119e"],"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["7e7cf486535cf187cb3745154ca5dd3de3bd2999"],"d58e44159788900f4a2113b84463dc3fbbf80f20":["417142ff08fda9cf0b72d5133e63097a166c6458","475584d5e08a22ad3fc7babefe006d77bc744567"],"93dd449115a9247533e44bab47e8429e5dccbc6d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c9f72b4e0953a7ed14ab0430053c1bb65f2ef529"],"c9f72b4e0953a7ed14ab0430053c1bb65f2ef529":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"7e7cf486535cf187cb3745154ca5dd3de3bd2999":["6a47d642ab24da1a811adce4bda9cc52c520ca13"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["7ae958a739da1866696f442384393ba2f13e33e5"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["1d3f7ab1a502671bbdb03bcced21e764d2483221"],"7ae958a739da1866696f442384393ba2f13e33e5":["20e94e61fe5291647346b70437617e6b6c370408"]},"commit2Childs":{"54ca69905c5d9d1529286f06ab1d12c68f6c13cb":[],"6a47d642ab24da1a811adce4bda9cc52c520ca13":["7e7cf486535cf187cb3745154ca5dd3de3bd2999"],"fb17639909a369c1e64866842e5c213440acc17e":["954e59be3da8dc1b046646ad7af4b466852009d3"],"475584d5e08a22ad3fc7babefe006d77bc744567":["d58e44159788900f4a2113b84463dc3fbbf80f20"],"20e94e61fe5291647346b70437617e6b6c370408":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","7ae958a739da1866696f442384393ba2f13e33e5"],"04c370507e5521b2eb998530736f1c19b851ed5a":["1d3f7ab1a502671bbdb03bcced21e764d2483221"],"09ab8ee44ca898536770d0106a7c0ee4be4f0eb7":[],"56572ec06f1407c066d6b7399413178b33176cd8":[],"954e59be3da8dc1b046646ad7af4b466852009d3":["6a47d642ab24da1a811adce4bda9cc52c520ca13"],"417142ff08fda9cf0b72d5133e63097a166c6458":["475584d5e08a22ad3fc7babefe006d77bc744567","d58e44159788900f4a2113b84463dc3fbbf80f20"],"1d3f7ab1a502671bbdb03bcced21e764d2483221":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1":["20e94e61fe5291647346b70437617e6b6c370408","09ab8ee44ca898536770d0106a7c0ee4be4f0eb7"],"d58e44159788900f4a2113b84463dc3fbbf80f20":["04c370507e5521b2eb998530736f1c19b851ed5a"],"93dd449115a9247533e44bab47e8429e5dccbc6d":["fb17639909a369c1e64866842e5c213440acc17e","56572ec06f1407c066d6b7399413178b33176cd8"],"c9f72b4e0953a7ed14ab0430053c1bb65f2ef529":["93dd449115a9247533e44bab47e8429e5dccbc6d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["56572ec06f1407c066d6b7399413178b33176cd8","93dd449115a9247533e44bab47e8429e5dccbc6d","c9f72b4e0953a7ed14ab0430053c1bb65f2ef529"],"7e7cf486535cf187cb3745154ca5dd3de3bd2999":["0bdb67d0b49ddf963c3bfc4975fce171ad3aacb1"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["417142ff08fda9cf0b72d5133e63097a166c6458"],"7ae958a739da1866696f442384393ba2f13e33e5":["417142ff08fda9cf0b72d5133e63097a166c6458","9fc47cb7b4346802411bb432f501ed0673d7119e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["54ca69905c5d9d1529286f06ab1d12c68f6c13cb","09ab8ee44ca898536770d0106a7c0ee4be4f0eb7","56572ec06f1407c066d6b7399413178b33176cd8","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}