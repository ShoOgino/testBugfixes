{"path":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","commits":[{"id":"52c7e49be259508735752fba88085255014a6ecf","date":1398706273,"type":0,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","pathOld":"/dev/null","sourceNew":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state) throws IOException {\n    int docCount = state.segmentInfo.getDocCount();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            perField.docValuesWriter.finish(docCount);\n            perField.docValuesWriter.flush(state, dvConsumer);\n            perField.docValuesWriter = null;\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": its column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3394716f52b34ab259ad5247e7595d9f9db6e935","date":1398791921,"type":0,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","pathOld":"/dev/null","sourceNew":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state) throws IOException {\n    int docCount = state.segmentInfo.getDocCount();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            perField.docValuesWriter.finish(docCount);\n            perField.docValuesWriter.flush(state, dvConsumer);\n            perField.docValuesWriter = null;\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": its column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","date":1398844771,"type":0,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","pathOld":"/dev/null","sourceNew":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state) throws IOException {\n    int docCount = state.segmentInfo.getDocCount();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            perField.docValuesWriter.finish(docCount);\n            perField.docValuesWriter.flush(state, dvConsumer);\n            perField.docValuesWriter = null;\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": its column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bbe4fb4b1f72f7087bd421083ec10c83ed6c7c3f","date":1414076606,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","sourceNew":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state) throws IOException {\n    int docCount = state.segmentInfo.getDocCount();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.hasDocValues() == false) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            perField.docValuesWriter.finish(docCount);\n            perField.docValuesWriter.flush(state, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.hasDocValues()) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": its column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","sourceOld":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state) throws IOException {\n    int docCount = state.segmentInfo.getDocCount();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            perField.docValuesWriter.finish(docCount);\n            perField.docValuesWriter.flush(state, dvConsumer);\n            perField.docValuesWriter = null;\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": its column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"556a4aab886d75371b2af129d87be3c2795cea76","date":1414954991,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","sourceNew":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state) throws IOException {\n    int docCount = state.segmentInfo.getDocCount();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            perField.docValuesWriter.finish(docCount);\n            perField.docValuesWriter.flush(state, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": its column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","sourceOld":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state) throws IOException {\n    int docCount = state.segmentInfo.getDocCount();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.hasDocValues() == false) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            perField.docValuesWriter.finish(docCount);\n            perField.docValuesWriter.flush(state, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.hasDocValues()) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": its column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1","date":1419400138,"type":3,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","sourceNew":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state) throws IOException {\n    int docCount = state.segmentInfo.getDocCount();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            perField.docValuesWriter.finish(docCount);\n            perField.docValuesWriter.flush(state, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","sourceOld":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state) throws IOException {\n    int docCount = state.segmentInfo.getDocCount();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            perField.docValuesWriter.finish(docCount);\n            perField.docValuesWriter.flush(state, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": its column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0267c69e2456a3477a1ad785723f2135da3117e","date":1425317087,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","sourceNew":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state) throws IOException {\n    int maxDoc = state.segmentInfo.maxDoc();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            perField.docValuesWriter.finish(maxDoc);\n            perField.docValuesWriter.flush(state, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","sourceOld":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state) throws IOException {\n    int docCount = state.segmentInfo.getDocCount();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            perField.docValuesWriter.finish(docCount);\n            perField.docValuesWriter.flush(state, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b06445ae1731e049327712db0454e5643ca9b7fe","date":1425329139,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","sourceNew":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state) throws IOException {\n    int maxDoc = state.segmentInfo.maxDoc();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            perField.docValuesWriter.finish(maxDoc);\n            perField.docValuesWriter.flush(state, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","sourceOld":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state) throws IOException {\n    int docCount = state.segmentInfo.getDocCount();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            perField.docValuesWriter.finish(docCount);\n            perField.docValuesWriter.flush(state, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","date":1427779360,"type":3,"author":"Ryan Ernst","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","sourceNew":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state) throws IOException {\n    int maxDoc = state.segmentInfo.maxDoc();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            perField.docValuesWriter.finish(maxDoc);\n            perField.docValuesWriter.flush(state, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","sourceOld":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state) throws IOException {\n    int docCount = state.segmentInfo.getDocCount();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            perField.docValuesWriter.finish(docCount);\n            perField.docValuesWriter.flush(state, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"86a0a50d2d14aaee1e635bbec914468551f7f9a2","date":1482234306,"type":5,"author":"Mike McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState,Sorter.DocMap).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","sourceNew":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state, Sorter.DocMap sortMap) throws IOException {\n    int maxDoc = state.segmentInfo.maxDoc();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            if (finishedDocValues.contains(perField.fieldInfo.name) == false) {\n              perField.docValuesWriter.finish(maxDoc);\n            }\n            perField.docValuesWriter.flush(state, sortMap, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","sourceOld":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state) throws IOException {\n    int maxDoc = state.segmentInfo.maxDoc();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            perField.docValuesWriter.finish(maxDoc);\n            perField.docValuesWriter.flush(state, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","date":1482251961,"type":4,"author":"Kevin Risden","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/DefaultIndexingChain#writeDocValues(SegmentWriteState).mjava","sourceNew":null,"sourceOld":"  /** Writes all buffered doc values (called from {@link #flush}). */\n  private void writeDocValues(SegmentWriteState state) throws IOException {\n    int maxDoc = state.segmentInfo.maxDoc();\n    DocValuesConsumer dvConsumer = null;\n    boolean success = false;\n    try {\n      for (int i=0;i<fieldHash.length;i++) {\n        PerField perField = fieldHash[i];\n        while (perField != null) {\n          if (perField.docValuesWriter != null) {\n            if (perField.fieldInfo.getDocValuesType() == DocValuesType.NONE) {\n              // BUG\n              throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has no docValues but wrote them\");\n            }\n            if (dvConsumer == null) {\n              // lazy init\n              DocValuesFormat fmt = state.segmentInfo.getCodec().docValuesFormat();\n              dvConsumer = fmt.fieldsConsumer(state);\n            }\n\n            perField.docValuesWriter.finish(maxDoc);\n            perField.docValuesWriter.flush(state, dvConsumer);\n            perField.docValuesWriter = null;\n          } else if (perField.fieldInfo.getDocValuesType() != DocValuesType.NONE) {\n            // BUG\n            throw new AssertionError(\"segment=\" + state.segmentInfo + \": field=\\\"\" + perField.fieldInfo.name + \"\\\" has docValues but did not write them\");\n          }\n          perField = perField.next;\n        }\n      }\n\n      // TODO: catch missing DV fields here?  else we have\n      // null/\"\" depending on how docs landed in segments?\n      // but we can't detect all cases, and we should leave\n      // this behavior undefined. dv is not \"schemaless\": it's column-stride.\n      success = true;\n    } finally {\n      if (success) {\n        IOUtils.close(dvConsumer);\n      } else {\n        IOUtils.closeWhileHandlingException(dvConsumer);\n      }\n    }\n\n    if (state.fieldInfos.hasDocValues() == false) {\n      if (dvConsumer != null) {\n        // BUG\n        throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has no docValues but wrote them\");\n      }\n    } else if (dvConsumer == null) {\n      // BUG\n      throw new AssertionError(\"segment=\" + state.segmentInfo + \": fieldInfos has docValues but did not wrote them\");\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3394716f52b34ab259ad5247e7595d9f9db6e935"],"b0267c69e2456a3477a1ad785723f2135da3117e":["8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1"],"556a4aab886d75371b2af129d87be3c2795cea76":["bbe4fb4b1f72f7087bd421083ec10c83ed6c7c3f"],"3394716f52b34ab259ad5247e7595d9f9db6e935":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","52c7e49be259508735752fba88085255014a6ecf"],"bbe4fb4b1f72f7087bd421083ec10c83ed6c7c3f":["3394716f52b34ab259ad5247e7595d9f9db6e935"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":["8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1","b0267c69e2456a3477a1ad785723f2135da3117e"],"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1":["556a4aab886d75371b2af129d87be3c2795cea76"],"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf":["b0267c69e2456a3477a1ad785723f2135da3117e","86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"b06445ae1731e049327712db0454e5643ca9b7fe":["8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1","b0267c69e2456a3477a1ad785723f2135da3117e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"86a0a50d2d14aaee1e635bbec914468551f7f9a2":["b0267c69e2456a3477a1ad785723f2135da3117e"],"52c7e49be259508735752fba88085255014a6ecf":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["86a0a50d2d14aaee1e635bbec914468551f7f9a2"]},"commit2Childs":{"c0cd85fde84cb318b4dc97710dcf15e2959a1bbe":[],"b0267c69e2456a3477a1ad785723f2135da3117e":["a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","b06445ae1731e049327712db0454e5643ca9b7fe","86a0a50d2d14aaee1e635bbec914468551f7f9a2"],"556a4aab886d75371b2af129d87be3c2795cea76":["8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1"],"3394716f52b34ab259ad5247e7595d9f9db6e935":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","bbe4fb4b1f72f7087bd421083ec10c83ed6c7c3f"],"bbe4fb4b1f72f7087bd421083ec10c83ed6c7c3f":["556a4aab886d75371b2af129d87be3c2795cea76"],"a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae":[],"8aa2bb13f56a3ad540fd2dc5e882e1ed4bf799d1":["b0267c69e2456a3477a1ad785723f2135da3117e","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","b06445ae1731e049327712db0454e5643ca9b7fe"],"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf":[],"b06445ae1731e049327712db0454e5643ca9b7fe":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","3394716f52b34ab259ad5247e7595d9f9db6e935","52c7e49be259508735752fba88085255014a6ecf"],"52c7e49be259508735752fba88085255014a6ecf":["3394716f52b34ab259ad5247e7595d9f9db6e935"],"86a0a50d2d14aaee1e635bbec914468551f7f9a2":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c0cd85fde84cb318b4dc97710dcf15e2959a1bbe","a0d1e2aaf870d9d4f740ed0aaaf5824ccd9394ae","5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","b06445ae1731e049327712db0454e5643ca9b7fe","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}