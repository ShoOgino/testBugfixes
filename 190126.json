{"path":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","commits":[{"id":"a6a5c1c40529f15b445e6720dfde1967e139bff1","date":1535375643,"type":1,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestTriggerIntegration#testNodeMarkersRegistration().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode(random());\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_added_trigger',\" +\n        \"'event' : 'nodeAdded',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode(random());\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(5000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(20000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode(random());\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_added_trigger',\" +\n        \"'event' : 'nodeAdded',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode(random());\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(5000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(20000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fc18bc8ea2e2c1e308757ff50671c774438e9f3e","date":1538052583,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_added_trigger',\" +\n        \"'event' : 'nodeAdded',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(5000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(20000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode(random());\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_added_trigger',\" +\n        \"'event' : 'nodeAdded',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode(random());\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(5000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(20000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bb222a3f9d9421d5c95afce73013fbd8de07ea1f","date":1543514331,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_added_trigger',\" +\n        \"'event' : 'nodeAdded',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(60000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(30000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_added_trigger',\" +\n        \"'event' : 'nodeAdded',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(5000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(20000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","bugFix":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3d0d2781c2dff0497b5a04e552e00554870d2496","date":1544401888,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_added_trigger',\" +\n        \"'event' : 'nodeAdded',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(60000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(30000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_added_trigger',\" +\n        \"'event' : 'nodeAdded',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(60000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(30000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","bugFix":null,"bugIntro":["98d4af357762468d37df7424f81785cd89b49a7b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ef2d9523abb6906938bf5685963ce2d30d541cd7","date":1544417732,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_added_trigger',\" +\n        \"'event' : 'nodeAdded',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(60000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(60000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_added_trigger',\" +\n        \"'event' : 'nodeAdded',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(60000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(30000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"460e835293fb6c26202eea1ba4ac24739db1755b","date":1544540322,"type":3,"author":"markrmiller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_added_trigger',\" +\n        \"'event' : 'nodeAdded',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(60000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(120000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_added_trigger',\" +\n        \"'event' : 'nodeAdded',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(60000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(60000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7e0abaca9e5481b5c3660805111683e8ce53bef3","date":1544554124,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_added_trigger',\" +\n        \"'event' : 'nodeAdded',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(60000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(120000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_added_trigger',\" +\n        \"'event' : 'nodeAdded',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(60000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(60000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"89948af0461fead48f44ba8fb7866f107ce83f22","date":1545157711,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_added_trigger',\" +\n        \"'event' : 'nodeAdded',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(60000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(120000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_added_trigger',\" +\n        \"'event' : 'nodeAdded',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    req = createAutoScalingRequest(SolrRequest.METHOD.POST, setTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(60000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(120000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"914270355efc1f9583010cb165bb031a1e698f84","date":1546908784,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","sourceNew":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    assertAutoScalingRequest\n      (\"{\" +\n       \"'set-trigger' : {\" +\n       \"'name' : 'node_added_trigger',\" +\n       \"'event' : 'nodeAdded',\" +\n       \"'waitFor' : '1s',\" +\n       \"'enabled' : true,\" +\n       \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest\n      (\"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(60000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(120000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    String setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_added_trigger',\" +\n        \"'event' : 'nodeAdded',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    SolrRequest req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    NamedList<Object> response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    setTriggerCommand = \"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n        \"}}\";\n    req = AutoScalingRequest.create(SolrRequest.METHOD.POST, setTriggerCommand);\n    response = solrClient.request(req);\n    assertEquals(response.get(\"result\").toString(), \"success\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(60000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(120000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","bugFix":null,"bugIntro":["98d4af357762468d37df7424f81785cd89b49a7b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"35b336749840ccc5e7c88aa0a787fc6e3730d6e7","date":1546960615,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","sourceNew":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-13072\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // get overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    assertAutoscalingUpdateComplete();\n\n    if (!listener.onChangeLatch.await(10000, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    assertAutoScalingRequest\n      (\"{\" +\n       \"'set-trigger' : {\" +\n       \"'name' : 'node_added_trigger',\" +\n       \"'event' : 'nodeAdded',\" +\n       \"'waitFor' : '1s',\" +\n       \"'enabled' : true,\" +\n       \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest\n      (\"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoscalingUpdateComplete();\n    overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    // one nodeAdded (not cleared yet) and one nodeLost\n    triggerFiredLatch = new CountDownLatch(2);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n    assertAutoscalingUpdateComplete();\n\n    if (!triggerFiredLatch.await(120000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(2, events.size());\n    TriggerEvent nodeAdded = null;\n    TriggerEvent nodeLost = null;\n    for (TriggerEvent ev : events) {\n      switch (ev.getEventType()) {\n        case NODEADDED:\n          nodeAdded = ev;\n          break;\n        case NODELOST:\n          nodeLost = ev;\n          break;\n        default:\n          fail(\"unexpected event type: \" + ev);\n      }\n    }\n    assertNotNull(\"expected nodeAdded event\", nodeAdded);\n    assertNotNull(\"expected nodeLost event\", nodeLost);\n    List<String> nodeNames = (List<String>)nodeLost.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    nodeNames = (List<String>)nodeAdded.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(node1));\n  }\n\n","sourceOld":"  @Test\n  @BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-12028\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // pick overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    assertAutoScalingRequest\n      (\"{\" +\n       \"'set-trigger' : {\" +\n       \"'name' : 'node_added_trigger',\" +\n       \"'event' : 'nodeAdded',\" +\n       \"'waitFor' : '1s',\" +\n       \"'enabled' : true,\" +\n       \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest\n      (\"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetRandomNode();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    cluster.getTimeSource().sleep(60000);\n    // nodeAdded marker should be consumed now by nodeAdded trigger\n    assertFalse(\"Path \" + pathAdded + \" should have been deleted\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(120000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>)ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","bugFix":null,"bugIntro":["98d4af357762468d37df7424f81785cd89b49a7b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3904abfa513b750aabc2b2fba5336ba86ed32490","date":1547515000,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","sourceNew":"  @Test\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // get overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    assertAutoscalingUpdateComplete();\n\n    if (!listener.onChangeLatch.await(10000, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    assertAutoScalingRequest\n      (\"{\" +\n       \"'set-trigger' : {\" +\n       \"'name' : 'node_added_trigger',\" +\n       \"'event' : 'nodeAdded',\" +\n       \"'waitFor' : '1s',\" +\n       \"'enabled' : true,\" +\n       \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest\n      (\"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoscalingUpdateComplete();\n    overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    // one nodeAdded (not cleared yet) and one nodeLost\n    triggerFiredLatch = new CountDownLatch(2);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n    assertAutoscalingUpdateComplete();\n\n    if (!triggerFiredLatch.await(120000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(2, events.size());\n    TriggerEvent nodeAdded = null;\n    TriggerEvent nodeLost = null;\n    for (TriggerEvent ev : events) {\n      switch (ev.getEventType()) {\n        case NODEADDED:\n          nodeAdded = ev;\n          break;\n        case NODELOST:\n          nodeLost = ev;\n          break;\n        default:\n          fail(\"unexpected event type: \" + ev);\n      }\n    }\n    assertNotNull(\"expected nodeAdded event\", nodeAdded);\n    assertNotNull(\"expected nodeLost event\", nodeLost);\n    List<String> nodeNames = (List<String>)nodeLost.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    nodeNames = (List<String>)nodeAdded.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(node1));\n  }\n\n","sourceOld":"  @Test\n  //@BadApple(bugUrl=\"https://issues.apache.org/jira/browse/SOLR-13072\")\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // get overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    assertAutoscalingUpdateComplete();\n\n    if (!listener.onChangeLatch.await(10000, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    assertAutoScalingRequest\n      (\"{\" +\n       \"'set-trigger' : {\" +\n       \"'name' : 'node_added_trigger',\" +\n       \"'event' : 'nodeAdded',\" +\n       \"'waitFor' : '1s',\" +\n       \"'enabled' : true,\" +\n       \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest\n      (\"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoscalingUpdateComplete();\n    overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    // one nodeAdded (not cleared yet) and one nodeLost\n    triggerFiredLatch = new CountDownLatch(2);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n    assertAutoscalingUpdateComplete();\n\n    if (!triggerFiredLatch.await(120000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(2, events.size());\n    TriggerEvent nodeAdded = null;\n    TriggerEvent nodeLost = null;\n    for (TriggerEvent ev : events) {\n      switch (ev.getEventType()) {\n        case NODEADDED:\n          nodeAdded = ev;\n          break;\n        case NODELOST:\n          nodeLost = ev;\n          break;\n        default:\n          fail(\"unexpected event type: \" + ev);\n      }\n    }\n    assertNotNull(\"expected nodeAdded event\", nodeAdded);\n    assertNotNull(\"expected nodeLost event\", nodeLost);\n    List<String> nodeNames = (List<String>)nodeLost.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    nodeNames = (List<String>)nodeAdded.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(node1));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"215b6316d63375fce4dfbf1f55967c739795a2f9","date":1551465498,"type":3,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","sourceNew":"  @Test\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // get overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // add a node\n    String node = cluster.simAddNode();\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    assertAutoscalingUpdateComplete();\n\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    assertAutoScalingRequest\n      (\"{\" +\n       \"'set-trigger' : {\" +\n       \"'name' : 'node_added_trigger',\" +\n       \"'event' : 'nodeAdded',\" +\n       \"'waitFor' : '1s',\" +\n       \"'enabled' : true,\" +\n       \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest\n      (\"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoscalingUpdateComplete();\n    overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    // one nodeAdded (not cleared yet) and one nodeLost\n    triggerFiredLatch = new CountDownLatch(2);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n\n    assertAutoscalingUpdateComplete();\n\n    assertTrue(\"trigger did not fire event after await()ing an excessive amount of time\",\n               triggerFiredLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(2, events.size());\n    TriggerEvent nodeAdded = null;\n    TriggerEvent nodeLost = null;\n    for (TriggerEvent ev : events) {\n      switch (ev.getEventType()) {\n        case NODEADDED:\n          nodeAdded = ev;\n          break;\n        case NODELOST:\n          nodeLost = ev;\n          break;\n        default:\n          fail(\"unexpected event type: \" + ev);\n      }\n    }\n    assertNotNull(\"expected nodeAdded event\", nodeAdded);\n    assertNotNull(\"expected nodeLost event\", nodeLost);\n    List<String> nodeNames = (List<String>)nodeLost.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    nodeNames = (List<String>)nodeAdded.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(node1));\n  }\n\n","sourceOld":"  @Test\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // get overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // add a node\n    String node = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    assertAutoscalingUpdateComplete();\n\n    if (!listener.onChangeLatch.await(10000, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    assertAutoScalingRequest\n      (\"{\" +\n       \"'set-trigger' : {\" +\n       \"'name' : 'node_added_trigger',\" +\n       \"'event' : 'nodeAdded',\" +\n       \"'waitFor' : '1s',\" +\n       \"'enabled' : true,\" +\n       \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest\n      (\"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoscalingUpdateComplete();\n    overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    // one nodeAdded (not cleared yet) and one nodeLost\n    triggerFiredLatch = new CountDownLatch(2);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    if (!listener.onChangeLatch.await(10000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n    assertAutoscalingUpdateComplete();\n\n    if (!triggerFiredLatch.await(120000 / SPEED, TimeUnit.MILLISECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(2, events.size());\n    TriggerEvent nodeAdded = null;\n    TriggerEvent nodeLost = null;\n    for (TriggerEvent ev : events) {\n      switch (ev.getEventType()) {\n        case NODEADDED:\n          nodeAdded = ev;\n          break;\n        case NODELOST:\n          nodeLost = ev;\n          break;\n        default:\n          fail(\"unexpected event type: \" + ev);\n      }\n    }\n    assertNotNull(\"expected nodeAdded event\", nodeAdded);\n    assertNotNull(\"expected nodeLost event\", nodeLost);\n    List<String> nodeNames = (List<String>)nodeLost.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    nodeNames = (List<String>)nodeAdded.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(node1));\n  }\n\n","bugFix":null,"bugIntro":["98d4af357762468d37df7424f81785cd89b49a7b"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"98d4af357762468d37df7424f81785cd89b49a7b","date":1570534862,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","sourceNew":"  @Test\n  public void testNodeMarkersRegistration() throws Exception {\n    triggerFiredLatch = new CountDownLatch(1);\n    listenerEventLatch = new CountDownLatch(1);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // get overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // add a node\n    String node = cluster.simAddNode();\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(1, listener.addedNodes.size());\n    assertTrue(listener.addedNodes.toString(), listener.addedNodes.contains(node));\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    assertAutoscalingUpdateComplete();\n\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n\n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    AtomicBoolean markerInactive = new AtomicBoolean();\n    timeout.waitFor(\"nodeLost marker to get inactive\", () -> {\n      try {\n        if (!cluster.getDistribStateManager().hasData(pathLost)) {\n          throw new RuntimeException(\"marker \" + pathLost + \" should exist!\");\n        }\n        Map<String, Object> markerData = Utils.getJson(cluster.getDistribStateManager(), pathLost);\n        markerInactive.set(markerData.getOrDefault(MARKER_STATE, MARKER_ACTIVE).equals(MARKER_INACTIVE));\n        return markerInactive.get();\n\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    // verify that the marker is inactive - the new overseer should deactivate markers once they are processed\n    assertTrue(\"Marker \" + pathLost + \" still active!\", markerInactive.get());\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    assertAutoScalingRequest\n      (\"{\" +\n       \"'set-trigger' : {\" +\n       \"'name' : 'node_added_triggerMR',\" +\n       \"'event' : 'nodeAdded',\" +\n       \"'waitFor' : '1s',\" +\n       \"'enabled' : true,\" +\n       \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest\n      (\"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_triggerMR',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest(\n        \"{\\n\" +\n            \"  \\\"set-listener\\\" : {\\n\" +\n            \"    \\\"name\\\" : \\\"listener_node_added_triggerMR\\\",\\n\" +\n            \"    \\\"trigger\\\" : \\\"node_added_triggerMR\\\",\\n\" +\n            \"    \\\"stage\\\" : \\\"STARTED\\\",\\n\" +\n            \"    \\\"class\\\" : \\\"\" + AssertingListener.class.getName()  + \"\\\"\\n\" +\n            \"  }\\n\" +\n            \"}\"\n    );\n    assertAutoscalingUpdateComplete();\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    listenerEventLatch.countDown(); // let the trigger thread continue\n\n    assertTrue(triggerFiredLatch.await(10, TimeUnit.SECONDS));\n\n    // kill this node\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n\n    cluster.simRemoveNode(node1, true);\n    if (!listener.onChangeLatch.await(10, TimeUnit.SECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(node1, listener.lostNodes.iterator().next());\n    // verify that a znode exists\n    String pathLost2 = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathLost2 + \" wasn't created\", cluster.getDistribStateManager().hasData(pathLost2));\n\n    listenerEventLatch.countDown(); // let the trigger thread continue\n\n    assertTrue(triggerFiredLatch.await(10, TimeUnit.SECONDS));\n\n    // triggers don't remove markers\n    assertTrue(\"Path \" + pathLost2 + \" should still exist\", cluster.getDistribStateManager().hasData(pathLost2));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRemoveNode(overseerLeader, true);\n    if (!listener.onChangeLatch.await(10, TimeUnit.SECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(20, TimeUnit.SECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>) ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","sourceOld":"  @Test\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // get overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // add a node\n    String node = cluster.simAddNode();\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    assertAutoscalingUpdateComplete();\n\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    assertAutoScalingRequest\n      (\"{\" +\n       \"'set-trigger' : {\" +\n       \"'name' : 'node_added_trigger',\" +\n       \"'event' : 'nodeAdded',\" +\n       \"'waitFor' : '1s',\" +\n       \"'enabled' : true,\" +\n       \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest\n      (\"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoscalingUpdateComplete();\n    overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    // one nodeAdded (not cleared yet) and one nodeLost\n    triggerFiredLatch = new CountDownLatch(2);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n\n    assertAutoscalingUpdateComplete();\n\n    assertTrue(\"trigger did not fire event after await()ing an excessive amount of time\",\n               triggerFiredLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(2, events.size());\n    TriggerEvent nodeAdded = null;\n    TriggerEvent nodeLost = null;\n    for (TriggerEvent ev : events) {\n      switch (ev.getEventType()) {\n        case NODEADDED:\n          nodeAdded = ev;\n          break;\n        case NODELOST:\n          nodeLost = ev;\n          break;\n        default:\n          fail(\"unexpected event type: \" + ev);\n      }\n    }\n    assertNotNull(\"expected nodeAdded event\", nodeAdded);\n    assertNotNull(\"expected nodeLost event\", nodeLost);\n    List<String> nodeNames = (List<String>)nodeLost.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    nodeNames = (List<String>)nodeAdded.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(node1));\n  }\n\n","bugFix":["35b336749840ccc5e7c88aa0a787fc6e3730d6e7","3d0d2781c2dff0497b5a04e552e00554870d2496","914270355efc1f9583010cb165bb031a1e698f84","1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","215b6316d63375fce4dfbf1f55967c739795a2f9"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b0b597c65628ca9e73913a07e81691f8229bae35","date":1571224353,"type":3,"author":"jimczi","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","sourceNew":"  @Test\n  public void testNodeMarkersRegistration() throws Exception {\n    triggerFiredLatch = new CountDownLatch(1);\n    listenerEventLatch = new CountDownLatch(1);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // get overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // add a node\n    String node = cluster.simAddNode();\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(1, listener.addedNodes.size());\n    assertTrue(listener.addedNodes.toString(), listener.addedNodes.contains(node));\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    assertAutoscalingUpdateComplete();\n\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n\n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    AtomicBoolean markerInactive = new AtomicBoolean();\n    timeout.waitFor(\"nodeLost marker to get inactive\", () -> {\n      try {\n        if (!cluster.getDistribStateManager().hasData(pathLost)) {\n          throw new RuntimeException(\"marker \" + pathLost + \" should exist!\");\n        }\n        Map<String, Object> markerData = Utils.getJson(cluster.getDistribStateManager(), pathLost);\n        markerInactive.set(markerData.getOrDefault(MARKER_STATE, MARKER_ACTIVE).equals(MARKER_INACTIVE));\n        return markerInactive.get();\n\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    // verify that the marker is inactive - the new overseer should deactivate markers once they are processed\n    assertTrue(\"Marker \" + pathLost + \" still active!\", markerInactive.get());\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    assertAutoScalingRequest\n      (\"{\" +\n       \"'set-trigger' : {\" +\n       \"'name' : 'node_added_triggerMR',\" +\n       \"'event' : 'nodeAdded',\" +\n       \"'waitFor' : '1s',\" +\n       \"'enabled' : true,\" +\n       \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest\n      (\"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_triggerMR',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest(\n        \"{\\n\" +\n            \"  \\\"set-listener\\\" : {\\n\" +\n            \"    \\\"name\\\" : \\\"listener_node_added_triggerMR\\\",\\n\" +\n            \"    \\\"trigger\\\" : \\\"node_added_triggerMR\\\",\\n\" +\n            \"    \\\"stage\\\" : \\\"STARTED\\\",\\n\" +\n            \"    \\\"class\\\" : \\\"\" + AssertingListener.class.getName()  + \"\\\"\\n\" +\n            \"  }\\n\" +\n            \"}\"\n    );\n    assertAutoscalingUpdateComplete();\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    listenerEventLatch.countDown(); // let the trigger thread continue\n\n    assertTrue(triggerFiredLatch.await(10, TimeUnit.SECONDS));\n\n    // kill this node\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n\n    cluster.simRemoveNode(node1, true);\n    if (!listener.onChangeLatch.await(10, TimeUnit.SECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(node1, listener.lostNodes.iterator().next());\n    // verify that a znode exists\n    String pathLost2 = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathLost2 + \" wasn't created\", cluster.getDistribStateManager().hasData(pathLost2));\n\n    listenerEventLatch.countDown(); // let the trigger thread continue\n\n    assertTrue(triggerFiredLatch.await(10, TimeUnit.SECONDS));\n\n    // triggers don't remove markers\n    assertTrue(\"Path \" + pathLost2 + \" should still exist\", cluster.getDistribStateManager().hasData(pathLost2));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRemoveNode(overseerLeader, true);\n    if (!listener.onChangeLatch.await(10, TimeUnit.SECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(20, TimeUnit.SECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>) ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","sourceOld":"  @Test\n  public void testNodeMarkersRegistration() throws Exception {\n    // for this test we want to create two triggers so we must assert that the actions were created twice\n    actionInitCalled = new CountDownLatch(2);\n    // similarly we want both triggers to fire\n    triggerFiredLatch = new CountDownLatch(2);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // get overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // add a node\n    String node = cluster.simAddNode();\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node, listener.addedNodes.iterator().next());\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    assertAutoscalingUpdateComplete();\n\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n    // verify that a znode does NOT exist - there's no nodeLost trigger,\n    // so the new overseer cleaned up existing nodeLost markers\n    \n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    timeout.waitFor(\"Path \" + pathLost + \" exists\", () -> {\n      try {\n        return !cluster.getDistribStateManager().hasData(pathLost);\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    assertFalse(\"Path \" + pathLost + \" exists\", cluster.getDistribStateManager().hasData(pathLost));\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    assertAutoScalingRequest\n      (\"{\" +\n       \"'set-trigger' : {\" +\n       \"'name' : 'node_added_trigger',\" +\n       \"'event' : 'nodeAdded',\" +\n       \"'waitFor' : '1s',\" +\n       \"'enabled' : true,\" +\n       \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest\n      (\"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_trigger',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoscalingUpdateComplete();\n    overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    listener.reset();\n    events.clear();\n    // one nodeAdded (not cleared yet) and one nodeLost\n    triggerFiredLatch = new CountDownLatch(2);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRestartOverseer(overseerLeader);\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n\n    assertAutoscalingUpdateComplete();\n\n    assertTrue(\"trigger did not fire event after await()ing an excessive amount of time\",\n               triggerFiredLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(2, events.size());\n    TriggerEvent nodeAdded = null;\n    TriggerEvent nodeLost = null;\n    for (TriggerEvent ev : events) {\n      switch (ev.getEventType()) {\n        case NODEADDED:\n          nodeAdded = ev;\n          break;\n        case NODELOST:\n          nodeLost = ev;\n          break;\n        default:\n          fail(\"unexpected event type: \" + ev);\n      }\n    }\n    assertNotNull(\"expected nodeAdded event\", nodeAdded);\n    assertNotNull(\"expected nodeLost event\", nodeLost);\n    List<String> nodeNames = (List<String>)nodeLost.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    nodeNames = (List<String>)nodeAdded.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(node1));\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aa2585c33d5d66a1c837c312221eb55ddb3c4300","date":1592493170,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","sourceNew":"  @Test\n  public void testNodeMarkersRegistration() throws Exception {\n    triggerFiredLatch = new CountDownLatch(1);\n    listenerEventLatch = new CountDownLatch(1);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // get overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // add a node\n    String node = cluster.simAddNode();\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(1, listener.addedNodes.size());\n    assertTrue(listener.addedNodes.toString(), listener.addedNodes.contains(node));\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    assertAutoscalingUpdateComplete();\n\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n\n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    AtomicBoolean markerInactive = new AtomicBoolean();\n    timeout.waitFor(\"nodeLost marker to get inactive\", () -> {\n      try {\n        if (!cluster.getDistribStateManager().hasData(pathLost)) {\n          throw new RuntimeException(\"marker \" + pathLost + \" should exist!\");\n        }\n        Map<String, Object> markerData = Utils.getJson(cluster.getDistribStateManager(), pathLost);\n        markerInactive.set(markerData.getOrDefault(MARKER_STATE, MARKER_ACTIVE).equals(MARKER_INACTIVE));\n        return markerInactive.get();\n\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    // verify that the marker is inactive - the new overseer should deactivate markers once they are processed\n    assertTrue(\"Marker \" + pathLost + \" still active!\", markerInactive.get());\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    assertAutoScalingRequest\n      (\"{\" +\n       \"'set-trigger' : {\" +\n       \"'name' : 'node_added_triggerMR',\" +\n       \"'event' : 'nodeAdded',\" +\n       \"'waitFor' : '1s',\" +\n       \"'enabled' : true,\" +\n       \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest\n      (\"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_triggerMR',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest(\n        \"{\\n\" +\n            \"  \\\"set-listener\\\" : {\\n\" +\n            \"    \\\"name\\\" : \\\"listener_node_added_triggerMR\\\",\\n\" +\n            \"    \\\"trigger\\\" : \\\"node_added_triggerMR\\\",\\n\" +\n            \"    \\\"stage\\\" : \\\"STARTED\\\",\\n\" +\n            \"    \\\"class\\\" : \\\"\" + AssertingListener.class.getName()  + \"\\\"\\n\" +\n            \"  }\\n\" +\n            \"}\"\n    );\n    assertAutoscalingUpdateComplete();\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    listenerEventLatch.countDown(); // let the trigger thread continue\n\n    assertTrue(triggerFiredLatch.await(10, TimeUnit.SECONDS));\n\n    // kill this node\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n\n    cluster.simRemoveNode(node1, true);\n    if (!listener.onChangeLatch.await(10, TimeUnit.SECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(node1, listener.lostNodes.iterator().next());\n    // verify that a znode exists\n    String pathLost2 = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathLost2 + \" wasn't created\", cluster.getDistribStateManager().hasData(pathLost2));\n\n    listenerEventLatch.countDown(); // let the trigger thread continue\n\n    assertTrue(triggerFiredLatch.await(10, TimeUnit.SECONDS));\n\n    // triggers don't remove markers\n    assertTrue(\"Path \" + pathLost2 + \" should still exist\", cluster.getDistribStateManager().hasData(pathLost2));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRemoveNode(overseerLeader, true);\n    if (!listener.onChangeLatch.await(10, TimeUnit.SECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(20, TimeUnit.SECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    @SuppressWarnings({\"unchecked\"})\n    List<String> nodeNames = (List<String>) ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","sourceOld":"  @Test\n  public void testNodeMarkersRegistration() throws Exception {\n    triggerFiredLatch = new CountDownLatch(1);\n    listenerEventLatch = new CountDownLatch(1);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // get overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // add a node\n    String node = cluster.simAddNode();\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(1, listener.addedNodes.size());\n    assertTrue(listener.addedNodes.toString(), listener.addedNodes.contains(node));\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    assertAutoscalingUpdateComplete();\n\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n\n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    AtomicBoolean markerInactive = new AtomicBoolean();\n    timeout.waitFor(\"nodeLost marker to get inactive\", () -> {\n      try {\n        if (!cluster.getDistribStateManager().hasData(pathLost)) {\n          throw new RuntimeException(\"marker \" + pathLost + \" should exist!\");\n        }\n        Map<String, Object> markerData = Utils.getJson(cluster.getDistribStateManager(), pathLost);\n        markerInactive.set(markerData.getOrDefault(MARKER_STATE, MARKER_ACTIVE).equals(MARKER_INACTIVE));\n        return markerInactive.get();\n\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    // verify that the marker is inactive - the new overseer should deactivate markers once they are processed\n    assertTrue(\"Marker \" + pathLost + \" still active!\", markerInactive.get());\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    assertAutoScalingRequest\n      (\"{\" +\n       \"'set-trigger' : {\" +\n       \"'name' : 'node_added_triggerMR',\" +\n       \"'event' : 'nodeAdded',\" +\n       \"'waitFor' : '1s',\" +\n       \"'enabled' : true,\" +\n       \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest\n      (\"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_triggerMR',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest(\n        \"{\\n\" +\n            \"  \\\"set-listener\\\" : {\\n\" +\n            \"    \\\"name\\\" : \\\"listener_node_added_triggerMR\\\",\\n\" +\n            \"    \\\"trigger\\\" : \\\"node_added_triggerMR\\\",\\n\" +\n            \"    \\\"stage\\\" : \\\"STARTED\\\",\\n\" +\n            \"    \\\"class\\\" : \\\"\" + AssertingListener.class.getName()  + \"\\\"\\n\" +\n            \"  }\\n\" +\n            \"}\"\n    );\n    assertAutoscalingUpdateComplete();\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    listenerEventLatch.countDown(); // let the trigger thread continue\n\n    assertTrue(triggerFiredLatch.await(10, TimeUnit.SECONDS));\n\n    // kill this node\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n\n    cluster.simRemoveNode(node1, true);\n    if (!listener.onChangeLatch.await(10, TimeUnit.SECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(node1, listener.lostNodes.iterator().next());\n    // verify that a znode exists\n    String pathLost2 = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathLost2 + \" wasn't created\", cluster.getDistribStateManager().hasData(pathLost2));\n\n    listenerEventLatch.countDown(); // let the trigger thread continue\n\n    assertTrue(triggerFiredLatch.await(10, TimeUnit.SECONDS));\n\n    // triggers don't remove markers\n    assertTrue(\"Path \" + pathLost2 + \" should still exist\", cluster.getDistribStateManager().hasData(pathLost2));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRemoveNode(overseerLeader, true);\n    if (!listener.onChangeLatch.await(10, TimeUnit.SECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(20, TimeUnit.SECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    List<String> nodeNames = (List<String>) ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3f504512a03d978990cbff30db0522b354e846db","date":1595247421,"type":4,"author":"Ishan Chattopadhyaya","isMerge":false,"pathNew":"/dev/null","pathOld":"solr/core/src/test/org/apache/solr/cloud/autoscaling/sim/TestSimTriggerIntegration#testNodeMarkersRegistration().mjava","sourceNew":null,"sourceOld":"  @Test\n  public void testNodeMarkersRegistration() throws Exception {\n    triggerFiredLatch = new CountDownLatch(1);\n    listenerEventLatch = new CountDownLatch(1);\n    TestLiveNodesListener listener = registerLiveNodesListener();\n\n    SolrClient solrClient = cluster.simGetSolrClient();\n\n    // get overseer node\n    String overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // add a node\n    String node = cluster.simAddNode();\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(1, listener.addedNodes.size());\n    assertTrue(listener.addedNodes.toString(), listener.addedNodes.contains(node));\n    // verify that a znode doesn't exist (no trigger)\n    String pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node;\n    assertFalse(\"Path \" + pathAdded + \" was created but there are no nodeAdded triggers\",\n        cluster.getDistribStateManager().hasData(pathAdded));\n    listener.reset();\n    // stop overseer\n    log.info(\"====== KILL OVERSEER 1\");\n    cluster.simRestartOverseer(overseerLeader);\n    assertAutoscalingUpdateComplete();\n\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(overseerLeader, listener.lostNodes.iterator().next());\n    assertEquals(0, listener.addedNodes.size());\n    // wait until the new overseer is up\n    cluster.getTimeSource().sleep(5000);\n\n    String pathLost = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + overseerLeader;\n    \n    TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, TimeSource.NANO_TIME);\n    AtomicBoolean markerInactive = new AtomicBoolean();\n    timeout.waitFor(\"nodeLost marker to get inactive\", () -> {\n      try {\n        if (!cluster.getDistribStateManager().hasData(pathLost)) {\n          throw new RuntimeException(\"marker \" + pathLost + \" should exist!\");\n        }\n        Map<String, Object> markerData = Utils.getJson(cluster.getDistribStateManager(), pathLost);\n        markerInactive.set(markerData.getOrDefault(MARKER_STATE, MARKER_ACTIVE).equals(MARKER_INACTIVE));\n        return markerInactive.get();\n\n      } catch (IOException | KeeperException | InterruptedException e) {\n        e.printStackTrace();\n        throw new RuntimeException(e);\n      }\n    });\n\n    // verify that the marker is inactive - the new overseer should deactivate markers once they are processed\n    assertTrue(\"Marker \" + pathLost + \" still active!\", markerInactive.get());\n\n    listener.reset();\n\n    // set up triggers\n\n    log.info(\"====== ADD TRIGGERS\");\n    assertAutoScalingRequest\n      (\"{\" +\n       \"'set-trigger' : {\" +\n       \"'name' : 'node_added_triggerMR',\" +\n       \"'event' : 'nodeAdded',\" +\n       \"'waitFor' : '1s',\" +\n       \"'enabled' : true,\" +\n       \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest\n      (\"{\" +\n        \"'set-trigger' : {\" +\n        \"'name' : 'node_lost_triggerMR',\" +\n        \"'event' : 'nodeLost',\" +\n        \"'waitFor' : '1s',\" +\n        \"'enabled' : true,\" +\n        \"'actions' : [{'name':'test','class':'\" + TestEventMarkerAction.class.getName() + \"'}]\" +\n       \"}}\");\n\n    assertAutoScalingRequest(\n        \"{\\n\" +\n            \"  \\\"set-listener\\\" : {\\n\" +\n            \"    \\\"name\\\" : \\\"listener_node_added_triggerMR\\\",\\n\" +\n            \"    \\\"trigger\\\" : \\\"node_added_triggerMR\\\",\\n\" +\n            \"    \\\"stage\\\" : \\\"STARTED\\\",\\n\" +\n            \"    \\\"class\\\" : \\\"\" + AssertingListener.class.getName()  + \"\\\"\\n\" +\n            \"  }\\n\" +\n            \"}\"\n    );\n    assertAutoscalingUpdateComplete();\n\n    overseerLeader = cluster.getSimClusterStateProvider().simGetOverseerLeader();\n\n    // create another node\n    log.info(\"====== ADD NODE 1\");\n    String node1 = cluster.simAddNode();\n    assertTrue(\"cluster onChange listener didn't execute even after await()ing an excessive amount of time\",\n               listener.onChangeLatch.await(60, TimeUnit.SECONDS));\n    assertEquals(1, listener.addedNodes.size());\n    assertEquals(node1, listener.addedNodes.iterator().next());\n    // verify that a znode exists\n    pathAdded = ZkStateReader.SOLR_AUTOSCALING_NODE_ADDED_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathAdded + \" wasn't created\", cluster.getDistribStateManager().hasData(pathAdded));\n\n    listenerEventLatch.countDown(); // let the trigger thread continue\n\n    assertTrue(triggerFiredLatch.await(10, TimeUnit.SECONDS));\n\n    // kill this node\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n\n    cluster.simRemoveNode(node1, true);\n    if (!listener.onChangeLatch.await(10, TimeUnit.SECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n    assertEquals(1, listener.lostNodes.size());\n    assertEquals(node1, listener.lostNodes.iterator().next());\n    // verify that a znode exists\n    String pathLost2 = ZkStateReader.SOLR_AUTOSCALING_NODE_LOST_PATH + \"/\" + node1;\n    assertTrue(\"Path \" + pathLost2 + \" wasn't created\", cluster.getDistribStateManager().hasData(pathLost2));\n\n    listenerEventLatch.countDown(); // let the trigger thread continue\n\n    assertTrue(triggerFiredLatch.await(10, TimeUnit.SECONDS));\n\n    // triggers don't remove markers\n    assertTrue(\"Path \" + pathLost2 + \" should still exist\", cluster.getDistribStateManager().hasData(pathLost2));\n\n    listener.reset();\n    events.clear();\n    triggerFiredLatch = new CountDownLatch(1);\n    // kill overseer again\n    log.info(\"====== KILL OVERSEER 2\");\n    cluster.simRemoveNode(overseerLeader, true);\n    if (!listener.onChangeLatch.await(10, TimeUnit.SECONDS)) {\n      fail(\"onChange listener didn't execute on cluster change\");\n    }\n\n\n    if (!triggerFiredLatch.await(20, TimeUnit.SECONDS)) {\n      fail(\"Trigger should have fired by now\");\n    }\n    assertEquals(1, events.size());\n    TriggerEvent ev = events.iterator().next();\n    @SuppressWarnings({\"unchecked\"})\n    List<String> nodeNames = (List<String>) ev.getProperty(TriggerEvent.NODE_NAMES);\n    assertTrue(nodeNames.contains(overseerLeader));\n    assertEquals(TriggerEventType.NODELOST, ev.getEventType());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"fc18bc8ea2e2c1e308757ff50671c774438e9f3e":["a6a5c1c40529f15b445e6720dfde1967e139bff1"],"460e835293fb6c26202eea1ba4ac24739db1755b":["ef2d9523abb6906938bf5685963ce2d30d541cd7"],"a6a5c1c40529f15b445e6720dfde1967e139bff1":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ef2d9523abb6906938bf5685963ce2d30d541cd7":["3d0d2781c2dff0497b5a04e552e00554870d2496"],"3f504512a03d978990cbff30db0522b354e846db":["aa2585c33d5d66a1c837c312221eb55ddb3c4300"],"35b336749840ccc5e7c88aa0a787fc6e3730d6e7":["914270355efc1f9583010cb165bb031a1e698f84"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["fc18bc8ea2e2c1e308757ff50671c774438e9f3e"],"215b6316d63375fce4dfbf1f55967c739795a2f9":["3904abfa513b750aabc2b2fba5336ba86ed32490"],"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["98d4af357762468d37df7424f81785cd89b49a7b"],"914270355efc1f9583010cb165bb031a1e698f84":["89948af0461fead48f44ba8fb7866f107ce83f22"],"98d4af357762468d37df7424f81785cd89b49a7b":["215b6316d63375fce4dfbf1f55967c739795a2f9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3d0d2781c2dff0497b5a04e552e00554870d2496":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"89948af0461fead48f44ba8fb7866f107ce83f22":["7e0abaca9e5481b5c3660805111683e8ce53bef3"],"7e0abaca9e5481b5c3660805111683e8ce53bef3":["ef2d9523abb6906938bf5685963ce2d30d541cd7","460e835293fb6c26202eea1ba4ac24739db1755b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3f504512a03d978990cbff30db0522b354e846db"],"3904abfa513b750aabc2b2fba5336ba86ed32490":["35b336749840ccc5e7c88aa0a787fc6e3730d6e7"],"b0b597c65628ca9e73913a07e81691f8229bae35":["215b6316d63375fce4dfbf1f55967c739795a2f9","98d4af357762468d37df7424f81785cd89b49a7b"]},"commit2Childs":{"fc18bc8ea2e2c1e308757ff50671c774438e9f3e":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"460e835293fb6c26202eea1ba4ac24739db1755b":["7e0abaca9e5481b5c3660805111683e8ce53bef3"],"a6a5c1c40529f15b445e6720dfde1967e139bff1":["fc18bc8ea2e2c1e308757ff50671c774438e9f3e"],"ef2d9523abb6906938bf5685963ce2d30d541cd7":["460e835293fb6c26202eea1ba4ac24739db1755b","7e0abaca9e5481b5c3660805111683e8ce53bef3"],"3f504512a03d978990cbff30db0522b354e846db":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"35b336749840ccc5e7c88aa0a787fc6e3730d6e7":["3904abfa513b750aabc2b2fba5336ba86ed32490"],"bb222a3f9d9421d5c95afce73013fbd8de07ea1f":["3d0d2781c2dff0497b5a04e552e00554870d2496"],"215b6316d63375fce4dfbf1f55967c739795a2f9":["98d4af357762468d37df7424f81785cd89b49a7b","b0b597c65628ca9e73913a07e81691f8229bae35"],"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["3f504512a03d978990cbff30db0522b354e846db"],"914270355efc1f9583010cb165bb031a1e698f84":["35b336749840ccc5e7c88aa0a787fc6e3730d6e7"],"98d4af357762468d37df7424f81785cd89b49a7b":["aa2585c33d5d66a1c837c312221eb55ddb3c4300","b0b597c65628ca9e73913a07e81691f8229bae35"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a6a5c1c40529f15b445e6720dfde1967e139bff1"],"3d0d2781c2dff0497b5a04e552e00554870d2496":["ef2d9523abb6906938bf5685963ce2d30d541cd7"],"89948af0461fead48f44ba8fb7866f107ce83f22":["914270355efc1f9583010cb165bb031a1e698f84"],"7e0abaca9e5481b5c3660805111683e8ce53bef3":["89948af0461fead48f44ba8fb7866f107ce83f22"],"3904abfa513b750aabc2b2fba5336ba86ed32490":["215b6316d63375fce4dfbf1f55967c739795a2f9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[],"b0b597c65628ca9e73913a07e81691f8229bae35":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817","b0b597c65628ca9e73913a07e81691f8229bae35"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}