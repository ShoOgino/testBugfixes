{"path":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","sourceNew":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","sourceNew":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","pathOld":"solr/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","sourceNew":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51338b5fe0f5d865f3d3ce9ed83d94ae4733a8c5","date":1320922486,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","sourceNew":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f08557cdb6c60ac7b88a9342c983a20cd236e74f","date":1330954480,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","sourceNew":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","sourceNew":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(IndexBasedSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"541f6605a29362fa8a42f33b69069e7da5178034","date":1337786849,"type":3,"author":"James Dyer","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","sourceNew":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3599646b4d4c346cf74d334813488b8b337b5bf5","date":1337790261,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","sourceNew":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, false, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0d579490a72f2e6297eaa648940611234c57cf1","date":1395917140,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","sourceNew":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = TestUtil.createTempDir(LuceneTestCase.getTestClass().getSimpleName());\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1416f9d09d016a6894cd17e1caac137dad2bba59","date":1395941020,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","sourceNew":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(dataDir, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(TEMP_DIR, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bb1f22cfa77230b5f05b7784feae5367f6bbb488","date":1395968145,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","sourceNew":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(createTempDir(), \"spellingIdx\");\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = TestUtil.createTempDir(LuceneTestCase.getTestClass().getSimpleName());\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":["1e9ce820cd3ed9efb959c181daaafd22f0c70143"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1e9ce820cd3ed9efb959c181daaafd22f0c70143","date":1396201051,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","sourceNew":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = createTempDir();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(createTempDir(), \"spellingIdx\");\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":["bb1f22cfa77230b5f05b7784feae5367f6bbb488"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a0f5bb79c600763ffe7b8141df59a3169d31e48","date":1396689440,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","sourceNew":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = createTempDir();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = new File(dataDir, \"spellingIdx\" + new Date().getTime());\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f4abec28b874149a7223e32cc7a01704c27790de","date":1410644789,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","sourceNew":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = createTempDir().toFile();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = createTempDir();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4ab833f2b623042c834458d4cbcad05073a93793","date":1527625631,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","sourceNew":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = createTempDir().toFile();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    h.getCore().withSearcher(searcher -> {\n      checker.build(core, searcher);\n\n      IndexReader reader = searcher.getIndexReader();\n      Collection<Token> tokens = queryConverter.convert(\"documemt\");\n      SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n      SpellingResult result = checker.getSuggestions(spellOpts);\n      assertTrue(\"result is null and it shouldn't be\", result != null);\n      //should be lowercased, b/c we are using a lowercasing analyzer\n      Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n      assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n      assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n      Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n      assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n      assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n      //test something not in the spell checker\n      spellOpts.tokens = queryConverter.convert(\"super\");\n      result = checker.getSuggestions(spellOpts);\n      assertTrue(\"result is null and it shouldn't be\", result != null);\n      suggestions = result.get(spellOpts.tokens.iterator().next());\n      assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n      spellOpts.tokens = queryConverter.convert(\"document\");\n      result = checker.getSuggestions(spellOpts);\n      assertTrue(\"result is null and it shouldn't be\", result != null);\n      suggestions = result.get(spellOpts.tokens.iterator().next());\n      assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n      return null;\n    });\n  }\n\n","sourceOld":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = createTempDir().toFile();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2138c838f1c8052d94d61eb1e205dce7fa6932ef","date":1527642223,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","sourceNew":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = createTempDir().toFile();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    h.getCore().withSearcher(searcher -> {\n      checker.build(core, searcher);\n\n      IndexReader reader = searcher.getIndexReader();\n      Collection<Token> tokens = queryConverter.convert(\"documemt\");\n      SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n      SpellingResult result = checker.getSuggestions(spellOpts);\n      assertTrue(\"result is null and it shouldn't be\", result != null);\n      //should be lowercased, b/c we are using a lowercasing analyzer\n      Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n      assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n      assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n      Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n      assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n      assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n      //test something not in the spell checker\n      spellOpts.tokens = queryConverter.convert(\"super\");\n      result = checker.getSuggestions(spellOpts);\n      assertTrue(\"result is null and it shouldn't be\", result != null);\n      suggestions = result.get(spellOpts.tokens.iterator().next());\n      assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n      spellOpts.tokens = queryConverter.convert(\"document\");\n      result = checker.getSuggestions(spellOpts);\n      assertTrue(\"result is null and it shouldn't be\", result != null);\n      suggestions = result.get(spellOpts.tokens.iterator().next());\n      assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n      return null;\n    });\n  }\n\n","sourceOld":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = createTempDir().toFile();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    RefCounted<SolrIndexSearcher> holder = core.getSearcher();\n    SolrIndexSearcher searcher = holder.get();\n    try {\n    checker.build(core, searcher);\n\n    IndexReader reader = searcher.getIndexReader();\n    Collection<Token> tokens = queryConverter.convert(\"documemt\");\n    SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n    SpellingResult result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    //should be lowercased, b/c we are using a lowercasing analyzer\n    Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n    assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n    Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n    assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n    assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n    //test something not in the spell checker\n    spellOpts.tokens = queryConverter.convert(\"super\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n    spellOpts.tokens = queryConverter.convert(\"document\");\n    result = checker.getSuggestions(spellOpts);\n    assertTrue(\"result is null and it shouldn't be\", result != null);\n    suggestions = result.get(spellOpts.tokens.iterator().next());\n    assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n    } finally {\n      holder.decref();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aa2585c33d5d66a1c837c312221eb55ddb3c4300","date":1592493170,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","pathOld":"solr/core/src/test/org/apache/solr/spelling/IndexBasedSpellCheckerTest#testExtendedResults().mjava","sourceNew":"  @Test\n  @SuppressWarnings({\"unchecked\"})\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    @SuppressWarnings({\"rawtypes\"})\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = createTempDir().toFile();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    h.getCore().withSearcher(searcher -> {\n      checker.build(core, searcher);\n\n      IndexReader reader = searcher.getIndexReader();\n      Collection<Token> tokens = queryConverter.convert(\"documemt\");\n      SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n      SpellingResult result = checker.getSuggestions(spellOpts);\n      assertTrue(\"result is null and it shouldn't be\", result != null);\n      //should be lowercased, b/c we are using a lowercasing analyzer\n      Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n      assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n      assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n      Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n      assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n      assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n      //test something not in the spell checker\n      spellOpts.tokens = queryConverter.convert(\"super\");\n      result = checker.getSuggestions(spellOpts);\n      assertTrue(\"result is null and it shouldn't be\", result != null);\n      suggestions = result.get(spellOpts.tokens.iterator().next());\n      assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n      spellOpts.tokens = queryConverter.convert(\"document\");\n      result = checker.getSuggestions(spellOpts);\n      assertTrue(\"result is null and it shouldn't be\", result != null);\n      suggestions = result.get(spellOpts.tokens.iterator().next());\n      assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n      return null;\n    });\n  }\n\n","sourceOld":"  @Test\n  public void testExtendedResults() throws Exception {\n    IndexBasedSpellChecker checker = new IndexBasedSpellChecker();\n    NamedList spellchecker = new NamedList();\n    spellchecker.add(\"classname\", IndexBasedSpellChecker.class.getName());\n\n    File indexDir = createTempDir().toFile();\n    indexDir.mkdirs();\n    spellchecker.add(AbstractLuceneSpellChecker.INDEX_DIR, indexDir.getAbsolutePath());\n    spellchecker.add(AbstractLuceneSpellChecker.FIELD, \"title\");\n    spellchecker.add(AbstractLuceneSpellChecker.SPELLCHECKER_ARG_NAME, spellchecker);\n    SolrCore core = h.getCore();\n    String dictName = checker.init(spellchecker, core);\n    assertTrue(dictName + \" is not equal to \" + SolrSpellChecker.DEFAULT_DICTIONARY_NAME,\n            dictName.equals(SolrSpellChecker.DEFAULT_DICTIONARY_NAME) == true);\n    h.getCore().withSearcher(searcher -> {\n      checker.build(core, searcher);\n\n      IndexReader reader = searcher.getIndexReader();\n      Collection<Token> tokens = queryConverter.convert(\"documemt\");\n      SpellingOptions spellOpts = new SpellingOptions(tokens, reader, 1, SuggestMode.SUGGEST_WHEN_NOT_IN_INDEX, true, 0.5f, null);\n      SpellingResult result = checker.getSuggestions(spellOpts);\n      assertTrue(\"result is null and it shouldn't be\", result != null);\n      //should be lowercased, b/c we are using a lowercasing analyzer\n      Map<String, Integer> suggestions = result.get(spellOpts.tokens.iterator().next());\n      assertTrue(\"documemt is null and it shouldn't be\", suggestions != null);\n      assertTrue(\"documemt Size: \" + suggestions.size() + \" is not: \" + 1, suggestions.size() == 1);\n      Map.Entry<String, Integer> entry = suggestions.entrySet().iterator().next();\n      assertTrue(entry.getKey() + \" is not equal to \" + \"document\", entry.getKey().equals(\"document\") == true);\n      assertTrue(entry.getValue() + \" does not equal: \" + 2, entry.getValue() == 2);\n\n      //test something not in the spell checker\n      spellOpts.tokens = queryConverter.convert(\"super\");\n      result = checker.getSuggestions(spellOpts);\n      assertTrue(\"result is null and it shouldn't be\", result != null);\n      suggestions = result.get(spellOpts.tokens.iterator().next());\n      assertTrue(\"suggestions size should be 0\", suggestions.size()==0);\n\n      spellOpts.tokens = queryConverter.convert(\"document\");\n      result = checker.getSuggestions(spellOpts);\n      assertTrue(\"result is null and it shouldn't be\", result != null);\n      suggestions = result.get(spellOpts.tokens.iterator().next());\n      assertTrue(\"suggestions is not null and it should be\", suggestions == null);\n      return null;\n    });\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"bb1f22cfa77230b5f05b7784feae5367f6bbb488":["d0d579490a72f2e6297eaa648940611234c57cf1"],"2a0f5bb79c600763ffe7b8141df59a3169d31e48":["1416f9d09d016a6894cd17e1caac137dad2bba59","1e9ce820cd3ed9efb959c181daaafd22f0c70143"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["51338b5fe0f5d865f3d3ce9ed83d94ae4733a8c5","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["51338b5fe0f5d865f3d3ce9ed83d94ae4733a8c5"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"f4abec28b874149a7223e32cc7a01704c27790de":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"d0d579490a72f2e6297eaa648940611234c57cf1":["541f6605a29362fa8a42f33b69069e7da5178034"],"4ab833f2b623042c834458d4cbcad05073a93793":["f4abec28b874149a7223e32cc7a01704c27790de"],"541f6605a29362fa8a42f33b69069e7da5178034":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["2138c838f1c8052d94d61eb1e205dce7fa6932ef"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1416f9d09d016a6894cd17e1caac137dad2bba59":["541f6605a29362fa8a42f33b69069e7da5178034"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"3599646b4d4c346cf74d334813488b8b337b5bf5":["f08557cdb6c60ac7b88a9342c983a20cd236e74f","541f6605a29362fa8a42f33b69069e7da5178034"],"51338b5fe0f5d865f3d3ce9ed83d94ae4733a8c5":["c26f00b574427b55127e869b935845554afde1fa"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1e9ce820cd3ed9efb959c181daaafd22f0c70143":["bb1f22cfa77230b5f05b7784feae5367f6bbb488"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["aa2585c33d5d66a1c837c312221eb55ddb3c4300"],"2138c838f1c8052d94d61eb1e205dce7fa6932ef":["f4abec28b874149a7223e32cc7a01704c27790de","4ab833f2b623042c834458d4cbcad05073a93793"]},"commit2Childs":{"bb1f22cfa77230b5f05b7784feae5367f6bbb488":["1e9ce820cd3ed9efb959c181daaafd22f0c70143"],"2a0f5bb79c600763ffe7b8141df59a3169d31e48":["f4abec28b874149a7223e32cc7a01704c27790de"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","541f6605a29362fa8a42f33b69069e7da5178034","3599646b4d4c346cf74d334813488b8b337b5bf5"],"c26f00b574427b55127e869b935845554afde1fa":["51338b5fe0f5d865f3d3ce9ed83d94ae4733a8c5"],"d0d579490a72f2e6297eaa648940611234c57cf1":["bb1f22cfa77230b5f05b7784feae5367f6bbb488"],"f4abec28b874149a7223e32cc7a01704c27790de":["4ab833f2b623042c834458d4cbcad05073a93793","2138c838f1c8052d94d61eb1e205dce7fa6932ef"],"4ab833f2b623042c834458d4cbcad05073a93793":["2138c838f1c8052d94d61eb1e205dce7fa6932ef"],"541f6605a29362fa8a42f33b69069e7da5178034":["d0d579490a72f2e6297eaa648940611234c57cf1","1416f9d09d016a6894cd17e1caac137dad2bba59","3599646b4d4c346cf74d334813488b8b337b5bf5"],"aa2585c33d5d66a1c837c312221eb55ddb3c4300":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"1416f9d09d016a6894cd17e1caac137dad2bba59":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c26f00b574427b55127e869b935845554afde1fa","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"3599646b4d4c346cf74d334813488b8b337b5bf5":[],"51338b5fe0f5d865f3d3ce9ed83d94ae4733a8c5":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"1e9ce820cd3ed9efb959c181daaafd22f0c70143":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"2138c838f1c8052d94d61eb1e205dce7fa6932ef":["aa2585c33d5d66a1c837c312221eb55ddb3c4300"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","3599646b4d4c346cf74d334813488b8b337b5bf5","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}