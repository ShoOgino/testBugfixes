{"path":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","pathOld":"contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","sourceNew":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","sourceOld":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"01f60198ece724a6e96cd0b45f289cf42ff83d4f","date":1286864103,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","sourceNew":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n    Values valueType;\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    trySetIndexValues(nameField);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    trySetIndexValues(dateField);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    trySetIndexValues(titleField);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      trySetIndexValues(bodyField);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        trySetIndexValues(bytesField);\n        doc.add(bytesField);\n        \n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          trySetIndexValues(f);\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","sourceOld":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cc8cf08f8700fa613f15866f2612ce0c4f639219","date":1287774732,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","sourceNew":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n    Values valueType;\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    trySetIndexValues(idField);\n\n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    trySetIndexValues(nameField);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    trySetIndexValues(dateField);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    trySetIndexValues(titleField);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      trySetIndexValues(bodyField);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        trySetIndexValues(bytesField);\n        doc.add(bytesField);\n        \n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          trySetIndexValues(f);\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","sourceOld":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n    Values valueType;\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    trySetIndexValues(nameField);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    trySetIndexValues(dateField);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    trySetIndexValues(titleField);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      trySetIndexValues(bodyField);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        trySetIndexValues(bytesField);\n        doc.add(bytesField);\n        \n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          trySetIndexValues(f);\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"aa2fc2eb37a1f19e90850f787d9e085950ebfa04","date":1291597075,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","sourceNew":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n    Type valueType;\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    trySetIndexValues(idField);\n\n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    trySetIndexValues(nameField);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    trySetIndexValues(dateField);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    trySetIndexValues(titleField);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      trySetIndexValues(bodyField);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        trySetIndexValues(bytesField);\n        doc.add(bytesField);\n        \n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          trySetIndexValues(f);\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","sourceOld":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n    Values valueType;\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    trySetIndexValues(idField);\n\n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    trySetIndexValues(nameField);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    trySetIndexValues(dateField);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    trySetIndexValues(titleField);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      trySetIndexValues(bodyField);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        trySetIndexValues(bytesField);\n        doc.add(bytesField);\n        \n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          trySetIndexValues(f);\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"af0757679472670141514cb791eafeed05abc4e5","date":1292883496,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","sourceNew":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    int id;\n    if (r != null) {\n      id = r.nextInt(updateDocIDLimit);\n    } else {\n      id = docData.getID();\n      if (id == -1) {\n        id = numDocsCreated.getAndIncrement();\n      }\n    }\n    idField.setValue(Integer.toString(id));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    DateUtil util = dateParsers.get();\n    if (util == null) {\n      util = new DateUtil();\n      dateParsers.set(util);\n    }\n    Date date = null;\n    String dateString = docData.getDate();\n    if (dateString != null) {\n      util.pos.setIndex(0);\n      date = util.parser.parse(dateString, util.pos);\n      //System.out.println(dateString + \" parsed to \" + date);\n    } else {\n      dateString = \"\";\n    }\n    Field dateStringField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateStringField.setValue(dateString);\n    doc.add(dateStringField);\n\n    if (date == null) {\n      // just set to right now\n      date = new Date();\n    }\n\n    NumericField dateField = ds.getNumericField(DATE_MSEC_FIELD);\n    dateField.setLongValue(date.getTime());\n    doc.add(dateField);\n\n    util.cal.setTime(date);\n    final int sec = util.cal.get(Calendar.HOUR_OF_DAY)*3600 + util.cal.get(Calendar.MINUTE)*60 + util.cal.get(Calendar.SECOND);\n\n    NumericField timeSecField = ds.getNumericField(TIME_SEC_FIELD);\n    timeSecField.setIntValue(sec);\n    doc.add(timeSecField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","sourceOld":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":["a78a90fc9701e511308346ea29f4f5e548bb39fe","a78a90fc9701e511308346ea29f4f5e548bb39fe","fa0f44f887719e97183771e977cfc4bfb485b766","fa0f44f887719e97183771e977cfc4bfb485b766"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","sourceNew":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    int id;\n    if (r != null) {\n      id = r.nextInt(updateDocIDLimit);\n    } else {\n      id = docData.getID();\n      if (id == -1) {\n        id = numDocsCreated.getAndIncrement();\n      }\n    }\n    idField.setValue(Integer.toString(id));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    DateUtil util = dateParsers.get();\n    if (util == null) {\n      util = new DateUtil();\n      dateParsers.set(util);\n    }\n    Date date = null;\n    String dateString = docData.getDate();\n    if (dateString != null) {\n      util.pos.setIndex(0);\n      date = util.parser.parse(dateString, util.pos);\n      //System.out.println(dateString + \" parsed to \" + date);\n    } else {\n      dateString = \"\";\n    }\n    Field dateStringField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateStringField.setValue(dateString);\n    doc.add(dateStringField);\n\n    if (date == null) {\n      // just set to right now\n      date = new Date();\n    }\n\n    NumericField dateField = ds.getNumericField(DATE_MSEC_FIELD);\n    dateField.setLongValue(date.getTime());\n    doc.add(dateField);\n\n    util.cal.setTime(date);\n    final int sec = util.cal.get(Calendar.HOUR_OF_DAY)*3600 + util.cal.get(Calendar.MINUTE)*60 + util.cal.get(Calendar.SECOND);\n\n    NumericField timeSecField = ds.getNumericField(TIME_SEC_FIELD);\n    timeSecField.setIntValue(sec);\n    doc.add(timeSecField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","sourceOld":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ecc11368dc265bfdad90214f8bf5da99016ab1e2","date":1294144090,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"modules/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","sourceNew":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    int id;\n    if (r != null) {\n      id = r.nextInt(updateDocIDLimit);\n    } else {\n      id = docData.getID();\n      if (id == -1) {\n        id = numDocsCreated.getAndIncrement();\n      }\n    }\n    idField.setValue(Integer.toString(id));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    DateUtil util = dateParsers.get();\n    if (util == null) {\n      util = new DateUtil();\n      dateParsers.set(util);\n    }\n    Date date = null;\n    String dateString = docData.getDate();\n    if (dateString != null) {\n      util.pos.setIndex(0);\n      date = util.parser.parse(dateString, util.pos);\n      //System.out.println(dateString + \" parsed to \" + date);\n    } else {\n      dateString = \"\";\n    }\n    Field dateStringField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateStringField.setValue(dateString);\n    doc.add(dateStringField);\n\n    if (date == null) {\n      // just set to right now\n      date = new Date();\n    }\n\n    NumericField dateField = ds.getNumericField(DATE_MSEC_FIELD);\n    dateField.setLongValue(date.getTime());\n    doc.add(dateField);\n\n    util.cal.setTime(date);\n    final int sec = util.cal.get(Calendar.HOUR_OF_DAY)*3600 + util.cal.get(Calendar.MINUTE)*60 + util.cal.get(Calendar.SECOND);\n\n    NumericField timeSecField = ds.getNumericField(TIME_SEC_FIELD);\n    timeSecField.setIntValue(sec);\n    doc.add(timeSecField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","sourceOld":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    int id;\n    if (r != null) {\n      id = r.nextInt(updateDocIDLimit);\n    } else {\n      id = docData.getID();\n      if (id == -1) {\n        id = numDocsCreated.getAndIncrement();\n      }\n    }\n    idField.setValue(Integer.toString(id));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    DateUtil util = dateParsers.get();\n    if (util == null) {\n      util = new DateUtil();\n      dateParsers.set(util);\n    }\n    Date date = null;\n    String dateString = docData.getDate();\n    if (dateString != null) {\n      util.pos.setIndex(0);\n      date = util.parser.parse(dateString, util.pos);\n      //System.out.println(dateString + \" parsed to \" + date);\n    } else {\n      dateString = \"\";\n    }\n    Field dateStringField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateStringField.setValue(dateString);\n    doc.add(dateStringField);\n\n    if (date == null) {\n      // just set to right now\n      date = new Date();\n    }\n\n    NumericField dateField = ds.getNumericField(DATE_MSEC_FIELD);\n    dateField.setLongValue(date.getTime());\n    doc.add(dateField);\n\n    util.cal.setTime(date);\n    final int sec = util.cal.get(Calendar.HOUR_OF_DAY)*3600 + util.cal.get(Calendar.MINUTE)*60 + util.cal.get(Calendar.SECOND);\n\n    NumericField timeSecField = ds.getNumericField(TIME_SEC_FIELD);\n    timeSecField.setIntValue(sec);\n    doc.add(timeSecField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"70ad682703b8585f5d0a637efec044d57ec05efb","date":1294259117,"type":4,"author":"Simon Willnauer","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","sourceNew":null,"sourceOld":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n    Type valueType;\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    idField.setValue(\"doc\" + (r != null ? r.nextInt(updateDocIDLimit) : incrNumDocsCreated()));\n    doc.add(idField);\n    trySetIndexValues(idField);\n\n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    trySetIndexValues(nameField);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    String date = docData.getDate();\n    if (date == null) {\n      date = \"\";\n    }\n    Field dateField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateField.setValue(date);\n    trySetIndexValues(dateField);\n    doc.add(dateField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    trySetIndexValues(titleField);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      trySetIndexValues(bodyField);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        trySetIndexValues(bytesField);\n        doc.add(bytesField);\n        \n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          trySetIndexValues(f);\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"868da859b43505d9d2a023bfeae6dd0c795f5295","date":1294948401,"type":5,"author":"Michael Busch","isMerge":true,"pathNew":"modules/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","pathOld":"lucene/contrib/benchmark/src/java/org/apache/lucene/benchmark/byTask/feeds/DocMaker#createDocument(DocData,int,int).mjava","sourceNew":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    int id;\n    if (r != null) {\n      id = r.nextInt(updateDocIDLimit);\n    } else {\n      id = docData.getID();\n      if (id == -1) {\n        id = numDocsCreated.getAndIncrement();\n      }\n    }\n    idField.setValue(Integer.toString(id));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    DateUtil util = dateParsers.get();\n    if (util == null) {\n      util = new DateUtil();\n      dateParsers.set(util);\n    }\n    Date date = null;\n    String dateString = docData.getDate();\n    if (dateString != null) {\n      util.pos.setIndex(0);\n      date = util.parser.parse(dateString, util.pos);\n      //System.out.println(dateString + \" parsed to \" + date);\n    } else {\n      dateString = \"\";\n    }\n    Field dateStringField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateStringField.setValue(dateString);\n    doc.add(dateStringField);\n\n    if (date == null) {\n      // just set to right now\n      date = new Date();\n    }\n\n    NumericField dateField = ds.getNumericField(DATE_MSEC_FIELD);\n    dateField.setLongValue(date.getTime());\n    doc.add(dateField);\n\n    util.cal.setTime(date);\n    final int sec = util.cal.get(Calendar.HOUR_OF_DAY)*3600 + util.cal.get(Calendar.MINUTE)*60 + util.cal.get(Calendar.SECOND);\n\n    NumericField timeSecField = ds.getNumericField(TIME_SEC_FIELD);\n    timeSecField.setIntValue(sec);\n    doc.add(timeSecField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","sourceOld":"  // create a doc\n  // use only part of the body, modify it to keep the rest (or use all if size==0).\n  // reset the docdata properties so they are not added more than once.\n  private Document createDocument(DocData docData, int size, int cnt) throws UnsupportedEncodingException {\n\n    final DocState ds = getDocState();\n    final Document doc = reuseFields ? ds.doc : new Document();\n    doc.getFields().clear();\n    \n    // Set ID_FIELD\n    Field idField = ds.getField(ID_FIELD, storeVal, Index.NOT_ANALYZED_NO_NORMS, termVecVal);\n    int id;\n    if (r != null) {\n      id = r.nextInt(updateDocIDLimit);\n    } else {\n      id = docData.getID();\n      if (id == -1) {\n        id = numDocsCreated.getAndIncrement();\n      }\n    }\n    idField.setValue(Integer.toString(id));\n    doc.add(idField);\n    \n    // Set NAME_FIELD\n    String name = docData.getName();\n    if (name == null) name = \"\";\n    name = cnt < 0 ? name : name + \"_\" + cnt;\n    Field nameField = ds.getField(NAME_FIELD, storeVal, indexVal, termVecVal);\n    nameField.setValue(name);\n    doc.add(nameField);\n    \n    // Set DATE_FIELD\n    DateUtil util = dateParsers.get();\n    if (util == null) {\n      util = new DateUtil();\n      dateParsers.set(util);\n    }\n    Date date = null;\n    String dateString = docData.getDate();\n    if (dateString != null) {\n      util.pos.setIndex(0);\n      date = util.parser.parse(dateString, util.pos);\n      //System.out.println(dateString + \" parsed to \" + date);\n    } else {\n      dateString = \"\";\n    }\n    Field dateStringField = ds.getField(DATE_FIELD, storeVal, indexVal, termVecVal);\n    dateStringField.setValue(dateString);\n    doc.add(dateStringField);\n\n    if (date == null) {\n      // just set to right now\n      date = new Date();\n    }\n\n    NumericField dateField = ds.getNumericField(DATE_MSEC_FIELD);\n    dateField.setLongValue(date.getTime());\n    doc.add(dateField);\n\n    util.cal.setTime(date);\n    final int sec = util.cal.get(Calendar.HOUR_OF_DAY)*3600 + util.cal.get(Calendar.MINUTE)*60 + util.cal.get(Calendar.SECOND);\n\n    NumericField timeSecField = ds.getNumericField(TIME_SEC_FIELD);\n    timeSecField.setIntValue(sec);\n    doc.add(timeSecField);\n    \n    // Set TITLE_FIELD\n    String title = docData.getTitle();\n    Field titleField = ds.getField(TITLE_FIELD, storeVal, indexVal, termVecVal);\n    titleField.setValue(title == null ? \"\" : title);\n    doc.add(titleField);\n    \n    String body = docData.getBody();\n    if (body != null && body.length() > 0) {\n      String bdy;\n      if (size <= 0 || size >= body.length()) {\n        bdy = body; // use all\n        docData.setBody(\"\"); // nothing left\n      } else {\n        // attempt not to break words - if whitespace found within next 20 chars...\n        for (int n = size - 1; n < size + 20 && n < body.length(); n++) {\n          if (Character.isWhitespace(body.charAt(n))) {\n            size = n;\n            break;\n          }\n        }\n        bdy = body.substring(0, size); // use part\n        docData.setBody(body.substring(size)); // some left\n      }\n      Field bodyField = ds.getField(BODY_FIELD, bodyStoreVal, bodyIndexVal, termVecVal);\n      bodyField.setValue(bdy);\n      doc.add(bodyField);\n      \n      if (storeBytes) {\n        Field bytesField = ds.getField(BYTES_FIELD, Store.YES, Index.NOT_ANALYZED_NO_NORMS, TermVector.NO);\n        bytesField.setValue(bdy.getBytes(\"UTF-8\"));\n        doc.add(bytesField);\n      }\n    }\n\n    if (indexProperties) {\n      Properties props = docData.getProps();\n      if (props != null) {\n        for (final Map.Entry<Object,Object> entry : props.entrySet()) {\n          Field f = ds.getField((String) entry.getKey(), storeVal, indexVal, termVecVal);\n          f.setValue((String) entry.getValue());\n          doc.add(f);\n        }\n        docData.setProps(null);\n      }\n    }\n    \n    //System.out.println(\"============== Created doc \"+numDocsCreated+\" :\\n\"+doc+\"\\n==========\");\n    return doc;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"70ad682703b8585f5d0a637efec044d57ec05efb":["aa2fc2eb37a1f19e90850f787d9e085950ebfa04","ecc11368dc265bfdad90214f8bf5da99016ab1e2"],"ecc11368dc265bfdad90214f8bf5da99016ab1e2":["af0757679472670141514cb791eafeed05abc4e5"],"af0757679472670141514cb791eafeed05abc4e5":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cc8cf08f8700fa613f15866f2612ce0c4f639219":["01f60198ece724a6e96cd0b45f289cf42ff83d4f"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["9454a6510e2db155fb01faa5c049b06ece95fab9","af0757679472670141514cb791eafeed05abc4e5"],"aa2fc2eb37a1f19e90850f787d9e085950ebfa04":["cc8cf08f8700fa613f15866f2612ce0c4f639219"],"868da859b43505d9d2a023bfeae6dd0c795f5295":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","ecc11368dc265bfdad90214f8bf5da99016ab1e2"],"01f60198ece724a6e96cd0b45f289cf42ff83d4f":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ecc11368dc265bfdad90214f8bf5da99016ab1e2"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"70ad682703b8585f5d0a637efec044d57ec05efb":[],"ecc11368dc265bfdad90214f8bf5da99016ab1e2":["70ad682703b8585f5d0a637efec044d57ec05efb","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"af0757679472670141514cb791eafeed05abc4e5":["ecc11368dc265bfdad90214f8bf5da99016ab1e2","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"cc8cf08f8700fa613f15866f2612ce0c4f639219":["aa2fc2eb37a1f19e90850f787d9e085950ebfa04"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["868da859b43505d9d2a023bfeae6dd0c795f5295"],"aa2fc2eb37a1f19e90850f787d9e085950ebfa04":["70ad682703b8585f5d0a637efec044d57ec05efb"],"01f60198ece724a6e96cd0b45f289cf42ff83d4f":["cc8cf08f8700fa613f15866f2612ce0c4f639219"],"868da859b43505d9d2a023bfeae6dd0c795f5295":[],"9454a6510e2db155fb01faa5c049b06ece95fab9":["af0757679472670141514cb791eafeed05abc4e5","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","01f60198ece724a6e96cd0b45f289cf42ff83d4f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["70ad682703b8585f5d0a637efec044d57ec05efb","868da859b43505d9d2a023bfeae6dd0c795f5295","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}