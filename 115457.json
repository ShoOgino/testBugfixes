{"path":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","commits":[{"id":"dc3f094cafa4a87b4066e1d6710fa4e6afe6260e","date":1393532367,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell2/Dictionary#Dictionary(InputStream,InputStream).mjava","sourceNew":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    BufferedInputStream buffered = new BufferedInputStream(affix, 8192);\n    buffered.mark(8192);\n    String encoding = getDictionaryEncoding(affix);\n    buffered.reset();\n    CharsetDecoder decoder = getJavaEncoding(encoding);\n    readAffixFile(buffered, decoder);\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n    stripLookup.add(new BytesRef()); // no strip -> ord 0\n    PositiveIntOutputs o = PositiveIntOutputs.getSingleton();\n    Builder<Long> b = new Builder<Long>(FST.INPUT_TYPE.BYTE4, o);\n    readDictionaryFiles(dictionaries, decoder, b);\n    words = b.finish();\n  }\n\n","sourceOld":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionary InputStream for reading the hunspell dictionary file (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, InputStream dictionary) throws IOException, ParseException {\n    BufferedInputStream buffered = new BufferedInputStream(affix, 8192);\n    buffered.mark(8192);\n    String encoding = getDictionaryEncoding(affix);\n    buffered.reset();\n    CharsetDecoder decoder = getJavaEncoding(encoding);\n    readAffixFile(buffered, decoder);\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n    stripLookup.add(new BytesRef()); // no strip -> ord 0\n    PositiveIntOutputs o = PositiveIntOutputs.getSingleton();\n    Builder<Long> b = new Builder<Long>(FST.INPUT_TYPE.BYTE4, o);\n    readDictionaryFile(dictionary, decoder, b);\n    words = b.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ba791bce8103c79e38f957e9c5a53a75871bd918","date":1393539206,"type":1,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/HunspellDictionary#HunspellDictionary(InputStream,List[InputStream],Version,boolean,boolean).mjava","sourceNew":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    BufferedInputStream buffered = new BufferedInputStream(affix, 8192);\n    buffered.mark(8192);\n    String encoding = getDictionaryEncoding(affix);\n    buffered.reset();\n    CharsetDecoder decoder = getJavaEncoding(encoding);\n    readAffixFile(buffered, decoder);\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n    stripLookup.add(new BytesRef()); // no strip -> ord 0\n    PositiveIntOutputs o = PositiveIntOutputs.getSingleton();\n    Builder<Long> b = new Builder<Long>(FST.INPUT_TYPE.BYTE4, o);\n    readDictionaryFiles(dictionaries, decoder, b);\n    words = b.finish();\n  }\n\n","sourceOld":"  /**\n   * Creates a new HunspellDictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStreams for reading the hunspell dictionary file (won't be closed).\n   * @param version Lucene Version\n   * @param ignoreCase If true, dictionary matching will be case insensitive\n   * @param strictAffixParsing Affix strict parsing enabled or not (an error while reading a rule causes exception or is ignored)\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public HunspellDictionary(InputStream affix, List<InputStream> dictionaries, Version version, boolean ignoreCase, boolean strictAffixParsing) throws IOException, ParseException {\n    this.version = version;\n    this.ignoreCase = ignoreCase;\n    String encoding = getDictionaryEncoding(affix);\n    CharsetDecoder decoder = getJavaEncoding(encoding);\n    readAffixFile(affix, decoder, strictAffixParsing);\n    words = new CharArrayMap<List<HunspellWord>>(version, 65535 /* guess */, this.ignoreCase);\n    for (InputStream dictionary : dictionaries) {\n      readDictionaryFile(dictionary, decoder);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b58bd8dd457a9b46b007c641d5b6e747afb8904a","date":1393616676,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","sourceNew":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    BufferedInputStream buffered = new BufferedInputStream(affix, 8192);\n    buffered.mark(8192);\n    String encoding = getDictionaryEncoding(affix);\n    buffered.reset();\n    CharsetDecoder decoder = getJavaEncoding(encoding);\n    readAffixFile(buffered, decoder);\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n    stripLookup.add(new BytesRef()); // no strip -> ord 0\n    IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n    Builder<IntsRef> b = new Builder<IntsRef>(FST.INPUT_TYPE.BYTE4, o);\n    readDictionaryFiles(dictionaries, decoder, b);\n    words = b.finish();\n  }\n\n","sourceOld":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    BufferedInputStream buffered = new BufferedInputStream(affix, 8192);\n    buffered.mark(8192);\n    String encoding = getDictionaryEncoding(affix);\n    buffered.reset();\n    CharsetDecoder decoder = getJavaEncoding(encoding);\n    readAffixFile(buffered, decoder);\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n    stripLookup.add(new BytesRef()); // no strip -> ord 0\n    PositiveIntOutputs o = PositiveIntOutputs.getSingleton();\n    Builder<Long> b = new Builder<Long>(FST.INPUT_TYPE.BYTE4, o);\n    readDictionaryFiles(dictionaries, decoder, b);\n    words = b.finish();\n  }\n\n","bugFix":null,"bugIntro":["6d4fb2cc011096cc0cff79f0adcf03dc734b9352"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7","date":1393724838,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","sourceNew":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    // hungarian has thousands of AF before the SET, so a 32k buffer is needed \n    BufferedInputStream buffered = new BufferedInputStream(affix, 32768);\n    buffered.mark(32768);\n    String encoding = getDictionaryEncoding(buffered);\n    buffered.reset();\n    CharsetDecoder decoder = getJavaEncoding(encoding);\n    readAffixFile(buffered, decoder);\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n    stripLookup.add(new BytesRef()); // no strip -> ord 0\n    IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n    Builder<IntsRef> b = new Builder<IntsRef>(FST.INPUT_TYPE.BYTE4, o);\n    readDictionaryFiles(dictionaries, decoder, b);\n    words = b.finish();\n  }\n\n","sourceOld":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    BufferedInputStream buffered = new BufferedInputStream(affix, 8192);\n    buffered.mark(8192);\n    String encoding = getDictionaryEncoding(affix);\n    buffered.reset();\n    CharsetDecoder decoder = getJavaEncoding(encoding);\n    readAffixFile(buffered, decoder);\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n    stripLookup.add(new BytesRef()); // no strip -> ord 0\n    IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n    Builder<IntsRef> b = new Builder<IntsRef>(FST.INPUT_TYPE.BYTE4, o);\n    readDictionaryFiles(dictionaries, decoder, b);\n    words = b.finish();\n  }\n\n","bugFix":["c214bc712d04c78c4d434119d560d0a4dd2fce4f"],"bugIntro":["436457d41a3d830862d2aca1ba3b94528bd7bb88","6d4fb2cc011096cc0cff79f0adcf03dc734b9352"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5ae9942cbee38a49d234c2f022e3a265133d1914","date":1393952688,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","sourceNew":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    // hungarian has thousands of AF before the SET, so a 32k buffer is needed \n    BufferedInputStream buffered = new BufferedInputStream(affix, 32768);\n    buffered.mark(32768);\n    String encoding = getDictionaryEncoding(buffered);\n    buffered.reset();\n    CharsetDecoder decoder = getJavaEncoding(encoding);\n    readAffixFile(buffered, decoder);\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n    stripLookup.add(new BytesRef()); // no strip -> ord 0\n    IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n    Builder<IntsRef> b = new Builder<IntsRef>(FST.INPUT_TYPE.BYTE4, o);\n    readDictionaryFiles(dictionaries, decoder, b);\n    words = b.finish();\n  }\n\n","sourceOld":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    // hungarian has thousands of AF before the SET, so a 32k buffer is needed \n    BufferedInputStream buffered = new BufferedInputStream(affix, 32768);\n    buffered.mark(32768);\n    String encoding = getDictionaryEncoding(buffered);\n    buffered.reset();\n    CharsetDecoder decoder = getJavaEncoding(encoding);\n    readAffixFile(buffered, decoder);\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n    stripLookup.add(new BytesRef()); // no strip -> ord 0\n    IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n    Builder<IntsRef> b = new Builder<IntsRef>(FST.INPUT_TYPE.BYTE4, o);\n    readDictionaryFiles(dictionaries, decoder, b);\n    words = b.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"436457d41a3d830862d2aca1ba3b94528bd7bb88","date":1393955480,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","sourceNew":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    // TODO: we really need to probably buffer this on disk since so many newer dictionaries\n    // (en_GB, hu_HU, etc) now have tons of AM lines (morph metadata) etc before they finally declare \n    // their encoding... but for now this large buffer is a workaround\n    BufferedInputStream buffered = new BufferedInputStream(affix, 65536);\n    buffered.mark(65536);\n    String encoding = getDictionaryEncoding(buffered);\n    buffered.reset();\n    CharsetDecoder decoder = getJavaEncoding(encoding);\n    readAffixFile(buffered, decoder);\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n    stripLookup.add(new BytesRef()); // no strip -> ord 0\n    IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n    Builder<IntsRef> b = new Builder<IntsRef>(FST.INPUT_TYPE.BYTE4, o);\n    readDictionaryFiles(dictionaries, decoder, b);\n    words = b.finish();\n  }\n\n","sourceOld":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    // hungarian has thousands of AF before the SET, so a 32k buffer is needed \n    BufferedInputStream buffered = new BufferedInputStream(affix, 32768);\n    buffered.mark(32768);\n    String encoding = getDictionaryEncoding(buffered);\n    buffered.reset();\n    CharsetDecoder decoder = getJavaEncoding(encoding);\n    readAffixFile(buffered, decoder);\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n    stripLookup.add(new BytesRef()); // no strip -> ord 0\n    IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n    Builder<IntsRef> b = new Builder<IntsRef>(FST.INPUT_TYPE.BYTE4, o);\n    readDictionaryFiles(dictionaries, decoder, b);\n    words = b.finish();\n  }\n\n","bugFix":["1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7"],"bugIntro":["6d4fb2cc011096cc0cff79f0adcf03dc734b9352"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"96ea64d994d340044e0d57aeb6a5871539d10ca5","date":1394225445,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","sourceNew":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    // TODO: we really need to probably buffer this on disk since so many newer dictionaries\n    // (en_GB, hu_HU, etc) now have tons of AM lines (morph metadata) etc before they finally declare \n    // their encoding... but for now this large buffer is a workaround\n    BufferedInputStream buffered = new BufferedInputStream(affix, 65536);\n    buffered.mark(65536);\n    String encoding = getDictionaryEncoding(buffered);\n    buffered.reset();\n    CharsetDecoder decoder = getJavaEncoding(encoding);\n    readAffixFile(buffered, decoder);\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n    stripLookup.add(new BytesRef()); // no strip -> ord 0\n    IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n    Builder<IntsRef> b = new Builder<IntsRef>(FST.INPUT_TYPE.BYTE4, o);\n    readDictionaryFiles(dictionaries, decoder, b);\n    words = b.finish();\n  }\n\n","sourceOld":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    // hungarian has thousands of AF before the SET, so a 32k buffer is needed \n    BufferedInputStream buffered = new BufferedInputStream(affix, 32768);\n    buffered.mark(32768);\n    String encoding = getDictionaryEncoding(buffered);\n    buffered.reset();\n    CharsetDecoder decoder = getJavaEncoding(encoding);\n    readAffixFile(buffered, decoder);\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n    stripLookup.add(new BytesRef()); // no strip -> ord 0\n    IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n    Builder<IntsRef> b = new Builder<IntsRef>(FST.INPUT_TYPE.BYTE4, o);\n    readDictionaryFiles(dictionaries, decoder, b);\n    words = b.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6d4fb2cc011096cc0cff79f0adcf03dc734b9352","date":1394386069,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","sourceNew":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n    stripLookup.add(new BytesRef()); // no strip -> ord 0\n\n    File aff = File.createTempFile(\"affix\", \"aff\", tempDir);\n    OutputStream out = new BufferedOutputStream(new FileOutputStream(aff));\n    InputStream aff1 = null;\n    InputStream aff2 = null;\n    try {\n      // copy contents of affix stream to temp file\n      final byte [] buffer = new byte [1024 * 8];\n      int len;\n      while ((len = affix.read(buffer)) > 0) {\n        out.write(buffer, 0, len);\n      }\n      out.close();\n      \n      // pass 1: get encoding\n      aff1 = new BufferedInputStream(new FileInputStream(aff));\n      String encoding = getDictionaryEncoding(aff1);\n      \n      // pass 2: parse affixes\n      CharsetDecoder decoder = getJavaEncoding(encoding);\n      aff2 = new BufferedInputStream(new FileInputStream(aff));\n      readAffixFile(aff2, decoder);\n      \n      // read dictionary entries\n      IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n      Builder<IntsRef> b = new Builder<IntsRef>(FST.INPUT_TYPE.BYTE4, o);\n      readDictionaryFiles(dictionaries, decoder, b);\n      words = b.finish();\n      aliases = null; // no longer needed\n    } finally {\n      IOUtils.closeWhileHandlingException(out, aff1, aff2);\n      aff.delete();\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    // TODO: we really need to probably buffer this on disk since so many newer dictionaries\n    // (en_GB, hu_HU, etc) now have tons of AM lines (morph metadata) etc before they finally declare \n    // their encoding... but for now this large buffer is a workaround\n    BufferedInputStream buffered = new BufferedInputStream(affix, 65536);\n    buffered.mark(65536);\n    String encoding = getDictionaryEncoding(buffered);\n    buffered.reset();\n    CharsetDecoder decoder = getJavaEncoding(encoding);\n    readAffixFile(buffered, decoder);\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n    stripLookup.add(new BytesRef()); // no strip -> ord 0\n    IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n    Builder<IntsRef> b = new Builder<IntsRef>(FST.INPUT_TYPE.BYTE4, o);\n    readDictionaryFiles(dictionaries, decoder, b);\n    words = b.finish();\n  }\n\n","bugFix":["436457d41a3d830862d2aca1ba3b94528bd7bb88","1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7","c214bc712d04c78c4d434119d560d0a4dd2fce4f","b58bd8dd457a9b46b007c641d5b6e747afb8904a","dc3f094cafa4a87b4066e1d6710fa4e6afe6260e"],"bugIntro":["cbc3688252d4a8045d69a164236b2cf87b721f17"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","date":1394564625,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","sourceNew":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n    stripLookup.add(new BytesRef()); // no strip -> ord 0\n\n    File aff = File.createTempFile(\"affix\", \"aff\", tempDir);\n    OutputStream out = new BufferedOutputStream(new FileOutputStream(aff));\n    InputStream aff1 = null;\n    InputStream aff2 = null;\n    try {\n      // copy contents of affix stream to temp file\n      final byte [] buffer = new byte [1024 * 8];\n      int len;\n      while ((len = affix.read(buffer)) > 0) {\n        out.write(buffer, 0, len);\n      }\n      out.close();\n      \n      // pass 1: get encoding\n      aff1 = new BufferedInputStream(new FileInputStream(aff));\n      String encoding = getDictionaryEncoding(aff1);\n      \n      // pass 2: parse affixes\n      CharsetDecoder decoder = getJavaEncoding(encoding);\n      aff2 = new BufferedInputStream(new FileInputStream(aff));\n      readAffixFile(aff2, decoder);\n      \n      // read dictionary entries\n      IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n      Builder<IntsRef> b = new Builder<IntsRef>(FST.INPUT_TYPE.BYTE4, o);\n      readDictionaryFiles(dictionaries, decoder, b);\n      words = b.finish();\n      aliases = null; // no longer needed\n    } finally {\n      IOUtils.closeWhileHandlingException(out, aff1, aff2);\n      aff.delete();\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    // TODO: we really need to probably buffer this on disk since so many newer dictionaries\n    // (en_GB, hu_HU, etc) now have tons of AM lines (morph metadata) etc before they finally declare \n    // their encoding... but for now this large buffer is a workaround\n    BufferedInputStream buffered = new BufferedInputStream(affix, 65536);\n    buffered.mark(65536);\n    String encoding = getDictionaryEncoding(buffered);\n    buffered.reset();\n    CharsetDecoder decoder = getJavaEncoding(encoding);\n    readAffixFile(buffered, decoder);\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n    stripLookup.add(new BytesRef()); // no strip -> ord 0\n    IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n    Builder<IntsRef> b = new Builder<IntsRef>(FST.INPUT_TYPE.BYTE4, o);\n    readDictionaryFiles(dictionaries, decoder, b);\n    words = b.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"09fb4238d56f62faff1f0c866bee53facad482ec","date":1394631888,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","sourceNew":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n\n    File aff = File.createTempFile(\"affix\", \"aff\", tempDir);\n    OutputStream out = new BufferedOutputStream(new FileOutputStream(aff));\n    InputStream aff1 = null;\n    InputStream aff2 = null;\n    try {\n      // copy contents of affix stream to temp file\n      final byte [] buffer = new byte [1024 * 8];\n      int len;\n      while ((len = affix.read(buffer)) > 0) {\n        out.write(buffer, 0, len);\n      }\n      out.close();\n      \n      // pass 1: get encoding\n      aff1 = new BufferedInputStream(new FileInputStream(aff));\n      String encoding = getDictionaryEncoding(aff1);\n      \n      // pass 2: parse affixes\n      CharsetDecoder decoder = getJavaEncoding(encoding);\n      aff2 = new BufferedInputStream(new FileInputStream(aff));\n      readAffixFile(aff2, decoder);\n      \n      // read dictionary entries\n      IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n      Builder<IntsRef> b = new Builder<IntsRef>(FST.INPUT_TYPE.BYTE4, o);\n      readDictionaryFiles(dictionaries, decoder, b);\n      words = b.finish();\n      aliases = null; // no longer needed\n    } finally {\n      IOUtils.closeWhileHandlingException(out, aff1, aff2);\n      aff.delete();\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n    stripLookup.add(new BytesRef()); // no strip -> ord 0\n\n    File aff = File.createTempFile(\"affix\", \"aff\", tempDir);\n    OutputStream out = new BufferedOutputStream(new FileOutputStream(aff));\n    InputStream aff1 = null;\n    InputStream aff2 = null;\n    try {\n      // copy contents of affix stream to temp file\n      final byte [] buffer = new byte [1024 * 8];\n      int len;\n      while ((len = affix.read(buffer)) > 0) {\n        out.write(buffer, 0, len);\n      }\n      out.close();\n      \n      // pass 1: get encoding\n      aff1 = new BufferedInputStream(new FileInputStream(aff));\n      String encoding = getDictionaryEncoding(aff1);\n      \n      // pass 2: parse affixes\n      CharsetDecoder decoder = getJavaEncoding(encoding);\n      aff2 = new BufferedInputStream(new FileInputStream(aff));\n      readAffixFile(aff2, decoder);\n      \n      // read dictionary entries\n      IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n      Builder<IntsRef> b = new Builder<IntsRef>(FST.INPUT_TYPE.BYTE4, o);\n      readDictionaryFiles(dictionaries, decoder, b);\n      words = b.finish();\n      aliases = null; // no longer needed\n    } finally {\n      IOUtils.closeWhileHandlingException(out, aff1, aff2);\n      aff.delete();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","sourceNew":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n\n    File aff = File.createTempFile(\"affix\", \"aff\", tempDir);\n    OutputStream out = new BufferedOutputStream(new FileOutputStream(aff));\n    InputStream aff1 = null;\n    InputStream aff2 = null;\n    try {\n      // copy contents of affix stream to temp file\n      final byte [] buffer = new byte [1024 * 8];\n      int len;\n      while ((len = affix.read(buffer)) > 0) {\n        out.write(buffer, 0, len);\n      }\n      out.close();\n      \n      // pass 1: get encoding\n      aff1 = new BufferedInputStream(new FileInputStream(aff));\n      String encoding = getDictionaryEncoding(aff1);\n      \n      // pass 2: parse affixes\n      CharsetDecoder decoder = getJavaEncoding(encoding);\n      aff2 = new BufferedInputStream(new FileInputStream(aff));\n      readAffixFile(aff2, decoder);\n      \n      // read dictionary entries\n      IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n      Builder<IntsRef> b = new Builder<>(FST.INPUT_TYPE.BYTE4, o);\n      readDictionaryFiles(dictionaries, decoder, b);\n      words = b.finish();\n      aliases = null; // no longer needed\n    } finally {\n      IOUtils.closeWhileHandlingException(out, aff1, aff2);\n      aff.delete();\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n\n    File aff = File.createTempFile(\"affix\", \"aff\", tempDir);\n    OutputStream out = new BufferedOutputStream(new FileOutputStream(aff));\n    InputStream aff1 = null;\n    InputStream aff2 = null;\n    try {\n      // copy contents of affix stream to temp file\n      final byte [] buffer = new byte [1024 * 8];\n      int len;\n      while ((len = affix.read(buffer)) > 0) {\n        out.write(buffer, 0, len);\n      }\n      out.close();\n      \n      // pass 1: get encoding\n      aff1 = new BufferedInputStream(new FileInputStream(aff));\n      String encoding = getDictionaryEncoding(aff1);\n      \n      // pass 2: parse affixes\n      CharsetDecoder decoder = getJavaEncoding(encoding);\n      aff2 = new BufferedInputStream(new FileInputStream(aff));\n      readAffixFile(aff2, decoder);\n      \n      // read dictionary entries\n      IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n      Builder<IntsRef> b = new Builder<IntsRef>(FST.INPUT_TYPE.BYTE4, o);\n      readDictionaryFiles(dictionaries, decoder, b);\n      words = b.finish();\n      aliases = null; // no longer needed\n    } finally {\n      IOUtils.closeWhileHandlingException(out, aff1, aff2);\n      aff.delete();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"5916de6e2f6deb9da923b2710f6451668e94a20c","date":1403356557,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","sourceNew":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n\n    File aff = File.createTempFile(\"affix\", \"aff\", tempDir);\n    OutputStream out = new BufferedOutputStream(new FileOutputStream(aff));\n    InputStream aff1 = null;\n    InputStream aff2 = null;\n    try {\n      // copy contents of affix stream to temp file\n      final byte [] buffer = new byte [1024 * 8];\n      int len;\n      while ((len = affix.read(buffer)) > 0) {\n        out.write(buffer, 0, len);\n      }\n      out.close();\n      \n      // pass 1: get encoding\n      aff1 = new BufferedInputStream(new FileInputStream(aff));\n      String encoding = getDictionaryEncoding(aff1);\n      \n      // pass 2: parse affixes\n      CharsetDecoder decoder = getJavaEncoding(encoding);\n      aff2 = new BufferedInputStream(new FileInputStream(aff));\n      readAffixFile(aff2, decoder);\n      \n      // read dictionary entries\n      IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n      Builder<IntsRef> b = new Builder<>(FST.INPUT_TYPE.BYTE4, o);\n      readDictionaryFiles(dictionaries, decoder, b);\n      words = b.finish();\n      aliases = null; // no longer needed\n      morphAliases = null; // no longer needed\n    } finally {\n      IOUtils.closeWhileHandlingException(out, aff1, aff2);\n      aff.delete();\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n\n    File aff = File.createTempFile(\"affix\", \"aff\", tempDir);\n    OutputStream out = new BufferedOutputStream(new FileOutputStream(aff));\n    InputStream aff1 = null;\n    InputStream aff2 = null;\n    try {\n      // copy contents of affix stream to temp file\n      final byte [] buffer = new byte [1024 * 8];\n      int len;\n      while ((len = affix.read(buffer)) > 0) {\n        out.write(buffer, 0, len);\n      }\n      out.close();\n      \n      // pass 1: get encoding\n      aff1 = new BufferedInputStream(new FileInputStream(aff));\n      String encoding = getDictionaryEncoding(aff1);\n      \n      // pass 2: parse affixes\n      CharsetDecoder decoder = getJavaEncoding(encoding);\n      aff2 = new BufferedInputStream(new FileInputStream(aff));\n      readAffixFile(aff2, decoder);\n      \n      // read dictionary entries\n      IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n      Builder<IntsRef> b = new Builder<>(FST.INPUT_TYPE.BYTE4, o);\n      readDictionaryFiles(dictionaries, decoder, b);\n      words = b.finish();\n      aliases = null; // no longer needed\n    } finally {\n      IOUtils.closeWhileHandlingException(out, aff1, aff2);\n      aff.delete();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cbc3688252d4a8045d69a164236b2cf87b721f17","date":1409846185,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","sourceNew":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n\n    File aff = File.createTempFile(\"affix\", \"aff\", tempDir);\n    OutputStream out = new BufferedOutputStream(new FileOutputStream(aff));\n    InputStream aff1 = null;\n    InputStream aff2 = null;\n    boolean success = false;\n    try {\n      // copy contents of affix stream to temp file\n      final byte [] buffer = new byte [1024 * 8];\n      int len;\n      while ((len = affix.read(buffer)) > 0) {\n        out.write(buffer, 0, len);\n      }\n      out.close();\n      \n      // pass 1: get encoding\n      aff1 = new BufferedInputStream(new FileInputStream(aff));\n      String encoding = getDictionaryEncoding(aff1);\n      \n      // pass 2: parse affixes\n      CharsetDecoder decoder = getJavaEncoding(encoding);\n      aff2 = new BufferedInputStream(new FileInputStream(aff));\n      readAffixFile(aff2, decoder);\n      \n      // read dictionary entries\n      IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n      Builder<IntsRef> b = new Builder<>(FST.INPUT_TYPE.BYTE4, o);\n      readDictionaryFiles(dictionaries, decoder, b);\n      words = b.finish();\n      aliases = null; // no longer needed\n      morphAliases = null; // no longer needed\n      success = true;\n    } finally {\n      IOUtils.closeWhileHandlingException(out, aff1, aff2);\n      if (success) {\n        Files.delete(aff.toPath());\n      } else {\n        IOUtils.deleteFilesIgnoringExceptions(aff);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n\n    File aff = File.createTempFile(\"affix\", \"aff\", tempDir);\n    OutputStream out = new BufferedOutputStream(new FileOutputStream(aff));\n    InputStream aff1 = null;\n    InputStream aff2 = null;\n    try {\n      // copy contents of affix stream to temp file\n      final byte [] buffer = new byte [1024 * 8];\n      int len;\n      while ((len = affix.read(buffer)) > 0) {\n        out.write(buffer, 0, len);\n      }\n      out.close();\n      \n      // pass 1: get encoding\n      aff1 = new BufferedInputStream(new FileInputStream(aff));\n      String encoding = getDictionaryEncoding(aff1);\n      \n      // pass 2: parse affixes\n      CharsetDecoder decoder = getJavaEncoding(encoding);\n      aff2 = new BufferedInputStream(new FileInputStream(aff));\n      readAffixFile(aff2, decoder);\n      \n      // read dictionary entries\n      IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n      Builder<IntsRef> b = new Builder<>(FST.INPUT_TYPE.BYTE4, o);\n      readDictionaryFiles(dictionaries, decoder, b);\n      words = b.finish();\n      aliases = null; // no longer needed\n      morphAliases = null; // no longer needed\n    } finally {\n      IOUtils.closeWhileHandlingException(out, aff1, aff2);\n      aff.delete();\n    }\n  }\n\n","bugFix":["6d4fb2cc011096cc0cff79f0adcf03dc734b9352"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f4abec28b874149a7223e32cc7a01704c27790de","date":1410644789,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","sourceNew":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n\n    Path aff = Files.createTempFile(tempDir, \"affix\", \"aff\");\n    OutputStream out = new BufferedOutputStream(Files.newOutputStream(aff));\n    InputStream aff1 = null;\n    InputStream aff2 = null;\n    boolean success = false;\n    try {\n      // copy contents of affix stream to temp file\n      final byte [] buffer = new byte [1024 * 8];\n      int len;\n      while ((len = affix.read(buffer)) > 0) {\n        out.write(buffer, 0, len);\n      }\n      out.close();\n      \n      // pass 1: get encoding\n      aff1 = new BufferedInputStream(Files.newInputStream(aff));\n      String encoding = getDictionaryEncoding(aff1);\n      \n      // pass 2: parse affixes\n      CharsetDecoder decoder = getJavaEncoding(encoding);\n      aff2 = new BufferedInputStream(Files.newInputStream(aff));\n      readAffixFile(aff2, decoder);\n      \n      // read dictionary entries\n      IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n      Builder<IntsRef> b = new Builder<>(FST.INPUT_TYPE.BYTE4, o);\n      readDictionaryFiles(dictionaries, decoder, b);\n      words = b.finish();\n      aliases = null; // no longer needed\n      morphAliases = null; // no longer needed\n      success = true;\n    } finally {\n      IOUtils.closeWhileHandlingException(out, aff1, aff2);\n      if (success) {\n        Files.delete(aff);\n      } else {\n        IOUtils.deleteFilesIgnoringExceptions(aff);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n\n    File aff = File.createTempFile(\"affix\", \"aff\", tempDir);\n    OutputStream out = new BufferedOutputStream(new FileOutputStream(aff));\n    InputStream aff1 = null;\n    InputStream aff2 = null;\n    boolean success = false;\n    try {\n      // copy contents of affix stream to temp file\n      final byte [] buffer = new byte [1024 * 8];\n      int len;\n      while ((len = affix.read(buffer)) > 0) {\n        out.write(buffer, 0, len);\n      }\n      out.close();\n      \n      // pass 1: get encoding\n      aff1 = new BufferedInputStream(new FileInputStream(aff));\n      String encoding = getDictionaryEncoding(aff1);\n      \n      // pass 2: parse affixes\n      CharsetDecoder decoder = getJavaEncoding(encoding);\n      aff2 = new BufferedInputStream(new FileInputStream(aff));\n      readAffixFile(aff2, decoder);\n      \n      // read dictionary entries\n      IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n      Builder<IntsRef> b = new Builder<>(FST.INPUT_TYPE.BYTE4, o);\n      readDictionaryFiles(dictionaries, decoder, b);\n      words = b.finish();\n      aliases = null; // no longer needed\n      morphAliases = null; // no longer needed\n      success = true;\n    } finally {\n      IOUtils.closeWhileHandlingException(out, aff1, aff2);\n      if (success) {\n        Files.delete(aff.toPath());\n      } else {\n        IOUtils.deleteFilesIgnoringExceptions(aff);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"867e3d9153fb761456b54a9dcce566e1545c5ef6","date":1444903098,"type":5,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(Directory,String,InputStream,List[InputStream],boolean).mjava","pathOld":"lucene/analysis/common/src/java/org/apache/lucene/analysis/hunspell/Dictionary#Dictionary(InputStream,List[InputStream],boolean).mjava","sourceNew":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param tempDir Directory to use for offline sorting\n   * @param tempFileNamePrefix prefix to use to generate temp file names\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(Directory tempDir, String tempFileNamePrefix, InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n\n    Path aff = Files.createTempFile(tempPath, \"affix\", \"aff\");\n    OutputStream out = new BufferedOutputStream(Files.newOutputStream(aff));\n    InputStream aff1 = null;\n    InputStream aff2 = null;\n    boolean success = false;\n    try {\n      // copy contents of affix stream to temp file\n      final byte [] buffer = new byte [1024 * 8];\n      int len;\n      while ((len = affix.read(buffer)) > 0) {\n        out.write(buffer, 0, len);\n      }\n      out.close();\n      \n      // pass 1: get encoding\n      aff1 = new BufferedInputStream(Files.newInputStream(aff));\n      String encoding = getDictionaryEncoding(aff1);\n      \n      // pass 2: parse affixes\n      CharsetDecoder decoder = getJavaEncoding(encoding);\n      aff2 = new BufferedInputStream(Files.newInputStream(aff));\n      readAffixFile(aff2, decoder);\n      \n      // read dictionary entries\n      IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n      Builder<IntsRef> b = new Builder<>(FST.INPUT_TYPE.BYTE4, o);\n      readDictionaryFiles(tempDir, tempFileNamePrefix, dictionaries, decoder, b);\n      words = b.finish();\n      aliases = null; // no longer needed\n      morphAliases = null; // no longer needed\n      success = true;\n    } finally {\n      IOUtils.closeWhileHandlingException(out, aff1, aff2);\n      if (success) {\n        Files.delete(aff);\n      } else {\n        IOUtils.deleteFilesIgnoringExceptions(aff);\n      }\n    }\n  }\n\n","sourceOld":"  /**\n   * Creates a new Dictionary containing the information read from the provided InputStreams to hunspell affix\n   * and dictionary files.\n   * You have to close the provided InputStreams yourself.\n   *\n   * @param affix InputStream for reading the hunspell affix file (won't be closed).\n   * @param dictionaries InputStream for reading the hunspell dictionary files (won't be closed).\n   * @throws IOException Can be thrown while reading from the InputStreams\n   * @throws ParseException Can be thrown if the content of the files does not meet expected formats\n   */\n  public Dictionary(InputStream affix, List<InputStream> dictionaries, boolean ignoreCase) throws IOException, ParseException {\n    this.ignoreCase = ignoreCase;\n    this.needsInputCleaning = ignoreCase;\n    this.needsOutputCleaning = false; // set if we have an OCONV\n    flagLookup.add(new BytesRef()); // no flags -> ord 0\n\n    Path aff = Files.createTempFile(tempDir, \"affix\", \"aff\");\n    OutputStream out = new BufferedOutputStream(Files.newOutputStream(aff));\n    InputStream aff1 = null;\n    InputStream aff2 = null;\n    boolean success = false;\n    try {\n      // copy contents of affix stream to temp file\n      final byte [] buffer = new byte [1024 * 8];\n      int len;\n      while ((len = affix.read(buffer)) > 0) {\n        out.write(buffer, 0, len);\n      }\n      out.close();\n      \n      // pass 1: get encoding\n      aff1 = new BufferedInputStream(Files.newInputStream(aff));\n      String encoding = getDictionaryEncoding(aff1);\n      \n      // pass 2: parse affixes\n      CharsetDecoder decoder = getJavaEncoding(encoding);\n      aff2 = new BufferedInputStream(Files.newInputStream(aff));\n      readAffixFile(aff2, decoder);\n      \n      // read dictionary entries\n      IntSequenceOutputs o = IntSequenceOutputs.getSingleton();\n      Builder<IntsRef> b = new Builder<>(FST.INPUT_TYPE.BYTE4, o);\n      readDictionaryFiles(dictionaries, decoder, b);\n      words = b.finish();\n      aliases = null; // no longer needed\n      morphAliases = null; // no longer needed\n      success = true;\n    } finally {\n      IOUtils.closeWhileHandlingException(out, aff1, aff2);\n      if (success) {\n        Files.delete(aff);\n      } else {\n        IOUtils.deleteFilesIgnoringExceptions(aff);\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["09fb4238d56f62faff1f0c866bee53facad482ec"],"96ea64d994d340044e0d57aeb6a5871539d10ca5":["1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7","436457d41a3d830862d2aca1ba3b94528bd7bb88"],"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4":["96ea64d994d340044e0d57aeb6a5871539d10ca5","6d4fb2cc011096cc0cff79f0adcf03dc734b9352"],"b58bd8dd457a9b46b007c641d5b6e747afb8904a":["ba791bce8103c79e38f957e9c5a53a75871bd918"],"f4abec28b874149a7223e32cc7a01704c27790de":["cbc3688252d4a8045d69a164236b2cf87b721f17"],"09fb4238d56f62faff1f0c866bee53facad482ec":["6d4fb2cc011096cc0cff79f0adcf03dc734b9352"],"1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7":["b58bd8dd457a9b46b007c641d5b6e747afb8904a"],"5916de6e2f6deb9da923b2710f6451668e94a20c":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"cbc3688252d4a8045d69a164236b2cf87b721f17":["5916de6e2f6deb9da923b2710f6451668e94a20c"],"ba791bce8103c79e38f957e9c5a53a75871bd918":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","dc3f094cafa4a87b4066e1d6710fa4e6afe6260e"],"dc3f094cafa4a87b4066e1d6710fa4e6afe6260e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"5ae9942cbee38a49d234c2f022e3a265133d1914":["1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"436457d41a3d830862d2aca1ba3b94528bd7bb88":["5ae9942cbee38a49d234c2f022e3a265133d1914"],"867e3d9153fb761456b54a9dcce566e1545c5ef6":["f4abec28b874149a7223e32cc7a01704c27790de"],"6d4fb2cc011096cc0cff79f0adcf03dc734b9352":["436457d41a3d830862d2aca1ba3b94528bd7bb88"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["867e3d9153fb761456b54a9dcce566e1545c5ef6"]},"commit2Childs":{"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["5916de6e2f6deb9da923b2710f6451668e94a20c"],"96ea64d994d340044e0d57aeb6a5871539d10ca5":["a58bbbe1c866963764d3f15d3a26a6a85f6c6af4"],"a58bbbe1c866963764d3f15d3a26a6a85f6c6af4":[],"b58bd8dd457a9b46b007c641d5b6e747afb8904a":["1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7"],"09fb4238d56f62faff1f0c866bee53facad482ec":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"f4abec28b874149a7223e32cc7a01704c27790de":["867e3d9153fb761456b54a9dcce566e1545c5ef6"],"1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7":["96ea64d994d340044e0d57aeb6a5871539d10ca5","5ae9942cbee38a49d234c2f022e3a265133d1914"],"5916de6e2f6deb9da923b2710f6451668e94a20c":["cbc3688252d4a8045d69a164236b2cf87b721f17"],"ba791bce8103c79e38f957e9c5a53a75871bd918":["b58bd8dd457a9b46b007c641d5b6e747afb8904a"],"cbc3688252d4a8045d69a164236b2cf87b721f17":["f4abec28b874149a7223e32cc7a01704c27790de"],"dc3f094cafa4a87b4066e1d6710fa4e6afe6260e":["ba791bce8103c79e38f957e9c5a53a75871bd918"],"5ae9942cbee38a49d234c2f022e3a265133d1914":["436457d41a3d830862d2aca1ba3b94528bd7bb88"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["ba791bce8103c79e38f957e9c5a53a75871bd918","dc3f094cafa4a87b4066e1d6710fa4e6afe6260e"],"436457d41a3d830862d2aca1ba3b94528bd7bb88":["96ea64d994d340044e0d57aeb6a5871539d10ca5","6d4fb2cc011096cc0cff79f0adcf03dc734b9352"],"6d4fb2cc011096cc0cff79f0adcf03dc734b9352":["a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","09fb4238d56f62faff1f0c866bee53facad482ec"],"867e3d9153fb761456b54a9dcce566e1545c5ef6":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["a58bbbe1c866963764d3f15d3a26a6a85f6c6af4","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}