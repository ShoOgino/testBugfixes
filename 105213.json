{"path":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","commits":[{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":1,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6a7d929a865de9eba83219154403f4d3cad47930","date":1373324758,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      } \n      \n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"37a0f60745e53927c4c876cfe5b5a58170f0646c","date":1373994005,"type":3,"author":"Han Jiang","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      } \n      \n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      } \n      \n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<Query>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      } \n      \n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<Query>(sets.length-end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<Weight>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fb17639909a369c1e64866842e5c213440acc17e","date":1423238093,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      } \n      \n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq, true));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      } \n      \n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"954e59be3da8dc1b046646ad7af4b466852009d3","date":1423482367,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      } \n      \n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq, PostingsEnum.FLAG_FREQS));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      } \n      \n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq, true));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6a47d642ab24da1a811adce4bda9cc52c520ca13","date":1423483323,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      } \n      \n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq, true));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      } \n      \n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq, PostingsEnum.FLAG_FREQS));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"16b25963ad38ed289ebf0f7af31269fa1ce80a11","date":1442083896,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      } \n      \n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getLiveDocs();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq, true));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getLiveDocs();\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      } \n      \n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getPositiveDocSet(matchAllDocsQuery);\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq, true));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getPositiveDocSet(matchAllDocsQuery);\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ac9de183adbc9483681f275ac1e2d92ed19f52e1","date":1452414626,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocs();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq, true));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getLiveDocs();\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries==null || queries.size()==0) {\n      if (setFilter != null)\n        pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer=null;\n\n    boolean[] neg = new boolean[queries.size()+1];\n    DocSet[] sets = new DocSet[queries.size()+1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery)q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length-end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      } \n      \n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length-end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q==posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz<smallestCount) {\n          smallestCount=sz;\n          smallestIndex=end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer==null) {\n      answer = getLiveDocs();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i=0; i<end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i=0; i<end; i++) {\n      if (!neg[i] && i!=smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq, true));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getLiveDocs();\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i=postFilters.size()-1; i>=0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter)postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d30c75558ec9c248a36d6e6768872ee9bed928a4","date":1452963398,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocs();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq, true));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n      pf.hasDeletedDocs = (answer == null);  // if all clauses were uncached, the resulting filter may match deleted docs\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getLiveDocs();\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocs();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq, true));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getLiveDocs();\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9fc47cb7b4346802411bb432f501ed0673d7119e","date":1512640179,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocs();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq, ScoreMode.COMPLETE));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n      pf.hasDeletedDocs = (answer == null);  // if all clauses were uncached, the resulting filter may match deleted docs\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getLiveDocs();\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocs();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq, true));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n      pf.hasDeletedDocs = (answer == null);  // if all clauses were uncached, the resulting filter may match deleted docs\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getLiveDocs();\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"417142ff08fda9cf0b72d5133e63097a166c6458","date":1512729693,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocs();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq, ScoreMode.COMPLETE));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n      pf.hasDeletedDocs = (answer == null);  // if all clauses were uncached, the resulting filter may match deleted docs\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getLiveDocs();\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocs();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq, true));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n      pf.hasDeletedDocs = (answer == null);  // if all clauses were uncached, the resulting filter may match deleted docs\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getLiveDocs();\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"475584d5e08a22ad3fc7babefe006d77bc744567","date":1523282824,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocs();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createWeight(rewrite(qq), ScoreMode.COMPLETE, 1));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n      pf.hasDeletedDocs = (answer == null);  // if all clauses were uncached, the resulting filter may match deleted docs\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getLiveDocs();\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocs();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq, ScoreMode.COMPLETE));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n      pf.hasDeletedDocs = (answer == null);  // if all clauses were uncached, the resulting filter may match deleted docs\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getLiveDocs();\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d58e44159788900f4a2113b84463dc3fbbf80f20","date":1523319203,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocs();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createWeight(rewrite(qq), ScoreMode.COMPLETE, 1));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n      pf.hasDeletedDocs = (answer == null);  // if all clauses were uncached, the resulting filter may match deleted docs\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getLiveDocs();\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocs();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createNormalizedWeight(qq, ScoreMode.COMPLETE));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n      pf.hasDeletedDocs = (answer == null);  // if all clauses were uncached, the resulting filter may match deleted docs\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getLiveDocs();\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"16fb59ed0a06960e7f3c0343d15d638ec5ea2b10","date":1527104253,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocs();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createWeight(rewrite(qq), ScoreMode.COMPLETE_NO_SCORES, 1));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n      pf.hasDeletedDocs = (answer == null);  // if all clauses were uncached, the resulting filter may match deleted docs\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getLiveDocs();\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocs();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createWeight(rewrite(qq), ScoreMode.COMPLETE, 1));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n      pf.hasDeletedDocs = (answer == null);  // if all clauses were uncached, the resulting filter may match deleted docs\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getLiveDocs();\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bf29cc8a76949bbcbc15b386a9e46a533f5b3332","date":1527778512,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocSet();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createWeight(rewrite(qq), ScoreMode.COMPLETE_NO_SCORES, 1));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n      pf.hasDeletedDocs = (answer == null);  // if all clauses were uncached, the resulting filter may match deleted docs\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getLiveDocSet();\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocs();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createWeight(rewrite(qq), ScoreMode.COMPLETE_NO_SCORES, 1));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n      pf.hasDeletedDocs = (answer == null);  // if all clauses were uncached, the resulting filter may match deleted docs\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getLiveDocs();\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"65bb42906a110f043122b3338eb5393db03e3706","date":1586291109,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  /**\n   * INTERNAL: Processes conjunction (AND) of both args into a {@link ProcessedFilter} result.\n   * Either arg may be null/empty thus doesn't restrict the matching docs.\n   * Queries typically are resolved against the filter cache, and populate it.\n   */\n  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) {\n        pf.answer = setFilter;\n        pf.filter = setFilter.getTopFilter();\n      }\n      return pf;\n    }\n\n    // We combine all the filter queries that come from the filter cache & setFilter into \"answer\".\n    // This might become pf.filterAsDocSet but not if there are any non-cached filters\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    } // we are done with setFilter at this point\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocSet();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    // ignore \"answer\" if it simply matches all docs\n    if (answer != null && answer.size() == numDocs()) {\n      answer = null;\n    }\n\n    // answer is done.\n\n    // If no notCached nor postFilters, we can return now.\n    if (notCached == null && postFilters == null) {\n      // \"answer\" is the only part of the filter, so set it.\n      if (answer != null) {\n        pf.answer = answer;\n        pf.filter = answer.getTopFilter();\n      }\n      return pf;\n    }\n    // pf.answer will remain null ...  (our local \"answer\" var is not the complete answer)\n\n    // Set pf.filter based on combining \"answer\" and \"notCached\"\n    if (notCached == null) {\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    } else {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createWeight(rewrite(qq), ScoreMode.COMPLETE_NO_SCORES, 1));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n      pf.hasDeletedDocs = (answer == null);  // if all clauses were uncached, the resulting filter may match deleted docs\n    }\n\n    // Set pf.postFilter\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) pf.filter = setFilter.getTopFilter();\n      return pf;\n    }\n\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    }\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocSet();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    if (notCached != null) {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createWeight(rewrite(qq), ScoreMode.COMPLETE_NO_SCORES, 1));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n      pf.hasDeletedDocs = (answer == null);  // if all clauses were uncached, the resulting filter may match deleted docs\n    } else {\n      if (postFilters == null) {\n        if (answer == null) {\n          answer = getLiveDocSet();\n        }\n        // \"answer\" is the only part of the filter, so set it.\n        pf.answer = answer;\n      }\n\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    }\n\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"49731339ba07ef57ca4823faf0252a8b31dc33e2","date":1587256137,"type":3,"author":"David Smiley","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","pathOld":"solr/core/src/java/org/apache/solr/search/SolrIndexSearcher#getProcessedFilter(DocSet,List[Query]).mjava","sourceNew":"  /**\n   * INTERNAL: Processes conjunction (AND) of both args into a {@link ProcessedFilter} result.\n   * Either arg may be null/empty thus doesn't restrict the matching docs.\n   * Queries typically are resolved against the filter cache, and populate it.\n   */\n  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) {\n        pf.answer = setFilter;\n        pf.filter = setFilter.getTopFilter();\n      }\n      return pf;\n    }\n\n    // We combine all the filter queries that come from the filter cache & setFilter into \"answer\".\n    // This might become pf.filterAsDocSet but not if there are any non-cached filters\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    } // we are done with setFilter at this point\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocSet();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    // ignore \"answer\" if it simply matches all docs\n    if (answer != null && answer.size() == numDocs()) {\n      answer = null;\n    }\n\n    // answer is done.\n\n    // If no notCached nor postFilters, we can return now.\n    if (notCached == null && postFilters == null) {\n      // \"answer\" is the only part of the filter, so set it.\n      if (answer != null) {\n        pf.answer = answer;\n        pf.filter = answer.getTopFilter();\n      }\n      return pf;\n    }\n    // pf.answer will remain null ...  (our local \"answer\" var is not the complete answer)\n\n    // Set pf.filter based on combining \"answer\" and \"notCached\"\n    if (notCached == null) {\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    } else {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createWeight(rewrite(qq), ScoreMode.COMPLETE_NO_SCORES, 1));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n    }\n\n    // Set pf.postFilter\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","sourceOld":"  /**\n   * INTERNAL: Processes conjunction (AND) of both args into a {@link ProcessedFilter} result.\n   * Either arg may be null/empty thus doesn't restrict the matching docs.\n   * Queries typically are resolved against the filter cache, and populate it.\n   */\n  public ProcessedFilter getProcessedFilter(DocSet setFilter, List<Query> queries) throws IOException {\n    ProcessedFilter pf = new ProcessedFilter();\n    if (queries == null || queries.size() == 0) {\n      if (setFilter != null) {\n        pf.answer = setFilter;\n        pf.filter = setFilter.getTopFilter();\n      }\n      return pf;\n    }\n\n    // We combine all the filter queries that come from the filter cache & setFilter into \"answer\".\n    // This might become pf.filterAsDocSet but not if there are any non-cached filters\n    DocSet answer = null;\n\n    boolean[] neg = new boolean[queries.size() + 1];\n    DocSet[] sets = new DocSet[queries.size() + 1];\n    List<Query> notCached = null;\n    List<Query> postFilters = null;\n\n    int end = 0;\n    int smallestIndex = -1;\n\n    if (setFilter != null) {\n      answer = sets[end++] = setFilter;\n      smallestIndex = end;\n    } // we are done with setFilter at this point\n\n    int smallestCount = Integer.MAX_VALUE;\n    for (Query q : queries) {\n      if (q instanceof ExtendedQuery) {\n        ExtendedQuery eq = (ExtendedQuery) q;\n        if (!eq.getCache()) {\n          if (eq.getCost() >= 100 && eq instanceof PostFilter) {\n            if (postFilters == null) postFilters = new ArrayList<>(sets.length - end);\n            postFilters.add(q);\n          } else {\n            if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n            notCached.add(q);\n          }\n          continue;\n        }\n      }\n\n      if (filterCache == null) {\n        // there is no cache: don't pull bitsets\n        if (notCached == null) notCached = new ArrayList<>(sets.length - end);\n        WrappedQuery uncached = new WrappedQuery(q);\n        uncached.setCache(false);\n        notCached.add(uncached);\n        continue;\n      }\n\n      Query posQuery = QueryUtils.getAbs(q);\n      sets[end] = getPositiveDocSet(posQuery);\n      // Negative query if absolute value different from original\n      if (q == posQuery) {\n        neg[end] = false;\n        // keep track of the smallest positive set.\n        // This optimization is only worth it if size() is cached, which it would\n        // be if we don't do any set operations.\n        int sz = sets[end].size();\n        if (sz < smallestCount) {\n          smallestCount = sz;\n          smallestIndex = end;\n          answer = sets[end];\n        }\n      } else {\n        neg[end] = true;\n      }\n\n      end++;\n    }\n\n    // Are all of our normal cached filters negative?\n    if (end > 0 && answer == null) {\n      answer = getLiveDocSet();\n    }\n\n    // do negative queries first to shrink set size\n    for (int i = 0; i < end; i++) {\n      if (neg[i]) answer = answer.andNot(sets[i]);\n    }\n\n    for (int i = 0; i < end; i++) {\n      if (!neg[i] && i != smallestIndex) answer = answer.intersection(sets[i]);\n    }\n\n    // ignore \"answer\" if it simply matches all docs\n    if (answer != null && answer.size() == numDocs()) {\n      answer = null;\n    }\n\n    // answer is done.\n\n    // If no notCached nor postFilters, we can return now.\n    if (notCached == null && postFilters == null) {\n      // \"answer\" is the only part of the filter, so set it.\n      if (answer != null) {\n        pf.answer = answer;\n        pf.filter = answer.getTopFilter();\n      }\n      return pf;\n    }\n    // pf.answer will remain null ...  (our local \"answer\" var is not the complete answer)\n\n    // Set pf.filter based on combining \"answer\" and \"notCached\"\n    if (notCached == null) {\n      if (answer != null) {\n        pf.filter = answer.getTopFilter();\n      }\n    } else {\n      Collections.sort(notCached, sortByCost);\n      List<Weight> weights = new ArrayList<>(notCached.size());\n      for (Query q : notCached) {\n        Query qq = QueryUtils.makeQueryable(q);\n        weights.add(createWeight(rewrite(qq), ScoreMode.COMPLETE_NO_SCORES, 1));\n      }\n      pf.filter = new FilterImpl(answer, weights);\n      pf.hasDeletedDocs = (answer == null);  // if all clauses were uncached, the resulting filter may match deleted docs\n    }\n\n    // Set pf.postFilter\n    if (postFilters != null) {\n      Collections.sort(postFilters, sortByCost);\n      for (int i = postFilters.size() - 1; i >= 0; i--) {\n        DelegatingCollector prev = pf.postFilter;\n        pf.postFilter = ((PostFilter) postFilters.get(i)).getFilterCollector(this);\n        if (prev != null) pf.postFilter.setDelegate(prev);\n      }\n    }\n\n    return pf;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"6a7d929a865de9eba83219154403f4d3cad47930":["c26f00b574427b55127e869b935845554afde1fa"],"16b25963ad38ed289ebf0f7af31269fa1ce80a11":["6a47d642ab24da1a811adce4bda9cc52c520ca13"],"6a47d642ab24da1a811adce4bda9cc52c520ca13":["954e59be3da8dc1b046646ad7af4b466852009d3"],"fb17639909a369c1e64866842e5c213440acc17e":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["6a7d929a865de9eba83219154403f4d3cad47930"],"475584d5e08a22ad3fc7babefe006d77bc744567":["417142ff08fda9cf0b72d5133e63097a166c6458"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":["c26f00b574427b55127e869b935845554afde1fa","6a7d929a865de9eba83219154403f4d3cad47930"],"65bb42906a110f043122b3338eb5393db03e3706":["bf29cc8a76949bbcbc15b386a9e46a533f5b3332"],"c26f00b574427b55127e869b935845554afde1fa":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"d30c75558ec9c248a36d6e6768872ee9bed928a4":["ac9de183adbc9483681f275ac1e2d92ed19f52e1"],"ac9de183adbc9483681f275ac1e2d92ed19f52e1":["16b25963ad38ed289ebf0f7af31269fa1ce80a11"],"954e59be3da8dc1b046646ad7af4b466852009d3":["fb17639909a369c1e64866842e5c213440acc17e"],"417142ff08fda9cf0b72d5133e63097a166c6458":["d30c75558ec9c248a36d6e6768872ee9bed928a4","9fc47cb7b4346802411bb432f501ed0673d7119e"],"d58e44159788900f4a2113b84463dc3fbbf80f20":["417142ff08fda9cf0b72d5133e63097a166c6458","475584d5e08a22ad3fc7babefe006d77bc744567"],"bf29cc8a76949bbcbc15b386a9e46a533f5b3332":["16fb59ed0a06960e7f3c0343d15d638ec5ea2b10"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"49731339ba07ef57ca4823faf0252a8b31dc33e2":["65bb42906a110f043122b3338eb5393db03e3706"],"16fb59ed0a06960e7f3c0343d15d638ec5ea2b10":["d58e44159788900f4a2113b84463dc3fbbf80f20"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"9fc47cb7b4346802411bb432f501ed0673d7119e":["d30c75558ec9c248a36d6e6768872ee9bed928a4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["49731339ba07ef57ca4823faf0252a8b31dc33e2"]},"commit2Childs":{"6a7d929a865de9eba83219154403f4d3cad47930":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","37a0f60745e53927c4c876cfe5b5a58170f0646c"],"16b25963ad38ed289ebf0f7af31269fa1ce80a11":["ac9de183adbc9483681f275ac1e2d92ed19f52e1"],"6a47d642ab24da1a811adce4bda9cc52c520ca13":["16b25963ad38ed289ebf0f7af31269fa1ce80a11"],"fb17639909a369c1e64866842e5c213440acc17e":["954e59be3da8dc1b046646ad7af4b466852009d3"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["fb17639909a369c1e64866842e5c213440acc17e"],"475584d5e08a22ad3fc7babefe006d77bc744567":["d58e44159788900f4a2113b84463dc3fbbf80f20"],"37a0f60745e53927c4c876cfe5b5a58170f0646c":[],"c26f00b574427b55127e869b935845554afde1fa":["6a7d929a865de9eba83219154403f4d3cad47930","37a0f60745e53927c4c876cfe5b5a58170f0646c"],"65bb42906a110f043122b3338eb5393db03e3706":["49731339ba07ef57ca4823faf0252a8b31dc33e2"],"d30c75558ec9c248a36d6e6768872ee9bed928a4":["417142ff08fda9cf0b72d5133e63097a166c6458","9fc47cb7b4346802411bb432f501ed0673d7119e"],"954e59be3da8dc1b046646ad7af4b466852009d3":["6a47d642ab24da1a811adce4bda9cc52c520ca13"],"ac9de183adbc9483681f275ac1e2d92ed19f52e1":["d30c75558ec9c248a36d6e6768872ee9bed928a4"],"417142ff08fda9cf0b72d5133e63097a166c6458":["475584d5e08a22ad3fc7babefe006d77bc744567","d58e44159788900f4a2113b84463dc3fbbf80f20"],"d58e44159788900f4a2113b84463dc3fbbf80f20":["16fb59ed0a06960e7f3c0343d15d638ec5ea2b10"],"bf29cc8a76949bbcbc15b386a9e46a533f5b3332":["65bb42906a110f043122b3338eb5393db03e3706"],"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["c26f00b574427b55127e869b935845554afde1fa","c903c3d15906a3da96b8c0c2fb704491005fdbdb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"16fb59ed0a06960e7f3c0343d15d638ec5ea2b10":["bf29cc8a76949bbcbc15b386a9e46a533f5b3332"],"49731339ba07ef57ca4823faf0252a8b31dc33e2":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"9fc47cb7b4346802411bb432f501ed0673d7119e":["417142ff08fda9cf0b72d5133e63097a166c6458"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["37a0f60745e53927c4c876cfe5b5a58170f0646c","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}