{"path":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8","date":1328775259,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = topReaderContext.leaves();\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = ReaderUtil.leaves(topReaderContext);\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = topReaderContext.leaves();\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random, dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = topReaderContext.leaves();\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random.nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random.nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"04f07771a2a7dd3a395700665ed839c3dae2def2","date":1339350139,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = topReaderContext.leaves();\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_UNSTORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = topReaderContext.leaves();\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","date":1340090669,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      for (AtomicReaderContext atomicReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      AtomicReaderContext[] leaves = topReaderContext.leaves();\n      for (AtomicReaderContext atomicReaderContext : leaves) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"211b1506e56f7860762fbd4698f6d1d1b57f672c","date":1344976996,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext atomicReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      for (AtomicReaderContext atomicReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","date":1345029782,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext atomicReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      for (AtomicReaderContext atomicReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3c188105a9aae04f56c24996f98f8333fc825d2e","date":1345031914,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext atomicReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      for (AtomicReaderContext atomicReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1c93396a1df03720cb20e2c2f513a6fa59b21e4c","date":1345032673,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      for (AtomicReaderContext atomicReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext atomicReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b05c56a41b733e02a189c48895922b5bd8c7f3d1","date":1345033322,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext atomicReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getTopReaderContext();\n      for (AtomicReaderContext atomicReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext atomicReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext atomicReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext atomicReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext atomicReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext atomicReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.shutdown();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext atomicReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (LeafReaderContext leafReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            leafReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = leafReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (AtomicReaderContext atomicReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            atomicReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = atomicReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (LeafReaderContext leafReaderContext : topReaderContext.leaves()) {\n        PostingsEnum docsAndPosEnum = getDocsAndPositions(\n            leafReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = leafReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (LeafReaderContext leafReaderContext : topReaderContext.leaves()) {\n        DocsAndPositionsEnum docsAndPosEnum = getDocsAndPositions(\n            leafReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = leafReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocsAndPositions#testLargeNumberOfPositions().mjava","sourceNew":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (LeafReaderContext leafReaderContext : topReaderContext.leaves()) {\n        PostingsEnum docsAndPosEnum = getDocsAndPositions(\n            leafReaderContext.reader(), bytes);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = leafReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","sourceOld":"  /**\n   * tests retrieval of positions for terms that have a large number of\n   * occurrences to force test of buffer refill during positions iteration.\n   */\n  public void testLargeNumberOfPositions() throws IOException {\n    Directory dir = newDirectory();\n    RandomIndexWriter writer = new RandomIndexWriter(random(), dir,\n        newIndexWriterConfig(new MockAnalyzer(random())));\n    int howMany = 1000;\n    FieldType customType = new FieldType(TextField.TYPE_NOT_STORED);\n    customType.setOmitNorms(true);\n    for (int i = 0; i < 39; i++) {\n      Document doc = new Document();\n      StringBuilder builder = new StringBuilder();\n      for (int j = 0; j < howMany; j++) {\n        if (j % 2 == 0) {\n          builder.append(\"even \");\n        } else {\n          builder.append(\"odd \");\n        }\n      }\n      doc.add(newField(fieldName, builder.toString(), customType));\n      writer.addDocument(doc);\n    }\n\n    // now do searches\n    IndexReader reader = writer.getReader();\n    writer.close();\n\n    int num = atLeast(13);\n    for (int i = 0; i < num; i++) {\n      BytesRef bytes = new BytesRef(\"even\");\n\n      IndexReaderContext topReaderContext = reader.getContext();\n      for (LeafReaderContext leafReaderContext : topReaderContext.leaves()) {\n        PostingsEnum docsAndPosEnum = getDocsAndPositions(\n            leafReaderContext.reader(), bytes, null);\n        assertNotNull(docsAndPosEnum);\n\n        int initDoc = 0;\n        int maxDoc = leafReaderContext.reader().maxDoc();\n        // initially advance or do next doc\n        if (random().nextBoolean()) {\n          initDoc = docsAndPosEnum.nextDoc();\n        } else {\n          initDoc = docsAndPosEnum.advance(random().nextInt(maxDoc));\n        }\n        String msg = \"Iteration: \" + i + \" initDoc: \" + initDoc; // TODO: + \" payloads: \" + usePayload;\n        assertEquals(howMany / 2, docsAndPosEnum.freq());\n        for (int j = 0; j < howMany; j += 2) {\n          assertEquals(\"position missmatch index: \" + j + \" with freq: \"\n              + docsAndPosEnum.freq() + \" -- \" + msg, j,\n              docsAndPosEnum.nextPosition());\n        }\n      }\n    }\n    reader.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c","211b1506e56f7860762fbd4698f6d1d1b57f672c"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["3c188105a9aae04f56c24996f98f8333fc825d2e"],"211b1506e56f7860762fbd4698f6d1d1b57f672c":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c","211b1506e56f7860762fbd4698f6d1d1b57f672c"],"51f5280f31484820499077f41fcdfe92d527d9dc":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["51f5280f31484820499077f41fcdfe92d527d9dc"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["211b1506e56f7860762fbd4698f6d1d1b57f672c"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0f4464508ee83288c8c4585b533f9faaa93aa314"]},"commit2Childs":{"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"3c188105a9aae04f56c24996f98f8333fc825d2e":["1c93396a1df03720cb20e2c2f513a6fa59b21e4c"],"4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c":["3c188105a9aae04f56c24996f98f8333fc825d2e","211b1506e56f7860762fbd4698f6d1d1b57f672c","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198"],"b05c56a41b733e02a189c48895922b5bd8c7f3d1":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8"],"1c93396a1df03720cb20e2c2f513a6fa59b21e4c":["b05c56a41b733e02a189c48895922b5bd8c7f3d1"],"211b1506e56f7860762fbd4698f6d1d1b57f672c":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"0d4602ca2700dfd2f6159ad1499e5b6d1f3b92a8":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198":[],"51f5280f31484820499077f41fcdfe92d527d9dc":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["51f5280f31484820499077f41fcdfe92d527d9dc"],"04f07771a2a7dd3a395700665ed839c3dae2def2":["4c5ae929ce8aa0c4856f0d6bfd4c196bc2d3eb9c"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["b05c56a41b733e02a189c48895922b5bd8c7f3d1","c1fe8ee1a5a1ef00a9c4793ec26f17bd90342198","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}