{"path":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest#testKeywordAttribute().mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest#testKeywordAttribute().mjava","pathOld":"modules/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest#testKeywordAttribute().mjava","sourceNew":"  /**\n   * Simple test for KeywordAttribute\n   */\n  public void testKeywordAttribute() throws IOException {\n    MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"lucene is awesome\"), MockTokenizer.WHITESPACE, true);\n    tokenizer.setEnableChecks(true);\n    HunspellStemFilter filter = new HunspellStemFilter(tokenizer, DICTIONARY);\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"lucen\", \"is\", \"awesome\"}, new int[] {1, 0, 1, 1});\n    \n    // assert with keywork marker\n    tokenizer = new MockTokenizer(new StringReader(\"lucene is awesome\"), MockTokenizer.WHITESPACE, true);\n    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(\"Lucene\"), true);\n    filter = new HunspellStemFilter(new KeywordMarkerFilter(tokenizer, set), DICTIONARY);\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"is\", \"awesome\"}, new int[] {1, 1, 1});\n  }\n\n","sourceOld":"  /**\n   * Simple test for KeywordAttribute\n   */\n  public void testKeywordAttribute() throws IOException {\n    MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"lucene is awesome\"), MockTokenizer.WHITESPACE, true);\n    tokenizer.setEnableChecks(true);\n    HunspellStemFilter filter = new HunspellStemFilter(tokenizer, DICTIONARY);\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"lucen\", \"is\", \"awesome\"}, new int[] {1, 0, 1, 1});\n    \n    // assert with keywork marker\n    tokenizer = new MockTokenizer(new StringReader(\"lucene is awesome\"), MockTokenizer.WHITESPACE, true);\n    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(\"Lucene\"), true);\n    filter = new HunspellStemFilter(new KeywordMarkerFilter(tokenizer, set), DICTIONARY);\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"is\", \"awesome\"}, new int[] {1, 1, 1});\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a32c7218952a3082e8be4be1a325fd217603f365","date":1363034315,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest#testKeywordAttribute().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest#testKeywordAttribute().mjava","sourceNew":"  /**\n   * Simple test for KeywordAttribute\n   */\n  public void testKeywordAttribute() throws IOException {\n    MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"lucene is awesome\"), MockTokenizer.WHITESPACE, true);\n    tokenizer.setEnableChecks(true);\n    HunspellStemFilter filter = new HunspellStemFilter(tokenizer, DICTIONARY);\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"lucen\", \"is\", \"awesome\"}, new int[] {1, 0, 1, 1});\n    \n    // assert with keywork marker\n    tokenizer = new MockTokenizer(new StringReader(\"lucene is awesome\"), MockTokenizer.WHITESPACE, true);\n    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(\"Lucene\"), true);\n    filter = new HunspellStemFilter(new SetKeywordMarkerFilter(tokenizer, set), DICTIONARY);\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"is\", \"awesome\"}, new int[] {1, 1, 1});\n  }\n\n","sourceOld":"  /**\n   * Simple test for KeywordAttribute\n   */\n  public void testKeywordAttribute() throws IOException {\n    MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"lucene is awesome\"), MockTokenizer.WHITESPACE, true);\n    tokenizer.setEnableChecks(true);\n    HunspellStemFilter filter = new HunspellStemFilter(tokenizer, DICTIONARY);\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"lucen\", \"is\", \"awesome\"}, new int[] {1, 0, 1, 1});\n    \n    // assert with keywork marker\n    tokenizer = new MockTokenizer(new StringReader(\"lucene is awesome\"), MockTokenizer.WHITESPACE, true);\n    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(\"Lucene\"), true);\n    filter = new HunspellStemFilter(new KeywordMarkerFilter(tokenizer, set), DICTIONARY);\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"is\", \"awesome\"}, new int[] {1, 1, 1});\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"765dd1af5470eb0ccafa626a8442dec4b7495a19","date":1374166958,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest#testKeywordAttribute().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest#testKeywordAttribute().mjava","sourceNew":"  /**\n   * Simple test for KeywordAttribute\n   */\n  public void testKeywordAttribute() throws IOException {\n    MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"lucene is awesome\"), MockTokenizer.WHITESPACE, true);\n    tokenizer.setEnableChecks(true);\n    HunspellStemFilter filter = new HunspellStemFilter(tokenizer, DICTIONARY, _TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"lucen\", \"is\", \"awesome\"}, new int[] {1, 0, 1, 1});\n    \n    // assert with keywork marker\n    tokenizer = new MockTokenizer(new StringReader(\"lucene is awesome\"), MockTokenizer.WHITESPACE, true);\n    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(\"Lucene\"), true);\n    filter = new HunspellStemFilter(new SetKeywordMarkerFilter(tokenizer, set), DICTIONARY, _TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"is\", \"awesome\"}, new int[] {1, 1, 1});\n  }\n\n","sourceOld":"  /**\n   * Simple test for KeywordAttribute\n   */\n  public void testKeywordAttribute() throws IOException {\n    MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"lucene is awesome\"), MockTokenizer.WHITESPACE, true);\n    tokenizer.setEnableChecks(true);\n    HunspellStemFilter filter = new HunspellStemFilter(tokenizer, DICTIONARY);\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"lucen\", \"is\", \"awesome\"}, new int[] {1, 0, 1, 1});\n    \n    // assert with keywork marker\n    tokenizer = new MockTokenizer(new StringReader(\"lucene is awesome\"), MockTokenizer.WHITESPACE, true);\n    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(\"Lucene\"), true);\n    filter = new HunspellStemFilter(new SetKeywordMarkerFilter(tokenizer, set), DICTIONARY);\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"is\", \"awesome\"}, new int[] {1, 1, 1});\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest#testKeywordAttribute().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest#testKeywordAttribute().mjava","sourceNew":"  /**\n   * Simple test for KeywordAttribute\n   */\n  public void testKeywordAttribute() throws IOException {\n    MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"lucene is awesome\"), MockTokenizer.WHITESPACE, true);\n    tokenizer.setEnableChecks(true);\n    HunspellStemFilter filter = new HunspellStemFilter(tokenizer, DICTIONARY, _TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"lucen\", \"is\", \"awesome\"}, new int[] {1, 0, 1, 1});\n    \n    // assert with keywork marker\n    tokenizer = new MockTokenizer(new StringReader(\"lucene is awesome\"), MockTokenizer.WHITESPACE, true);\n    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(\"Lucene\"), true);\n    filter = new HunspellStemFilter(new SetKeywordMarkerFilter(tokenizer, set), DICTIONARY, _TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"is\", \"awesome\"}, new int[] {1, 1, 1});\n  }\n\n","sourceOld":"  /**\n   * Simple test for KeywordAttribute\n   */\n  public void testKeywordAttribute() throws IOException {\n    MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"lucene is awesome\"), MockTokenizer.WHITESPACE, true);\n    tokenizer.setEnableChecks(true);\n    HunspellStemFilter filter = new HunspellStemFilter(tokenizer, DICTIONARY);\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"lucen\", \"is\", \"awesome\"}, new int[] {1, 0, 1, 1});\n    \n    // assert with keywork marker\n    tokenizer = new MockTokenizer(new StringReader(\"lucene is awesome\"), MockTokenizer.WHITESPACE, true);\n    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(\"Lucene\"), true);\n    filter = new HunspellStemFilter(new SetKeywordMarkerFilter(tokenizer, set), DICTIONARY);\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"is\", \"awesome\"}, new int[] {1, 1, 1});\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338","date":1389274049,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest#testKeywordAttribute().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest#testKeywordAttribute().mjava","sourceNew":"  /**\n   * Simple test for KeywordAttribute\n   */\n  public void testKeywordAttribute() throws IOException {\n    MockTokenizer tokenizer = whitespaceMockTokenizer(\"lucene is awesome\");\n    tokenizer.setEnableChecks(true);\n    HunspellStemFilter filter = new HunspellStemFilter(tokenizer, DICTIONARY, _TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"lucen\", \"is\", \"awesome\"}, new int[] {1, 0, 1, 1});\n    \n    // assert with keywork marker\n    tokenizer = whitespaceMockTokenizer(\"lucene is awesome\");\n    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(\"Lucene\"), true);\n    filter = new HunspellStemFilter(new SetKeywordMarkerFilter(tokenizer, set), DICTIONARY, _TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"is\", \"awesome\"}, new int[] {1, 1, 1});\n  }\n\n","sourceOld":"  /**\n   * Simple test for KeywordAttribute\n   */\n  public void testKeywordAttribute() throws IOException {\n    MockTokenizer tokenizer = new MockTokenizer(new StringReader(\"lucene is awesome\"), MockTokenizer.WHITESPACE, true);\n    tokenizer.setEnableChecks(true);\n    HunspellStemFilter filter = new HunspellStemFilter(tokenizer, DICTIONARY, _TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"lucen\", \"is\", \"awesome\"}, new int[] {1, 0, 1, 1});\n    \n    // assert with keywork marker\n    tokenizer = new MockTokenizer(new StringReader(\"lucene is awesome\"), MockTokenizer.WHITESPACE, true);\n    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(\"Lucene\"), true);\n    filter = new HunspellStemFilter(new SetKeywordMarkerFilter(tokenizer, set), DICTIONARY, _TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"is\", \"awesome\"}, new int[] {1, 1, 1});\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest#testKeywordAttribute().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest#testKeywordAttribute().mjava","sourceNew":"  /**\n   * Simple test for KeywordAttribute\n   */\n  public void testKeywordAttribute() throws IOException {\n    MockTokenizer tokenizer = whitespaceMockTokenizer(\"lucene is awesome\");\n    tokenizer.setEnableChecks(true);\n    HunspellStemFilter filter = new HunspellStemFilter(tokenizer, DICTIONARY, TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"lucen\", \"is\", \"awesome\"}, new int[] {1, 0, 1, 1});\n    \n    // assert with keywork marker\n    tokenizer = whitespaceMockTokenizer(\"lucene is awesome\");\n    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(\"Lucene\"), true);\n    filter = new HunspellStemFilter(new SetKeywordMarkerFilter(tokenizer, set), DICTIONARY, TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"is\", \"awesome\"}, new int[] {1, 1, 1});\n  }\n\n","sourceOld":"  /**\n   * Simple test for KeywordAttribute\n   */\n  public void testKeywordAttribute() throws IOException {\n    MockTokenizer tokenizer = whitespaceMockTokenizer(\"lucene is awesome\");\n    tokenizer.setEnableChecks(true);\n    HunspellStemFilter filter = new HunspellStemFilter(tokenizer, DICTIONARY, _TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"lucen\", \"is\", \"awesome\"}, new int[] {1, 0, 1, 1});\n    \n    // assert with keywork marker\n    tokenizer = whitespaceMockTokenizer(\"lucene is awesome\");\n    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(\"Lucene\"), true);\n    filter = new HunspellStemFilter(new SetKeywordMarkerFilter(tokenizer, set), DICTIONARY, _TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"is\", \"awesome\"}, new int[] {1, 1, 1});\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"dc3f094cafa4a87b4066e1d6710fa4e6afe6260e","date":1393532367,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/TestHunspellStemFilter#testKeywordAttribute().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest#testKeywordAttribute().mjava","sourceNew":"  /** Simple test for KeywordAttribute */\n  public void testKeywordAttribute() throws IOException {\n    MockTokenizer tokenizer = whitespaceMockTokenizer(\"lucene is awesome\");\n    tokenizer.setEnableChecks(true);\n    HunspellStemFilter filter = new HunspellStemFilter(tokenizer, dictionary, TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"lucen\", \"is\", \"awesome\"}, new int[] {1, 0, 1, 1});\n    \n    // assert with keyword marker\n    tokenizer = whitespaceMockTokenizer(\"lucene is awesome\");\n    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(\"Lucene\"), true);\n    filter = new HunspellStemFilter(new SetKeywordMarkerFilter(tokenizer, set), dictionary, TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"is\", \"awesome\"}, new int[] {1, 1, 1});\n  }\n\n","sourceOld":"  /**\n   * Simple test for KeywordAttribute\n   */\n  public void testKeywordAttribute() throws IOException {\n    MockTokenizer tokenizer = whitespaceMockTokenizer(\"lucene is awesome\");\n    tokenizer.setEnableChecks(true);\n    HunspellStemFilter filter = new HunspellStemFilter(tokenizer, DICTIONARY, TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"lucen\", \"is\", \"awesome\"}, new int[] {1, 0, 1, 1});\n    \n    // assert with keywork marker\n    tokenizer = whitespaceMockTokenizer(\"lucene is awesome\");\n    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(\"Lucene\"), true);\n    filter = new HunspellStemFilter(new SetKeywordMarkerFilter(tokenizer, set), DICTIONARY, TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"is\", \"awesome\"}, new int[] {1, 1, 1});\n  }\n\n","bugFix":null,"bugIntro":["1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7","1bc1343e76d5f1ad7d6a35dd8c55fb52f9b4e3a7"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ba791bce8103c79e38f957e9c5a53a75871bd918","date":1393539206,"type":5,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/TestHunspellStemFilter#testKeywordAttribute().mjava","pathOld":"lucene/analysis/common/src/test/org/apache/lucene/analysis/hunspell/HunspellStemFilterTest#testKeywordAttribute().mjava","sourceNew":"  /** Simple test for KeywordAttribute */\n  public void testKeywordAttribute() throws IOException {\n    MockTokenizer tokenizer = whitespaceMockTokenizer(\"lucene is awesome\");\n    tokenizer.setEnableChecks(true);\n    HunspellStemFilter filter = new HunspellStemFilter(tokenizer, dictionary, TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"lucen\", \"is\", \"awesome\"}, new int[] {1, 0, 1, 1});\n    \n    // assert with keyword marker\n    tokenizer = whitespaceMockTokenizer(\"lucene is awesome\");\n    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(\"Lucene\"), true);\n    filter = new HunspellStemFilter(new SetKeywordMarkerFilter(tokenizer, set), dictionary, TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"is\", \"awesome\"}, new int[] {1, 1, 1});\n  }\n\n","sourceOld":"  /**\n   * Simple test for KeywordAttribute\n   */\n  public void testKeywordAttribute() throws IOException {\n    MockTokenizer tokenizer = whitespaceMockTokenizer(\"lucene is awesome\");\n    tokenizer.setEnableChecks(true);\n    HunspellStemFilter filter = new HunspellStemFilter(tokenizer, DICTIONARY, TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"lucen\", \"is\", \"awesome\"}, new int[] {1, 0, 1, 1});\n    \n    // assert with keywork marker\n    tokenizer = whitespaceMockTokenizer(\"lucene is awesome\");\n    CharArraySet set = new CharArraySet(TEST_VERSION_CURRENT, Arrays.asList(\"Lucene\"), true);\n    filter = new HunspellStemFilter(new SetKeywordMarkerFilter(tokenizer, set), DICTIONARY, TestUtil.nextInt(random(), 1, 3));\n    assertTokenStreamContents(filter, new String[]{\"lucene\", \"is\", \"awesome\"}, new int[] {1, 1, 1});\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"ba791bce8103c79e38f957e9c5a53a75871bd918":["6613659748fe4411a7dcf85266e55db1f95f7315","dc3f094cafa4a87b4066e1d6710fa4e6afe6260e"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["765dd1af5470eb0ccafa626a8442dec4b7495a19"],"a32c7218952a3082e8be4be1a325fd217603f365":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"dc3f094cafa4a87b4066e1d6710fa4e6afe6260e":["6613659748fe4411a7dcf85266e55db1f95f7315"],"6613659748fe4411a7dcf85266e55db1f95f7315":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["a32c7218952a3082e8be4be1a325fd217603f365"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["ba791bce8103c79e38f957e9c5a53a75871bd918"],"765dd1af5470eb0ccafa626a8442dec4b7495a19":["a32c7218952a3082e8be4be1a325fd217603f365"]},"commit2Childs":{"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a32c7218952a3082e8be4be1a325fd217603f365"],"ba791bce8103c79e38f957e9c5a53a75871bd918":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"dc3f094cafa4a87b4066e1d6710fa4e6afe6260e":["ba791bce8103c79e38f957e9c5a53a75871bd918"],"ae889fd5c8a69f6b5d130d3c895bfa5b04d07338":["6613659748fe4411a7dcf85266e55db1f95f7315"],"a32c7218952a3082e8be4be1a325fd217603f365":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","765dd1af5470eb0ccafa626a8442dec4b7495a19"],"6613659748fe4411a7dcf85266e55db1f95f7315":["ba791bce8103c79e38f957e9c5a53a75871bd918","dc3f094cafa4a87b4066e1d6710fa4e6afe6260e"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"765dd1af5470eb0ccafa626a8442dec4b7495a19":["ae889fd5c8a69f6b5d130d3c895bfa5b04d07338"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}