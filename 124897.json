{"path":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","pathOld":"lucene/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","sourceNew":"  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (MergeState.IndexReaderAndLiveDocs readerAndLiveDocs : mergeState.readers) {\n      final AtomicReader reader = readerAndLiveDocs.reader;\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        FieldInfo merged = mergeState.fieldInfos.add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.normsPresent()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n  }\n\n","sourceOld":"  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (MergeState.IndexReaderAndLiveDocs readerAndLiveDocs : mergeState.readers) {\n      final AtomicReader reader = readerAndLiveDocs.reader;\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        FieldInfo merged = mergeState.fieldInfos.add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.normsPresent()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"46818a810eab72123f0e37e6ec5f2d426bd47be1","date":1331482161,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","sourceNew":"  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (MergeState.IndexReaderAndLiveDocs readerAndLiveDocs : mergeState.readers) {\n      final AtomicReader reader = readerAndLiveDocs.reader;\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        FieldInfo merged = mergeState.fieldInfos.add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.hasNorms()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n  }\n\n","sourceOld":"  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (MergeState.IndexReaderAndLiveDocs readerAndLiveDocs : mergeState.readers) {\n      final AtomicReader reader = readerAndLiveDocs.reader;\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        FieldInfo merged = mergeState.fieldInfos.add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.normsPresent()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"38e3b736c7ca086d61b7dbb841c905ee115490da","date":1331657018,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","sourceNew":"  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (MergeState.IndexReaderAndLiveDocs readerAndLiveDocs : mergeState.readers) {\n      final AtomicReader reader = readerAndLiveDocs.reader;\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        FieldInfo merged = mergeState.fieldInfos.add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.hasNorms()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n  }\n\n","sourceOld":"  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (MergeState.IndexReaderAndLiveDocs readerAndLiveDocs : mergeState.readers) {\n      final AtomicReader reader = readerAndLiveDocs.reader;\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        FieldInfo merged = mergeState.fieldInfos.add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.normsPresent()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"76923f6a33f2c4bec7f584e3f251261afe7ea276","date":1337149711,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","sourceNew":"  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (MergeState.IndexReaderAndLiveDocs readerAndLiveDocs : mergeState.readers) {\n      final AtomicReader reader = readerAndLiveDocs.reader;\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        // nocommit: ugly\n        FieldInfo merged = ((MutableFieldInfos)mergeState.fieldInfos).add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.hasNorms()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n  }\n\n","sourceOld":"  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (MergeState.IndexReaderAndLiveDocs readerAndLiveDocs : mergeState.readers) {\n      final AtomicReader reader = readerAndLiveDocs.reader;\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        FieldInfo merged = mergeState.fieldInfos.add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.hasNorms()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"030c3c949a4d9470b22d6b1aa20e836d96c72cb7","date":1337350881,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","sourceNew":"  // NOTE: this is actually merging all the fieldinfos\n  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (MergeState.IndexReaderAndLiveDocs readerAndLiveDocs : mergeState.readers) {\n      final AtomicReader reader = readerAndLiveDocs.reader;\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        FieldInfo merged = fieldInfosBuilder.add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.hasNorms()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n    mergeState.fieldInfos = fieldInfosBuilder.finish();\n  }\n\n","sourceOld":"  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (MergeState.IndexReaderAndLiveDocs readerAndLiveDocs : mergeState.readers) {\n      final AtomicReader reader = readerAndLiveDocs.reader;\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        // nocommit: ugly\n        FieldInfo merged = ((MutableFieldInfos)mergeState.fieldInfos).add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.hasNorms()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"cd9165e54429bb5c99e75d5cb1c926cc98772456","date":1337362687,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","sourceNew":"  // NOTE: this is actually merging all the fieldinfos\n  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the\n    // valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (MergeState.IndexReaderAndLiveDocs readerAndLiveDocs : mergeState.readers) {\n      final AtomicReader reader = readerAndLiveDocs.reader;\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        FieldInfo merged = fieldInfosBuilder.add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.hasNorms()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n    mergeState.fieldInfos = fieldInfosBuilder.finish();\n  }\n\n","sourceOld":"  // NOTE: this is actually merging all the fieldinfos\n  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (MergeState.IndexReaderAndLiveDocs readerAndLiveDocs : mergeState.readers) {\n      final AtomicReader reader = readerAndLiveDocs.reader;\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        FieldInfo merged = fieldInfosBuilder.add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.hasNorms()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n    mergeState.fieldInfos = fieldInfosBuilder.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","sourceNew":"  // NOTE: this is actually merging all the fieldinfos\n  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the\n    // valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (MergeState.IndexReaderAndLiveDocs readerAndLiveDocs : mergeState.readers) {\n      final AtomicReader reader = readerAndLiveDocs.reader;\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        FieldInfo merged = fieldInfosBuilder.add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.hasNorms()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n    mergeState.fieldInfos = fieldInfosBuilder.finish();\n  }\n\n","sourceOld":"  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (MergeState.IndexReaderAndLiveDocs readerAndLiveDocs : mergeState.readers) {\n      final AtomicReader reader = readerAndLiveDocs.reader;\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        FieldInfo merged = mergeState.fieldInfos.add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.hasNorms()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c95a819869502635864dac0a788f874787e3395b","date":1341394787,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","sourceNew":"  // NOTE: this is actually merging all the fieldinfos\n  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the\n    // valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (AtomicReader reader : mergeState.readers) {\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        FieldInfo merged = fieldInfosBuilder.add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.hasNorms()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n    mergeState.fieldInfos = fieldInfosBuilder.finish();\n  }\n\n","sourceOld":"  // NOTE: this is actually merging all the fieldinfos\n  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the\n    // valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (MergeState.IndexReaderAndLiveDocs readerAndLiveDocs : mergeState.readers) {\n      final AtomicReader reader = readerAndLiveDocs.reader;\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        FieldInfo merged = fieldInfosBuilder.add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.hasNorms()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n    mergeState.fieldInfos = fieldInfosBuilder.finish();\n  }\n\n","bugFix":["da6d5ac19a80d65b1e864251f155d30960353b7e","9e8d5a6ffbfa3405d234a87c833741eabed98d13"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","sourceNew":"  // NOTE: this is actually merging all the fieldinfos\n  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the\n    // valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (AtomicReader reader : mergeState.readers) {\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        FieldInfo merged = fieldInfosBuilder.add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.hasNorms()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n    mergeState.fieldInfos = fieldInfosBuilder.finish();\n  }\n\n","sourceOld":"  // NOTE: this is actually merging all the fieldinfos\n  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the\n    // valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (MergeState.IndexReaderAndLiveDocs readerAndLiveDocs : mergeState.readers) {\n      final AtomicReader reader = readerAndLiveDocs.reader;\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        FieldInfo merged = fieldInfosBuilder.add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.hasNorms()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n    mergeState.fieldInfos = fieldInfosBuilder.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0837ab0472feecb3a54260729d845f839e1cbd72","date":1358283639,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","sourceNew":null,"sourceOld":"  // NOTE: this is actually merging all the fieldinfos\n  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the\n    // valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (AtomicReader reader : mergeState.readers) {\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        FieldInfo merged = fieldInfosBuilder.add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.hasNorms()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n    mergeState.fieldInfos = fieldInfosBuilder.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":4,"author":"Robert Muir","isMerge":true,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/index/SegmentMerger#mergeDocValuesAndNormsFieldInfos().mjava","sourceNew":null,"sourceOld":"  // NOTE: this is actually merging all the fieldinfos\n  public void mergeDocValuesAndNormsFieldInfos() throws IOException {\n    // mapping from all docvalues fields found to their promoted types\n    // this is because FieldInfos does not store the\n    // valueSize\n    Map<FieldInfo,TypePromoter> docValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n    Map<FieldInfo,TypePromoter> normValuesTypes = new HashMap<FieldInfo,TypePromoter>();\n\n    for (AtomicReader reader : mergeState.readers) {\n      FieldInfos readerFieldInfos = reader.getFieldInfos();\n      for (FieldInfo fi : readerFieldInfos) {\n        FieldInfo merged = fieldInfosBuilder.add(fi);\n        // update the type promotion mapping for this reader\n        if (fi.hasDocValues()) {\n          TypePromoter previous = docValuesTypes.get(merged);\n          docValuesTypes.put(merged, mergeDocValuesType(previous, reader.docValues(fi.name))); \n        }\n        if (fi.hasNorms()) {\n          TypePromoter previous = normValuesTypes.get(merged);\n          normValuesTypes.put(merged, mergeDocValuesType(previous, reader.normValues(fi.name))); \n        }\n      }\n    }\n    updatePromoted(normValuesTypes, true);\n    updatePromoted(docValuesTypes, false);\n    mergeState.fieldInfos = fieldInfosBuilder.finish();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c95a819869502635864dac0a788f874787e3395b":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"38e3b736c7ca086d61b7dbb841c905ee115490da":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","46818a810eab72123f0e37e6ec5f2d426bd47be1"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"030c3c949a4d9470b22d6b1aa20e836d96c72cb7":["76923f6a33f2c4bec7f584e3f251261afe7ea276"],"cd9165e54429bb5c99e75d5cb1c926cc98772456":["030c3c949a4d9470b22d6b1aa20e836d96c72cb7"],"76923f6a33f2c4bec7f584e3f251261afe7ea276":["46818a810eab72123f0e37e6ec5f2d426bd47be1"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["46818a810eab72123f0e37e6ec5f2d426bd47be1","cd9165e54429bb5c99e75d5cb1c926cc98772456"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["c95a819869502635864dac0a788f874787e3395b","0837ab0472feecb3a54260729d845f839e1cbd72"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","c95a819869502635864dac0a788f874787e3395b"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"46818a810eab72123f0e37e6ec5f2d426bd47be1":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"0837ab0472feecb3a54260729d845f839e1cbd72":["c95a819869502635864dac0a788f874787e3395b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["d4d69c535930b5cce125cff868d40f6373dc27d4"]},"commit2Childs":{"c95a819869502635864dac0a788f874787e3395b":["d4d69c535930b5cce125cff868d40f6373dc27d4","fe33227f6805edab2036cbb80645cc4e2d1fa424","0837ab0472feecb3a54260729d845f839e1cbd72"],"38e3b736c7ca086d61b7dbb841c905ee115490da":[],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["38e3b736c7ca086d61b7dbb841c905ee115490da","46818a810eab72123f0e37e6ec5f2d426bd47be1"],"030c3c949a4d9470b22d6b1aa20e836d96c72cb7":["cd9165e54429bb5c99e75d5cb1c926cc98772456"],"cd9165e54429bb5c99e75d5cb1c926cc98772456":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"76923f6a33f2c4bec7f584e3f251261afe7ea276":["030c3c949a4d9470b22d6b1aa20e836d96c72cb7"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["c95a819869502635864dac0a788f874787e3395b","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"46818a810eab72123f0e37e6ec5f2d426bd47be1":["38e3b736c7ca086d61b7dbb841c905ee115490da","76923f6a33f2c4bec7f584e3f251261afe7ea276","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"0837ab0472feecb3a54260729d845f839e1cbd72":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["38e3b736c7ca086d61b7dbb841c905ee115490da","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}