{"path":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","commits":[{"id":"66e0b82bd39567aa2bf534e5282d05fb4a4a2c76","date":1471585465,"type":1,"author":"Noble Paul","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#deleteShard(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n\n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = null;\n    if (asyncId != null) {\n      requestMap = new HashMap<>(slice.getReplicas().size(), 1.0f);\n    }\n\n    try {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.UNLOAD.toString());\n      params.set(CoreAdminParams.DELETE_INDEX, message.getBool(CoreAdminParams.DELETE_INDEX, true));\n      params.set(CoreAdminParams.DELETE_INSTANCE_DIR, message.getBool(CoreAdminParams.DELETE_INSTANCE_DIR, true));\n      params.set(CoreAdminParams.DELETE_DATA_DIR, message.getBool(CoreAdminParams.DELETE_DATA_DIR, true));\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n\n      ocmh.processResponses(results, shardHandler, true, \"Failed to delete shard\", asyncId, requestMap, Collections.emptySet());\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (! timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","sourceOld":"  private void deleteShard(ClusterState clusterState, ZkNodeProps message, NamedList results) {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n    \n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n    \n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = null;\n    if (asyncId != null) {\n      requestMap = new HashMap<>(slice.getReplicas().size(), 1.0f);\n    }\n    \n    try {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.UNLOAD.toString());\n      params.set(CoreAdminParams.DELETE_INDEX, message.getBool(CoreAdminParams.DELETE_INDEX, true));\n      params.set(CoreAdminParams.DELETE_INSTANCE_DIR, message.getBool(CoreAdminParams.DELETE_INSTANCE_DIR, true));\n      params.set(CoreAdminParams.DELETE_DATA_DIR, message.getBool(CoreAdminParams.DELETE_DATA_DIR, true));\n\n      sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n\n      processResponses(results, shardHandler, true, \"Failed to delete shard\", asyncId, requestMap, Collections.emptySet());\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n      \n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (! timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n      \n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n      \n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"403d05f7f8d69b65659157eff1bc1d2717f04c66","date":1471692961,"type":1,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/OverseerCollectionMessageHandler#deleteShard(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n\n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = null;\n    if (asyncId != null) {\n      requestMap = new HashMap<>(slice.getReplicas().size(), 1.0f);\n    }\n\n    try {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.UNLOAD.toString());\n      params.set(CoreAdminParams.DELETE_INDEX, message.getBool(CoreAdminParams.DELETE_INDEX, true));\n      params.set(CoreAdminParams.DELETE_INSTANCE_DIR, message.getBool(CoreAdminParams.DELETE_INSTANCE_DIR, true));\n      params.set(CoreAdminParams.DELETE_DATA_DIR, message.getBool(CoreAdminParams.DELETE_DATA_DIR, true));\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n\n      ocmh.processResponses(results, shardHandler, true, \"Failed to delete shard\", asyncId, requestMap, Collections.emptySet());\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (! timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","sourceOld":"  private void deleteShard(ClusterState clusterState, ZkNodeProps message, NamedList results) {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n    \n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n    \n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION)) {\n      throw new SolrException(ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n    ShardHandler shardHandler = shardHandlerFactory.getShardHandler();\n\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = null;\n    if (asyncId != null) {\n      requestMap = new HashMap<>(slice.getReplicas().size(), 1.0f);\n    }\n    \n    try {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminAction.UNLOAD.toString());\n      params.set(CoreAdminParams.DELETE_INDEX, message.getBool(CoreAdminParams.DELETE_INDEX, true));\n      params.set(CoreAdminParams.DELETE_INSTANCE_DIR, message.getBool(CoreAdminParams.DELETE_INSTANCE_DIR, true));\n      params.set(CoreAdminParams.DELETE_DATA_DIR, message.getBool(CoreAdminParams.DELETE_DATA_DIR, true));\n\n      sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n\n      processResponses(results, shardHandler, true, \"Failed to delete shard\", asyncId, requestMap, Collections.emptySet());\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n      \n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (! timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n      \n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n      \n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d76e8ac2404f9119d48b15059f36129cb99a56ce","date":1472495477,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n\n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = null;\n    if (asyncId != null) {\n      requestMap = new HashMap<>(slice.getReplicas().size(), 1.0f);\n    }\n\n    try {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.UNLOAD.toString());\n      params.set(CoreAdminParams.DELETE_INDEX, message.getBool(CoreAdminParams.DELETE_INDEX, true));\n      params.set(CoreAdminParams.DELETE_INSTANCE_DIR, message.getBool(CoreAdminParams.DELETE_INSTANCE_DIR, true));\n      params.set(CoreAdminParams.DELETE_DATA_DIR, message.getBool(CoreAdminParams.DELETE_DATA_DIR, true));\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n\n      ocmh.processResponses(results, shardHandler, true, \"Failed to delete shard\", asyncId, requestMap, Collections.emptySet());\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (! timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n\n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = null;\n    if (asyncId != null) {\n      requestMap = new HashMap<>(slice.getReplicas().size(), 1.0f);\n    }\n\n    try {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.UNLOAD.toString());\n      params.set(CoreAdminParams.DELETE_INDEX, message.getBool(CoreAdminParams.DELETE_INDEX, true));\n      params.set(CoreAdminParams.DELETE_INSTANCE_DIR, message.getBool(CoreAdminParams.DELETE_INSTANCE_DIR, true));\n      params.set(CoreAdminParams.DELETE_DATA_DIR, message.getBool(CoreAdminParams.DELETE_DATA_DIR, true));\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n\n      ocmh.processResponses(results, shardHandler, true, \"Failed to delete shard\", asyncId, requestMap, Collections.emptySet());\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (! timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"092c3ae5fefa024f6d0c427be5f23dd3bfbdd20c","date":1472580862,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n\n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    String asyncId = message.getStr(ASYNC);\n\n    try {\n      List<ZkNodeProps> replicas = getReplicasForSlice(collectionName, slice);\n      CountDownLatch cleanupLatch = new CountDownLatch(replicas.size());\n      for (ZkNodeProps r : replicas) {\n        final ZkNodeProps replica = r.plus(message.getProperties()).plus(\"parallel\", \"true\").plus(ASYNC, asyncId);\n        log.info(\"Deleting replica for collection={} shard={} on node={}\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(CoreAdminParams.NODE));\n        NamedList deleteResult = new NamedList();\n        try {\n          ((DeleteReplicaCmd)ocmh.commandMap.get(DELETEREPLICA)).deleteReplica(clusterState, replica, deleteResult, () -> {\n            cleanupLatch.countDown();\n            if (deleteResult.get(\"failure\") != null) {\n              synchronized (results) {\n                results.add(\"failure\", String.format(Locale.ROOT, \"Failed to delete replica for collection=%s shard=%s\" +\n                    \" on node=%s\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(NODE_NAME_PROP)));\n              }\n            }\n            SimpleOrderedMap success = (SimpleOrderedMap) deleteResult.get(\"success\");\n            if (success != null) {\n              synchronized (results)  {\n                results.add(\"success\", success);\n              }\n            }\n          });\n        } catch (KeeperException e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n        } catch (Exception e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n          throw e;\n        }\n      }\n      log.debug(\"Waiting for delete shard action to complete\");\n      cleanupLatch.await(5, TimeUnit.MINUTES);\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (!timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n\n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = null;\n    if (asyncId != null) {\n      requestMap = new HashMap<>(slice.getReplicas().size(), 1.0f);\n    }\n\n    try {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.UNLOAD.toString());\n      params.set(CoreAdminParams.DELETE_INDEX, message.getBool(CoreAdminParams.DELETE_INDEX, true));\n      params.set(CoreAdminParams.DELETE_INSTANCE_DIR, message.getBool(CoreAdminParams.DELETE_INSTANCE_DIR, true));\n      params.set(CoreAdminParams.DELETE_DATA_DIR, message.getBool(CoreAdminParams.DELETE_DATA_DIR, true));\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n\n      ocmh.processResponses(results, shardHandler, true, \"Failed to delete shard\", asyncId, requestMap, Collections.emptySet());\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (! timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","bugFix":["3bbb741690cdafda7f1f7549c26351c912917a69","34127d6b305c3e200d697bfcb58e639d65250c6f","439c63ae5d22132fca810a0029a854e97d2c1a3e","66e0b82bd39567aa2bf534e5282d05fb4a4a2c76","bcf9886c8ff537aafde14de48ebf744f5673f08b"],"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"bc8f206328a706450934717bec7ccc22ad166fc0","date":1473142172,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n\n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    String asyncId = message.getStr(ASYNC);\n\n    try {\n      List<ZkNodeProps> replicas = getReplicasForSlice(collectionName, slice);\n      CountDownLatch cleanupLatch = new CountDownLatch(replicas.size());\n      for (ZkNodeProps r : replicas) {\n        final ZkNodeProps replica = r.plus(message.getProperties()).plus(\"parallel\", \"true\").plus(ASYNC, asyncId);\n        log.info(\"Deleting replica for collection={} shard={} on node={}\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(CoreAdminParams.NODE));\n        NamedList deleteResult = new NamedList();\n        try {\n          ((DeleteReplicaCmd)ocmh.commandMap.get(DELETEREPLICA)).deleteReplica(clusterState, replica, deleteResult, () -> {\n            cleanupLatch.countDown();\n            if (deleteResult.get(\"failure\") != null) {\n              synchronized (results) {\n                results.add(\"failure\", String.format(Locale.ROOT, \"Failed to delete replica for collection=%s shard=%s\" +\n                    \" on node=%s\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(NODE_NAME_PROP)));\n              }\n            }\n            SimpleOrderedMap success = (SimpleOrderedMap) deleteResult.get(\"success\");\n            if (success != null) {\n              synchronized (results)  {\n                results.add(\"success\", success);\n              }\n            }\n          });\n        } catch (KeeperException e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n        } catch (Exception e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n          throw e;\n        }\n      }\n      log.debug(\"Waiting for delete shard action to complete\");\n      cleanupLatch.await(5, TimeUnit.MINUTES);\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (!timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n\n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = null;\n    if (asyncId != null) {\n      requestMap = new HashMap<>(slice.getReplicas().size(), 1.0f);\n    }\n\n    try {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.UNLOAD.toString());\n      params.set(CoreAdminParams.DELETE_INDEX, message.getBool(CoreAdminParams.DELETE_INDEX, true));\n      params.set(CoreAdminParams.DELETE_INSTANCE_DIR, message.getBool(CoreAdminParams.DELETE_INSTANCE_DIR, true));\n      params.set(CoreAdminParams.DELETE_DATA_DIR, message.getBool(CoreAdminParams.DELETE_DATA_DIR, true));\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n\n      ocmh.processResponses(results, shardHandler, true, \"Failed to delete shard\", asyncId, requestMap, Collections.emptySet());\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (! timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6a23ab64d81a448ad6ec571cbfc9599cc09b4e4b","date":1473679846,"type":3,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n\n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION) || state == Slice.State.RECOVERY_FAILED) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    String asyncId = message.getStr(ASYNC);\n\n    try {\n      List<ZkNodeProps> replicas = getReplicasForSlice(collectionName, slice);\n      CountDownLatch cleanupLatch = new CountDownLatch(replicas.size());\n      for (ZkNodeProps r : replicas) {\n        final ZkNodeProps replica = r.plus(message.getProperties()).plus(\"parallel\", \"true\").plus(ASYNC, asyncId);\n        log.info(\"Deleting replica for collection={} shard={} on node={}\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(CoreAdminParams.NODE));\n        NamedList deleteResult = new NamedList();\n        try {\n          ((DeleteReplicaCmd)ocmh.commandMap.get(DELETEREPLICA)).deleteReplica(clusterState, replica, deleteResult, () -> {\n            cleanupLatch.countDown();\n            if (deleteResult.get(\"failure\") != null) {\n              synchronized (results) {\n                results.add(\"failure\", String.format(Locale.ROOT, \"Failed to delete replica for collection=%s shard=%s\" +\n                    \" on node=%s\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(NODE_NAME_PROP)));\n              }\n            }\n            SimpleOrderedMap success = (SimpleOrderedMap) deleteResult.get(\"success\");\n            if (success != null) {\n              synchronized (results)  {\n                results.add(\"success\", success);\n              }\n            }\n          });\n        } catch (KeeperException e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n        } catch (Exception e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n          throw e;\n        }\n      }\n      log.debug(\"Waiting for delete shard action to complete\");\n      cleanupLatch.await(5, TimeUnit.MINUTES);\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (!timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n\n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    String asyncId = message.getStr(ASYNC);\n\n    try {\n      List<ZkNodeProps> replicas = getReplicasForSlice(collectionName, slice);\n      CountDownLatch cleanupLatch = new CountDownLatch(replicas.size());\n      for (ZkNodeProps r : replicas) {\n        final ZkNodeProps replica = r.plus(message.getProperties()).plus(\"parallel\", \"true\").plus(ASYNC, asyncId);\n        log.info(\"Deleting replica for collection={} shard={} on node={}\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(CoreAdminParams.NODE));\n        NamedList deleteResult = new NamedList();\n        try {\n          ((DeleteReplicaCmd)ocmh.commandMap.get(DELETEREPLICA)).deleteReplica(clusterState, replica, deleteResult, () -> {\n            cleanupLatch.countDown();\n            if (deleteResult.get(\"failure\") != null) {\n              synchronized (results) {\n                results.add(\"failure\", String.format(Locale.ROOT, \"Failed to delete replica for collection=%s shard=%s\" +\n                    \" on node=%s\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(NODE_NAME_PROP)));\n              }\n            }\n            SimpleOrderedMap success = (SimpleOrderedMap) deleteResult.get(\"success\");\n            if (success != null) {\n              synchronized (results)  {\n                results.add(\"success\", success);\n              }\n            }\n          });\n        } catch (KeeperException e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n        } catch (Exception e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n          throw e;\n        }\n      }\n      log.debug(\"Waiting for delete shard action to complete\");\n      cleanupLatch.await(5, TimeUnit.MINUTES);\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (!timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","bugFix":["439c63ae5d22132fca810a0029a854e97d2c1a3e"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"89424def13674ea17829b41c5883c54ecc31a132","date":1473767373,"type":3,"author":"Noble Paul","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n\n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION) || state == Slice.State.RECOVERY_FAILED) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    String asyncId = message.getStr(ASYNC);\n\n    try {\n      List<ZkNodeProps> replicas = getReplicasForSlice(collectionName, slice);\n      CountDownLatch cleanupLatch = new CountDownLatch(replicas.size());\n      for (ZkNodeProps r : replicas) {\n        final ZkNodeProps replica = r.plus(message.getProperties()).plus(\"parallel\", \"true\").plus(ASYNC, asyncId);\n        log.info(\"Deleting replica for collection={} shard={} on node={}\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(CoreAdminParams.NODE));\n        NamedList deleteResult = new NamedList();\n        try {\n          ((DeleteReplicaCmd)ocmh.commandMap.get(DELETEREPLICA)).deleteReplica(clusterState, replica, deleteResult, () -> {\n            cleanupLatch.countDown();\n            if (deleteResult.get(\"failure\") != null) {\n              synchronized (results) {\n                results.add(\"failure\", String.format(Locale.ROOT, \"Failed to delete replica for collection=%s shard=%s\" +\n                    \" on node=%s\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(NODE_NAME_PROP)));\n              }\n            }\n            SimpleOrderedMap success = (SimpleOrderedMap) deleteResult.get(\"success\");\n            if (success != null) {\n              synchronized (results)  {\n                results.add(\"success\", success);\n              }\n            }\n          });\n        } catch (KeeperException e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n        } catch (Exception e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n          throw e;\n        }\n      }\n      log.debug(\"Waiting for delete shard action to complete\");\n      cleanupLatch.await(5, TimeUnit.MINUTES);\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (!timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n\n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    String asyncId = message.getStr(ASYNC);\n\n    try {\n      List<ZkNodeProps> replicas = getReplicasForSlice(collectionName, slice);\n      CountDownLatch cleanupLatch = new CountDownLatch(replicas.size());\n      for (ZkNodeProps r : replicas) {\n        final ZkNodeProps replica = r.plus(message.getProperties()).plus(\"parallel\", \"true\").plus(ASYNC, asyncId);\n        log.info(\"Deleting replica for collection={} shard={} on node={}\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(CoreAdminParams.NODE));\n        NamedList deleteResult = new NamedList();\n        try {\n          ((DeleteReplicaCmd)ocmh.commandMap.get(DELETEREPLICA)).deleteReplica(clusterState, replica, deleteResult, () -> {\n            cleanupLatch.countDown();\n            if (deleteResult.get(\"failure\") != null) {\n              synchronized (results) {\n                results.add(\"failure\", String.format(Locale.ROOT, \"Failed to delete replica for collection=%s shard=%s\" +\n                    \" on node=%s\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(NODE_NAME_PROP)));\n              }\n            }\n            SimpleOrderedMap success = (SimpleOrderedMap) deleteResult.get(\"success\");\n            if (success != null) {\n              synchronized (results)  {\n                results.add(\"success\", success);\n              }\n            }\n          });\n        } catch (KeeperException e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n        } catch (Exception e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n          throw e;\n        }\n      }\n      log.debug(\"Waiting for delete shard action to complete\");\n      cleanupLatch.await(5, TimeUnit.MINUTES);\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (!timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"17e5da53e4e5bd659e22add9bba1cfa222e7e30d","date":1475435902,"type":3,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n\n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION) || state == Slice.State.RECOVERY_FAILED) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    String asyncId = message.getStr(ASYNC);\n\n    try {\n      List<ZkNodeProps> replicas = getReplicasForSlice(collectionName, slice);\n      CountDownLatch cleanupLatch = new CountDownLatch(replicas.size());\n      for (ZkNodeProps r : replicas) {\n        final ZkNodeProps replica = r.plus(message.getProperties()).plus(\"parallel\", \"true\").plus(ASYNC, asyncId);\n        log.info(\"Deleting replica for collection={} shard={} on node={}\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(CoreAdminParams.NODE));\n        NamedList deleteResult = new NamedList();\n        try {\n          ((DeleteReplicaCmd)ocmh.commandMap.get(DELETEREPLICA)).deleteReplica(clusterState, replica, deleteResult, () -> {\n            cleanupLatch.countDown();\n            if (deleteResult.get(\"failure\") != null) {\n              synchronized (results) {\n                results.add(\"failure\", String.format(Locale.ROOT, \"Failed to delete replica for collection=%s shard=%s\" +\n                    \" on node=%s\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(NODE_NAME_PROP)));\n              }\n            }\n            SimpleOrderedMap success = (SimpleOrderedMap) deleteResult.get(\"success\");\n            if (success != null) {\n              synchronized (results)  {\n                results.add(\"success\", success);\n              }\n            }\n          });\n        } catch (KeeperException e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n        } catch (Exception e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n          throw e;\n        }\n      }\n      log.debug(\"Waiting for delete shard action to complete\");\n      cleanupLatch.await(5, TimeUnit.MINUTES);\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (!timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n\n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION)) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n    ShardHandler shardHandler = ocmh.shardHandlerFactory.getShardHandler();\n\n    String asyncId = message.getStr(ASYNC);\n    Map<String, String> requestMap = null;\n    if (asyncId != null) {\n      requestMap = new HashMap<>(slice.getReplicas().size(), 1.0f);\n    }\n\n    try {\n      ModifiableSolrParams params = new ModifiableSolrParams();\n      params.set(CoreAdminParams.ACTION, CoreAdminParams.CoreAdminAction.UNLOAD.toString());\n      params.set(CoreAdminParams.DELETE_INDEX, message.getBool(CoreAdminParams.DELETE_INDEX, true));\n      params.set(CoreAdminParams.DELETE_INSTANCE_DIR, message.getBool(CoreAdminParams.DELETE_INSTANCE_DIR, true));\n      params.set(CoreAdminParams.DELETE_DATA_DIR, message.getBool(CoreAdminParams.DELETE_DATA_DIR, true));\n\n      ocmh.sliceCmd(clusterState, params, null, slice, shardHandler, asyncId, requestMap);\n\n      ocmh.processResponses(results, shardHandler, true, \"Failed to delete shard\", asyncId, requestMap, Collections.emptySet());\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (! timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":0,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"/dev/null","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n\n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION) || state == Slice.State.RECOVERY_FAILED) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    String asyncId = message.getStr(ASYNC);\n\n    try {\n      List<ZkNodeProps> replicas = getReplicasForSlice(collectionName, slice);\n      CountDownLatch cleanupLatch = new CountDownLatch(replicas.size());\n      for (ZkNodeProps r : replicas) {\n        final ZkNodeProps replica = r.plus(message.getProperties()).plus(\"parallel\", \"true\").plus(ASYNC, asyncId);\n        log.info(\"Deleting replica for collection={} shard={} on node={}\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(CoreAdminParams.NODE));\n        NamedList deleteResult = new NamedList();\n        try {\n          ((DeleteReplicaCmd)ocmh.commandMap.get(DELETEREPLICA)).deleteReplica(clusterState, replica, deleteResult, () -> {\n            cleanupLatch.countDown();\n            if (deleteResult.get(\"failure\") != null) {\n              synchronized (results) {\n                results.add(\"failure\", String.format(Locale.ROOT, \"Failed to delete replica for collection=%s shard=%s\" +\n                    \" on node=%s\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(NODE_NAME_PROP)));\n              }\n            }\n            SimpleOrderedMap success = (SimpleOrderedMap) deleteResult.get(\"success\");\n            if (success != null) {\n              synchronized (results)  {\n                results.add(\"success\", success);\n              }\n            }\n          });\n        } catch (KeeperException e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n        } catch (Exception e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n          throw e;\n        }\n      }\n      log.debug(\"Waiting for delete shard action to complete\");\n      cleanupLatch.await(5, TimeUnit.MINUTES);\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (!timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"344b0840364d990b29b97467bfcc766ff8325d11","date":1501574100,"type":3,"author":"Cao Manh Dat","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getCollection(collectionName).getSlice(sliceId);\n    if (slice == null) throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n        \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION) || state == Slice.State.RECOVERY_FAILED) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    String asyncId = message.getStr(ASYNC);\n\n    try {\n      List<ZkNodeProps> replicas = getReplicasForSlice(collectionName, slice);\n      CountDownLatch cleanupLatch = new CountDownLatch(replicas.size());\n      for (ZkNodeProps r : replicas) {\n        final ZkNodeProps replica = r.plus(message.getProperties()).plus(\"parallel\", \"true\").plus(ASYNC, asyncId);\n        log.info(\"Deleting replica for collection={} shard={} on node={}\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(CoreAdminParams.NODE));\n        NamedList deleteResult = new NamedList();\n        try {\n          ((DeleteReplicaCmd)ocmh.commandMap.get(DELETEREPLICA)).deleteReplica(clusterState, replica, deleteResult, () -> {\n            cleanupLatch.countDown();\n            if (deleteResult.get(\"failure\") != null) {\n              synchronized (results) {\n                results.add(\"failure\", String.format(Locale.ROOT, \"Failed to delete replica for collection=%s shard=%s\" +\n                    \" on node=%s\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(NODE_NAME_PROP)));\n              }\n            }\n            SimpleOrderedMap success = (SimpleOrderedMap) deleteResult.get(\"success\");\n            if (success != null) {\n              synchronized (results)  {\n                results.add(\"success\", success);\n              }\n            }\n          });\n        } catch (KeeperException e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n        } catch (Exception e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n          throw e;\n        }\n      }\n      log.debug(\"Waiting for delete shard action to complete\");\n      cleanupLatch.await(5, TimeUnit.MINUTES);\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (!timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n\n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION) || state == Slice.State.RECOVERY_FAILED) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    String asyncId = message.getStr(ASYNC);\n\n    try {\n      List<ZkNodeProps> replicas = getReplicasForSlice(collectionName, slice);\n      CountDownLatch cleanupLatch = new CountDownLatch(replicas.size());\n      for (ZkNodeProps r : replicas) {\n        final ZkNodeProps replica = r.plus(message.getProperties()).plus(\"parallel\", \"true\").plus(ASYNC, asyncId);\n        log.info(\"Deleting replica for collection={} shard={} on node={}\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(CoreAdminParams.NODE));\n        NamedList deleteResult = new NamedList();\n        try {\n          ((DeleteReplicaCmd)ocmh.commandMap.get(DELETEREPLICA)).deleteReplica(clusterState, replica, deleteResult, () -> {\n            cleanupLatch.countDown();\n            if (deleteResult.get(\"failure\") != null) {\n              synchronized (results) {\n                results.add(\"failure\", String.format(Locale.ROOT, \"Failed to delete replica for collection=%s shard=%s\" +\n                    \" on node=%s\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(NODE_NAME_PROP)));\n              }\n            }\n            SimpleOrderedMap success = (SimpleOrderedMap) deleteResult.get(\"success\");\n            if (success != null) {\n              synchronized (results)  {\n                results.add(\"success\", success);\n              }\n            }\n          });\n        } catch (KeeperException e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n        } catch (Exception e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n          throw e;\n        }\n      }\n      log.debug(\"Waiting for delete shard action to complete\");\n      cleanupLatch.await(5, TimeUnit.MINUTES);\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (!timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","bugFix":["04c8df3f10a676c3de5dbf390f17a2de2d45cacd","4ee5a5186e7187cd42c6f7ff64b6e7206a780325","439c63ae5d22132fca810a0029a854e97d2c1a3e","66e0b82bd39567aa2bf534e5282d05fb4a4a2c76"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","date":1502192746,"type":3,"author":"Shalin Shekhar Mangar","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getCollection(collectionName).getSlice(sliceId);\n    if (slice == null) throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n        \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION) || state == Slice.State.RECOVERY_FAILED) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    String asyncId = message.getStr(ASYNC);\n\n    try {\n      List<ZkNodeProps> replicas = getReplicasForSlice(collectionName, slice);\n      CountDownLatch cleanupLatch = new CountDownLatch(replicas.size());\n      for (ZkNodeProps r : replicas) {\n        final ZkNodeProps replica = r.plus(message.getProperties()).plus(\"parallel\", \"true\").plus(ASYNC, asyncId);\n        log.info(\"Deleting replica for collection={} shard={} on node={}\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(CoreAdminParams.NODE));\n        NamedList deleteResult = new NamedList();\n        try {\n          ((DeleteReplicaCmd)ocmh.commandMap.get(DELETEREPLICA)).deleteReplica(clusterState, replica, deleteResult, () -> {\n            cleanupLatch.countDown();\n            if (deleteResult.get(\"failure\") != null) {\n              synchronized (results) {\n                results.add(\"failure\", String.format(Locale.ROOT, \"Failed to delete replica for collection=%s shard=%s\" +\n                    \" on node=%s\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(NODE_NAME_PROP)));\n              }\n            }\n            SimpleOrderedMap success = (SimpleOrderedMap) deleteResult.get(\"success\");\n            if (success != null) {\n              synchronized (results)  {\n                results.add(\"success\", success);\n              }\n            }\n          });\n        } catch (KeeperException e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n        } catch (Exception e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n          throw e;\n        }\n      }\n      log.debug(\"Waiting for delete shard action to complete\");\n      cleanupLatch.await(5, TimeUnit.MINUTES);\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (!timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getSlice(collectionName, sliceId);\n\n    if (slice == null) {\n      if (clusterState.hasCollection(collectionName)) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n            \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n      } else {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"No collection with the specified name exists: \" + collectionName);\n      }\n    }\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION) || state == Slice.State.RECOVERY_FAILED) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    String asyncId = message.getStr(ASYNC);\n\n    try {\n      List<ZkNodeProps> replicas = getReplicasForSlice(collectionName, slice);\n      CountDownLatch cleanupLatch = new CountDownLatch(replicas.size());\n      for (ZkNodeProps r : replicas) {\n        final ZkNodeProps replica = r.plus(message.getProperties()).plus(\"parallel\", \"true\").plus(ASYNC, asyncId);\n        log.info(\"Deleting replica for collection={} shard={} on node={}\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(CoreAdminParams.NODE));\n        NamedList deleteResult = new NamedList();\n        try {\n          ((DeleteReplicaCmd)ocmh.commandMap.get(DELETEREPLICA)).deleteReplica(clusterState, replica, deleteResult, () -> {\n            cleanupLatch.countDown();\n            if (deleteResult.get(\"failure\") != null) {\n              synchronized (results) {\n                results.add(\"failure\", String.format(Locale.ROOT, \"Failed to delete replica for collection=%s shard=%s\" +\n                    \" on node=%s\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(NODE_NAME_PROP)));\n              }\n            }\n            SimpleOrderedMap success = (SimpleOrderedMap) deleteResult.get(\"success\");\n            if (success != null) {\n              synchronized (results)  {\n                results.add(\"success\", success);\n              }\n            }\n          });\n        } catch (KeeperException e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n        } catch (Exception e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n          throw e;\n        }\n      }\n      log.debug(\"Waiting for delete shard action to complete\");\n      cleanupLatch.await(5, TimeUnit.MINUTES);\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (!timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","date":1513252583,"type":3,"author":"Andrzej Bialecki","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getCollection(collectionName).getSlice(sliceId);\n    if (slice == null) throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n        \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION) || state == Slice.State.RECOVERY_FAILED) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    String asyncId = message.getStr(ASYNC);\n\n    try {\n      List<ZkNodeProps> replicas = getReplicasForSlice(collectionName, slice);\n      CountDownLatch cleanupLatch = new CountDownLatch(replicas.size());\n      for (ZkNodeProps r : replicas) {\n        final ZkNodeProps replica = r.plus(message.getProperties()).plus(\"parallel\", \"true\").plus(ASYNC, asyncId);\n        log.info(\"Deleting replica for collection={} shard={} on node={}\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(CoreAdminParams.NODE));\n        NamedList deleteResult = new NamedList();\n        try {\n          ((DeleteReplicaCmd)ocmh.commandMap.get(DELETEREPLICA)).deleteReplica(clusterState, replica, deleteResult, () -> {\n            cleanupLatch.countDown();\n            if (deleteResult.get(\"failure\") != null) {\n              synchronized (results) {\n                results.add(\"failure\", String.format(Locale.ROOT, \"Failed to delete replica for collection=%s shard=%s\" +\n                    \" on node=%s\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(NODE_NAME_PROP)));\n              }\n            }\n            SimpleOrderedMap success = (SimpleOrderedMap) deleteResult.get(\"success\");\n            if (success != null) {\n              synchronized (results)  {\n                results.add(\"success\", success);\n              }\n            }\n          });\n        } catch (KeeperException e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n        } catch (Exception e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n          throw e;\n        }\n      }\n      log.debug(\"Waiting for delete shard action to complete\");\n      cleanupLatch.await(5, TimeUnit.MINUTES);\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, timeSource);\n      boolean removed = false;\n      while (!timeout.hasTimedOut()) {\n        timeout.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          timeout.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getCollection(collectionName).getSlice(sliceId);\n    if (slice == null) throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n        \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION) || state == Slice.State.RECOVERY_FAILED) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    String asyncId = message.getStr(ASYNC);\n\n    try {\n      List<ZkNodeProps> replicas = getReplicasForSlice(collectionName, slice);\n      CountDownLatch cleanupLatch = new CountDownLatch(replicas.size());\n      for (ZkNodeProps r : replicas) {\n        final ZkNodeProps replica = r.plus(message.getProperties()).plus(\"parallel\", \"true\").plus(ASYNC, asyncId);\n        log.info(\"Deleting replica for collection={} shard={} on node={}\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(CoreAdminParams.NODE));\n        NamedList deleteResult = new NamedList();\n        try {\n          ((DeleteReplicaCmd)ocmh.commandMap.get(DELETEREPLICA)).deleteReplica(clusterState, replica, deleteResult, () -> {\n            cleanupLatch.countDown();\n            if (deleteResult.get(\"failure\") != null) {\n              synchronized (results) {\n                results.add(\"failure\", String.format(Locale.ROOT, \"Failed to delete replica for collection=%s shard=%s\" +\n                    \" on node=%s\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(NODE_NAME_PROP)));\n              }\n            }\n            SimpleOrderedMap success = (SimpleOrderedMap) deleteResult.get(\"success\");\n            if (success != null) {\n              synchronized (results)  {\n                results.add(\"success\", success);\n              }\n            }\n          });\n        } catch (KeeperException e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n        } catch (Exception e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n          throw e;\n        }\n      }\n      log.debug(\"Waiting for delete shard action to complete\");\n      cleanupLatch.await(5, TimeUnit.MINUTES);\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS);\n      boolean removed = false;\n      while (!timeout.hasTimedOut()) {\n        Thread.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          Thread.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","bugFix":null,"bugIntro":["bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f","bb222a3f9d9421d5c95afce73013fbd8de07ea1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"6146c07c0dee1ae1e42926167acd127fed5ef59d","date":1516129420,"type":5,"author":"Varun Thacker","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getCollection(collectionName).getSlice(sliceId);\n    if (slice == null) throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n        \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION) || state == Slice.State.RECOVERY_FAILED) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    String asyncId = message.getStr(ASYNC);\n\n    try {\n      List<ZkNodeProps> replicas = getReplicasForSlice(collectionName, slice);\n      CountDownLatch cleanupLatch = new CountDownLatch(replicas.size());\n      for (ZkNodeProps r : replicas) {\n        final ZkNodeProps replica = r.plus(message.getProperties()).plus(\"parallel\", \"true\").plus(ASYNC, asyncId);\n        log.info(\"Deleting replica for collection={} shard={} on node={}\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(CoreAdminParams.NODE));\n        NamedList deleteResult = new NamedList();\n        try {\n          ((DeleteReplicaCmd)ocmh.commandMap.get(DELETEREPLICA)).deleteReplica(clusterState, replica, deleteResult, () -> {\n            cleanupLatch.countDown();\n            if (deleteResult.get(\"failure\") != null) {\n              synchronized (results) {\n                results.add(\"failure\", String.format(Locale.ROOT, \"Failed to delete replica for collection=%s shard=%s\" +\n                    \" on node=%s\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(NODE_NAME_PROP)));\n              }\n            }\n            SimpleOrderedMap success = (SimpleOrderedMap) deleteResult.get(\"success\");\n            if (success != null) {\n              synchronized (results)  {\n                results.add(\"success\", success);\n              }\n            }\n          });\n        } catch (KeeperException e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n        } catch (Exception e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n          throw e;\n        }\n      }\n      log.debug(\"Waiting for delete shard action to complete\");\n      cleanupLatch.await(5, TimeUnit.MINUTES);\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, timeSource);\n      boolean removed = false;\n      while (!timeout.hasTimedOut()) {\n        timeout.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          timeout.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getCollection(collectionName).getSlice(sliceId);\n    if (slice == null) throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n        \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION) || state == Slice.State.RECOVERY_FAILED) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    String asyncId = message.getStr(ASYNC);\n\n    try {\n      List<ZkNodeProps> replicas = getReplicasForSlice(collectionName, slice);\n      CountDownLatch cleanupLatch = new CountDownLatch(replicas.size());\n      for (ZkNodeProps r : replicas) {\n        final ZkNodeProps replica = r.plus(message.getProperties()).plus(\"parallel\", \"true\").plus(ASYNC, asyncId);\n        log.info(\"Deleting replica for collection={} shard={} on node={}\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(CoreAdminParams.NODE));\n        NamedList deleteResult = new NamedList();\n        try {\n          ((DeleteReplicaCmd)ocmh.commandMap.get(DELETEREPLICA)).deleteReplica(clusterState, replica, deleteResult, () -> {\n            cleanupLatch.countDown();\n            if (deleteResult.get(\"failure\") != null) {\n              synchronized (results) {\n                results.add(\"failure\", String.format(Locale.ROOT, \"Failed to delete replica for collection=%s shard=%s\" +\n                    \" on node=%s\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(NODE_NAME_PROP)));\n              }\n            }\n            SimpleOrderedMap success = (SimpleOrderedMap) deleteResult.get(\"success\");\n            if (success != null) {\n              synchronized (results)  {\n                results.add(\"success\", success);\n              }\n            }\n          });\n        } catch (KeeperException e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n        } catch (Exception e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n          throw e;\n        }\n      }\n      log.debug(\"Waiting for delete shard action to complete\");\n      cleanupLatch.await(5, TimeUnit.MINUTES);\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, timeSource);\n      boolean removed = false;\n      while (!timeout.hasTimedOut()) {\n        timeout.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          timeout.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b94236357aaa22b76c10629851fe4e376e0cea82","date":1516710914,"type":5,"author":"Karl Wright","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/cloud/api/collections/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","pathOld":"solr/core/src/java/org/apache/solr/cloud/DeleteShardCmd#call(ClusterState,ZkNodeProps,NamedList).mjava","sourceNew":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getCollection(collectionName).getSlice(sliceId);\n    if (slice == null) throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n        \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION) || state == Slice.State.RECOVERY_FAILED) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    String asyncId = message.getStr(ASYNC);\n\n    try {\n      List<ZkNodeProps> replicas = getReplicasForSlice(collectionName, slice);\n      CountDownLatch cleanupLatch = new CountDownLatch(replicas.size());\n      for (ZkNodeProps r : replicas) {\n        final ZkNodeProps replica = r.plus(message.getProperties()).plus(\"parallel\", \"true\").plus(ASYNC, asyncId);\n        log.info(\"Deleting replica for collection={} shard={} on node={}\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(CoreAdminParams.NODE));\n        NamedList deleteResult = new NamedList();\n        try {\n          ((DeleteReplicaCmd)ocmh.commandMap.get(DELETEREPLICA)).deleteReplica(clusterState, replica, deleteResult, () -> {\n            cleanupLatch.countDown();\n            if (deleteResult.get(\"failure\") != null) {\n              synchronized (results) {\n                results.add(\"failure\", String.format(Locale.ROOT, \"Failed to delete replica for collection=%s shard=%s\" +\n                    \" on node=%s\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(NODE_NAME_PROP)));\n              }\n            }\n            SimpleOrderedMap success = (SimpleOrderedMap) deleteResult.get(\"success\");\n            if (success != null) {\n              synchronized (results)  {\n                results.add(\"success\", success);\n              }\n            }\n          });\n        } catch (KeeperException e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n        } catch (Exception e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n          throw e;\n        }\n      }\n      log.debug(\"Waiting for delete shard action to complete\");\n      cleanupLatch.await(5, TimeUnit.MINUTES);\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, timeSource);\n      boolean removed = false;\n      while (!timeout.hasTimedOut()) {\n        timeout.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          timeout.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","sourceOld":"  @Override\n  public void call(ClusterState clusterState, ZkNodeProps message, NamedList results) throws Exception {\n    String collectionName = message.getStr(ZkStateReader.COLLECTION_PROP);\n    String sliceId = message.getStr(ZkStateReader.SHARD_ID_PROP);\n\n    log.info(\"Delete shard invoked\");\n    Slice slice = clusterState.getCollection(collectionName).getSlice(sliceId);\n    if (slice == null) throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,\n        \"No shard with name \" + sliceId + \" exists for collection \" + collectionName);\n\n    // For now, only allow for deletions of Inactive slices or custom hashes (range==null).\n    // TODO: Add check for range gaps on Slice deletion\n    final Slice.State state = slice.getState();\n    if (!(slice.getRange() == null || state == Slice.State.INACTIVE || state == Slice.State.RECOVERY\n        || state == Slice.State.CONSTRUCTION) || state == Slice.State.RECOVERY_FAILED) {\n      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, \"The slice: \" + slice.getName() + \" is currently \" + state\n          + \". Only non-active (or custom-hashed) slices can be deleted.\");\n    }\n\n    if (state == Slice.State.RECOVERY)  {\n      // mark the slice as 'construction' and only then try to delete the cores\n      // see SOLR-9455\n      DistributedQueue inQueue = Overseer.getStateUpdateQueue(ocmh.zkStateReader.getZkClient());\n      Map<String, Object> propMap = new HashMap<>();\n      propMap.put(Overseer.QUEUE_OPERATION, OverseerAction.UPDATESHARDSTATE.toLower());\n      propMap.put(sliceId, Slice.State.CONSTRUCTION.toString());\n      propMap.put(ZkStateReader.COLLECTION_PROP, collectionName);\n      ZkNodeProps m = new ZkNodeProps(propMap);\n      inQueue.offer(Utils.toJSON(m));\n    }\n\n    String asyncId = message.getStr(ASYNC);\n\n    try {\n      List<ZkNodeProps> replicas = getReplicasForSlice(collectionName, slice);\n      CountDownLatch cleanupLatch = new CountDownLatch(replicas.size());\n      for (ZkNodeProps r : replicas) {\n        final ZkNodeProps replica = r.plus(message.getProperties()).plus(\"parallel\", \"true\").plus(ASYNC, asyncId);\n        log.info(\"Deleting replica for collection={} shard={} on node={}\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(CoreAdminParams.NODE));\n        NamedList deleteResult = new NamedList();\n        try {\n          ((DeleteReplicaCmd)ocmh.commandMap.get(DELETEREPLICA)).deleteReplica(clusterState, replica, deleteResult, () -> {\n            cleanupLatch.countDown();\n            if (deleteResult.get(\"failure\") != null) {\n              synchronized (results) {\n                results.add(\"failure\", String.format(Locale.ROOT, \"Failed to delete replica for collection=%s shard=%s\" +\n                    \" on node=%s\", replica.getStr(COLLECTION_PROP), replica.getStr(SHARD_ID_PROP), replica.getStr(NODE_NAME_PROP)));\n              }\n            }\n            SimpleOrderedMap success = (SimpleOrderedMap) deleteResult.get(\"success\");\n            if (success != null) {\n              synchronized (results)  {\n                results.add(\"success\", success);\n              }\n            }\n          });\n        } catch (KeeperException e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n        } catch (Exception e) {\n          log.warn(\"Error deleting replica: \" + r, e);\n          cleanupLatch.countDown();\n          throw e;\n        }\n      }\n      log.debug(\"Waiting for delete shard action to complete\");\n      cleanupLatch.await(5, TimeUnit.MINUTES);\n\n      ZkNodeProps m = new ZkNodeProps(Overseer.QUEUE_OPERATION, DELETESHARD.toLower(), ZkStateReader.COLLECTION_PROP,\n          collectionName, ZkStateReader.SHARD_ID_PROP, sliceId);\n      ZkStateReader zkStateReader = ocmh.zkStateReader;\n      Overseer.getStateUpdateQueue(zkStateReader.getZkClient()).offer(Utils.toJSON(m));\n\n      // wait for a while until we don't see the shard\n      TimeOut timeout = new TimeOut(30, TimeUnit.SECONDS, timeSource);\n      boolean removed = false;\n      while (!timeout.hasTimedOut()) {\n        timeout.sleep(100);\n        DocCollection collection = zkStateReader.getClusterState().getCollection(collectionName);\n        removed = collection.getSlice(sliceId) == null;\n        if (removed) {\n          timeout.sleep(100); // just a bit of time so it's more likely other readers see on return\n          break;\n        }\n      }\n      if (!removed) {\n        throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n            \"Could not fully remove collection: \" + collectionName + \" shard: \" + sliceId);\n      }\n\n      log.info(\"Successfully deleted collection: \" + collectionName + \", shard: \" + sliceId);\n    } catch (SolrException e) {\n      throw e;\n    } catch (Exception e) {\n      throw new SolrException(SolrException.ErrorCode.SERVER_ERROR,\n          \"Error executing delete operation for collection: \" + collectionName + \" shard: \" + sliceId, e);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"b94236357aaa22b76c10629851fe4e376e0cea82":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","66e0b82bd39567aa2bf534e5282d05fb4a4a2c76"],"344b0840364d990b29b97467bfcc766ff8325d11":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"6a23ab64d81a448ad6ec571cbfc9599cc09b4e4b":["bc8f206328a706450934717bec7ccc22ad166fc0"],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"bc8f206328a706450934717bec7ccc22ad166fc0":["403d05f7f8d69b65659157eff1bc1d2717f04c66","092c3ae5fefa024f6d0c427be5f23dd3bfbdd20c"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"092c3ae5fefa024f6d0c427be5f23dd3bfbdd20c":["d76e8ac2404f9119d48b15059f36129cb99a56ce"],"89424def13674ea17829b41c5883c54ecc31a132":["092c3ae5fefa024f6d0c427be5f23dd3bfbdd20c","6a23ab64d81a448ad6ec571cbfc9599cc09b4e4b"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d","344b0840364d990b29b97467bfcc766ff8325d11"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["403d05f7f8d69b65659157eff1bc1d2717f04c66","89424def13674ea17829b41c5883c54ecc31a132"],"66e0b82bd39567aa2bf534e5282d05fb4a4a2c76":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"d76e8ac2404f9119d48b15059f36129cb99a56ce":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["344b0840364d990b29b97467bfcc766ff8325d11"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["b94236357aaa22b76c10629851fe4e376e0cea82"]},"commit2Childs":{"b94236357aaa22b76c10629851fe4e376e0cea82":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"403d05f7f8d69b65659157eff1bc1d2717f04c66":["bc8f206328a706450934717bec7ccc22ad166fc0","17e5da53e4e5bd659e22add9bba1cfa222e7e30d","d76e8ac2404f9119d48b15059f36129cb99a56ce"],"344b0840364d990b29b97467bfcc766ff8325d11":["7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","1d4bf9d5308dfef350829c28f2b3b2648df1e9b1"],"6a23ab64d81a448ad6ec571cbfc9599cc09b4e4b":["89424def13674ea17829b41c5883c54ecc31a132"],"6146c07c0dee1ae1e42926167acd127fed5ef59d":["b94236357aaa22b76c10629851fe4e376e0cea82"],"bc8f206328a706450934717bec7ccc22ad166fc0":["6a23ab64d81a448ad6ec571cbfc9599cc09b4e4b"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"092c3ae5fefa024f6d0c427be5f23dd3bfbdd20c":["bc8f206328a706450934717bec7ccc22ad166fc0","89424def13674ea17829b41c5883c54ecc31a132"],"89424def13674ea17829b41c5883c54ecc31a132":["17e5da53e4e5bd659e22add9bba1cfa222e7e30d"],"7a23cf16c8fa265dc0a564adcabb55e3f054e0ac":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["403d05f7f8d69b65659157eff1bc1d2717f04c66","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","66e0b82bd39567aa2bf534e5282d05fb4a4a2c76"],"17e5da53e4e5bd659e22add9bba1cfa222e7e30d":["344b0840364d990b29b97467bfcc766ff8325d11","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac"],"66e0b82bd39567aa2bf534e5282d05fb4a4a2c76":["403d05f7f8d69b65659157eff1bc1d2717f04c66"],"d76e8ac2404f9119d48b15059f36129cb99a56ce":["092c3ae5fefa024f6d0c427be5f23dd3bfbdd20c"],"1d4bf9d5308dfef350829c28f2b3b2648df1e9b1":["b94236357aaa22b76c10629851fe4e376e0cea82","6146c07c0dee1ae1e42926167acd127fed5ef59d"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["4cce5816ef15a48a0bc11e5d400497ee4301dd3b","7a23cf16c8fa265dc0a564adcabb55e3f054e0ac","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}