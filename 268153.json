{"path":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","commits":[{"id":"39c13c15172a8b9d27019144ee871d39e4d42a0a","date":1311302849,"type":0,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n    final int maxConcurrentCommits = 2;   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(5000);  // number of query operations to perform in total\n    int nReadThreads = 10;\n\n\n    for (int i=0; i<ndocs; i++) {\n      model.put(i, -1L);\n    }\n    committedModel.putAll(model);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n            int id = rand.nextInt(ndocs);\n            Long val = model.get(id);\n            long nextVal = Math.abs(val)+1;\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = random.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                if (rand.nextInt(100) < softCommitPercent)\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                else\n                  assertU(commit());\n              }\n\n              committedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n              numCommitting.decrementAndGet();\n            } else if (oper < commitPercent + deletePercent) {\n              assertU(\"<delete><id>\" + id + \"</id></delete>\");\n              model.put(id, -nextVal);\n            } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n              assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n              model.put(id, -nextVal);\n            } else {\n              assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              int oper = rand.nextInt(100);\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                val = committedModel.get(id);\n              }\n\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            }\n          }\n          catch (Throwable e) {\n            ex = e;\n            operations.set(-1L);\n            SolrException.log(log,e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    assertNull(ex);\n\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"49a4d79ca95e946251c9209af4952ed7db8b1026","date":1311357077,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n    final int maxConcurrentCommits = 2;   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(10000);  // number of query operations to perform in total\n    int nReadThreads = 10;\n\n\n    for (int i=0; i<ndocs; i++) {\n      model.put(i, -1L);\n    }\n    committedModel.putAll(model);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n              int id = rand.nextInt(ndocs);\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              // set the lastId before we actually change it sometimes to try and\n              // uncover more race conditions between writing and reading\n              boolean before = random.nextBoolean();\n              if (before) {\n                lastId = id;\n              }\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n\n                  synchronized(this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                  }\n\n                  if (rand.nextInt(100) < softCommitPercent)\n                    assertU(h.commit(\"softCommit\",\"true\"));\n                  else\n                    assertU(commit());\n\n                  synchronized(this) {\n                    // install this snapshot only if it's newer than the current one\n                    if (version >= committedModelClock) {\n                      committedModel = newCommittedModel;\n                      committedModelClock = version;\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else if (oper < commitPercent + deletePercent) {\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n              } else {\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n              }\n\n              if (!before) {\n                lastId = id;\n              }\n            }\n          } catch (Throwable e) {\n            ex = e;\n            SolrException.log(log,e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              int oper = rand.nextInt(100);\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                val = committedModel.get(id);\n              }\n\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            }\n          }\n          catch (Throwable e) {\n            ex = e;\n            operations.set(-1L);\n            SolrException.log(log,e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    assertNull(ex);\n\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n    final int maxConcurrentCommits = 2;   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(5000);  // number of query operations to perform in total\n    int nReadThreads = 10;\n\n\n    for (int i=0; i<ndocs; i++) {\n      model.put(i, -1L);\n    }\n    committedModel.putAll(model);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n            int id = rand.nextInt(ndocs);\n            Long val = model.get(id);\n            long nextVal = Math.abs(val)+1;\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = random.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                if (rand.nextInt(100) < softCommitPercent)\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                else\n                  assertU(commit());\n              }\n\n              committedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n              numCommitting.decrementAndGet();\n            } else if (oper < commitPercent + deletePercent) {\n              assertU(\"<delete><id>\" + id + \"</id></delete>\");\n              model.put(id, -nextVal);\n            } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n              assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n              model.put(id, -nextVal);\n            } else {\n              assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              int oper = rand.nextInt(100);\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                val = committedModel.get(id);\n              }\n\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            }\n          }\n          catch (Throwable e) {\n            ex = e;\n            operations.set(-1L);\n            SolrException.log(log,e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    assertNull(ex);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8441036e95d6b46771828fdaac1ff1575b23ec43","date":1311590202,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n    final int maxConcurrentCommits = 2;   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(10000);  // number of query operations to perform in total\n    int nReadThreads = 10;\n\n\n    for (int i=0; i<ndocs; i++) {\n      model.put(i, -1L);\n    }\n    committedModel.putAll(model);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n              int id = rand.nextInt(ndocs);\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              // set the lastId before we actually change it sometimes to try and\n              // uncover more race conditions between writing and reading\n              boolean before = random.nextBoolean();\n              if (before) {\n                lastId = id;\n              }\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n\n                  synchronized(TestRealTimeGet.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                  }\n\n                  if (rand.nextInt(100) < softCommitPercent)\n                    assertU(h.commit(\"softCommit\",\"true\"));\n                  else\n                    assertU(commit());\n\n                  synchronized(TestRealTimeGet.this) {\n                    // install this snapshot only if it's newer than the current one\n                    if (version >= committedModelClock) {\n                      committedModel = newCommittedModel;\n                      committedModelClock = version;\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else if (oper < commitPercent + deletePercent) {\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n              } else {\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n              }\n\n              if (!before) {\n                lastId = id;\n              }\n            }\n          } catch (Throwable e) {\n            ex = e;\n            SolrException.log(log,e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              int oper = rand.nextInt(100);\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            }\n          }\n          catch (Throwable e) {\n            ex = e;\n            operations.set(-1L);\n            SolrException.log(log,e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    assertNull(ex);\n\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n    final int maxConcurrentCommits = 2;   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(10000);  // number of query operations to perform in total\n    int nReadThreads = 10;\n\n\n    for (int i=0; i<ndocs; i++) {\n      model.put(i, -1L);\n    }\n    committedModel.putAll(model);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n              int id = rand.nextInt(ndocs);\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              // set the lastId before we actually change it sometimes to try and\n              // uncover more race conditions between writing and reading\n              boolean before = random.nextBoolean();\n              if (before) {\n                lastId = id;\n              }\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n\n                  synchronized(this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                  }\n\n                  if (rand.nextInt(100) < softCommitPercent)\n                    assertU(h.commit(\"softCommit\",\"true\"));\n                  else\n                    assertU(commit());\n\n                  synchronized(this) {\n                    // install this snapshot only if it's newer than the current one\n                    if (version >= committedModelClock) {\n                      committedModel = newCommittedModel;\n                      committedModelClock = version;\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else if (oper < commitPercent + deletePercent) {\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n              } else {\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n              }\n\n              if (!before) {\n                lastId = id;\n              }\n            }\n          } catch (Throwable e) {\n            ex = e;\n            SolrException.log(log,e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              int oper = rand.nextInt(100);\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                val = committedModel.get(id);\n              }\n\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            }\n          }\n          catch (Throwable e) {\n            ex = e;\n            operations.set(-1L);\n            SolrException.log(log,e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    assertNull(ex);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c615600525185e653f4176180f81b01a32cef120","date":1311603961,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n    final int maxConcurrentCommits = 2;   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(10000);  // number of query operations to perform in total\n    int nReadThreads = 10;\n\n\n    for (int i=0; i<ndocs; i++) {\n      model.put(i, -1L);\n    }\n    committedModel.putAll(model);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n            int id = rand.nextInt(ndocs);\n            Long val = model.get(id);\n            long nextVal = Math.abs(val)+1;\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = random.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent)\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                else\n                  assertU(commit());\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n            } else if (oper < commitPercent + deletePercent) {\n              assertU(\"<delete><id>\" + id + \"</id></delete>\");\n              model.put(id, -nextVal);\n            } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n              assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n              model.put(id, -nextVal);\n            } else {\n              assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          while (operations.decrementAndGet() >= 0) {\n            int oper = rand.nextInt(100);\n            // bias toward a recently changed doc\n            int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n            // when indexing, we update the index, then the model\n            // so when querying, we should first check the model, and then the index\n\n            boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n            long val;\n\n            if (realTime) {\n              val = model.get(id);\n            } else {\n              synchronized(TestRealTimeGet.this) {\n                val = committedModel.get(id);\n              }\n            }\n\n            SolrQueryRequest sreq;\n            if (realTime) {\n              sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n            } else {\n              sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n            }\n\n            try {\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            } catch (Exception e) {\n              fail(e.toString());\n            }\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n    final int maxConcurrentCommits = 2;   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(10000);  // number of query operations to perform in total\n    int nReadThreads = 10;\n\n\n    for (int i=0; i<ndocs; i++) {\n      model.put(i, -1L);\n    }\n    committedModel.putAll(model);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.get() > 0) {\n              int oper = rand.nextInt(100);\n              int id = rand.nextInt(ndocs);\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              // set the lastId before we actually change it sometimes to try and\n              // uncover more race conditions between writing and reading\n              boolean before = random.nextBoolean();\n              if (before) {\n                lastId = id;\n              }\n\n              if (oper < commitPercent) {\n                if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                  Map<Integer,Long> newCommittedModel;\n                  long version;\n\n                  synchronized(TestRealTimeGet.this) {\n                    newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                    version = snapshotCount++;\n                  }\n\n                  if (rand.nextInt(100) < softCommitPercent)\n                    assertU(h.commit(\"softCommit\",\"true\"));\n                  else\n                    assertU(commit());\n\n                  synchronized(TestRealTimeGet.this) {\n                    // install this snapshot only if it's newer than the current one\n                    if (version >= committedModelClock) {\n                      committedModel = newCommittedModel;\n                      committedModelClock = version;\n                    }\n                  }\n                }\n                numCommitting.decrementAndGet();\n              } else if (oper < commitPercent + deletePercent) {\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n              } else {\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n              }\n\n              if (!before) {\n                lastId = id;\n              }\n            }\n          } catch (Throwable e) {\n            ex = e;\n            SolrException.log(log,e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              int oper = rand.nextInt(100);\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            }\n          }\n          catch (Throwable e) {\n            ex = e;\n            operations.set(-1L);\n            SolrException.log(log,e);\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n    assertNull(ex);\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"41537328cfa3ccff80ac357efa2f357bccc17490","date":1311606920,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n    final int maxConcurrentCommits = 2;   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(10000);  // number of query operations to perform in total\n    int nReadThreads = 10;\n\n    final Object[] syncArr = new Object[ndocs];\n\n    for (int i=0; i<ndocs; i++) {\n      model.put(i, -1L);\n      syncArr[i] = new Object();\n    }\n    committedModel.putAll(model);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent)\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                else\n                  assertU(commit());\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = random.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            synchronized (sync) {\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n              } else {\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n              }\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              int oper = rand.nextInt(100);\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log,e);\n            fail(e.toString());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n    final int maxConcurrentCommits = 2;   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(10000);  // number of query operations to perform in total\n    int nReadThreads = 10;\n\n\n    for (int i=0; i<ndocs; i++) {\n      model.put(i, -1L);\n    }\n    committedModel.putAll(model);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n            int id = rand.nextInt(ndocs);\n            Long val = model.get(id);\n            long nextVal = Math.abs(val)+1;\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = random.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent)\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                else\n                  assertU(commit());\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n            } else if (oper < commitPercent + deletePercent) {\n              assertU(\"<delete><id>\" + id + \"</id></delete>\");\n              model.put(id, -nextVal);\n            } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n              assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n              model.put(id, -nextVal);\n            } else {\n              assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          while (operations.decrementAndGet() >= 0) {\n            int oper = rand.nextInt(100);\n            // bias toward a recently changed doc\n            int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n            // when indexing, we update the index, then the model\n            // so when querying, we should first check the model, and then the index\n\n            boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n            long val;\n\n            if (realTime) {\n              val = model.get(id);\n            } else {\n              synchronized(TestRealTimeGet.this) {\n                val = committedModel.get(id);\n              }\n            }\n\n            SolrQueryRequest sreq;\n            if (realTime) {\n              sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n            } else {\n              sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n            }\n\n            try {\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            } catch (Exception e) {\n              fail(e.toString());\n            }\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n  }\n\n","bugFix":null,"bugIntro":["c00afe74a80796ed1f30a9509b150ff104746a1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"4aa2440480b1dcdc4da1711d161e7d62248dcabb","date":1311784060,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n    final int maxConcurrentCommits = 2;   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(10000);  // number of query operations to perform in total\n    int nReadThreads = 10;\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent)\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                else\n                  assertU(commit());\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = random.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            synchronized (sync) {\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n              } else {\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                model.put(id, nextVal);\n              }\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              int oper = rand.nextInt(100);\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log,e);\n            fail(e.toString());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n    final int maxConcurrentCommits = 2;   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(10000);  // number of query operations to perform in total\n    int nReadThreads = 10;\n\n    final Object[] syncArr = new Object[ndocs];\n\n    for (int i=0; i<ndocs; i++) {\n      model.put(i, -1L);\n      syncArr[i] = new Object();\n    }\n    committedModel.putAll(model);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent)\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                else\n                  assertU(commit());\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = random.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            synchronized (sync) {\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n              } else {\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n              }\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              int oper = rand.nextInt(100);\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log,e);\n            fail(e.toString());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7d8e411397bc0d26f70339dbe2d59dc162d92237","date":1311795429,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n    final int maxConcurrentCommits = 2;   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(0);  // number of query operations to perform in total       // TODO: once lucene level passes, we can move on to the solr level\n    int nReadThreads = 10;\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent)\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                else\n                  assertU(commit());\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = random.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            synchronized (sync) {\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n              } else {\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                model.put(id, nextVal);\n              }\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              int oper = rand.nextInt(100);\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log,e);\n            fail(e.toString());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n    final int maxConcurrentCommits = 2;   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(10000);  // number of query operations to perform in total\n    int nReadThreads = 10;\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent)\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                else\n                  assertU(commit());\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = random.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            synchronized (sync) {\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n              } else {\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                model.put(id, nextVal);\n              }\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              int oper = rand.nextInt(100);\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log,e);\n            fail(e.toString());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":["c00afe74a80796ed1f30a9509b150ff104746a1f"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"73f40b658bbabc7fa3c8db81a47ba2e03af28f8a","date":1311798814,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n    final int maxConcurrentCommits = 2;   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(0);  // number of query operations to perform in total       // TODO: once lucene level passes, we can move on to the solr level\n    int nReadThreads = 10;\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent)\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                else\n                  assertU(commit());\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            synchronized (sync) {\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n              } else {\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                model.put(id, nextVal);\n              }\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              int oper = rand.nextInt(100);\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log,e);\n            fail(e.toString());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n    final int maxConcurrentCommits = 2;   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(0);  // number of query operations to perform in total       // TODO: once lucene level passes, we can move on to the solr level\n    int nReadThreads = 10;\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent)\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                else\n                  assertU(commit());\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = random.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            synchronized (sync) {\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n              } else {\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                model.put(id, nextVal);\n              }\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              int oper = rand.nextInt(100);\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log,e);\n            fail(e.toString());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c00afe74a80796ed1f30a9509b150ff104746a1f","date":1312881735,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n    final int maxConcurrentCommits = 2;   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(1000);  // number of query operations to perform in total       // TODO: once lucene level passes, we can move on to the solr level\n    int nReadThreads = 10;\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent)\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                else\n                  assertU(commit());\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            synchronized (sync) {\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n              } else {\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                model.put(id, nextVal);\n              }\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              int oper = rand.nextInt(100);\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log,e);\n            fail(e.toString());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n    final int maxConcurrentCommits = 2;   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(0);  // number of query operations to perform in total       // TODO: once lucene level passes, we can move on to the solr level\n    int nReadThreads = 10;\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent)\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                else\n                  assertU(commit());\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            synchronized (sync) {\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n              } else {\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                model.put(id, nextVal);\n              }\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              int oper = rand.nextInt(100);\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log,e);\n            fail(e.toString());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":["7d8e411397bc0d26f70339dbe2d59dc162d92237","41537328cfa3ccff80ac357efa2f357bccc17490"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d8d4043f61e1bb9e99e8008fed9a79c6478826e1","date":1312930770,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n    int nReadThreads = 10;\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent)\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                else\n                  assertU(commit());\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            synchronized (sync) {\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n              } else {\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                model.put(id, nextVal);\n              }\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              int oper = rand.nextInt(100);\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log,e);\n            fail(e.toString());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n    final int maxConcurrentCommits = 2;   // number of committers at a time... needed if we want to avoid commit errors due to exceeding the max\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(1000);  // number of query operations to perform in total       // TODO: once lucene level passes, we can move on to the solr level\n    int nReadThreads = 10;\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent)\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                else\n                  assertU(commit());\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            synchronized (sync) {\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n              } else {\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                model.put(id, nextVal);\n              }\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              int oper = rand.nextInt(100);\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log,e);\n            fail(e.toString());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bd0ef6574805f3cb9880e0983b7548a6aa933508","date":1315345052,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(60); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 0;  // real-time get isn't currently supported with delete-by-query\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"commit start\");\n                  assertU(commit());\n                  verbose(\"commit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            synchronized (sync) {\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                if (VERBOSE) {\n                  verbose(\"deleting id\",id,\"val=\",nextVal);\n                }\n\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal);\n                }\n\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                model.put(id, nextVal);\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                if (foundVal < Math.abs(val)) {\n                  verbose(\"ERROR, id=\", id, \"foundVal=\",foundVal,\"model val=\",val);\n                  assertTrue(foundVal >= Math.abs(val));\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    // update variables\n    final int commitPercent = 10;\n    final int softCommitPercent = 50; // what percent of the commits are soft\n    final int deletePercent = 8;\n    final int deleteByQueryPercent = 4;\n    final int ndocs = 100;\n    int nWriteThreads = 10;\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n    // query variables\n    final int percentRealtimeQuery = 0;   // realtime get is not implemented yet\n    final AtomicLong operations = new AtomicLong(atLeast(10000));  // number of query operations to perform in total\n    int nReadThreads = 10;\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent)\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                else\n                  assertU(commit());\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            synchronized (sync) {\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n              } else {\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                model.put(id, nextVal);\n              }\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              int oper = rand.nextInt(100);\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                assertTrue(foundVal >= Math.abs(val));\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log,e);\n            fail(e.toString());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7a3554ff15950ad0e3bcbb4e4e2ddb45b0b0f27e","date":1320267737,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 0;  // real-time get isn't currently supported with delete-by-query\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    // final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            synchronized (sync) {\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                if (VERBOSE) {\n                  verbose(\"deleting id\",id,\"val=\",nextVal);\n                }\n\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal);\n                }\n\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                model.put(id, nextVal);\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                if (foundVal < Math.abs(val)) {\n                  verbose(\"ERROR, id\", id, \"foundVal=\",foundVal,\"model val=\",val,\"realTime=\",realTime);\n                  assertTrue(foundVal >= Math.abs(val));\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(60); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 0;  // real-time get isn't currently supported with delete-by-query\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"commit start\");\n                  assertU(commit());\n                  verbose(\"commit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            synchronized (sync) {\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                if (VERBOSE) {\n                  verbose(\"deleting id\",id,\"val=\",nextVal);\n                }\n\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal);\n                }\n\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                model.put(id, nextVal);\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                if (foundVal < Math.abs(val)) {\n                  verbose(\"ERROR, id=\", id, \"foundVal=\",foundVal,\"model val=\",val);\n                  assertTrue(foundVal >= Math.abs(val));\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2c007e7c4cf8c55bc2a5884e315123afaaeec87f","date":1327520966,"type":3,"author":"Mark Robert Miller","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 1+random.nextInt(5);\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                if (VERBOSE) {\n                  verbose(\"deleting id\",id,\"val=\",nextVal);\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = deleteAndGetVersion(Integer.toString(id), null);\n\n                model.put(id, new DocInfo(version, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal);\n                }\n\n                // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                Long version = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal)), null);\n                model.put(id, new DocInfo(version, nextVal));\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 0;  // real-time get isn't currently supported with delete-by-query\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    // final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            synchronized (sync) {\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                if (VERBOSE) {\n                  verbose(\"deleting id\",id,\"val=\",nextVal);\n                }\n\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal);\n                }\n\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                model.put(id, nextVal);\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                if (foundVal < Math.abs(val)) {\n                  verbose(\"ERROR, id\", id, \"foundVal=\",foundVal,\"model val=\",val,\"realTime=\",realTime);\n                  assertTrue(foundVal >= Math.abs(val));\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","date":1327523564,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 1+random.nextInt(5);\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                if (VERBOSE) {\n                  verbose(\"deleting id\",id,\"val=\",nextVal);\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = deleteAndGetVersion(Integer.toString(id), null);\n\n                model.put(id, new DocInfo(version, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal);\n                }\n\n                // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                Long version = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal)), null);\n                model.put(id, new DocInfo(version, nextVal));\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 0;  // real-time get isn't currently supported with delete-by-query\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    // final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            synchronized (sync) {\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                if (VERBOSE) {\n                  verbose(\"deleting id\",id,\"val=\",nextVal);\n                }\n\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal);\n                }\n\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                model.put(id, nextVal);\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                if (foundVal < Math.abs(val)) {\n                  verbose(\"ERROR, id\", id, \"foundVal=\",foundVal,\"model val=\",val,\"realTime=\",realTime);\n                  assertTrue(foundVal >= Math.abs(val));\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0d22ac6a4146774c1bc8400160fc0b6150294e92","date":1327528604,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 1+random.nextInt(5);\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                if (VERBOSE) {\n                  verbose(\"deleting id\",id,\"val=\",nextVal);\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = deleteAndGetVersion(Integer.toString(id), null);\n\n                model.put(id, new DocInfo(version, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal);\n                }\n\n                // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                Long version = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal)), null);\n                model.put(id, new DocInfo(version, nextVal));\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 0;  // real-time get isn't currently supported with delete-by-query\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    // final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,Long> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,Long>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            synchronized (sync) {\n              Long val = model.get(id);\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                if (VERBOSE) {\n                  verbose(\"deleting id\",id,\"val=\",nextVal);\n                }\n\n                assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                model.put(id, -nextVal);\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, -nextVal);\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal);\n                }\n\n                assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                model.put(id, nextVal);\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              long val;\n\n              if (realTime) {\n                val = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  val = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                if (foundVal < Math.abs(val)) {\n                  verbose(\"ERROR, id\", id, \"foundVal=\",foundVal,\"model val=\",val,\"realTime=\",realTime);\n                  assertTrue(foundVal >= Math.abs(val));\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f08557cdb6c60ac7b88a9342c983a20cd236e74f","date":1330954480,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 1+random.nextInt(5);\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                if (VERBOSE) {\n                  verbose(\"deleting id\",id,\"val=\",nextVal);\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = deleteAndGetVersion(Integer.toString(id), null);\n\n                model.put(id, new DocInfo(version, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal);\n                }\n\n                // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                Long version = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal)), null);\n                model.put(id, new DocInfo(version, nextVal));\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 1+random.nextInt(5);\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                if (VERBOSE) {\n                  verbose(\"deleting id\",id,\"val=\",nextVal);\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = deleteAndGetVersion(Integer.toString(id), null);\n\n                model.put(id, new DocInfo(version, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal);\n                }\n\n                // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                Long version = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal)), null);\n                model.put(id, new DocInfo(version, nextVal));\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","date":1331075828,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 1+random.nextInt(5);\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                if (VERBOSE) {\n                  verbose(\"deleting id\",id,\"val=\",nextVal);\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = deleteAndGetVersion(Integer.toString(id), null);\n\n                model.put(id, new DocInfo(version, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal);\n                }\n\n                // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                Long version = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal)), null);\n                model.put(id, new DocInfo(version, nextVal));\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 1+random.nextInt(5);\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(h.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                if (VERBOSE) {\n                  verbose(\"deleting id\",id,\"val=\",nextVal);\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = deleteAndGetVersion(Integer.toString(id), null);\n\n                model.put(id, new DocInfo(version, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal);\n                }\n\n                // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                Long version = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal)), null);\n                model.put(id, new DocInfo(version, nextVal));\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                if (VERBOSE) {\n                  verbose(\"deleting id\",id,\"val=\",nextVal);\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = deleteAndGetVersion(Integer.toString(id), null);\n\n                model.put(id, new DocInfo(version, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal);\n                }\n\n                // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                Long version = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal)), null);\n                model.put(id, new DocInfo(version, nextVal));\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random.nextInt(20);\n    final int softCommitPercent = 30+random.nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random.nextInt(25);\n    final int deleteByQueryPercent = 1+random.nextInt(5);\n    final int ndocs = 5 + (random.nextBoolean() ? random.nextInt(25) : random.nextInt(200));\n    int nWriteThreads = 5 + random.nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random.nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                if (VERBOSE) {\n                  verbose(\"deleting id\",id,\"val=\",nextVal);\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = deleteAndGetVersion(Integer.toString(id), null);\n\n                model.put(id, new DocInfo(version, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal);\n                }\n\n                // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                Long version = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal)), null);\n                model.put(id, new DocInfo(version, nextVal));\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random.nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"1bea3922196318026c4274f2013416acb60c691e","date":1336496433,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                if (VERBOSE) {\n                  verbose(\"deleting id\",id,\"val=\",nextVal);\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = deleteAndGetVersion(Integer.toString(id), null);\n\n                model.put(id, new DocInfo(version, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal);\n                }\n\n                // assertU(adoc(\"id\",Integer.toString(id), field, Long.toString(nextVal)));\n                Long version = addAndGetVersion(sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal)), null);\n                model.put(id, new DocInfo(version, nextVal));\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          SolrException.log(log, e);\n          fail(e.getMessage());\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n          catch (Throwable e) {\n            operations.set(-1L);\n            SolrException.log(log, e);\n            fail(e.getMessage());\n          }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2b2e7536fb06d1abad6c7543a0657bdad5242c5e","date":1341417762,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"    /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fe33227f6805edab2036cbb80645cc4e2d1fa424","date":1342713534,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"    /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"    /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"    /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<Thread>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<Integer,DocInfo>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2b0085a9ec29ebc27be992a3712f4bd5d65d2106","date":1450912573,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"    /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int filteredGetPercent = random().nextInt( random().nextInt(20)+1 );   // percent of time that a get will be filtered... we normally don't want too high.\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n\n              boolean filteredOut = false;\n              SolrQueryRequest sreq;\n              if (realTime) {\n                ModifiableSolrParams p = params(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n                if (rand.nextInt(100) < filteredGetPercent) {\n                  int idToFilter = rand.nextBoolean() ? id : rand.nextInt(ndocs);\n                  filteredOut = idToFilter != id;\n                  p.add(\"fq\", \"id:\"+idToFilter);\n                }\n                sreq = req(p);\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n                // This is also correct when filteredOut==true\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (filteredOut || foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"    /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n              SolrQueryRequest sreq;\n              if (realTime) {\n                sreq = req(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6554f36a4636755009195a7840518bf6b4f03d6c","date":1481906808,"type":3,"author":"yonik","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"    /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int filteredGetPercent = random().nextInt( random().nextInt(20)+1 );   // percent of time that a get will be filtered... we normally don't want too high.\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time...\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n\n              boolean filteredOut = false;\n              SolrQueryRequest sreq;\n              if (realTime) {\n                ModifiableSolrParams p = params(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n                if (rand.nextInt(100) < filteredGetPercent) {\n                  int idToFilter = rand.nextBoolean() ? id : rand.nextInt(ndocs);\n                  filteredOut = idToFilter != id;\n                  p.add(\"fq\", \"id:\"+idToFilter);\n                }\n                sreq = req(p);\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n                // This is also correct when filteredOut==true\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (filteredOut || foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"    /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int filteredGetPercent = random().nextInt( random().nextInt(20)+1 );   // percent of time that a get will be filtered... we normally don't want too high.\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n\n              boolean filteredOut = false;\n              SolrQueryRequest sreq;\n              if (realTime) {\n                ModifiableSolrParams p = params(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n                if (rand.nextInt(100) < filteredGetPercent) {\n                  int idToFilter = rand.nextBoolean() ? id : rand.nextInt(ndocs);\n                  filteredOut = idToFilter != id;\n                  p.add(\"fq\", \"id:\"+idToFilter);\n                }\n                sreq = req(p);\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n                // This is also correct when filteredOut==true\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (filteredOut || foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","date":1482251961,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"    /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int filteredGetPercent = random().nextInt( random().nextInt(20)+1 );   // percent of time that a get will be filtered... we normally don't want too high.\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time...\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n\n              boolean filteredOut = false;\n              SolrQueryRequest sreq;\n              if (realTime) {\n                ModifiableSolrParams p = params(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n                if (rand.nextInt(100) < filteredGetPercent) {\n                  int idToFilter = rand.nextBoolean() ? id : rand.nextInt(ndocs);\n                  filteredOut = idToFilter != id;\n                  p.add(\"fq\", \"id:\"+idToFilter);\n                }\n                sreq = req(p);\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n                // This is also correct when filteredOut==true\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (filteredOut || foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"    /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int filteredGetPercent = random().nextInt( random().nextInt(20)+1 );   // percent of time that a get will be filtered... we normally don't want too high.\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time... it should be <= maxWarmingSearchers\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n\n              boolean filteredOut = false;\n              SolrQueryRequest sreq;\n              if (realTime) {\n                ModifiableSolrParams p = params(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n                if (rand.nextInt(100) < filteredGetPercent) {\n                  int idToFilter = rand.nextBoolean() ? id : rand.nextInt(ndocs);\n                  filteredOut = idToFilter != id;\n                  p.add(\"fq\", \"id:\"+idToFilter);\n                }\n                sreq = req(p);\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n                // This is also correct when filteredOut==true\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (filteredOut || foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5de502b5478255493125e7e801411ba17a6682ec","date":1490974101,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"    /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int filteredGetPercent = random().nextInt( random().nextInt(20)+1 );   // percent of time that a get will be filtered... we normally don't want too high.\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time...\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), FIELD, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n\n              boolean filteredOut = false;\n              SolrQueryRequest sreq;\n              if (realTime) {\n                ModifiableSolrParams p = params(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n                if (rand.nextInt(100) < filteredGetPercent) {\n                  int idToFilter = rand.nextBoolean() ? id : rand.nextInt(ndocs);\n                  filteredOut = idToFilter != id;\n                  p.add(\"fq\", \"id:\"+idToFilter);\n                }\n                sreq = req(p);\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n                // This is also correct when filteredOut==true\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(FIELD));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (filteredOut || foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"    /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int filteredGetPercent = random().nextInt( random().nextInt(20)+1 );   // percent of time that a get will be filtered... we normally don't want too high.\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time...\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n\n              boolean filteredOut = false;\n              SolrQueryRequest sreq;\n              if (realTime) {\n                ModifiableSolrParams p = params(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n                if (rand.nextInt(100) < filteredGetPercent) {\n                  int idToFilter = rand.nextBoolean() ? id : rand.nextInt(ndocs);\n                  filteredOut = idToFilter != id;\n                  p.add(\"fq\", \"id:\"+idToFilter);\n                }\n                sreq = req(p);\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n                // This is also correct when filteredOut==true\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (filteredOut || foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6f20fd35e3055a0c5b387df0b986a68d65d86441","date":1491045405,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"    /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int filteredGetPercent = random().nextInt( random().nextInt(20)+1 );   // percent of time that a get will be filtered... we normally don't want too high.\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time...\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), FIELD, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n\n              boolean filteredOut = false;\n              SolrQueryRequest sreq;\n              if (realTime) {\n                ModifiableSolrParams p = params(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n                if (rand.nextInt(100) < filteredGetPercent) {\n                  int idToFilter = rand.nextBoolean() ? id : rand.nextInt(ndocs);\n                  filteredOut = idToFilter != id;\n                  p.add(\"fq\", \"id:\"+idToFilter);\n                }\n                sreq = req(p);\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n                // This is also correct when filteredOut==true\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(FIELD));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (filteredOut || foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"    /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int filteredGetPercent = random().nextInt( random().nextInt(20)+1 );   // percent of time that a get will be filtered... we normally don't want too high.\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time...\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), field, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n\n              boolean filteredOut = false;\n              SolrQueryRequest sreq;\n              if (realTime) {\n                ModifiableSolrParams p = params(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n                if (rand.nextInt(100) < filteredGetPercent) {\n                  int idToFilter = rand.nextBoolean() ? id : rand.nextInt(ndocs);\n                  filteredOut = idToFilter != id;\n                  p.add(\"fq\", \"id:\"+idToFilter);\n                }\n                sreq = req(p);\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n                // This is also correct when filteredOut==true\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(field));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (filteredOut || foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"464e7336798bc8a1281d5cf610c649c5a0784e83","date":1541256496,"type":3,"author":"Jason Gerlowski","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int filteredGetPercent = random().nextInt( random().nextInt(20)+1 );   // percent of time that a get will be filtered... we normally don't want too high.\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time...\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    SolrException se = expectThrows(SolrException.class, \"should not get random version\",\n                        () -> deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion))));\n                    assertEquals(409, se.code());\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), FIELD, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    SolrException se = expectThrows(SolrException.class, \"should not get bad version\",\n                        () -> addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion))));\n                    assertEquals(409, se.code());\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n\n              boolean filteredOut = false;\n              SolrQueryRequest sreq;\n              if (realTime) {\n                ModifiableSolrParams p = params(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n                if (rand.nextInt(100) < filteredGetPercent) {\n                  int idToFilter = rand.nextBoolean() ? id : rand.nextInt(ndocs);\n                  filteredOut = idToFilter != id;\n                  p.add(\"fq\", \"id:\"+idToFilter);\n                }\n                sreq = req(p);\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n                // This is also correct when filteredOut==true\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(FIELD));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (filteredOut || foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"    /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int filteredGetPercent = random().nextInt( random().nextInt(20)+1 );   // percent of time that a get will be filtered... we normally don't want too high.\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time...\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), FIELD, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    try {\n                      version = addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion)));\n                      fail();\n                    } catch (SolrException se) {\n                      assertEquals(409, se.code());\n                    }\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n\n              boolean filteredOut = false;\n              SolrQueryRequest sreq;\n              if (realTime) {\n                ModifiableSolrParams p = params(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n                if (rand.nextInt(100) < filteredGetPercent) {\n                  int idToFilter = rand.nextBoolean() ? id : rand.nextInt(ndocs);\n                  filteredOut = idToFilter != id;\n                  p.add(\"fq\", \"id:\"+idToFilter);\n                }\n                sreq = req(p);\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n                // This is also correct when filteredOut==true\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(FIELD));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (filteredOut || foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"3714bcf66a68a1600e9dd11442fc1b33b62ef088","date":1556832005,"type":3,"author":"noble","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int filteredGetPercent = random().nextInt( random().nextInt(20)+1 );   // percent of time that a get will be filtered... we normally don't want too high.\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time...\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    SolrException se = expectThrows(SolrException.class, \"should not get random version\",\n                        () -> deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion))));\n                    assertEquals(409, se.code());\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), FIELD, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    SolrException se = expectThrows(SolrException.class, \"should not get bad version\",\n                        () -> addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion))));\n                    assertEquals(409, se.code());\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n\n              boolean filteredOut = false;\n              SolrQueryRequest sreq;\n              if (realTime) {\n                ModifiableSolrParams p = params(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n                if (rand.nextInt(100) < filteredGetPercent) {\n                  int idToFilter = rand.nextBoolean() ? id : rand.nextInt(ndocs);\n                  filteredOut = idToFilter != id;\n                  p.add(\"fq\", \"id:\"+idToFilter);\n                }\n                sreq = req(p);\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map) Utils.fromJSONString(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n                // This is also correct when filteredOut==true\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(FIELD));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (filteredOut || foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int filteredGetPercent = random().nextInt( random().nextInt(20)+1 );   // percent of time that a get will be filtered... we normally don't want too high.\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time...\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    SolrException se = expectThrows(SolrException.class, \"should not get random version\",\n                        () -> deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion))));\n                    assertEquals(409, se.code());\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), FIELD, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    SolrException se = expectThrows(SolrException.class, \"should not get bad version\",\n                        () -> addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion))));\n                    assertEquals(409, se.code());\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n\n              boolean filteredOut = false;\n              SolrQueryRequest sreq;\n              if (realTime) {\n                ModifiableSolrParams p = params(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n                if (rand.nextInt(100) < filteredGetPercent) {\n                  int idToFilter = rand.nextBoolean() ? id : rand.nextInt(ndocs);\n                  filteredOut = idToFilter != id;\n                  p.add(\"fq\", \"id:\"+idToFilter);\n                }\n                sreq = req(p);\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map)ObjectBuilder.fromJSON(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n                // This is also correct when filteredOut==true\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(FIELD));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (filteredOut || foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e98520789adb1d5ad05afb4956eca0944a929688","date":1592430701,"type":3,"author":"Erick Erickson","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","pathOld":"solr/core/src/test/org/apache/solr/search/TestRealTimeGet#testStressGetRealtime().mjava","sourceNew":"  /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int filteredGetPercent = random().nextInt( random().nextInt(20)+1 );   // percent of time that a get will be filtered... we normally don't want too high.\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time...\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    SolrException se = expectThrows(SolrException.class, \"should not get random version\",\n                        () -> deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion))));\n                    assertEquals(409, se.code());\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), FIELD, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    SolrException se = expectThrows(SolrException.class, \"should not get bad version\",\n                        () -> addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion))));\n                    assertEquals(409, se.code());\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n\n              boolean filteredOut = false;\n              SolrQueryRequest sreq;\n              if (realTime) {\n                ModifiableSolrParams p = params(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n                if (rand.nextInt(100) < filteredGetPercent) {\n                  int idToFilter = rand.nextBoolean() ? id : rand.nextInt(ndocs);\n                  filteredOut = idToFilter != id;\n                  p.add(\"fq\", \"id:\"+idToFilter);\n                }\n                sreq = req(p);\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              @SuppressWarnings({\"rawtypes\"})\n              Map rsp = (Map) Utils.fromJSONString(response);\n              @SuppressWarnings({\"rawtypes\"})\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n                // This is also correct when filteredOut==true\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(FIELD));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (filteredOut || foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","sourceOld":"  /***\n    @Test\n    public void testGetRealtime() throws Exception {\n      SolrQueryRequest sr1 = req(\"q\",\"foo\");\n      IndexReader r1 = sr1.getCore().getRealtimeReader();\n\n      assertU(adoc(\"id\",\"1\"));\n\n      IndexReader r2 = sr1.getCore().getRealtimeReader();\n      assertNotSame(r1, r2);\n      int refcount = r2.getRefCount();\n\n      // make sure a new reader wasn't opened\n      IndexReader r3 = sr1.getCore().getRealtimeReader();\n      assertSame(r2, r3);\n      assertEquals(refcount+1, r3.getRefCount());\n\n      assertU(commit());\n\n      // this is not critical, but currently a commit does not refresh the reader\n      // if nothing has changed\n      IndexReader r4 = sr1.getCore().getRealtimeReader();\n      assertEquals(refcount+2, r4.getRefCount());\n\n\n      r1.decRef();\n      r2.decRef();\n      r3.decRef();\n      r4.decRef();\n      sr1.close();\n    }\n    ***/\n\n\n  @Test\n  public void testStressGetRealtime() throws Exception {\n    clearIndex();\n    assertU(commit());\n\n    // req().getCore().getUpdateHandler().getIndexWriterProvider().getIndexWriter(req().getCore()).setInfoStream(System.out);\n\n    final int commitPercent = 5 + random().nextInt(20);\n    final int softCommitPercent = 30+random().nextInt(75); // what percent of the commits are soft\n    final int deletePercent = 4+random().nextInt(25);\n    final int deleteByQueryPercent = 1+random().nextInt(5);\n    final int optimisticPercent = 1+random().nextInt(50);    // percent change that an update uses optimistic locking\n    final int optimisticCorrectPercent = 25+random().nextInt(70);    // percent change that a version specified will be correct\n    final int filteredGetPercent = random().nextInt( random().nextInt(20)+1 );   // percent of time that a get will be filtered... we normally don't want too high.\n    final int ndocs = 5 + (random().nextBoolean() ? random().nextInt(25) : random().nextInt(200));\n    int nWriteThreads = 5 + random().nextInt(25);\n\n    final int maxConcurrentCommits = nWriteThreads;   // number of committers at a time...\n\n        // query variables\n    final int percentRealtimeQuery = 60;\n    final AtomicLong operations = new AtomicLong(50000);  // number of query operations to perform in total\n    int nReadThreads = 5 + random().nextInt(25);\n\n\n    verbose(\"commitPercent=\", commitPercent);\n    verbose(\"softCommitPercent=\",softCommitPercent);\n    verbose(\"deletePercent=\",deletePercent);\n    verbose(\"deleteByQueryPercent=\", deleteByQueryPercent);\n    verbose(\"ndocs=\", ndocs);\n    verbose(\"nWriteThreads=\", nWriteThreads);\n    verbose(\"nReadThreads=\", nReadThreads);\n    verbose(\"percentRealtimeQuery=\", percentRealtimeQuery);\n    verbose(\"maxConcurrentCommits=\", maxConcurrentCommits);\n    verbose(\"operations=\", operations);\n\n\n    initModel(ndocs);\n\n    final AtomicInteger numCommitting = new AtomicInteger();\n\n    List<Thread> threads = new ArrayList<>();\n\n    for (int i=0; i<nWriteThreads; i++) {\n      Thread thread = new Thread(\"WRITER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n          while (operations.get() > 0) {\n            int oper = rand.nextInt(100);\n\n            if (oper < commitPercent) {\n              if (numCommitting.incrementAndGet() <= maxConcurrentCommits) {\n                Map<Integer,DocInfo> newCommittedModel;\n                long version;\n\n                synchronized(TestRealTimeGet.this) {\n                  newCommittedModel = new HashMap<>(model);  // take a snapshot\n                  version = snapshotCount++;\n                  verbose(\"took snapshot version=\",version);\n                }\n\n                if (rand.nextInt(100) < softCommitPercent) {\n                  verbose(\"softCommit start\");\n                  assertU(TestHarness.commit(\"softCommit\",\"true\"));\n                  verbose(\"softCommit end\");\n                } else {\n                  verbose(\"hardCommit start\");\n                  assertU(commit());\n                  verbose(\"hardCommit end\");\n                }\n\n                synchronized(TestRealTimeGet.this) {\n                  // install this model snapshot only if it's newer than the current one\n                  if (version >= committedModelClock) {\n                    if (VERBOSE) {\n                      verbose(\"installing new committedModel version=\"+committedModelClock);\n                    }\n                    committedModel = newCommittedModel;\n                    committedModelClock = version;\n                  }\n                }\n              }\n              numCommitting.decrementAndGet();\n              continue;\n            }\n\n\n            int id = rand.nextInt(ndocs);\n            Object sync = syncArr[id];\n\n            // set the lastId before we actually change it sometimes to try and\n            // uncover more race conditions between writing and reading\n            boolean before = rand.nextBoolean();\n            if (before) {\n              lastId = id;\n            }\n\n            // We can't concurrently update the same document and retain our invariants of increasing values\n            // since we can't guarantee what order the updates will be executed.\n            // Even with versions, we can't remove the sync because increasing versions does not mean increasing vals.\n            synchronized (sync) {\n              DocInfo info = model.get(id);\n\n              long val = info.val;\n              long nextVal = Math.abs(val)+1;\n\n              if (oper < commitPercent + deletePercent) {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"deleting id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"deleting id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                // assertU(\"<delete><id>\" + id + \"</id></delete>\");\n                Long version = null;\n\n                if (opt) {\n                  if (correct) {\n                    version = deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    SolrException se = expectThrows(SolrException.class, \"should not get random version\",\n                        () -> deleteAndGetVersion(Integer.toString(id), params(\"_version_\", Long.toString(badVersion))));\n                    assertEquals(409, se.code());\n                  }\n                } else {\n                  version = deleteAndGetVersion(Integer.toString(id), null);\n                }\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, -nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"deleting id\", id, \"val=\",nextVal,\"DONE\");\n                }\n              } else if (oper < commitPercent + deletePercent + deleteByQueryPercent) {\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id \",id, \"val=\",nextVal);\n                }\n\n                assertU(\"<delete><query>id:\" + id + \"</query></delete>\");\n                model.put(id, new DocInfo(-1L, -nextVal));\n                if (VERBOSE) {\n                  verbose(\"deleteByQuery id\",id, \"val=\",nextVal,\"DONE\");\n                }\n              } else {\n                boolean opt = rand.nextInt() < optimisticPercent;\n                boolean correct = opt ? rand.nextInt() < optimisticCorrectPercent : false;\n                long badVersion = correct ? 0 : badVersion(rand, info.version);\n\n                if (VERBOSE) {\n                  if (!opt) {\n                    verbose(\"adding id\",id,\"val=\",nextVal);\n                  } else {\n                    verbose(\"adding id\",id,\"val=\",nextVal, \"existing_version=\",info.version,  (correct ? \"\" : (\" bad_version=\" + badVersion)));\n                  }\n                }\n\n                Long version = null;\n                SolrInputDocument sd = sdoc(\"id\", Integer.toString(id), FIELD, Long.toString(nextVal));\n\n                if (opt) {\n                  if (correct) {\n                    version = addAndGetVersion(sd, params(\"_version_\", Long.toString(info.version)));\n                  } else {\n                    SolrException se = expectThrows(SolrException.class, \"should not get bad version\",\n                        () -> addAndGetVersion(sd, params(\"_version_\", Long.toString(badVersion))));\n                    assertEquals(409, se.code());\n                  }\n                } else {\n                  version = addAndGetVersion(sd, null);\n                }\n\n\n                if (version != null) {\n                  model.put(id, new DocInfo(version, nextVal));\n                }\n\n                if (VERBOSE) {\n                  verbose(\"adding id\", id, \"val=\", nextVal,\"DONE\");\n                }\n\n              }\n            }   // end sync\n\n            if (!before) {\n              lastId = id;\n            }\n          }\n        } catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n        }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (int i=0; i<nReadThreads; i++) {\n      Thread thread = new Thread(\"READER\"+i) {\n        Random rand = new Random(random().nextInt());\n\n        @Override\n        public void run() {\n          try {\n            while (operations.decrementAndGet() >= 0) {\n              // bias toward a recently changed doc\n              int id = rand.nextInt(100) < 25 ? lastId : rand.nextInt(ndocs);\n\n              // when indexing, we update the index, then the model\n              // so when querying, we should first check the model, and then the index\n\n              boolean realTime = rand.nextInt(100) < percentRealtimeQuery;\n              DocInfo info;\n\n              if (realTime) {\n                info = model.get(id);\n              } else {\n                synchronized(TestRealTimeGet.this) {\n                  info = committedModel.get(id);\n                }\n              }\n\n              if (VERBOSE) {\n                verbose(\"querying id\", id);\n              }\n\n              boolean filteredOut = false;\n              SolrQueryRequest sreq;\n              if (realTime) {\n                ModifiableSolrParams p = params(\"wt\",\"json\", \"qt\",\"/get\", \"ids\",Integer.toString(id));\n                if (rand.nextInt(100) < filteredGetPercent) {\n                  int idToFilter = rand.nextBoolean() ? id : rand.nextInt(ndocs);\n                  filteredOut = idToFilter != id;\n                  p.add(\"fq\", \"id:\"+idToFilter);\n                }\n                sreq = req(p);\n              } else {\n                sreq = req(\"wt\",\"json\", \"q\",\"id:\"+Integer.toString(id), \"omitHeader\",\"true\");\n              }\n\n              String response = h.query(sreq);\n              Map rsp = (Map) Utils.fromJSONString(response);\n              List doclist = (List)(((Map)rsp.get(\"response\")).get(\"docs\"));\n              if (doclist.size() == 0) {\n                // there's no info we can get back with a delete, so not much we can check without further synchronization\n                // This is also correct when filteredOut==true\n              } else {\n                assertEquals(1, doclist.size());\n                long foundVal = (Long)(((Map)doclist.get(0)).get(FIELD));\n                long foundVer = (Long)(((Map)doclist.get(0)).get(\"_version_\"));\n                if (filteredOut || foundVal < Math.abs(info.val)\n                    || (foundVer == info.version && foundVal != info.val) ) {    // if the version matches, the val must\n                  verbose(\"ERROR, id=\", id, \"found=\",response,\"model\",info);\n                  assertTrue(false);\n                }\n              }\n            }\n          }\n        catch (Throwable e) {\n          operations.set(-1L);\n          throw new RuntimeException(e);\n        }\n      }\n      };\n\n      threads.add(thread);\n    }\n\n\n    for (Thread thread : threads) {\n      thread.start();\n    }\n\n    for (Thread thread : threads) {\n      thread.join();\n    }\n\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"5de502b5478255493125e7e801411ba17a6682ec":["6554f36a4636755009195a7840518bf6b4f03d6c"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f","f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"49a4d79ca95e946251c9209af4952ed7db8b1026":["39c13c15172a8b9d27019144ee871d39e4d42a0a"],"6f20fd35e3055a0c5b387df0b986a68d65d86441":["6554f36a4636755009195a7840518bf6b4f03d6c"],"c615600525185e653f4176180f81b01a32cef120":["8441036e95d6b46771828fdaac1ff1575b23ec43"],"1bea3922196318026c4274f2013416acb60c691e":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"c00afe74a80796ed1f30a9509b150ff104746a1f":["73f40b658bbabc7fa3c8db81a47ba2e03af28f8a"],"e98520789adb1d5ad05afb4956eca0944a929688":["3714bcf66a68a1600e9dd11442fc1b33b62ef088"],"7a3554ff15950ad0e3bcbb4e4e2ddb45b0b0f27e":["bd0ef6574805f3cb9880e0983b7548a6aa933508"],"0d22ac6a4146774c1bc8400160fc0b6150294e92":["7a3554ff15950ad0e3bcbb4e4e2ddb45b0b0f27e","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"39c13c15172a8b9d27019144ee871d39e4d42a0a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"4aa2440480b1dcdc4da1711d161e7d62248dcabb":["41537328cfa3ccff80ac357efa2f357bccc17490"],"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf":["2b0085a9ec29ebc27be992a3712f4bd5d65d2106","6554f36a4636755009195a7840518bf6b4f03d6c"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"2b2e7536fb06d1abad6c7543a0657bdad5242c5e":["1bea3922196318026c4274f2013416acb60c691e"],"464e7336798bc8a1281d5cf610c649c5a0784e83":["5de502b5478255493125e7e801411ba17a6682ec"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["2b2e7536fb06d1abad6c7543a0657bdad5242c5e"],"73f40b658bbabc7fa3c8db81a47ba2e03af28f8a":["7d8e411397bc0d26f70339dbe2d59dc162d92237"],"6554f36a4636755009195a7840518bf6b4f03d6c":["2b0085a9ec29ebc27be992a3712f4bd5d65d2106"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"d8d4043f61e1bb9e99e8008fed9a79c6478826e1":["c00afe74a80796ed1f30a9509b150ff104746a1f"],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":["7a3554ff15950ad0e3bcbb4e4e2ddb45b0b0f27e","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"2b0085a9ec29ebc27be992a3712f4bd5d65d2106":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"3714bcf66a68a1600e9dd11442fc1b33b62ef088":["464e7336798bc8a1281d5cf610c649c5a0784e83"],"8441036e95d6b46771828fdaac1ff1575b23ec43":["49a4d79ca95e946251c9209af4952ed7db8b1026"],"41537328cfa3ccff80ac357efa2f357bccc17490":["c615600525185e653f4176180f81b01a32cef120"],"bd0ef6574805f3cb9880e0983b7548a6aa933508":["d8d4043f61e1bb9e99e8008fed9a79c6478826e1"],"7d8e411397bc0d26f70339dbe2d59dc162d92237":["4aa2440480b1dcdc4da1711d161e7d62248dcabb"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":["1bea3922196318026c4274f2013416acb60c691e","2b2e7536fb06d1abad6c7543a0657bdad5242c5e"],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["7a3554ff15950ad0e3bcbb4e4e2ddb45b0b0f27e"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["f08557cdb6c60ac7b88a9342c983a20cd236e74f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["e98520789adb1d5ad05afb4956eca0944a929688"]},"commit2Childs":{"5de502b5478255493125e7e801411ba17a6682ec":["464e7336798bc8a1281d5cf610c649c5a0784e83"],"9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab":[],"49a4d79ca95e946251c9209af4952ed7db8b1026":["8441036e95d6b46771828fdaac1ff1575b23ec43"],"6f20fd35e3055a0c5b387df0b986a68d65d86441":[],"c615600525185e653f4176180f81b01a32cef120":["41537328cfa3ccff80ac357efa2f357bccc17490"],"1bea3922196318026c4274f2013416acb60c691e":["2b2e7536fb06d1abad6c7543a0657bdad5242c5e","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"c00afe74a80796ed1f30a9509b150ff104746a1f":["d8d4043f61e1bb9e99e8008fed9a79c6478826e1"],"e98520789adb1d5ad05afb4956eca0944a929688":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"7a3554ff15950ad0e3bcbb4e4e2ddb45b0b0f27e":["0d22ac6a4146774c1bc8400160fc0b6150294e92","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","2c007e7c4cf8c55bc2a5884e315123afaaeec87f"],"0d22ac6a4146774c1bc8400160fc0b6150294e92":[],"39c13c15172a8b9d27019144ee871d39e4d42a0a":["49a4d79ca95e946251c9209af4952ed7db8b1026"],"4aa2440480b1dcdc4da1711d161e7d62248dcabb":["7d8e411397bc0d26f70339dbe2d59dc162d92237"],"5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf":[],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["39c13c15172a8b9d27019144ee871d39e4d42a0a"],"2b2e7536fb06d1abad6c7543a0657bdad5242c5e":["634f330c54fd3f9f491d52036dc3f40b4f4d8934","fe33227f6805edab2036cbb80645cc4e2d1fa424"],"464e7336798bc8a1281d5cf610c649c5a0784e83":["3714bcf66a68a1600e9dd11442fc1b33b62ef088"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["2b0085a9ec29ebc27be992a3712f4bd5d65d2106"],"73f40b658bbabc7fa3c8db81a47ba2e03af28f8a":["c00afe74a80796ed1f30a9509b150ff104746a1f"],"6554f36a4636755009195a7840518bf6b4f03d6c":["5de502b5478255493125e7e801411ba17a6682ec","6f20fd35e3055a0c5b387df0b986a68d65d86441","5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf"],"f08557cdb6c60ac7b88a9342c983a20cd236e74f":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"d8d4043f61e1bb9e99e8008fed9a79c6478826e1":["bd0ef6574805f3cb9880e0983b7548a6aa933508"],"a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d":[],"2b0085a9ec29ebc27be992a3712f4bd5d65d2106":["5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","6554f36a4636755009195a7840518bf6b4f03d6c"],"3714bcf66a68a1600e9dd11442fc1b33b62ef088":["e98520789adb1d5ad05afb4956eca0944a929688"],"8441036e95d6b46771828fdaac1ff1575b23ec43":["c615600525185e653f4176180f81b01a32cef120"],"41537328cfa3ccff80ac357efa2f357bccc17490":["4aa2440480b1dcdc4da1711d161e7d62248dcabb"],"bd0ef6574805f3cb9880e0983b7548a6aa933508":["7a3554ff15950ad0e3bcbb4e4e2ddb45b0b0f27e"],"7d8e411397bc0d26f70339dbe2d59dc162d92237":["73f40b658bbabc7fa3c8db81a47ba2e03af28f8a"],"fe33227f6805edab2036cbb80645cc4e2d1fa424":[],"2c007e7c4cf8c55bc2a5884e315123afaaeec87f":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","0d22ac6a4146774c1bc8400160fc0b6150294e92","f08557cdb6c60ac7b88a9342c983a20cd236e74f","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["1bea3922196318026c4274f2013416acb60c691e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["9946ea6d8ddf0b8c20b2ca6a816b7168b023a6ab","6f20fd35e3055a0c5b387df0b986a68d65d86441","0d22ac6a4146774c1bc8400160fc0b6150294e92","5acd68c5f07f7ee604c2eeffe801f4a2d7a1a5bf","a3c68e20c73359a10cf3eb4a35c9fa7ab1f3c30d","fe33227f6805edab2036cbb80645cc4e2d1fa424","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}