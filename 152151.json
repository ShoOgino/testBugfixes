{"path":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"46818a810eab72123f0e37e6ec5f2d426bd47be1","date":1331482161,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == (reader.normValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"38e3b736c7ca086d61b7dbb841c905ee115490da","date":1331657018,"type":3,"author":"Ryan McKinley","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == (reader.normValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == !reader.hasNorms(fi.name));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"629c38c4ae4e303d0617e05fbfe508140b32f0a3","date":1334500904,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == (reader.normValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == (reader.normValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"76923f6a33f2c4bec7f584e3f251261afe7ea276","date":1337149711,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.normValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == (reader.normValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"9d153abcf92dc5329d98571a8c3035df9bd80648","date":1337702630,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.normValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.normValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.normValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed) {\n        assertTrue(fi.omitNorms == (reader.normValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4","date":1341839195,"type":3,"author":"Uwe Schindler","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.normValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.normValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1d028314cced5858683a1bb4741423d0f934257b","date":1346596535,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.normValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField [] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.normValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0837ab0472feecb3a54260729d845f839e1cbd72","date":1358283639,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.simpleNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.normValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b8acf0807ca5f38beda8e0f7d5ab46ff39f81200","date":1358521790,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.simpleNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d4d69c535930b5cce125cff868d40f6373dc27d4","date":1360270101,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.normValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":["76923f6a33f2c4bec7f584e3f251261afe7ea276"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a45bec74b98f6fc05f52770cfb425739e6563960","date":1375119292,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","date":1376366778,"type":3,"author":"Han Jiang","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, DirectoryReader.DEFAULT_TERMS_INDEX_DIVISOR, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0","date":1383367127,"type":3,"author":"Shai Erera","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentInfoPerCommit info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.shutdown();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e","date":1406737224,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.shutdown();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.shutdown();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.shutdown();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"556a4aab886d75371b2af129d87be3c2795cea76","date":1414954991,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.getIndexOptions() != IndexOptions.NONE) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.isIndexed()) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c","date":1453060490,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.getIndexOptions() != IndexOptions.NONE) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n    StoredDocument doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    StorableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.getIndexOptions() != IndexOptions.NONE) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"31741cf1390044e38a2ec3127cf302ba841bfd75","date":1491292636,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.getIndexOptions() != IndexOptions.NONE) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.getIndexOptions() != IndexOptions.NONE) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"92212fd254551a0b1156aafc3a1a6ed1a43932ad","date":1491296431,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.getIndexOptions() != IndexOptions.NONE) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.getIndexOptions() != IndexOptions.NONE) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"790693f23f4e88a59fbb25e47cc25f6d493b03cb","date":1553077690,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, false, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.getIndexOptions() != IndexOptions.NONE) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.getIndexOptions() != IndexOptions.NONE) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"763da4a9605e47013078edc323b9d4b608f0f9e0","date":1555353576,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, false, newIOContext(random()), Collections.emptyMap());\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.getIndexOptions() != IndexOptions.NONE) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, false, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.getIndexOptions() != IndexOptions.NONE) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a4e83191a3e02851a0b67e5335e6922f3e9ea86d","date":1583489709,"type":3,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, false, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.getIndexOptions() != IndexOptions.NONE) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, false, newIOContext(random()), Collections.emptyMap());\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.getIndexOptions() != IndexOptions.NONE) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bec68e7c41fed133827595747d853cad504e481e","date":1583501052,"type":3,"author":"Bruno Roustant","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestDocumentWriter#testAddDocument().mjava","sourceNew":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.getIndexOptions() != IndexOptions.NONE) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","sourceOld":"  public void testAddDocument() throws Exception {\n    Document testDoc = new Document();\n    DocHelper.setupDoc(testDoc);\n    IndexWriter writer = new IndexWriter(dir, newIndexWriterConfig(new MockAnalyzer(random())));\n    writer.addDocument(testDoc);\n    writer.commit();\n    SegmentCommitInfo info = writer.newestSegment();\n    writer.close();\n    //After adding the document, we should be able to read it back in\n    SegmentReader reader = new SegmentReader(info, Version.LATEST.major, false, newIOContext(random()));\n    assertTrue(reader != null);\n    Document doc = reader.document(0);\n    assertTrue(doc != null);\n\n    //System.out.println(\"Document: \" + doc);\n    IndexableField[] fields = doc.getFields(\"textField2\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_2_TEXT));\n    assertTrue(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"textField1\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_1_TEXT));\n    assertFalse(fields[0].fieldType().storeTermVectors());\n\n    fields = doc.getFields(\"keyField\");\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.KEYWORD_TEXT));\n\n    fields = doc.getFields(DocHelper.NO_NORMS_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.NO_NORMS_TEXT));\n\n    fields = doc.getFields(DocHelper.TEXT_FIELD_3_KEY);\n    assertTrue(fields != null && fields.length == 1);\n    assertTrue(fields[0].stringValue().equals(DocHelper.FIELD_3_TEXT));\n\n    // test that the norms are not present in the segment if\n    // omitNorms is true\n    for (FieldInfo fi : reader.getFieldInfos()) {\n      if (fi.getIndexOptions() != IndexOptions.NONE) {\n        assertTrue(fi.omitsNorms() == (reader.getNormValues(fi.name) == null));\n      }\n    }\n    reader.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["a45bec74b98f6fc05f52770cfb425739e6563960"],"763da4a9605e47013078edc323b9d4b608f0f9e0":["790693f23f4e88a59fbb25e47cc25f6d493b03cb"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a4e83191a3e02851a0b67e5335e6922f3e9ea86d":["763da4a9605e47013078edc323b9d4b608f0f9e0"],"31741cf1390044e38a2ec3127cf302ba841bfd75":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"76923f6a33f2c4bec7f584e3f251261afe7ea276":["629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"1d028314cced5858683a1bb4741423d0f934257b":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4"],"b8acf0807ca5f38beda8e0f7d5ab46ff39f81200":["0837ab0472feecb3a54260729d845f839e1cbd72"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"0837ab0472feecb3a54260729d845f839e1cbd72":["1d028314cced5858683a1bb4741423d0f934257b"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"92212fd254551a0b1156aafc3a1a6ed1a43932ad":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["556a4aab886d75371b2af129d87be3c2795cea76"],"790693f23f4e88a59fbb25e47cc25f6d493b03cb":["31741cf1390044e38a2ec3127cf302ba841bfd75"],"38e3b736c7ca086d61b7dbb841c905ee115490da":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","46818a810eab72123f0e37e6ec5f2d426bd47be1"],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"a45bec74b98f6fc05f52770cfb425739e6563960":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["76923f6a33f2c4bec7f584e3f251261afe7ea276"],"bec68e7c41fed133827595747d853cad504e481e":["a4e83191a3e02851a0b67e5335e6922f3e9ea86d"],"556a4aab886d75371b2af129d87be3c2795cea76":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["629c38c4ae4e303d0617e05fbfe508140b32f0a3","9d153abcf92dc5329d98571a8c3035df9bd80648"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["1d028314cced5858683a1bb4741423d0f934257b","b8acf0807ca5f38beda8e0f7d5ab46ff39f81200"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"46818a810eab72123f0e37e6ec5f2d426bd47be1":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["46818a810eab72123f0e37e6ec5f2d426bd47be1"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["bec68e7c41fed133827595747d853cad504e481e"]},"commit2Childs":{"8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4":["1d028314cced5858683a1bb4741423d0f934257b"],"73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"763da4a9605e47013078edc323b9d4b608f0f9e0":["a4e83191a3e02851a0b67e5335e6922f3e9ea86d"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["38e3b736c7ca086d61b7dbb841c905ee115490da","46818a810eab72123f0e37e6ec5f2d426bd47be1"],"a4e83191a3e02851a0b67e5335e6922f3e9ea86d":["bec68e7c41fed133827595747d853cad504e481e"],"31741cf1390044e38a2ec3127cf302ba841bfd75":["790693f23f4e88a59fbb25e47cc25f6d493b03cb"],"76923f6a33f2c4bec7f584e3f251261afe7ea276":["9d153abcf92dc5329d98571a8c3035df9bd80648"],"1d028314cced5858683a1bb4741423d0f934257b":["0837ab0472feecb3a54260729d845f839e1cbd72","d4d69c535930b5cce125cff868d40f6373dc27d4"],"b8acf0807ca5f38beda8e0f7d5ab46ff39f81200":["d4d69c535930b5cce125cff868d40f6373dc27d4"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee":[],"0837ab0472feecb3a54260729d845f839e1cbd72":["b8acf0807ca5f38beda8e0f7d5ab46ff39f81200"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["54a6bea0b991120a99ad0e2f72ae853fd5ecae0e"],"92212fd254551a0b1156aafc3a1a6ed1a43932ad":[],"6654c5f3ec2e4a84ef867c82d4eec872c2372c8c":["31741cf1390044e38a2ec3127cf302ba841bfd75","92212fd254551a0b1156aafc3a1a6ed1a43932ad"],"790693f23f4e88a59fbb25e47cc25f6d493b03cb":["763da4a9605e47013078edc323b9d4b608f0f9e0"],"38e3b736c7ca086d61b7dbb841c905ee115490da":[],"54a6bea0b991120a99ad0e2f72ae853fd5ecae0e":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"a45bec74b98f6fc05f52770cfb425739e6563960":["73b0a97ef3bd519a5e43398ea9eabe6eed97f6b0"],"9d153abcf92dc5329d98571a8c3035df9bd80648":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"bec68e7c41fed133827595747d853cad504e481e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"556a4aab886d75371b2af129d87be3c2795cea76":["6654c5f3ec2e4a84ef867c82d4eec872c2372c8c"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["8f0e28f2a7f0f3f0fca1a2ffedaa10c7ac9536c4","1d028314cced5858683a1bb4741423d0f934257b"],"d4d69c535930b5cce125cff868d40f6373dc27d4":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","a45bec74b98f6fc05f52770cfb425739e6563960"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["556a4aab886d75371b2af129d87be3c2795cea76"],"46818a810eab72123f0e37e6ec5f2d426bd47be1":["38e3b736c7ca086d61b7dbb841c905ee115490da","629c38c4ae4e303d0617e05fbfe508140b32f0a3"],"629c38c4ae4e303d0617e05fbfe508140b32f0a3":["76923f6a33f2c4bec7f584e3f251261afe7ea276","615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["8989a9672fc1bb2d9a549a4f9005a7d0b0d728ee","92212fd254551a0b1156aafc3a1a6ed1a43932ad","38e3b736c7ca086d61b7dbb841c905ee115490da","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}