{"path":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","commits":[{"id":"b89678825b68eccaf09e6ab71675fc0b0af1e099","date":1334669779,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","pathOld":"lucene/contrib/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","sourceNew":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        termList.add(new TermInfo(term, dpEnum.startOffset(), dpEnum.endOffset(), pos));\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","sourceOld":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        termList.add(new TermInfo(term, dpEnum.startOffset(), dpEnum.endOffset(), pos));\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"79acd0ca7a7750de61516c6b6687a37c8765313b","date":1338910729,"type":3,"author":"Koji Sekiguchi","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","sourceNew":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.numDocs() - reader.numDeletedDocs();\n    float weight = 0;\n    \n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n        weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( fieldName, text ) + 1 ) ) + 1.0 );\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","sourceOld":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        termList.add(new TermInfo(term, dpEnum.startOffset(), dpEnum.endOffset(), pos));\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","bugFix":null,"bugIntro":["fb821cbfa5ecf725348dd3bc3878a9fadd24f725"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"322360ac5185a8446d3e0b530b2068bef67cd3d5","date":1343669494,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","sourceNew":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.numDocs() - reader.numDeletedDocs();\n    float weight = 0;\n    \n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n        weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( fieldName, text ) + 1 ) ) + 1.0 );\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","sourceOld":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.numDocs() - reader.numDeletedDocs();\n    float weight = 0;\n    \n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n        weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( fieldName, text ) + 1 ) ) + 1.0 );\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","date":1343768312,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","sourceNew":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.numDocs() - reader.numDeletedDocs();\n    float weight = 0;\n    \n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n        weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( fieldName, text ) + 1 ) ) + 1.0 );\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","sourceOld":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.numDocs() - reader.numDeletedDocs();\n    float weight = 0;\n    \n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n        weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( fieldName, text ) + 1 ) ) + 1.0 );\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"fb821cbfa5ecf725348dd3bc3878a9fadd24f725","date":1344264941,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","sourceNew":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( fieldName, text ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","sourceOld":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.numDocs() - reader.numDeletedDocs();\n    float weight = 0;\n    \n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n        weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( fieldName, text ) + 1 ) ) + 1.0 );\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","bugFix":["79acd0ca7a7750de61516c6b6687a37c8765313b"],"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"d6f074e73200c07d54f242d3880a8da5a35ff97b","date":1344507653,"type":3,"author":"Uwe Schindler","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","sourceNew":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( fieldName, text ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","sourceOld":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.numDocs() - reader.numDeletedDocs();\n    float weight = 0;\n    \n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum, true);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n        weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( fieldName, text ) + 1 ) ) + 1.0 );\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c7869f64c874ebf7f317d22c00baf2b6857797a6","date":1344856617,"type":3,"author":"Michael McCandless","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","sourceNew":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( fieldName, text ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","sourceOld":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.numDocs() - reader.numDeletedDocs();\n    float weight = 0;\n    \n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n        weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( fieldName, text ) + 1 ) ) + 1.0 );\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"b6a0e3c1c21aac8ecf75706605133012833585c7","date":1347535263,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","sourceNew":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","sourceOld":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( fieldName, text ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069","date":1348430063,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","sourceNew":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","sourceOld":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"0c066f7f6446f2d91513e81976f4b070a38763c7","date":1395242366,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","sourceNew":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n    \n    // now look for dups at the same position, linking them together\n    int currentPos = -1;\n    TermInfo previous = null;\n    TermInfo first = null;\n    Iterator<TermInfo> iterator = termList.iterator();\n    while (iterator.hasNext()) {\n      TermInfo current = iterator.next();\n      if (current.position == currentPos) {\n        assert previous != null;\n        previous.setNext(current);\n        previous = current;\n        iterator.remove();\n      } else {\n        if (previous != null) {\n          previous.setNext(first);\n        }\n        previous = first = current;\n        currentPos = current.position;\n      }\n    }\n    if (previous != null) {\n      previous.setNext(first);\n    }\n  }\n\n","sourceOld":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50","date":1407854805,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","sourceNew":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      spare.copyUTF8Bytes(text);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n    \n    // now look for dups at the same position, linking them together\n    int currentPos = -1;\n    TermInfo previous = null;\n    TermInfo first = null;\n    Iterator<TermInfo> iterator = termList.iterator();\n    while (iterator.hasNext()) {\n      TermInfo current = iterator.next();\n      if (current.position == currentPos) {\n        assert previous != null;\n        previous.setNext(current);\n        previous = current;\n        iterator.remove();\n      } else {\n        if (previous != null) {\n          previous.setNext(first);\n        }\n        previous = first = current;\n        currentPos = current.position;\n      }\n    }\n    if (previous != null) {\n      previous.setNext(first);\n    }\n  }\n\n","sourceOld":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRef spare = new CharsRef();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      UnicodeUtil.UTF8toUTF16(text, spare);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n    \n    // now look for dups at the same position, linking them together\n    int currentPos = -1;\n    TermInfo previous = null;\n    TermInfo first = null;\n    Iterator<TermInfo> iterator = termList.iterator();\n    while (iterator.hasNext()) {\n      TermInfo current = iterator.next();\n      if (current.position == currentPos) {\n        assert previous != null;\n        previous.setNext(current);\n        previous = current;\n        iterator.remove();\n      } else {\n        if (previous != null) {\n          previous.setNext(first);\n        }\n        previous = first = current;\n        currentPos = current.position;\n      }\n    }\n    if (previous != null) {\n      previous.setNext(first);\n    }\n  }\n\n","bugFix":["da6c07e76d701edbcc45c3e83ad8464a5e44a4c0","a1b3a24d5d9b47345473ff564f5cc127a7b526b4"],"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","sourceNew":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n    final TermsEnum termsEnum = vector.iterator(null);\n    PostingsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      spare.copyUTF8Bytes(text);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.FLAG_POSITIONS);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n    \n    // now look for dups at the same position, linking them together\n    int currentPos = -1;\n    TermInfo previous = null;\n    TermInfo first = null;\n    Iterator<TermInfo> iterator = termList.iterator();\n    while (iterator.hasNext()) {\n      TermInfo current = iterator.next();\n      if (current.position == currentPos) {\n        assert previous != null;\n        previous.setNext(current);\n        previous = current;\n        iterator.remove();\n      } else {\n        if (previous != null) {\n          previous.setNext(first);\n        }\n        previous = first = current;\n        currentPos = current.position;\n      }\n    }\n    if (previous != null) {\n      previous.setNext(first);\n    }\n  }\n\n","sourceOld":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n    final TermsEnum termsEnum = vector.iterator(null);\n    DocsAndPositionsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      spare.copyUTF8Bytes(text);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.docsAndPositions(null, dpEnum);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n    \n    // now look for dups at the same position, linking them together\n    int currentPos = -1;\n    TermInfo previous = null;\n    TermInfo first = null;\n    Iterator<TermInfo> iterator = termList.iterator();\n    while (iterator.hasNext()) {\n      TermInfo current = iterator.next();\n      if (current.position == currentPos) {\n        assert previous != null;\n        previous.setNext(current);\n        previous = current;\n        iterator.remove();\n      } else {\n        if (previous != null) {\n          previous.setNext(first);\n        }\n        previous = first = current;\n        currentPos = current.position;\n      }\n    }\n    if (previous != null) {\n      previous.setNext(first);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e73063b92d958076ef4ae8beb5f493e8ccdcecb4","date":1424177215,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","sourceNew":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n    final TermsEnum termsEnum = vector.iterator(null);\n    PostingsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      spare.copyUTF8Bytes(text);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.POSITIONS);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n    \n    // now look for dups at the same position, linking them together\n    int currentPos = -1;\n    TermInfo previous = null;\n    TermInfo first = null;\n    Iterator<TermInfo> iterator = termList.iterator();\n    while (iterator.hasNext()) {\n      TermInfo current = iterator.next();\n      if (current.position == currentPos) {\n        assert previous != null;\n        previous.setNext(current);\n        previous = current;\n        iterator.remove();\n      } else {\n        if (previous != null) {\n          previous.setNext(first);\n        }\n        previous = first = current;\n        currentPos = current.position;\n      }\n    }\n    if (previous != null) {\n      previous.setNext(first);\n    }\n  }\n\n","sourceOld":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n    final TermsEnum termsEnum = vector.iterator(null);\n    PostingsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      spare.copyUTF8Bytes(text);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.FLAG_POSITIONS);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n    \n    // now look for dups at the same position, linking them together\n    int currentPos = -1;\n    TermInfo previous = null;\n    TermInfo first = null;\n    Iterator<TermInfo> iterator = termList.iterator();\n    while (iterator.hasNext()) {\n      TermInfo current = iterator.next();\n      if (current.position == currentPos) {\n        assert previous != null;\n        previous.setNext(current);\n        previous = current;\n        iterator.remove();\n      } else {\n        if (previous != null) {\n          previous.setNext(first);\n        }\n        previous = first = current;\n        currentPos = current.position;\n      }\n    }\n    if (previous != null) {\n      previous.setNext(first);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"cb5311f0bff57ce15a23909f4cfb953773630534","date":1424827033,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","sourceNew":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n    final TermsEnum termsEnum = vector.iterator(null);\n    PostingsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      spare.copyUTF8Bytes(text);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      // nocommit: check\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.POSITIONS);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n    \n    // now look for dups at the same position, linking them together\n    int currentPos = -1;\n    TermInfo previous = null;\n    TermInfo first = null;\n    Iterator<TermInfo> iterator = termList.iterator();\n    while (iterator.hasNext()) {\n      TermInfo current = iterator.next();\n      if (current.position == currentPos) {\n        assert previous != null;\n        previous.setNext(current);\n        previous = current;\n        iterator.remove();\n      } else {\n        if (previous != null) {\n          previous.setNext(first);\n        }\n        previous = first = current;\n        currentPos = current.position;\n      }\n    }\n    if (previous != null) {\n      previous.setNext(first);\n    }\n  }\n\n","sourceOld":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n    final TermsEnum termsEnum = vector.iterator(null);\n    PostingsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      spare.copyUTF8Bytes(text);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.POSITIONS);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n    \n    // now look for dups at the same position, linking them together\n    int currentPos = -1;\n    TermInfo previous = null;\n    TermInfo first = null;\n    Iterator<TermInfo> iterator = termList.iterator();\n    while (iterator.hasNext()) {\n      TermInfo current = iterator.next();\n      if (current.position == currentPos) {\n        assert previous != null;\n        previous.setNext(current);\n        previous = current;\n        iterator.remove();\n      } else {\n        if (previous != null) {\n          previous.setNext(first);\n        }\n        previous = first = current;\n        currentPos = current.position;\n      }\n    }\n    if (previous != null) {\n      previous.setNext(first);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"26727660d8558b61512fa65b6dddab07cd0825c9","date":1427828573,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","sourceNew":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null || vector.hasPositions() == false) {\n      // null snippet\n      return;\n    }\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n    final TermsEnum termsEnum = vector.iterator(null);\n    PostingsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      spare.copyUTF8Bytes(text);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.POSITIONS);\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n    \n    // now look for dups at the same position, linking them together\n    int currentPos = -1;\n    TermInfo previous = null;\n    TermInfo first = null;\n    Iterator<TermInfo> iterator = termList.iterator();\n    while (iterator.hasNext()) {\n      TermInfo current = iterator.next();\n      if (current.position == currentPos) {\n        assert previous != null;\n        previous.setNext(current);\n        previous = current;\n        iterator.remove();\n      } else {\n        if (previous != null) {\n          previous.setNext(first);\n        }\n        previous = first = current;\n        currentPos = current.position;\n      }\n    }\n    if (previous != null) {\n      previous.setNext(first);\n    }\n  }\n\n","sourceOld":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n    final TermsEnum termsEnum = vector.iterator(null);\n    PostingsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      spare.copyUTF8Bytes(text);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      // nocommit: check\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.POSITIONS);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n    \n    // now look for dups at the same position, linking them together\n    int currentPos = -1;\n    TermInfo previous = null;\n    TermInfo first = null;\n    Iterator<TermInfo> iterator = termList.iterator();\n    while (iterator.hasNext()) {\n      TermInfo current = iterator.next();\n      if (current.position == currentPos) {\n        assert previous != null;\n        previous.setNext(current);\n        previous = current;\n        iterator.remove();\n      } else {\n        if (previous != null) {\n          previous.setNext(first);\n        }\n        previous = first = current;\n        currentPos = current.position;\n      }\n    }\n    if (previous != null) {\n      previous.setNext(first);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6b4e3cd382d0d075a0f1725649c084bb6510c483","date":1428096423,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","sourceNew":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null || vector.hasPositions() == false) {\n      // null snippet\n      return;\n    }\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n    final TermsEnum termsEnum = vector.iterator(null);\n    PostingsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      spare.copyUTF8Bytes(text);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.POSITIONS);\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n    \n    // now look for dups at the same position, linking them together\n    int currentPos = -1;\n    TermInfo previous = null;\n    TermInfo first = null;\n    Iterator<TermInfo> iterator = termList.iterator();\n    while (iterator.hasNext()) {\n      TermInfo current = iterator.next();\n      if (current.position == currentPos) {\n        assert previous != null;\n        previous.setNext(current);\n        previous = current;\n        iterator.remove();\n      } else {\n        if (previous != null) {\n          previous.setNext(first);\n        }\n        previous = first = current;\n        currentPos = current.position;\n      }\n    }\n    if (previous != null) {\n      previous.setNext(first);\n    }\n  }\n\n","sourceOld":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null) {\n      // null snippet\n      return;\n    }\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n    final TermsEnum termsEnum = vector.iterator(null);\n    PostingsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      spare.copyUTF8Bytes(text);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.POSITIONS);\n      if (dpEnum == null) {\n        // null snippet\n        return;\n      }\n\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n    \n    // now look for dups at the same position, linking them together\n    int currentPos = -1;\n    TermInfo previous = null;\n    TermInfo first = null;\n    Iterator<TermInfo> iterator = termList.iterator();\n    while (iterator.hasNext()) {\n      TermInfo current = iterator.next();\n      if (current.position == currentPos) {\n        assert previous != null;\n        previous.setNext(current);\n        previous = current;\n        iterator.remove();\n      } else {\n        if (previous != null) {\n          previous.setNext(first);\n        }\n        previous = first = current;\n        currentPos = current.position;\n      }\n    }\n    if (previous != null) {\n      previous.setNext(first);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","sourceNew":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null || vector.hasPositions() == false) {\n      // null snippet\n      return;\n    }\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n    final TermsEnum termsEnum = vector.iterator();\n    PostingsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      spare.copyUTF8Bytes(text);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.POSITIONS);\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n    \n    // now look for dups at the same position, linking them together\n    int currentPos = -1;\n    TermInfo previous = null;\n    TermInfo first = null;\n    Iterator<TermInfo> iterator = termList.iterator();\n    while (iterator.hasNext()) {\n      TermInfo current = iterator.next();\n      if (current.position == currentPos) {\n        assert previous != null;\n        previous.setNext(current);\n        previous = current;\n        iterator.remove();\n      } else {\n        if (previous != null) {\n          previous.setNext(first);\n        }\n        previous = first = current;\n        currentPos = current.position;\n      }\n    }\n    if (previous != null) {\n      previous.setNext(first);\n    }\n  }\n\n","sourceOld":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null || vector.hasPositions() == false) {\n      // null snippet\n      return;\n    }\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n    final TermsEnum termsEnum = vector.iterator(null);\n    PostingsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      spare.copyUTF8Bytes(text);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.POSITIONS);\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n    \n    // now look for dups at the same position, linking them together\n    int currentPos = -1;\n    TermInfo previous = null;\n    TermInfo first = null;\n    Iterator<TermInfo> iterator = termList.iterator();\n    while (iterator.hasNext()) {\n      TermInfo current = iterator.next();\n      if (current.position == currentPos) {\n        assert previous != null;\n        previous.setNext(current);\n        previous = current;\n        iterator.remove();\n      } else {\n        if (previous != null) {\n          previous.setNext(first);\n        }\n        previous = first = current;\n        currentPos = current.position;\n      }\n    }\n    if (previous != null) {\n      previous.setNext(first);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0f4464508ee83288c8c4585b533f9faaa93aa314","date":1435240759,"type":3,"author":"Adrien Grand","isMerge":false,"pathNew":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","pathOld":"lucene/highlighter/src/java/org/apache/lucene/search/vectorhighlight/FieldTermStack#FieldTermStack(IndexReader,int,String,FieldQuery).mjava","sourceNew":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null || vector.hasPositions() == false) {\n      // null snippet\n      return;\n    }\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n    final TermsEnum termsEnum = vector.iterator();\n    PostingsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      spare.copyUTF8Bytes(text);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.postings(dpEnum, PostingsEnum.POSITIONS);\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n    \n    // now look for dups at the same position, linking them together\n    int currentPos = -1;\n    TermInfo previous = null;\n    TermInfo first = null;\n    Iterator<TermInfo> iterator = termList.iterator();\n    while (iterator.hasNext()) {\n      TermInfo current = iterator.next();\n      if (current.position == currentPos) {\n        assert previous != null;\n        previous.setNext(current);\n        previous = current;\n        iterator.remove();\n      } else {\n        if (previous != null) {\n          previous.setNext(first);\n        }\n        previous = first = current;\n        currentPos = current.position;\n      }\n    }\n    if (previous != null) {\n      previous.setNext(first);\n    }\n  }\n\n","sourceOld":"  /**\n   * a constructor.\n   * \n   * @param reader IndexReader of the index\n   * @param docId document id to be highlighted\n   * @param fieldName field of the document to be highlighted\n   * @param fieldQuery FieldQuery object\n   * @throws IOException If there is a low-level I/O error\n   */\n  public FieldTermStack( IndexReader reader, int docId, String fieldName, final FieldQuery fieldQuery ) throws IOException {\n    this.fieldName = fieldName;\n    \n    Set<String> termSet = fieldQuery.getTermSet( fieldName );\n    // just return to make null snippet if un-matched fieldName specified when fieldMatch == true\n    if( termSet == null ) return;\n\n    final Fields vectors = reader.getTermVectors(docId);\n    if (vectors == null) {\n      // null snippet\n      return;\n    }\n\n    final Terms vector = vectors.terms(fieldName);\n    if (vector == null || vector.hasPositions() == false) {\n      // null snippet\n      return;\n    }\n\n    final CharsRefBuilder spare = new CharsRefBuilder();\n    final TermsEnum termsEnum = vector.iterator();\n    PostingsEnum dpEnum = null;\n    BytesRef text;\n    \n    int numDocs = reader.maxDoc();\n    \n    while ((text = termsEnum.next()) != null) {\n      spare.copyUTF8Bytes(text);\n      final String term = spare.toString();\n      if (!termSet.contains(term)) {\n        continue;\n      }\n      dpEnum = termsEnum.postings(null, dpEnum, PostingsEnum.POSITIONS);\n      dpEnum.nextDoc();\n      \n      // For weight look here: http://lucene.apache.org/core/3_6_0/api/core/org/apache/lucene/search/DefaultSimilarity.html\n      final float weight = ( float ) ( Math.log( numDocs / ( double ) ( reader.docFreq( new Term(fieldName, text) ) + 1 ) ) + 1.0 );\n\n      final int freq = dpEnum.freq();\n      \n      for(int i = 0;i < freq;i++) {\n        int pos = dpEnum.nextPosition();\n        if (dpEnum.startOffset() < 0) {\n          return; // no offsets, null snippet\n        }\n        termList.add( new TermInfo( term, dpEnum.startOffset(), dpEnum.endOffset(), pos, weight ) );\n      }\n    }\n    \n    // sort by position\n    Collections.sort(termList);\n    \n    // now look for dups at the same position, linking them together\n    int currentPos = -1;\n    TermInfo previous = null;\n    TermInfo first = null;\n    Iterator<TermInfo> iterator = termList.iterator();\n    while (iterator.hasNext()) {\n      TermInfo current = iterator.next();\n      if (current.position == currentPos) {\n        assert previous != null;\n        previous.setNext(current);\n        previous = current;\n        iterator.remove();\n      } else {\n        if (previous != null) {\n          previous.setNext(first);\n        }\n        previous = first = current;\n        currentPos = current.position;\n      }\n    }\n    if (previous != null) {\n      previous.setNext(first);\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["6b4e3cd382d0d075a0f1725649c084bb6510c483"],"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069":["b6a0e3c1c21aac8ecf75706605133012833585c7"],"fb821cbfa5ecf725348dd3bc3878a9fadd24f725":["322360ac5185a8446d3e0b530b2068bef67cd3d5"],"79acd0ca7a7750de61516c6b6687a37c8765313b":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["0c066f7f6446f2d91513e81976f4b070a38763c7"],"0c066f7f6446f2d91513e81976f4b070a38763c7":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069"],"51f5280f31484820499077f41fcdfe92d527d9dc":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"cb5311f0bff57ce15a23909f4cfb953773630534":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["51f5280f31484820499077f41fcdfe92d527d9dc"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","fb821cbfa5ecf725348dd3bc3878a9fadd24f725"],"6b4e3cd382d0d075a0f1725649c084bb6510c483":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4","26727660d8558b61512fa65b6dddab07cd0825c9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["79acd0ca7a7750de61516c6b6687a37c8765313b","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"b6a0e3c1c21aac8ecf75706605133012833585c7":["fb821cbfa5ecf725348dd3bc3878a9fadd24f725"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":["79acd0ca7a7750de61516c6b6687a37c8765313b","fb821cbfa5ecf725348dd3bc3878a9fadd24f725"],"26727660d8558b61512fa65b6dddab07cd0825c9":["cb5311f0bff57ce15a23909f4cfb953773630534"],"322360ac5185a8446d3e0b530b2068bef67cd3d5":["79acd0ca7a7750de61516c6b6687a37c8765313b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["0f4464508ee83288c8c4585b533f9faaa93aa314"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["0f4464508ee83288c8c4585b533f9faaa93aa314"],"c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069":["0c066f7f6446f2d91513e81976f4b070a38763c7"],"fb821cbfa5ecf725348dd3bc3878a9fadd24f725":["c7869f64c874ebf7f317d22c00baf2b6857797a6","b6a0e3c1c21aac8ecf75706605133012833585c7","d6f074e73200c07d54f242d3880a8da5a35ff97b"],"79acd0ca7a7750de61516c6b6687a37c8765313b":["b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f","d6f074e73200c07d54f242d3880a8da5a35ff97b","322360ac5185a8446d3e0b530b2068bef67cd3d5"],"7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50":["51f5280f31484820499077f41fcdfe92d527d9dc"],"0c066f7f6446f2d91513e81976f4b070a38763c7":["7dc6ea5fd38ce7aa8f36b3bac8b757da77f31d50"],"51f5280f31484820499077f41fcdfe92d527d9dc":["e73063b92d958076ef4ae8beb5f493e8ccdcecb4"],"cb5311f0bff57ce15a23909f4cfb953773630534":["26727660d8558b61512fa65b6dddab07cd0825c9"],"b89678825b68eccaf09e6ab71675fc0b0af1e099":["79acd0ca7a7750de61516c6b6687a37c8765313b"],"e73063b92d958076ef4ae8beb5f493e8ccdcecb4":["cb5311f0bff57ce15a23909f4cfb953773630534","6b4e3cd382d0d075a0f1725649c084bb6510c483"],"0f4464508ee83288c8c4585b533f9faaa93aa314":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"c7869f64c874ebf7f317d22c00baf2b6857797a6":[],"6b4e3cd382d0d075a0f1725649c084bb6510c483":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["b89678825b68eccaf09e6ab71675fc0b0af1e099"],"b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f":["c7869f64c874ebf7f317d22c00baf2b6857797a6"],"b6a0e3c1c21aac8ecf75706605133012833585c7":["c7bd1fdddb8e84c1857d1a55c32ced51f0ed2069"],"d6f074e73200c07d54f242d3880a8da5a35ff97b":[],"26727660d8558b61512fa65b6dddab07cd0825c9":["6b4e3cd382d0d075a0f1725649c084bb6510c483"],"322360ac5185a8446d3e0b530b2068bef67cd3d5":["fb821cbfa5ecf725348dd3bc3878a9fadd24f725","b7cbfe9a112ef62d75f3289e4c79bbe274cb2a4f"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c7869f64c874ebf7f317d22c00baf2b6857797a6","d6f074e73200c07d54f242d3880a8da5a35ff97b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}