{"path":"lucene/contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLucene1133().mjava","commits":[{"id":"9454a6510e2db155fb01faa5c049b06ece95fab9","date":1453508333,"type":1,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLucene1133().mjava","pathOld":"contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLucene1133().mjava","sourceNew":"  public void testLucene1133() throws Exception {\n    Set<String> untoks = new HashSet<String>();\n    untoks.add(WikipediaTokenizer.CATEGORY);\n    untoks.add(WikipediaTokenizer.ITALICS);\n    //should be exactly the same, regardless of untoks\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(LINK_PHRASES), WikipediaTokenizer.TOKENS_ONLY, untoks);\n    checkLinkPhrases(tf);\n    String test = \"[[Category:a b c d]] [[Category:e f g]] [[link here]] [[link there]] ''italics here'' something ''more italics'' [[Category:h   i   j]]\";\n    tf = new WikipediaTokenizer(new StringReader(test), WikipediaTokenizer.UNTOKENIZED_ONLY, untoks);\n    TermAttribute termAtt = tf.addAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = tf.addAttribute(PositionIncrementAttribute.class);\n    OffsetAttribute offsetAtt = tf.addAttribute(OffsetAttribute.class);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"a b c d\",\n        termAtt.term().equals(\"a b c d\") == true);\n    assertTrue(posIncrAtt.getPositionIncrement() + \" does not equal: \" + 1, posIncrAtt.getPositionIncrement() == 1);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 11, offsetAtt.startOffset() == 11);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 18, offsetAtt.endOffset() == 18);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"e f g\",\n        termAtt.term().equals(\"e f g\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 32, offsetAtt.startOffset() == 32);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 37, offsetAtt.endOffset() == 37);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"link\",\n        termAtt.term().equals(\"link\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 42, offsetAtt.startOffset() == 42);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 46, offsetAtt.endOffset() == 46);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"here\",\n        termAtt.term().equals(\"here\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 47, offsetAtt.startOffset() == 47);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 51, offsetAtt.endOffset() == 51);\n\n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"link\",\n        termAtt.term().equals(\"link\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 56, offsetAtt.startOffset() == 56);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 60, offsetAtt.endOffset() == 60);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"there\",\n        termAtt.term().equals(\"there\") == true);\n\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 61, offsetAtt.startOffset() == 61);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 66, offsetAtt.endOffset() == 66);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"italics here\",\n        termAtt.term().equals(\"italics here\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 71, offsetAtt.startOffset() == 71);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 83, offsetAtt.endOffset() == 83);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"something\",\n        termAtt.term().equals(\"something\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 86, offsetAtt.startOffset() == 86);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 95, offsetAtt.endOffset() == 95);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"more italics\",\n        termAtt.term().equals(\"more italics\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 98, offsetAtt.startOffset() == 98);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 110, offsetAtt.endOffset() == 110);\n\n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"h   i   j\",\n        termAtt.term().equals(\"h   i   j\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 124, offsetAtt.startOffset() == 124);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 133, offsetAtt.endOffset() == 133);\n\n    assertFalse(tf.incrementToken());\n  }\n\n","sourceOld":"  public void testLucene1133() throws Exception {\n    Set<String> untoks = new HashSet<String>();\n    untoks.add(WikipediaTokenizer.CATEGORY);\n    untoks.add(WikipediaTokenizer.ITALICS);\n    //should be exactly the same, regardless of untoks\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(LINK_PHRASES), WikipediaTokenizer.TOKENS_ONLY, untoks);\n    checkLinkPhrases(tf);\n    String test = \"[[Category:a b c d]] [[Category:e f g]] [[link here]] [[link there]] ''italics here'' something ''more italics'' [[Category:h   i   j]]\";\n    tf = new WikipediaTokenizer(new StringReader(test), WikipediaTokenizer.UNTOKENIZED_ONLY, untoks);\n    TermAttribute termAtt = tf.addAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = tf.addAttribute(PositionIncrementAttribute.class);\n    OffsetAttribute offsetAtt = tf.addAttribute(OffsetAttribute.class);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"a b c d\",\n        termAtt.term().equals(\"a b c d\") == true);\n    assertTrue(posIncrAtt.getPositionIncrement() + \" does not equal: \" + 1, posIncrAtt.getPositionIncrement() == 1);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 11, offsetAtt.startOffset() == 11);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 18, offsetAtt.endOffset() == 18);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"e f g\",\n        termAtt.term().equals(\"e f g\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 32, offsetAtt.startOffset() == 32);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 37, offsetAtt.endOffset() == 37);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"link\",\n        termAtt.term().equals(\"link\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 42, offsetAtt.startOffset() == 42);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 46, offsetAtt.endOffset() == 46);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"here\",\n        termAtt.term().equals(\"here\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 47, offsetAtt.startOffset() == 47);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 51, offsetAtt.endOffset() == 51);\n\n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"link\",\n        termAtt.term().equals(\"link\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 56, offsetAtt.startOffset() == 56);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 60, offsetAtt.endOffset() == 60);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"there\",\n        termAtt.term().equals(\"there\") == true);\n\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 61, offsetAtt.startOffset() == 61);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 66, offsetAtt.endOffset() == 66);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"italics here\",\n        termAtt.term().equals(\"italics here\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 71, offsetAtt.startOffset() == 71);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 83, offsetAtt.endOffset() == 83);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"something\",\n        termAtt.term().equals(\"something\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 86, offsetAtt.startOffset() == 86);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 95, offsetAtt.endOffset() == 95);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"more italics\",\n        termAtt.term().equals(\"more italics\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 98, offsetAtt.startOffset() == 98);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 110, offsetAtt.endOffset() == 110);\n\n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"h   i   j\",\n        termAtt.term().equals(\"h   i   j\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 124, offsetAtt.startOffset() == 124);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 133, offsetAtt.endOffset() == 133);\n\n    assertFalse(tf.incrementToken());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"344d7fb38511184be27e3eba27408ad5f634b91c","date":1270838455,"type":5,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/contrib/analyzers/common/src/test/org/apache/lucene/analysis/wikipedia/WikipediaTokenizerTest#testLucene1133().mjava","pathOld":"lucene/contrib/wikipedia/src/test/org/apache/lucene/wikipedia/analysis/WikipediaTokenizerTest#testLucene1133().mjava","sourceNew":"  public void testLucene1133() throws Exception {\n    Set<String> untoks = new HashSet<String>();\n    untoks.add(WikipediaTokenizer.CATEGORY);\n    untoks.add(WikipediaTokenizer.ITALICS);\n    //should be exactly the same, regardless of untoks\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(LINK_PHRASES), WikipediaTokenizer.TOKENS_ONLY, untoks);\n    checkLinkPhrases(tf);\n    String test = \"[[Category:a b c d]] [[Category:e f g]] [[link here]] [[link there]] ''italics here'' something ''more italics'' [[Category:h   i   j]]\";\n    tf = new WikipediaTokenizer(new StringReader(test), WikipediaTokenizer.UNTOKENIZED_ONLY, untoks);\n    TermAttribute termAtt = tf.addAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = tf.addAttribute(PositionIncrementAttribute.class);\n    OffsetAttribute offsetAtt = tf.addAttribute(OffsetAttribute.class);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"a b c d\",\n        termAtt.term().equals(\"a b c d\") == true);\n    assertTrue(posIncrAtt.getPositionIncrement() + \" does not equal: \" + 1, posIncrAtt.getPositionIncrement() == 1);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 11, offsetAtt.startOffset() == 11);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 18, offsetAtt.endOffset() == 18);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"e f g\",\n        termAtt.term().equals(\"e f g\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 32, offsetAtt.startOffset() == 32);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 37, offsetAtt.endOffset() == 37);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"link\",\n        termAtt.term().equals(\"link\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 42, offsetAtt.startOffset() == 42);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 46, offsetAtt.endOffset() == 46);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"here\",\n        termAtt.term().equals(\"here\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 47, offsetAtt.startOffset() == 47);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 51, offsetAtt.endOffset() == 51);\n\n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"link\",\n        termAtt.term().equals(\"link\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 56, offsetAtt.startOffset() == 56);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 60, offsetAtt.endOffset() == 60);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"there\",\n        termAtt.term().equals(\"there\") == true);\n\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 61, offsetAtt.startOffset() == 61);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 66, offsetAtt.endOffset() == 66);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"italics here\",\n        termAtt.term().equals(\"italics here\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 71, offsetAtt.startOffset() == 71);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 83, offsetAtt.endOffset() == 83);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"something\",\n        termAtt.term().equals(\"something\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 86, offsetAtt.startOffset() == 86);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 95, offsetAtt.endOffset() == 95);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"more italics\",\n        termAtt.term().equals(\"more italics\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 98, offsetAtt.startOffset() == 98);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 110, offsetAtt.endOffset() == 110);\n\n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"h   i   j\",\n        termAtt.term().equals(\"h   i   j\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 124, offsetAtt.startOffset() == 124);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 133, offsetAtt.endOffset() == 133);\n\n    assertFalse(tf.incrementToken());\n  }\n\n","sourceOld":"  public void testLucene1133() throws Exception {\n    Set<String> untoks = new HashSet<String>();\n    untoks.add(WikipediaTokenizer.CATEGORY);\n    untoks.add(WikipediaTokenizer.ITALICS);\n    //should be exactly the same, regardless of untoks\n    WikipediaTokenizer tf = new WikipediaTokenizer(new StringReader(LINK_PHRASES), WikipediaTokenizer.TOKENS_ONLY, untoks);\n    checkLinkPhrases(tf);\n    String test = \"[[Category:a b c d]] [[Category:e f g]] [[link here]] [[link there]] ''italics here'' something ''more italics'' [[Category:h   i   j]]\";\n    tf = new WikipediaTokenizer(new StringReader(test), WikipediaTokenizer.UNTOKENIZED_ONLY, untoks);\n    TermAttribute termAtt = tf.addAttribute(TermAttribute.class);\n    PositionIncrementAttribute posIncrAtt = tf.addAttribute(PositionIncrementAttribute.class);\n    OffsetAttribute offsetAtt = tf.addAttribute(OffsetAttribute.class);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"a b c d\",\n        termAtt.term().equals(\"a b c d\") == true);\n    assertTrue(posIncrAtt.getPositionIncrement() + \" does not equal: \" + 1, posIncrAtt.getPositionIncrement() == 1);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 11, offsetAtt.startOffset() == 11);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 18, offsetAtt.endOffset() == 18);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"e f g\",\n        termAtt.term().equals(\"e f g\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 32, offsetAtt.startOffset() == 32);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 37, offsetAtt.endOffset() == 37);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"link\",\n        termAtt.term().equals(\"link\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 42, offsetAtt.startOffset() == 42);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 46, offsetAtt.endOffset() == 46);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"here\",\n        termAtt.term().equals(\"here\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 47, offsetAtt.startOffset() == 47);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 51, offsetAtt.endOffset() == 51);\n\n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"link\",\n        termAtt.term().equals(\"link\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 56, offsetAtt.startOffset() == 56);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 60, offsetAtt.endOffset() == 60);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"there\",\n        termAtt.term().equals(\"there\") == true);\n\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 61, offsetAtt.startOffset() == 61);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 66, offsetAtt.endOffset() == 66);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"italics here\",\n        termAtt.term().equals(\"italics here\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 71, offsetAtt.startOffset() == 71);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 83, offsetAtt.endOffset() == 83);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"something\",\n        termAtt.term().equals(\"something\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 86, offsetAtt.startOffset() == 86);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 95, offsetAtt.endOffset() == 95);\n    \n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"more italics\",\n        termAtt.term().equals(\"more italics\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 98, offsetAtt.startOffset() == 98);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 110, offsetAtt.endOffset() == 110);\n\n    assertTrue(tf.incrementToken());\n    assertTrue(termAtt.term() + \" is not equal to \" + \"h   i   j\",\n        termAtt.term().equals(\"h   i   j\") == true);\n    assertTrue(offsetAtt.startOffset() + \" does not equal: \" + 124, offsetAtt.startOffset() == 124);\n    assertTrue(offsetAtt.endOffset() + \" does not equal: \" + 133, offsetAtt.endOffset() == 133);\n\n    assertFalse(tf.incrementToken());\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"344d7fb38511184be27e3eba27408ad5f634b91c":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["344d7fb38511184be27e3eba27408ad5f634b91c"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"344d7fb38511184be27e3eba27408ad5f634b91c":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["9454a6510e2db155fb01faa5c049b06ece95fab9"],"9454a6510e2db155fb01faa5c049b06ece95fab9":["344d7fb38511184be27e3eba27408ad5f634b91c"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}