{"path":"src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","commits":[{"id":"68df8db3f6c0c0ebbd1e40ba638115a748fb6a2a","date":1240390408,"type":0,"author":"Shalin Shekhar Mangar","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"/dev/null","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<List<NamedList>> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n      TokenStream tokenStream = analyzer.tokenStream(context.getFieldName(), new StringReader(value));\n      NamedList<List<NamedList>> namedList = new SimpleOrderedMap<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n\n    NamedList<List<NamedList>> namedList = new SimpleOrderedMap<List<NamedList>>();\n\n    TokenStream tokenStream = tokenizerChain.getTokenizerFactory().create(new StringReader(value));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : tokenizerChain.getTokenFilterFactories()) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":["be29e0e2cef1fd569147732e48caf8538790339b","f4dcc36aaf3ab07f15e069adf183b7e6de5dcccb","77e6111c8c695bcab271a048bf5aae6b05cf415b","77e6111c8c695bcab271a048bf5aae6b05cf415b","77e6111c8c695bcab271a048bf5aae6b05cf415b","782ed6a4b4ba50ec19734fc8db4e570ee193d627","782ed6a4b4ba50ec19734fc8db4e570ee193d627","782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"be29e0e2cef1fd569147732e48caf8538790339b","date":1250443738,"type":3,"author":"Yonik Seeley","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<List<NamedList>> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new SimpleOrderedMap<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n\n    NamedList<List<NamedList>> namedList = new SimpleOrderedMap<List<NamedList>>();\n\n    TokenStream tokenStream = tokenizerChain.getTokenizerFactory().create(new StringReader(value));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : tokenizerChain.getTokenFilterFactories()) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<List<NamedList>> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n      TokenStream tokenStream = analyzer.tokenStream(context.getFieldName(), new StringReader(value));\n      NamedList<List<NamedList>> namedList = new SimpleOrderedMap<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n\n    NamedList<List<NamedList>> namedList = new SimpleOrderedMap<List<NamedList>>();\n\n    TokenStream tokenStream = tokenizerChain.getTokenizerFactory().create(new StringReader(value));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : tokenizerChain.getTokenFilterFactories()) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","bugFix":["68df8db3f6c0c0ebbd1e40ba638115a748fb6a2a"],"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627","782ed6a4b4ba50ec19734fc8db4e570ee193d627","782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f4dcc36aaf3ab07f15e069adf183b7e6de5dcccb","date":1250701272,"type":3,"author":"Koji Sekiguchi","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<List<NamedList>> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new SimpleOrderedMap<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<List<NamedList>> namedList = new SimpleOrderedMap<List<NamedList>>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<List<NamedList>> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new SimpleOrderedMap<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n\n    NamedList<List<NamedList>> namedList = new SimpleOrderedMap<List<NamedList>>();\n\n    TokenStream tokenStream = tokenizerChain.getTokenizerFactory().create(new StringReader(value));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : tokenizerChain.getTokenFilterFactories()) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","bugFix":["68df8db3f6c0c0ebbd1e40ba638115a748fb6a2a"],"bugIntro":["1486037b0fcc4d552ab91d319279d41d68fe6a94","1486037b0fcc4d552ab91d319279d41d68fe6a94","1486037b0fcc4d552ab91d319279d41d68fe6a94"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"c75ad090b206e619a5fbf1b70a0ffd1f5c840a16","date":1256036507,"type":3,"author":"Koji Sekiguchi","isMerge":false,"pathNew":"src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<List<NamedList>> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<List<NamedList>> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new SimpleOrderedMap<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<List<NamedList>> namedList = new SimpleOrderedMap<List<NamedList>>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":["782ed6a4b4ba50ec19734fc8db4e570ee193d627","782ed6a4b4ba50ec19734fc8db4e570ee193d627","782ed6a4b4ba50ec19734fc8db4e570ee193d627"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"ad94625fb8d088209f46650c8097196fec67f00c","date":1453508319,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","pathOld":"src/java/org/apache/solr/handler/AnalysisRequestHandlerBase#analyzeValue(String,AnalysisContext).mjava","sourceNew":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<List<NamedList>> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","sourceOld":"  /**\n   * Analyzes the given value using the given Analyzer.\n   *\n   * @param value   Value to analyze\n   * @param context The {@link AnalysisContext analysis context}.\n   *\n   * @return NamedList containing the tokens produced by analyzing the given value\n   */\n  protected NamedList<List<NamedList>> analyzeValue(String value, AnalysisContext context) {\n\n    Analyzer analyzer = context.getAnalyzer();\n\n    if (!TokenizerChain.class.isInstance(analyzer)) {\n\n      TokenStream tokenStream = null;\n      try {\n        tokenStream = analyzer.reusableTokenStream(context.getFieldName(), new StringReader(value));\n        tokenStream.reset();\n      } catch (IOException e) {\n        throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, e);\n      }\n      NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(analyzeTokenStream(tokenStream), context));\n      return namedList;\n    }\n\n    TokenizerChain tokenizerChain = (TokenizerChain) analyzer;\n    CharFilterFactory[] cfiltfacs = tokenizerChain.getCharFilterFactories();\n    TokenizerFactory tfac = tokenizerChain.getTokenizerFactory();\n    TokenFilterFactory[] filtfacs = tokenizerChain.getTokenFilterFactories();\n\n    NamedList<List<NamedList>> namedList = new NamedList<List<NamedList>>();\n\n    if( cfiltfacs != null ){\n      String source = value;\n      for(CharFilterFactory cfiltfac : cfiltfacs ){\n        CharStream reader = CharReader.get(new StringReader(source));\n        reader = cfiltfac.create(reader);\n        source = writeCharStream(namedList, reader);\n      }\n    }\n\n    TokenStream tokenStream = tfac.create(tokenizerChain.charStream(new StringReader(value)));\n    List<Token> tokens = analyzeTokenStream(tokenStream);\n\n    namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokens, context));\n\n    ListBasedTokenStream listBasedTokenStream = new ListBasedTokenStream(tokens);\n\n    for (TokenFilterFactory tokenFilterFactory : filtfacs) {\n      tokenStream = tokenFilterFactory.create(listBasedTokenStream);\n      List<Token> tokenList = analyzeTokenStream(tokenStream);\n      namedList.add(tokenStream.getClass().getName(), convertTokensToNamedLists(tokenList, context));\n      listBasedTokenStream = new ListBasedTokenStream(tokenList);\n    }\n\n    return namedList;\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"68df8db3f6c0c0ebbd1e40ba638115a748fb6a2a":["3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":[],"be29e0e2cef1fd569147732e48caf8538790339b":["68df8db3f6c0c0ebbd1e40ba638115a748fb6a2a"],"ad94625fb8d088209f46650c8097196fec67f00c":["c75ad090b206e619a5fbf1b70a0ffd1f5c840a16"],"c75ad090b206e619a5fbf1b70a0ffd1f5c840a16":["f4dcc36aaf3ab07f15e069adf183b7e6de5dcccb"],"f4dcc36aaf3ab07f15e069adf183b7e6de5dcccb":["be29e0e2cef1fd569147732e48caf8538790339b"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"68df8db3f6c0c0ebbd1e40ba638115a748fb6a2a":["be29e0e2cef1fd569147732e48caf8538790339b"],"3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b":["68df8db3f6c0c0ebbd1e40ba638115a748fb6a2a"],"be29e0e2cef1fd569147732e48caf8538790339b":["f4dcc36aaf3ab07f15e069adf183b7e6de5dcccb"],"ad94625fb8d088209f46650c8097196fec67f00c":[],"c75ad090b206e619a5fbf1b70a0ffd1f5c840a16":["ad94625fb8d088209f46650c8097196fec67f00c"],"f4dcc36aaf3ab07f15e069adf183b7e6de5dcccb":["c75ad090b206e619a5fbf1b70a0ffd1f5c840a16"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["ad94625fb8d088209f46650c8097196fec67f00c","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","3cdb369a6112bacd5f5fc1d4e022bed2f8bffb9b"],"pathCommit":null}