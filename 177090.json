{"path":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","commits":[{"id":"dd04250707c52f2a0cecd6303dcc85617b122f6d","date":1304372426,"type":1,"author":"Ryan McKinley","isMerge":false,"pathNew":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(List[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","sourceNew":"  static void parseRules(Iterable<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","sourceOld":"  static void parseRules(List<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c700f8d0842d3e52bb2bdfbfdc046a137e836edb","date":1305285499,"type":1,"author":"Simon Willnauer","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(List[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","sourceNew":"  static void parseRules(Iterable<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","sourceOld":"  static void parseRules(List<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":0,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","pathOld":"/dev/null","sourceNew":"  static void parseRules(Iterable<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c903c3d15906a3da96b8c0c2fb704491005fdbdb","date":1453508227,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","sourceNew":"  static void parseRules(Iterable<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","sourceOld":"  static void parseRules(Iterable<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a258fbb26824fd104ed795e5d9033d2d040049ee","date":1453508252,"type":5,"author":"Dawid Weiss","isMerge":false,"pathNew":"solr/core/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","sourceNew":"  static void parseRules(Iterable<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","sourceOld":"  static void parseRules(Iterable<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c26f00b574427b55127e869b935845554afde1fa","date":1310252513,"type":5,"author":"Steven Rowe","isMerge":true,"pathNew":"solr/core/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","pathOld":"solr/src/java/org/apache/solr/analysis/SynonymFilterFactory#parseRules(Iterable[String],SynonymMap,String,String,boolean,TokenizerFactory).mjava","sourceNew":"  static void parseRules(Iterable<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","sourceOld":"  static void parseRules(Iterable<String> rules, SynonymMap map, String mappingSep,\n    String synSep, boolean expansion, TokenizerFactory tokFactory) {\n    int count=0;\n    for (String rule : rules) {\n      // To use regexes, we need an expression that specifies an odd number of chars.\n      // This can't really be done with string.split(), and since we need to\n      // do unescaping at some point anyway, we wouldn't be saving any effort\n      // by using regexes.\n\n      List<String> mapping = StrUtils.splitSmart(rule, mappingSep, false);\n\n      List<List<String>> source;\n      List<List<String>> target;\n\n      if (mapping.size() > 2) {\n        throw new RuntimeException(\"Invalid Synonym Rule:\" + rule);\n      } else if (mapping.size()==2) {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        target = getSynList(mapping.get(1), synSep, tokFactory);\n      } else {\n        source = getSynList(mapping.get(0), synSep, tokFactory);\n        if (expansion) {\n          // expand to all arguments\n          target = source;\n        } else {\n          // reduce to first argument\n          target = new ArrayList<List<String>>(1);\n          target.add(source.get(0));\n        }\n      }\n\n      boolean includeOrig=false;\n      for (List<String> fromToks : source) {\n        count++;\n        for (List<String> toToks : target) {\n          map.add(fromToks,\n                  SynonymMap.makeTokens(toToks),\n                  includeOrig,\n                  true\n          );\n        }\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["a3776dccca01c11e7046323cfad46a3b4a471233"],"c26f00b574427b55127e869b935845554afde1fa":["dd04250707c52f2a0cecd6303dcc85617b122f6d","c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"a3776dccca01c11e7046323cfad46a3b4a471233":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","dd04250707c52f2a0cecd6303dcc85617b122f6d"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","dd04250707c52f2a0cecd6303dcc85617b122f6d"],"a258fbb26824fd104ed795e5d9033d2d040049ee":["dd04250707c52f2a0cecd6303dcc85617b122f6d"],"dd04250707c52f2a0cecd6303dcc85617b122f6d":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["c26f00b574427b55127e869b935845554afde1fa"]},"commit2Childs":{"c903c3d15906a3da96b8c0c2fb704491005fdbdb":["c26f00b574427b55127e869b935845554afde1fa"],"a3776dccca01c11e7046323cfad46a3b4a471233":["c903c3d15906a3da96b8c0c2fb704491005fdbdb"],"c26f00b574427b55127e869b935845554afde1fa":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","dd04250707c52f2a0cecd6303dcc85617b122f6d"],"c700f8d0842d3e52bb2bdfbfdc046a137e836edb":[],"a258fbb26824fd104ed795e5d9033d2d040049ee":[],"dd04250707c52f2a0cecd6303dcc85617b122f6d":["c26f00b574427b55127e869b935845554afde1fa","a3776dccca01c11e7046323cfad46a3b4a471233","c700f8d0842d3e52bb2bdfbfdc046a137e836edb","a258fbb26824fd104ed795e5d9033d2d040049ee"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["c700f8d0842d3e52bb2bdfbfdc046a137e836edb","a258fbb26824fd104ed795e5d9033d2d040049ee","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}