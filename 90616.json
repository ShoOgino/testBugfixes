{"path":"solr/core/src/test/org/apache/solr/search/facet/TestJsonFacetRefinement#testSortedFacetRefinementPushingNonRefinedBucketBackIntoTopN().mjava","commits":[{"id":"84a99d9041ffa5585158e5a283ea1736b6b8b473","date":1532019928,"type":0,"author":"Chris Hostetter","isMerge":false,"pathNew":"solr/core/src/test/org/apache/solr/search/facet/TestJsonFacetRefinement#testSortedFacetRefinementPushingNonRefinedBucketBackIntoTopN().mjava","pathOld":"/dev/null","sourceNew":"  @Test\n  public void testSortedFacetRefinementPushingNonRefinedBucketBackIntoTopN() throws Exception {\n    initServers();\n    final Client client = servers.getClient(random().nextInt());\n    client.queryDefaults().set(\"shards\", servers.getShards(), \"debugQuery\", Boolean.toString(random().nextBoolean()));\n\n    List<SolrClient> clients = client.getClientProvider().all();\n    assertTrue(clients.size() >= 3); // we only use 2, but assert 3 to also test empty shard\n    final SolrClient c0 = clients.get(0);\n    final SolrClient c1 = clients.get(1);\n\n    client.deleteByQuery(\"*:*\", null);\n    int id = 0;\n\n    // all_ss is only used for sub-faceting...\n    // every doc will be in all_ss:z_all, (most c1 docs will be in all_ss:some\n    // (with index order tie breaker, c1 should return \"some\" when limit:1\n    //  but \"z_all\" should have a higher count from c0)\n    \n    // client 0 // shard1: A=1,B=1,C=2 ...\n    c0.add(sdoc(\"id\", id++, \"cat_s\",\"A\", \"price_i\",\"1\", \"all_ss\",\"z_all\"));\n    c0.add(sdoc(\"id\", id++, \"cat_s\",\"B\", \"price_i\",\"1\", \"all_ss\",\"z_all\"));\n    c0.add(sdoc(\"id\", id++, \"cat_s\",\"C\", \"price_i\",\"1\", \"all_ss\",\"z_all\"));\n    c0.add(sdoc(\"id\", id++, \"cat_s\",\"C\", \"price_i\",\"1\", \"all_ss\",\"z_all\"));\n    // ... X=3,Y=3\n    c0.add(sdoc(\"id\", id++, \"cat_s\",\"X\", \"price_i\",\"1\", \"all_ss\",\"z_all\"));\n    c0.add(sdoc(\"id\", id++, \"cat_s\",\"X\", \"price_i\",\"1\", \"all_ss\",\"z_all\"));\n    c0.add(sdoc(\"id\", id++, \"cat_s\",\"X\", \"price_i\",\"1\", \"all_ss\",\"z_all\"));\n    c0.add(sdoc(\"id\", id++, \"cat_s\",\"Y\", \"price_i\",\"1\", \"all_ss\",\"z_all\"));\n    c0.add(sdoc(\"id\", id++, \"cat_s\",\"Y\", \"price_i\",\"1\", \"all_ss\",\"z_all\"));\n    c0.add(sdoc(\"id\", id++, \"cat_s\",\"Y\", \"price_i\",\"1\", \"all_ss\",\"z_all\"));\n    \n    // client 1 // shard2: X=1,Y=2,Z=2 ...\n    c1.add(sdoc(\"id\", id++, \"cat_s\",\"X\", \"price_i\",\"1\", \"all_ss\",\"z_all\",\"all_ss\",\"some\"));\n    c1.add(sdoc(\"id\", id++, \"cat_s\",\"Y\", \"price_i\",\"1\", \"all_ss\",\"z_all\",\"all_ss\",\"some\"));\n    c1.add(sdoc(\"id\", id++, \"cat_s\",\"Y\", \"price_i\",\"1\", \"all_ss\",\"z_all\",\"all_ss\",\"some\"));\n    c1.add(sdoc(\"id\", id++, \"cat_s\",\"Z\", \"price_i\",\"1\", \"all_ss\",\"z_all\",\"all_ss\",\"some\"));\n    c1.add(sdoc(\"id\", id++, \"cat_s\",\"Z\", \"price_i\",\"1\", \"all_ss\",\"z_all\",\"all_ss\",\"some\"));\n    // ... C=4\n    c1.add(sdoc(\"id\", id++, \"cat_s\",\"C\", \"price_i\",\"1\", \"all_ss\",\"z_all\",\"all_ss\",\"some\"));\n    c1.add(sdoc(\"id\", id++, \"cat_s\",\"C\", \"price_i\",\"1\", \"all_ss\",\"z_all\",\"all_ss\",\"some\"));\n    c1.add(sdoc(\"id\", id++, \"cat_s\",\"C\", \"price_i\",\"1\", \"all_ss\",\"z_all\",\"all_ss\",\"some\"));\n    c1.add(sdoc(\"id\", id++, \"cat_s\",\"C\", \"price_i\",\"1\", \"all_ss\",\"z_all\",\"all_ss\",\"some\"));\n\n    // the amount of overrequest shouldn't matter for demonstrating the issue...\n    // it only changes how many C_fillerN & Z_fillerN terms are needed on each shard\n    final int overreq = TestUtil.nextInt(random(),0,20);\n    \n    // for overreq=n: C_n:(x2 on client0 + x4 on client1); Z_n:(x2 on client1)\n    for (int i = 0; i < overreq; i++) {\n      for (int t = 0; t < 2; t++) {\n        c0.add(sdoc(\"id\", id++, \"cat_s\",\"C_filler\"+i, \"price_i\",\"1\", \"all_ss\",\"z_all\"));\n        c1.add(sdoc(\"id\", id++, \"cat_s\",\"Z_filler\"+i, \"price_i\",\"1\", \"all_ss\",\"z_all\",\"all_ss\",\"some\"));\n      }\n      for (int t = 0; t < 4; t++) {\n        c1.add(sdoc(\"id\", id++, \"cat_s\",\"C_filler\"+i, \"price_i\",\"1\", \"all_ss\",\"z_all\",\"all_ss\",\"some\"));\n        // extra c0 docs that don't contribute to the cat_s facet,...\n        // just so \"z_all\" will win overall on parent facet\n        c0.add(sdoc(\"id\", id++, \"all_ss\",\"z_all\"));\n      }\n    }\n\n    \n    // Whole Collection: A=1,B=1,Z=2,X=4,Y=5,C=6\n    client.commit();\n    \n    // In an ideal world, 'Z:2' would be returned as the 3rd value,\n    // but neither C or Z make the topN cut in phase#1, so only A,B,X get refined.\n    // After refinement, X's increased values should *NOT* push it out of the (original) topN\n    // to let \"C\" bubble back up into the topN, with incomplete/inaccurate count/stats\n    // (NOTE: hueristic for num buckets refined is based on 'overrequest' unless explicit 'overrefine')\n    client.testJQ(params(\"q\", \"*:*\", \"rows\", \"0\", \"json.facet\", \"{\"\n                         + \" cat_count:{ type:terms, field:cat_s, limit:3, overrequest:\"+overreq\n                         + \"             , refine:true, sort:'count asc' },\"\n                         + \" cat_price:{ type:terms, field:cat_s, limit:3, overrequest:\"+overreq\n                         + \"             , refine:true, sort:'sum_p asc' \"\n                         + \"             , facet: { sum_p: 'sum(price_i)' } }\"\n                         + \"}\")\n                  , \"facets=={ count: \"+id+\",\"\n                  + \"  cat_count:{ buckets:[ \"\n                  + \"               {val:A,count:1},\"\n                  + \"               {val:B,count:1},\"\n                  + \"               {val:X,count:4},\"\n                  + \"  ] },\"\n                  + \"  cat_price:{ buckets:[ \"\n                  + \"               {val:A,count:1,sum_p:1.0},\"\n                  + \"               {val:B,count:1,sum_p:1.0},\"\n                  + \"               {val:X,count:4,sum_p:4.0},\"\n                  + \"  ] }\"\n                  + \"}\"\n                  );\n    \n    // if we do the same query but explicitly request enough overrefinement to get past the filler\n    // terms, we should get accurate counts for (C and) Z which should push X out\n    client.testJQ(params(\"q\", \"*:*\", \"rows\", \"0\", \"json.facet\", \"{\"\n                         + \" cat_count:{ type:terms, field:cat_s, limit:3, overrequest:\"+overreq\n                         + \"             , overrefine:\"+((1+overreq)*3)+\", refine:true, sort:'count asc' },\"\n                         + \" cat_price:{ type:terms, field:cat_s, limit:3, overrequest:\"+overreq\n                         + \"             , overrefine:\"+((1+overreq)*3)+\", refine:true, sort:'sum_p asc' \"\n                         + \"             , facet: { sum_p: 'sum(price_i)' } }\"\n                         + \"}\")\n                  , \"facets=={ count: \"+id+\",\"\n                  + \"  cat_count:{ buckets:[ \"\n                  + \"               {val:A,count:1},\"\n                  + \"               {val:B,count:1},\"\n                  + \"               {val:Z,count:2},\"\n                  + \"  ] },\"\n                  + \"  cat_price:{ buckets:[ \"\n                  + \"               {val:A,count:1,sum_p:1.0},\"\n                  + \"               {val:B,count:1,sum_p:1.0},\"\n                  + \"               {val:Z,count:2,sum_p:2.0},\"\n                  + \"  ] }\"\n                  + \"}\"\n                  );\n    \n    // if we use mincount=2, such that A & B get filtered out, then we should have buckets.size() < limit\n    // rather then buckets w/inaccurate counts/stats.\n    // (explicitly disabling overrefine & overrequest to prevent filler terms)\n    client.testJQ(params(\"q\", \"*:*\", \"rows\", \"0\", \"json.facet\", \"{\"\n                         + \" cat_count:{ type:terms, field:cat_s, limit:3, overrequest: 0, overrefine: 0\"\n                         + \"             , mincount: 2, refine:true, sort:'count asc' },\"\n                         + \" cat_price:{ type:terms, field:cat_s, limit:3, overrequest: 0, overrefine: 0\"\n                         + \"             , mincount: 2, refine:true, sort:'sum_p asc' \"\n                         + \"             , facet: { sum_p: 'sum(price_i)' } }\"\n                         + \"}\")\n                  , \"facets=={ count: \"+id+\",\"\n                  + \"  cat_count:{ buckets:[ \"\n                  + \"               {val:X,count:4},\"\n                  + \"  ] },\"\n                  + \"  cat_price:{ buckets:[ \"\n                  + \"               {val:X,count:4,sum_p:4.0},\"\n                  + \"  ] }\"\n                  + \"}\"\n                  );\n\n    // When our 'cat_s' facets are nested under an 'all_ss' facet, we should likewise not get\n    // any (sub) buckets with incomplete/inaccurate counts\n    //\n    // NOTE: parent facet limit is 1, testing with various top level overrequest/refine params to see\n    // how different refinement code paths of parent effect the child refinement\n    for (String top_refine : Arrays.asList(\"true\", \"false\")) {\n      // if our top level facet does *NO* overrequesting, then our shard1 will return \"some\" as it's\n      // (only) top term, which will lose to \"z_all\" from shard0, and the (single pass) refinement\n      // logic will have no choice but to choose & refine the child facet terms from shard0: A,B,C\n      client.testJQ(params(\"q\", \"*:*\", \"rows\", \"0\", \"json.facet\", \"{\"\n                           + \" all:{ type:terms, field:all_ss, limit:1, refine:\"+top_refine\n                           +        \", overrequest:0\"\n                           + \"       , facet:{\"\n                           + \"   cat_count:{ type:terms, field:cat_s, limit:3, overrequest:\"+overreq\n                           + \"               , refine:true, sort:'count asc' },\"\n                           + \"   cat_price:{ type:terms, field:cat_s, limit:3, overrequest:\"+overreq\n                           + \"               , refine:true, sort:'sum_p asc' \"\n                           + \"               , facet: { sum_p: 'sum(price_i)' } }\"\n                           + \"} } }\")\n                    , \"facets=={ count: \"+id+\",\"\n                    + \"all:{ buckets:[ \"\n                    + \"  { val:z_all, count: \"+id+\",\"\n                    + \"    cat_count:{ buckets:[ \"\n                    + \"                 {val:A,count:1},\"\n                    + \"                 {val:B,count:1},\"\n                    + \"                 {val:C,count:6},\"\n                    + \"    ] },\"\n                    + \"    cat_price:{ buckets:[ \"\n                    + \"                 {val:A,count:1,sum_p:1.0},\"\n                    + \"                 {val:B,count:1,sum_p:1.0},\"\n                    + \"                 {val:C,count:6,sum_p:6.0},\"\n                    + \"    ] }\"\n                    + \"} ] } }\"\n                    );\n\n      // With any overrequest param > 0 on the parent facet, both shards will return \"z_all\" as a\n      // viable candidate and the merge logic should recoginize that X is a better choice,\n      // even though the (single shard) stats for \"C\" will be lower\n      final int top_over = TestUtil.nextInt(random(), 1, 999);\n      client.testJQ(params(\"q\", \"*:*\", \"rows\", \"0\", \"json.facet\", \"{\"\n                           + \" all:{ type:terms, field:all_ss, limit:1, refine:\"+top_refine\n                           +        \", overrequest:\" + top_over\n                           + \"       , facet:{\"\n                           + \"   cat_count:{ type:terms, field:cat_s, limit:3, overrequest:\"+overreq\n                           + \"               , refine:true, sort:'count asc' },\"\n                           + \"   cat_price:{ type:terms, field:cat_s, limit:3, overrequest:\"+overreq\n                           + \"               , refine:true, sort:'sum_p asc' \"\n                           + \"               , facet: { sum_p: 'sum(price_i)' } }\"\n                           + \"} } }\")\n                    , \"facets=={ count: \"+id+\",\"\n                    + \"all:{ buckets:[ \"\n                    + \"  { val:z_all, count: \"+id+\",\"\n                    + \"    cat_count:{ buckets:[ \"\n                    + \"                 {val:A,count:1},\"\n                    + \"                 {val:B,count:1},\"\n                    + \"                 {val:X,count:4},\"\n                    + \"    ] },\"\n                    + \"    cat_price:{ buckets:[ \"\n                    + \"                 {val:A,count:1,sum_p:1.0},\"\n                    + \"                 {val:B,count:1,sum_p:1.0},\"\n                    + \"                 {val:X,count:4,sum_p:4.0},\"\n                    + \"    ] }\"\n                    + \"} ] } }\"\n                    );\n\n      // if we do the same query but explicitly request enough overrefinement on the child facet\n      // to get past the filler terms, we should get accurate counts for (C and) Z which should push X out\n      client.testJQ(params(\"q\", \"*:*\", \"rows\", \"0\", \"json.facet\", \"{\"\n                           + \" all:{ type:terms, field:all_ss, limit:1, refine:\"+top_refine\n                           +        \", overrequest:\" + top_over\n                           + \"       , facet:{\"\n                           + \"   cat_count:{ type:terms, field:cat_s, limit:3, overrequest:\"+((1+overreq)*3)\n                           + \"               , refine:true, sort:'count asc' },\"\n                           + \"   cat_price:{ type:terms, field:cat_s, limit:3, overrequest:\"+((1+overreq)*3)\n                           + \"               , refine:true, sort:'sum_p asc' \"\n                           + \"               , facet: { sum_p: 'sum(price_i)' } }\"\n                           + \"} } }\")\n                    , \"facets=={ count: \"+id+\",\"\n                    + \"all:{ buckets:[ \"\n                    + \"  { val:z_all, count: \"+id+\",\"\n                    + \"    cat_count:{ buckets:[ \"\n                    + \"                 {val:A,count:1},\"\n                    + \"                 {val:B,count:1},\"\n                    + \"                 {val:Z,count:2},\"\n                    + \"    ] },\"\n                    + \"    cat_price:{ buckets:[ \"\n                    + \"                 {val:A,count:1,sum_p:1.0},\"\n                    + \"                 {val:B,count:1,sum_p:1.0},\"\n                    + \"                 {val:Z,count:2,sum_p:2.0},\"\n                    + \"    ] }\"\n                    + \"} ] } }\"\n                    );\n\n    }\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"84a99d9041ffa5585158e5a283ea1736b6b8b473":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["84a99d9041ffa5585158e5a283ea1736b6b8b473"]},"commit2Childs":{"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["84a99d9041ffa5585158e5a283ea1736b6b8b473"],"84a99d9041ffa5585158e5a283ea1736b6b8b473":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}