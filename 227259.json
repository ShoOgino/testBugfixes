{"path":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","commits":[{"id":"84b590669deb3d3a471cec6cb13b104b2ee94418","date":1288889547,"type":1,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCorruptionAfterDiskFullDuringMerge().mjava","sourceNew":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()).setReaderPooling(true));\n\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(2);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()).setReaderPooling(true));\n\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(2);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"85a883878c0af761245ab048babc63d099f835f3","date":1289553330,"type":1,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriter#testCorruptionAfterDiskFullDuringMerge().mjava","sourceNew":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()).setReaderPooling(true));\n\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(2);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()).setReaderPooling(true));\n\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(2);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4e8cc373c801e54cec75daf9f52792cb4b17f536","date":1291116159,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","sourceNew":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()).setReaderPooling(true));\n\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(2);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3bb13258feba31ab676502787ab2e1779f129b7a","date":1291596436,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","sourceNew":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setMergeScheduler(new SerialMergeScheduler()).setReaderPooling(true));\n\n    ((LogMergePolicy) w.getMergePolicy()).setMergeFactor(2);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","date":1292920096,"type":0,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","pathOld":"/dev/null","sourceNew":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3","date":1297940445,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","sourceNew":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"f1bdbf92da222965b46c0a942c3857ba56e5c638","date":1298297608,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","sourceNew":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"bde51b089eb7f86171eb3406e38a274743f9b7ac","date":1298336439,"type":3,"author":"Michael Busch","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","sourceNew":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"f2c5f0cb44df114db4228c8f77861714b5cabaea","date":1302542431,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","sourceNew":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"962d04139994fce5193143ef35615499a9a96d78","date":1302693744,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","sourceNew":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"135621f3a0670a9394eb563224a3b76cc4dddc0f","date":1304344257,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","sourceNew":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a3776dccca01c11e7046323cfad46a3b4a471233","date":1306100719,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","sourceNew":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer()).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ff6fd241dc6610f7f81b62e3ba4cedf105939623","date":1307331653,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","sourceNew":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"79c2cb24929f2649a8875fb629086171f914d5ce","date":1307332717,"type":3,"author":"Steven Rowe","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","sourceNew":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"77cf4379b2824f6ea34b091c495d6e95c38ff9e2","date":1307610475,"type":3,"author":"Simon Willnauer","isMerge":true,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","sourceNew":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    _TestUtil.checkIndex(dir);\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c00afe74a80796ed1f30a9509b150ff104746a1f","date":1312881735,"type":3,"author":"Simon Willnauer","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","sourceNew":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1 || ftdm.didFail2);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    dir.close();\n  }\n\n","bugFix":["1085ea837da8f1e96697e17cf73e1d08e7329261"],"bugIntro":["05fe562aa248790944d43cdd478f512572835ba0"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"1509f151d7692d84fae414b2b799ac06ba60fcb4","date":1314451621,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","sourceNew":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n\n    doc.add(newField(\"f\", \"doctor who\", TextField.TYPE_UNSTORED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1 || ftdm.didFail2);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n    doc.add(newField(\"f\", \"doctor who\", Field.Store.YES, Field.Index.ANALYZED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1 || ftdm.didFail2);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":["04f07771a2a7dd3a395700665ed839c3dae2def2"],"isBuggy":true,"nexts":[],"revCommit":null},{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":5,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","pathOld":"lucene/src/test/org/apache/lucene/index/TestIndexWriterOnDiskFull#testCorruptionAfterDiskFullDuringMerge().mjava","sourceNew":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n\n    doc.add(newField(\"f\", \"doctor who\", TextField.TYPE_UNSTORED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1 || ftdm.didFail2);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    dir.close();\n  }\n\n","sourceOld":"  // LUCENE-2593\n  public void testCorruptionAfterDiskFullDuringMerge() throws IOException {\n    MockDirectoryWrapper dir = newDirectory();\n    //IndexWriter w = new IndexWriter(dir, newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).setReaderPooling(true));\n    IndexWriter w = new IndexWriter(\n        dir,\n        newIndexWriterConfig(TEST_VERSION_CURRENT, new MockAnalyzer(random)).\n            setMergeScheduler(new SerialMergeScheduler()).\n            setReaderPooling(true).\n            setMergePolicy(newLogMergePolicy(2))\n    );\n    _TestUtil.keepFullyDeletedSegments(w);\n\n    Document doc = new Document();\n\n    doc.add(newField(\"f\", \"doctor who\", TextField.TYPE_UNSTORED));\n    w.addDocument(doc);\n    w.commit();\n\n    w.deleteDocuments(new Term(\"f\", \"who\"));\n    w.addDocument(doc);\n    \n    // disk fills up!\n    FailTwiceDuringMerge ftdm = new FailTwiceDuringMerge();\n    ftdm.setDoFail();\n    dir.failOn(ftdm);\n\n    try {\n      w.commit();\n      fail(\"fake disk full IOExceptions not hit\");\n    } catch (IOException ioe) {\n      // expected\n      assertTrue(ftdm.didFail1 || ftdm.didFail2);\n    }\n    _TestUtil.checkIndex(dir);\n    ftdm.clearDoFail();\n    w.addDocument(doc);\n    w.close();\n\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":true,"nexts":[],"revCommit":null}],"commit2Parents":{"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["f2c5f0cb44df114db4228c8f77861714b5cabaea"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":["3bb13258feba31ab676502787ab2e1779f129b7a","e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"85a883878c0af761245ab048babc63d099f835f3":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","84b590669deb3d3a471cec6cb13b104b2ee94418"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["f1bdbf92da222965b46c0a942c3857ba56e5c638","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"962d04139994fce5193143ef35615499a9a96d78":["bde51b089eb7f86171eb3406e38a274743f9b7ac","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"c00afe74a80796ed1f30a9509b150ff104746a1f":["ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3":["4e8cc373c801e54cec75daf9f52792cb4b17f536"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3"],"84b590669deb3d3a471cec6cb13b104b2ee94418":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"79c2cb24929f2649a8875fb629086171f914d5ce":["a3776dccca01c11e7046323cfad46a3b4a471233","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"a3776dccca01c11e7046323cfad46a3b4a471233":["e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3","f2c5f0cb44df114db4228c8f77861714b5cabaea"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":["135621f3a0670a9394eb563224a3b76cc4dddc0f","ff6fd241dc6610f7f81b62e3ba4cedf105939623"],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["c00afe74a80796ed1f30a9509b150ff104746a1f"],"3bb13258feba31ab676502787ab2e1779f129b7a":["85a883878c0af761245ab048babc63d099f835f3","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["84b590669deb3d3a471cec6cb13b104b2ee94418"]},"commit2Childs":{"ff6fd241dc6610f7f81b62e3ba4cedf105939623":["c00afe74a80796ed1f30a9509b150ff104746a1f","79c2cb24929f2649a8875fb629086171f914d5ce","77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"f1bdbf92da222965b46c0a942c3857ba56e5c638":["135621f3a0670a9394eb563224a3b76cc4dddc0f"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"85a883878c0af761245ab048babc63d099f835f3":["3bb13258feba31ab676502787ab2e1779f129b7a"],"135621f3a0670a9394eb563224a3b76cc4dddc0f":["77cf4379b2824f6ea34b091c495d6e95c38ff9e2"],"962d04139994fce5193143ef35615499a9a96d78":[],"7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a":["bde51b089eb7f86171eb3406e38a274743f9b7ac"],"c00afe74a80796ed1f30a9509b150ff104746a1f":["1509f151d7692d84fae414b2b799ac06ba60fcb4"],"e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3":["f1bdbf92da222965b46c0a942c3857ba56e5c638","f2c5f0cb44df114db4228c8f77861714b5cabaea","a3776dccca01c11e7046323cfad46a3b4a471233","bde51b089eb7f86171eb3406e38a274743f9b7ac"],"f2c5f0cb44df114db4228c8f77861714b5cabaea":["ff6fd241dc6610f7f81b62e3ba4cedf105939623","135621f3a0670a9394eb563224a3b76cc4dddc0f","962d04139994fce5193143ef35615499a9a96d78","a3776dccca01c11e7046323cfad46a3b4a471233"],"84b590669deb3d3a471cec6cb13b104b2ee94418":["85a883878c0af761245ab048babc63d099f835f3","4e8cc373c801e54cec75daf9f52792cb4b17f536"],"79c2cb24929f2649a8875fb629086171f914d5ce":[],"a3776dccca01c11e7046323cfad46a3b4a471233":["79c2cb24929f2649a8875fb629086171f914d5ce"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["85a883878c0af761245ab048babc63d099f835f3","7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","84b590669deb3d3a471cec6cb13b104b2ee94418"],"77cf4379b2824f6ea34b091c495d6e95c38ff9e2":[],"1509f151d7692d84fae414b2b799ac06ba60fcb4":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"3bb13258feba31ab676502787ab2e1779f129b7a":["f1bdbf92da222965b46c0a942c3857ba56e5c638"],"bde51b089eb7f86171eb3406e38a274743f9b7ac":["962d04139994fce5193143ef35615499a9a96d78"],"4e8cc373c801e54cec75daf9f52792cb4b17f536":["7c65bc241a96282ca59ae736b4ffb5b7e5eeb23a","e69553ac9cbe3b2693b93c2fb0c211529b8ee4c3","3bb13258feba31ab676502787ab2e1779f129b7a"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["962d04139994fce5193143ef35615499a9a96d78","79c2cb24929f2649a8875fb629086171f914d5ce","77cf4379b2824f6ea34b091c495d6e95c38ff9e2","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}