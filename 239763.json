{"path":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","commits":[{"id":"86eb564c1d8d07da8b8cad1508dc1116c2f1ec2b","date":1349729649,"type":0,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"/dev/null","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":null,"bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"74b894c584342b7b718eb81d6318f69cdefc2a70","date":1352996144,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(_TestUtil.getPostingsFormat(\"field\"));\n\n    if (isSimpleText && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"429430d016e19235864e88ee07192080f778033d","date":1354488586,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(_TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(_TestUtil.getPostingsFormat(\"field\"));\n\n    if (isSimpleText && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"407687e67faf6e1f02a211ca078d8e3eed631027","date":1355157407,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(_TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6613659748fe4411a7dcf85266e55db1f95f7315","date":1392773913,"type":3,"author":"Benson Margulies","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1 && !doesntSupportOffsets.contains(TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = _TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(_TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(_TestUtil.getTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = _TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1 && !doesntSupportOffsets.contains(_TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"634f330c54fd3f9f491d52036dc3f40b4f4d8934","date":1394635157,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1 && !doesntSupportOffsets.contains(TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<String>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<String>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1 && !doesntSupportOffsets.contains(TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0d579490a72f2e6297eaa648940611234c57cf1","date":1395917140,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1 && !doesntSupportOffsets.contains(TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1 && !doesntSupportOffsets.contains(TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"91d86ebcdb45ce6a1b2584e2603f76db47523d0a","date":1396466913,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1 && !doesntSupportOffsets.contains(TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"5eb2511ababf862ea11e10761c70ee560cd84510","date":1396607225,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1 && !doesntSupportOffsets.contains(TestUtil.getPostingsFormat(\"field\"))) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c","date":1396633078,"type":3,"author":"Dawid Weiss","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"2a0f5bb79c600763ffe7b8141df59a3169d31e48","date":1396689440,"type":3,"author":"Dawid Weiss","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(TestUtil.getTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"ae14298f4eec6d5faee6a149f88ba57d14a6f21a","date":1396971290,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.shutdown();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"d0ef034a4f10871667ae75181537775ddcf8ade4","date":1407610475,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), TEST_VERSION_CURRENT, new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.shutdown();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"c9fb5f46e264daf5ba3860defe623a89d202dd87","date":1411516315,"type":3,"author":"Ryan Ernst","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    AtomicReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"51f5280f31484820499077f41fcdfe92d527d9dc","date":1423229122,"type":3,"author":"Alan Woodward","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a postingsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a docsAndPositionsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","date":1428522487,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a postingsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator(null);\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a postingsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"eeea025b4a7a8e8f70426ac4527ef481b3a86b72","date":1476199075,"type":3,"author":"yonik","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    FieldType fieldType = new FieldType(TextField.TYPE_NOT_STORED);\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a postingsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a postingsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"4cce5816ef15a48a0bc11e5d400497ee4301dd3b","date":1476991456,"type":3,"author":"Kevin Risden","isMerge":true,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    FieldType fieldType = new FieldType(TextField.TYPE_NOT_STORED);\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a postingsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    Field prototype = newTextField(\"field\", \"\", Field.Store.NO);\n    FieldType fieldType = new FieldType(prototype.fieldType());\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a postingsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f","date":1579652839,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","pathOld":"lucene/core/src/test/org/apache/lucene/index/TestBagOfPositions#test().mjava","sourceNew":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(100);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    FieldType fieldType = new FieldType(TextField.TYPE_NOT_STORED);\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a postingsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","sourceOld":"  public void test() throws Exception {\n    List<String> postingsList = new ArrayList<>();\n    int numTerms = atLeast(300);\n    final int maxTermsPerDoc = TestUtil.nextInt(random(), 10, 20);\n    boolean isSimpleText = \"SimpleText\".equals(TestUtil.getPostingsFormat(\"field\"));\n\n    IndexWriterConfig iwc = newIndexWriterConfig(random(), new MockAnalyzer(random()));\n\n    if ((isSimpleText || iwc.getMergePolicy() instanceof MockRandomMergePolicy) && (TEST_NIGHTLY || RANDOM_MULTIPLIER > 1)) {\n      // Otherwise test can take way too long (> 2 hours)\n      numTerms /= 2;\n    }\n    if (VERBOSE) {\n      System.out.println(\"maxTermsPerDoc=\" + maxTermsPerDoc);\n      System.out.println(\"numTerms=\" + numTerms);\n    }\n    for (int i = 0; i < numTerms; i++) {\n      String term = Integer.toString(i);\n      for (int j = 0; j < i; j++) {\n        postingsList.add(term);\n      }\n    }\n    Collections.shuffle(postingsList, random());\n\n    final ConcurrentLinkedQueue<String> postings = new ConcurrentLinkedQueue<>(postingsList);\n\n    Directory dir = newFSDirectory(createTempDir(\"bagofpositions\"));\n\n    final RandomIndexWriter iw = new RandomIndexWriter(random(), dir, iwc);\n\n    int threadCount = TestUtil.nextInt(random(), 1, 5);\n    if (VERBOSE) {\n      System.out.println(\"config: \" + iw.w.getConfig());\n      System.out.println(\"threadCount=\" + threadCount);\n    }\n    \n    FieldType fieldType = new FieldType(TextField.TYPE_NOT_STORED);\n    if (random().nextBoolean()) {\n      fieldType.setOmitNorms(true);\n    }\n    int options = random().nextInt(3);\n    if (options == 0) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS); // we dont actually need positions\n      fieldType.setStoreTermVectors(true); // but enforce term vectors when we do this so we check SOMETHING\n    } else if (options == 1) {\n      fieldType.setIndexOptions(IndexOptions.DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS);\n    }\n    // else just positions\n\n    Thread[] threads = new Thread[threadCount];\n    final CountDownLatch startingGun = new CountDownLatch(1);\n\n    for(int threadID=0;threadID<threadCount;threadID++) {\n      final Random threadRandom = new Random(random().nextLong());\n      final Document document = new Document();\n      final Field field = new Field(\"field\", \"\", fieldType);\n      document.add(field);\n      threads[threadID] = new Thread() {\n          @Override\n          public void run() {\n            try {\n              startingGun.await();\n              while (!postings.isEmpty()) {\n                StringBuilder text = new StringBuilder();\n                int numTerms = threadRandom.nextInt(maxTermsPerDoc);\n                for (int i = 0; i < numTerms; i++) {\n                  String token = postings.poll();\n                  if (token == null) {\n                    break;\n                  }\n                  text.append(' ');\n                  text.append(token);\n                }\n                field.setStringValue(text.toString());\n                iw.addDocument(document);\n              }\n            } catch (Exception e) {\n              throw new RuntimeException(e);\n            }\n          }\n        };\n      threads[threadID].start();\n    }\n    startingGun.countDown();\n    for(Thread t : threads) {\n      t.join();\n    }\n    \n    iw.forceMerge(1);\n    DirectoryReader ir = iw.getReader();\n    assertEquals(1, ir.leaves().size());\n    LeafReader air = ir.leaves().get(0).reader();\n    Terms terms = air.terms(\"field\");\n    // numTerms-1 because there cannot be a term 0 with 0 postings:\n    assertEquals(numTerms-1, terms.size());\n    TermsEnum termsEnum = terms.iterator();\n    BytesRef term;\n    while ((term = termsEnum.next()) != null) {\n      int value = Integer.parseInt(term.utf8ToString());\n      assertEquals(value, termsEnum.totalTermFreq());\n      // don't really need to check more than this, as CheckIndex\n      // will verify that totalTermFreq == total number of positions seen\n      // from a postingsEnum.\n    }\n    ir.close();\n    iw.close();\n    dir.close();\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["51f5280f31484820499077f41fcdfe92d527d9dc"],"5eb2511ababf862ea11e10761c70ee560cd84510":["d0d579490a72f2e6297eaa648940611234c57cf1","91d86ebcdb45ce6a1b2584e2603f76db47523d0a"],"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["eeea025b4a7a8e8f70426ac4527ef481b3a86b72"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["6613659748fe4411a7dcf85266e55db1f95f7315"],"eeea025b4a7a8e8f70426ac4527ef481b3a86b72":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"2a0f5bb79c600763ffe7b8141df59a3169d31e48":["91d86ebcdb45ce6a1b2584e2603f76db47523d0a","a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c"],"91d86ebcdb45ce6a1b2584e2603f76db47523d0a":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"6613659748fe4411a7dcf85266e55db1f95f7315":["429430d016e19235864e88ee07192080f778033d"],"407687e67faf6e1f02a211ca078d8e3eed631027":["86eb564c1d8d07da8b8cad1508dc1116c2f1ec2b","429430d016e19235864e88ee07192080f778033d"],"429430d016e19235864e88ee07192080f778033d":["74b894c584342b7b718eb81d6318f69cdefc2a70"],"86eb564c1d8d07da8b8cad1508dc1116c2f1ec2b":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"74b894c584342b7b718eb81d6318f69cdefc2a70":["86eb564c1d8d07da8b8cad1508dc1116c2f1ec2b"],"d0d579490a72f2e6297eaa648940611234c57cf1":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"51f5280f31484820499077f41fcdfe92d527d9dc":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82","eeea025b4a7a8e8f70426ac4527ef481b3a86b72"],"a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c":["5eb2511ababf862ea11e10761c70ee560cd84510"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"d0ef034a4f10871667ae75181537775ddcf8ade4":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f"]},"commit2Childs":{"0a773283ef5eab2e9c7136eeb66574a4b7a2dc82":["eeea025b4a7a8e8f70426ac4527ef481b3a86b72","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"5eb2511ababf862ea11e10761c70ee560cd84510":["a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c"],"fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"634f330c54fd3f9f491d52036dc3f40b4f4d8934":["91d86ebcdb45ce6a1b2584e2603f76db47523d0a","d0d579490a72f2e6297eaa648940611234c57cf1"],"eeea025b4a7a8e8f70426ac4527ef481b3a86b72":["fc1e9ddca40a3ddf8b097f2cf1fe2547fe8e384f","4cce5816ef15a48a0bc11e5d400497ee4301dd3b"],"2a0f5bb79c600763ffe7b8141df59a3169d31e48":["ae14298f4eec6d5faee6a149f88ba57d14a6f21a"],"91d86ebcdb45ce6a1b2584e2603f76db47523d0a":["5eb2511ababf862ea11e10761c70ee560cd84510","2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"6613659748fe4411a7dcf85266e55db1f95f7315":["634f330c54fd3f9f491d52036dc3f40b4f4d8934"],"407687e67faf6e1f02a211ca078d8e3eed631027":[],"429430d016e19235864e88ee07192080f778033d":["6613659748fe4411a7dcf85266e55db1f95f7315","407687e67faf6e1f02a211ca078d8e3eed631027"],"86eb564c1d8d07da8b8cad1508dc1116c2f1ec2b":["407687e67faf6e1f02a211ca078d8e3eed631027","74b894c584342b7b718eb81d6318f69cdefc2a70"],"74b894c584342b7b718eb81d6318f69cdefc2a70":["429430d016e19235864e88ee07192080f778033d"],"d0d579490a72f2e6297eaa648940611234c57cf1":["5eb2511ababf862ea11e10761c70ee560cd84510"],"51f5280f31484820499077f41fcdfe92d527d9dc":["0a773283ef5eab2e9c7136eeb66574a4b7a2dc82"],"c9fb5f46e264daf5ba3860defe623a89d202dd87":["51f5280f31484820499077f41fcdfe92d527d9dc"],"4cce5816ef15a48a0bc11e5d400497ee4301dd3b":[],"a9a24bae1e63c3bb5ff2fb47b0119240d840ee7c":["2a0f5bb79c600763ffe7b8141df59a3169d31e48"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["86eb564c1d8d07da8b8cad1508dc1116c2f1ec2b"],"d0ef034a4f10871667ae75181537775ddcf8ade4":["c9fb5f46e264daf5ba3860defe623a89d202dd87"],"ae14298f4eec6d5faee6a149f88ba57d14a6f21a":["d0ef034a4f10871667ae75181537775ddcf8ade4"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["407687e67faf6e1f02a211ca078d8e3eed631027","4cce5816ef15a48a0bc11e5d400497ee4301dd3b","cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}