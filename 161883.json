{"path":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","commits":[{"id":"3a119bbc8703c10faa329ec201c654b3a35a1e3e","date":1328644745,"type":1,"author":"Steven Rowe","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  public Lucene3xStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      if (docStoreOffset != -1 && si.getDocStoreIsCompoundFile()) {\n        d = storeCFSReader = new CompoundFileDirectory(si.dir, \n            IndexFileNames.segmentFileName(segment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION), context, false);\n      } else {\n        storeCFSReader = null;\n      }\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n      if (format > FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","sourceOld":"  public Lucene3xStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      if (docStoreOffset != -1 && si.getDocStoreIsCompoundFile()) {\n        d = storeCFSReader = new CompoundFileDirectory(si.dir, \n            IndexFileNames.segmentFileName(segment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION), context, false);\n      } else {\n        storeCFSReader = null;\n      }\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n      if (format > FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"203d7d3cb7712e10ef33009a63247ae40c302d7a","date":1337798111,"type":3,"author":"Michael McCandless","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  public Lucene3xStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.getDocCount();\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      if (docStoreOffset != -1 && si.getDocStoreIsCompoundFile()) {\n        d = storeCFSReader = new CompoundFileDirectory(si.dir, \n            IndexFileNames.segmentFileName(segment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION), context, false);\n      } else {\n        storeCFSReader = null;\n      }\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n      if (format > FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.getDocCount()) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.getDocCount());\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","sourceOld":"  public Lucene3xStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      if (docStoreOffset != -1 && si.getDocStoreIsCompoundFile()) {\n        d = storeCFSReader = new CompoundFileDirectory(si.dir, \n            IndexFileNames.segmentFileName(segment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION), context, false);\n      } else {\n        storeCFSReader = null;\n      }\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n      if (format > FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"6a917aca07a305ab70118a83e84d931503441271","date":1337826487,"type":3,"author":"Robert Muir","isMerge":false,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  public Lucene3xStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = Lucene3xSegmentInfoFormat.getDocStoreSegment(si);\n    final int docStoreOffset = Lucene3xSegmentInfoFormat.getDocStoreOffset(si);\n    final int size = si.getDocCount();\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      if (docStoreOffset != -1 && Lucene3xSegmentInfoFormat.getDocStoreIsCompoundFile(si)) {\n        d = storeCFSReader = new CompoundFileDirectory(si.dir, \n            IndexFileNames.segmentFileName(segment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION), context, false);\n      } else {\n        storeCFSReader = null;\n      }\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n      if (format > FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.getDocCount()) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.getDocCount());\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","sourceOld":"  public Lucene3xStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.getDocCount();\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      if (docStoreOffset != -1 && si.getDocStoreIsCompoundFile()) {\n        d = storeCFSReader = new CompoundFileDirectory(si.dir, \n            IndexFileNames.segmentFileName(segment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION), context, false);\n      } else {\n        storeCFSReader = null;\n      }\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n      if (format > FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.getDocCount()) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.getDocCount());\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"615ddbd81799980d0fdd95e0238e1c498b6f47b0","date":1338233290,"type":3,"author":"Robert Muir","isMerge":true,"pathNew":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":"  public Lucene3xStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = Lucene3xSegmentInfoFormat.getDocStoreSegment(si);\n    final int docStoreOffset = Lucene3xSegmentInfoFormat.getDocStoreOffset(si);\n    final int size = si.getDocCount();\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      if (docStoreOffset != -1 && Lucene3xSegmentInfoFormat.getDocStoreIsCompoundFile(si)) {\n        d = storeCFSReader = new CompoundFileDirectory(si.dir, \n            IndexFileNames.segmentFileName(segment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION), context, false);\n      } else {\n        storeCFSReader = null;\n      }\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n      if (format > FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.getDocCount()) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.getDocCount());\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","sourceOld":"  public Lucene3xStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = si.getDocStoreSegment();\n    final int docStoreOffset = si.getDocStoreOffset();\n    final int size = si.docCount;\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      if (docStoreOffset != -1 && si.getDocStoreIsCompoundFile()) {\n        d = storeCFSReader = new CompoundFileDirectory(si.dir, \n            IndexFileNames.segmentFileName(segment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION), context, false);\n      } else {\n        storeCFSReader = null;\n      }\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n      if (format > FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.docCount) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.docCount);\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null},{"id":"57ae3024996ccdb3c36c42cb890e1efb37df4ce8","date":1338343651,"type":4,"author":"Robert Muir","isMerge":false,"pathNew":"/dev/null","pathOld":"lucene/core/src/java/org/apache/lucene/codecs/lucene3x/Lucene3xStoredFieldsReader#Lucene3xStoredFieldsReader(Directory,SegmentInfo,FieldInfos,IOContext).mjava","sourceNew":null,"sourceOld":"  public Lucene3xStoredFieldsReader(Directory d, SegmentInfo si, FieldInfos fn, IOContext context) throws IOException {\n    final String segment = Lucene3xSegmentInfoFormat.getDocStoreSegment(si);\n    final int docStoreOffset = Lucene3xSegmentInfoFormat.getDocStoreOffset(si);\n    final int size = si.getDocCount();\n    boolean success = false;\n    fieldInfos = fn;\n    try {\n      if (docStoreOffset != -1 && Lucene3xSegmentInfoFormat.getDocStoreIsCompoundFile(si)) {\n        d = storeCFSReader = new CompoundFileDirectory(si.dir, \n            IndexFileNames.segmentFileName(segment, \"\", Lucene3xCodec.COMPOUND_FILE_STORE_EXTENSION), context, false);\n      } else {\n        storeCFSReader = null;\n      }\n      fieldsStream = d.openInput(IndexFileNames.segmentFileName(segment, \"\", FIELDS_EXTENSION), context);\n      final String indexStreamFN = IndexFileNames.segmentFileName(segment, \"\", FIELDS_INDEX_EXTENSION);\n      indexStream = d.openInput(indexStreamFN, context);\n      \n      format = indexStream.readInt();\n\n      if (format < FORMAT_MINIMUM)\n        throw new IndexFormatTooOldException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n      if (format > FORMAT_CURRENT)\n        throw new IndexFormatTooNewException(indexStream, format, FORMAT_MINIMUM, FORMAT_CURRENT);\n\n      final long indexSize = indexStream.length() - FORMAT_SIZE;\n      \n      if (docStoreOffset != -1) {\n        // We read only a slice out of this shared fields file\n        this.docStoreOffset = docStoreOffset;\n        this.size = size;\n\n        // Verify the file is long enough to hold all of our\n        // docs\n        assert ((int) (indexSize / 8)) >= size + this.docStoreOffset: \"indexSize=\" + indexSize + \" size=\" + size + \" docStoreOffset=\" + docStoreOffset;\n      } else {\n        this.docStoreOffset = 0;\n        this.size = (int) (indexSize >> 3);\n        // Verify two sources of \"maxDoc\" agree:\n        if (this.size != si.getDocCount()) {\n          throw new CorruptIndexException(\"doc counts differ for segment \" + segment + \": fieldsReader shows \" + this.size + \" but segmentInfo shows \" + si.getDocCount());\n        }\n      }\n      numTotalDocs = (int) (indexSize >> 3);\n      success = true;\n    } finally {\n      // With lock-less commits, it's entirely possible (and\n      // fine) to hit a FileNotFound exception above. In\n      // this case, we want to explicitly close any subset\n      // of things that were opened so that we don't have to\n      // wait for a GC to do so.\n      if (!success) {\n        close();\n      }\n    }\n  }\n\n","bugFix":null,"bugIntro":[],"isBuggy":false,"nexts":[],"revCommit":null}],"commit2Parents":{"57ae3024996ccdb3c36c42cb890e1efb37df4ce8":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["3a119bbc8703c10faa329ec201c654b3a35a1e3e","6a917aca07a305ab70118a83e84d931503441271"],"6a917aca07a305ab70118a83e84d931503441271":["203d7d3cb7712e10ef33009a63247ae40c302d7a"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":[],"203d7d3cb7712e10ef33009a63247ae40c302d7a":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8"]},"commit2Childs":{"57ae3024996ccdb3c36c42cb890e1efb37df4ce8":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"615ddbd81799980d0fdd95e0238e1c498b6f47b0":["57ae3024996ccdb3c36c42cb890e1efb37df4ce8"],"6a917aca07a305ab70118a83e84d931503441271":["615ddbd81799980d0fdd95e0238e1c498b6f47b0"],"3a119bbc8703c10faa329ec201c654b3a35a1e3e":["615ddbd81799980d0fdd95e0238e1c498b6f47b0","203d7d3cb7712e10ef33009a63247ae40c302d7a"],"a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85":["3a119bbc8703c10faa329ec201c654b3a35a1e3e"],"203d7d3cb7712e10ef33009a63247ae40c302d7a":["6a917aca07a305ab70118a83e84d931503441271"],"cd5edd1f2b162a5cfa08efd17851a07373a96817":[]},"heads":["cd5edd1f2b162a5cfa08efd17851a07373a96817"],"roots":["a0e7ee9d0d12370e8d2b5ae0a23b6e687e018d85"],"pathCommit":null}